Efficient_JJ methods_NNS for_IN topic_NN model_NN inference_NN on_IN streaming_NN document_NN collections_NNS
Topic_NN models_NNS provide_VBP a_DT powerful_JJ tool_NN for_IN analyzing_VBG large_JJ text_NN collections_NNS by_IN representing_VBG high_JJ dimensional_JJ data_NNS in_IN a_DT low_JJ dimensional_JJ subspace_NN ._.
Fitting_VBG a_DT topic_NN model_NN given_VBN a_DT set_NN of_IN training_NN documents_NNS requires_VBZ approximate_JJ inference_NN techniques_NNS that_WDT are_VBP computationally_RB expensive_JJ ._.
With_IN today_NN 's_POS large-scale_JJ ,_, constantly_RB expanding_VBG document_NN collections_NNS ,_, it_PRP is_VBZ useful_JJ to_TO be_VB able_JJ to_TO infer_VB topic_NN distributions_NNS for_IN new_JJ documents_NNS without_IN retraining_VBG the_DT model_NN ._.
In_IN this_DT paper_NN ,_, we_PRP empirically_RB evaluate_VBP the_DT performance_NN of_IN several_JJ methods_NNS for_IN topic_NN inference_NN in_IN previously_RB unseen_JJ documents_NNS ,_, including_VBG methods_NNS based_VBN on_IN Gibbs_NNP sampling_NN ,_, variational_JJ inference_NN ,_, and_CC a_DT new_JJ method_NN inspired_VBN by_IN text_NN classification_NN ._.
The_DT classification-based_JJ inference_NN method_NN produces_VBZ results_NNS similar_JJ to_TO iterative_JJ inference_NN methods_NNS ,_, but_CC requires_VBZ only_RB a_DT single_JJ matrix_NN multiplication_NN ._.
In_IN addition_NN to_TO these_DT inference_NN methods_NNS ,_, we_PRP present_VBP SparseLDA_NN ,_, an_DT algorithm_NN and_CC data_NN structure_NN for_IN evaluating_VBG Gibbs_NNP sampling_NN distributions_NNS ._.
Empirical_JJ results_NNS indicate_VBP that_IN SparseLDA_NN can_MD be_VB approximately_RB 20_CD times_NNS faster_RBR than_IN traditional_JJ LDA_NN and_CC provide_VB twice_RB the_DT speedup_NN of_IN previously_RB published_VBN fast_JJ sampling_NN methods_NNS ,_, while_IN also_RB using_VBG substantially_RB less_JJR memory_NN ._.
