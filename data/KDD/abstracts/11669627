The_DT offset_VBN tree_NN for_IN learning_VBG with_IN partial_JJ labels_NNS
We_PRP present_VBP an_DT algorithm_NN ,_, called_VBD the_DT Offset_NNP Tree_NNP ,_, for_IN learning_VBG to_TO make_VB decisions_NNS in_IN situations_NNS where_WRB the_DT payoff_NN of_IN only_RB one_CD choice_NN is_VBZ observed_VBN ,_, rather_RB than_IN all_DT choices_NNS ._.
The_DT algorithm_NN reduces_VBZ this_DT setting_NN to_TO binary_JJ classification_NN ,_, allowing_VBG one_CD to_TO reuse_VB any_DT existing_VBG ,_, fully_RB supervised_VBN binary_JJ classification_NN algorithm_NN in_IN this_DT partial_JJ information_NN setting_NN ._.
We_PRP show_VBP that_IN the_DT Offset_NNP Tree_NNP is_VBZ an_DT optimal_JJ reduction_NN to_TO binary_JJ classification_NN ._.
In_IN particular_JJ ,_, it_PRP has_VBZ regret_NN at_IN most_JJS -LRB-_-LRB- k-1_NN -RRB-_-RRB- times_NNS the_DT regret_NN of_IN the_DT binary_JJ classifier_NN it_PRP uses_VBZ -LRB-_-LRB- where_WRB k_NN is_VBZ the_DT number_NN of_IN choices_NNS -RRB-_-RRB- ,_, and_CC no_DT reduction_NN to_TO binary_JJ classification_NN can_MD do_VB better_RBR ._.
This_DT reduction_NN is_VBZ also_RB computationally_RB optimal_JJ ,_, both_DT at_IN training_NN and_CC test_NN time_NN ,_, requiring_VBG just_RB O_NN -LRB-_-LRB- log2_NN k_NN -RRB-_-RRB- work_NN to_TO train_VB on_IN an_DT example_NN or_CC make_VB a_DT prediction_NN ._.
Experiments_NNS with_IN the_DT Offset_NNP Tree_NNP show_VBP that_IN it_PRP generally_RB performs_VBZ better_JJR than_IN several_JJ alternative_JJ approaches_NNS ._.
