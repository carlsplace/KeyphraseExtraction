Large-scale_JJ matrix_NN factorization_NN with_IN distributed_VBN stochastic_JJ gradient_NN descent_NN
We_PRP provide_VBP a_DT novel_JJ algorithm_NN to_TO approximately_RB factor_VB large_JJ matrices_NNS with_IN millions_NNS of_IN rows_NNS ,_, millions_NNS of_IN columns_NNS ,_, and_CC billions_NNS of_IN nonzero_JJ elements_NNS ._.
Our_PRP$ approach_NN rests_VBZ on_IN stochastic_JJ gradient_NN descent_NN -LRB-_-LRB- SGD_NN -RRB-_-RRB- ,_, an_DT iterative_JJ stochastic_JJ optimization_NN algorithm_NN ._.
We_PRP first_RB develop_VBP a_DT novel_JJ ``_`` stratified_JJ ''_'' SGD_NN variant_NN -LRB-_-LRB- SSGD_NN -RRB-_-RRB- that_WDT applies_VBZ to_TO general_JJ loss-minimization_NN problems_NNS in_IN which_WDT the_DT loss_NN function_NN can_MD be_VB expressed_VBN as_IN a_DT weighted_JJ sum_NN of_IN ``_`` stratum_NN losses_NNS ._. ''_''
We_PRP establish_VBP sufficient_JJ conditions_NNS for_IN convergence_NN of_IN SSGD_NNP using_VBG results_NNS from_IN stochastic_JJ approximation_NN theory_NN and_CC regenerative_JJ process_NN theory_NN ._.
We_PRP then_RB specialize_VBP SSGD_NNP to_TO obtain_VB a_DT new_JJ matrix-factorization_NN algorithm_NN ,_, called_VBN DSGD_NNP ,_, that_WDT can_MD be_VB fully_RB distributed_VBN and_CC run_VBN on_IN web-scale_JJ datasets_NNS using_VBG ,_, e.g._FW ,_, MapReduce_NNP ._.
DSGD_NN can_MD handle_VB a_DT wide_JJ variety_NN of_IN matrix_NN factorizations_NNS ._.
We_PRP describe_VBP the_DT practical_JJ techniques_NNS used_VBN to_TO optimize_VB performance_NN in_IN our_PRP$ DSGD_NNP implementation_NN ._.
Experiments_NNS suggest_VBP that_IN DSGD_NN converges_VBZ significantly_RB faster_JJR and_CC has_VBZ better_JJR scalability_NN properties_NNS than_IN alternative_JJ algorithms_NNS ._.
