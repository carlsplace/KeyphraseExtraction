The_DT cost_NN of_IN privacy_NN :_: destruction_NN of_IN data-mining_JJ utility_NN in_IN anonymized_JJ data_NNS publishing_NN
Re-identification_NN is_VBZ a_DT major_JJ privacy_NN threat_NN to_TO public_JJ datasets_NNS containing_VBG individual_JJ records_NNS ._.
Many_JJ privacy_NN protection_NN algorithms_NNS rely_VBP on_IN generalization_NN and_CC suppression_NN of_IN ``_`` quasi-identifier_JJ ''_'' attributes_NNS such_JJ as_IN ZIP_NN code_NN and_CC birthdate_NN ._.
Their_PRP$ objective_NN is_VBZ usually_RB syntactic_JJ sanitization_NN :_: for_IN example_NN ,_, k-anonymity_NN requires_VBZ that_IN each_DT ``_`` quasi-identifier_JJ ''_'' tuple_NN appear_VBP in_IN at_IN least_JJS k_NN records_NNS ,_, while_IN l-diversity_NN requires_VBZ that_IN the_DT distribution_NN of_IN sensitive_JJ attributes_NNS for_IN each_DT quasi-identifier_NN have_VBP high_JJ entropy_NN ._.
The_DT utility_NN of_IN sanitized_VBN data_NNS is_VBZ also_RB measured_VBN syntactically_RB ,_, by_IN the_DT number_NN of_IN generalization_NN steps_NNS applied_VBD or_CC the_DT number_NN of_IN records_NNS with_IN the_DT same_JJ quasi-identifier_NN ._.
In_IN this_DT paper_NN ,_, we_PRP ask_VBP whether_IN generalization_NN and_CC suppression_NN of_IN quasi-identifiers_NNS offer_VBP any_DT benefits_NNS over_IN trivial_JJ sanitization_NN which_WDT simply_RB separates_VBZ quasi-identifiers_NNS from_IN sensitive_JJ attributes_NNS ._.
Previous_JJ work_NN showed_VBD that_IN k-anonymous_NN databases_NNS can_MD be_VB useful_JJ for_IN data_NNS mining_NN ,_, but_CC k-anonymization_NN does_VBZ not_RB guarantee_VB any_DT privacy_NN ._.
By_IN contrast_NN ,_, we_PRP measure_VBP the_DT tradeoff_NN between_IN privacy_NN -LRB-_-LRB- how_WRB much_RB can_MD the_DT adversary_NN learn_VB from_IN the_DT sanitized_VBN records_NNS ?_. -RRB-_-RRB-
and_CC utility_NN ,_, measured_VBN as_IN accuracy_NN of_IN data-mining_JJ algorithms_NNS executed_VBN on_IN the_DT same_JJ sanitized_VBN records_NNS ._.
For_IN our_PRP$ experimental_JJ evaluation_NN ,_, we_PRP use_VBP the_DT same_JJ datasets_NNS from_IN the_DT UCI_NNP machine_NN learning_NN repository_NN as_IN were_VBD used_VBN in_IN previous_JJ research_NN on_IN generalization_NN and_CC suppression_NN ._.
Our_PRP$ results_NNS demonstrate_VBP that_IN even_RB modest_JJ privacy_NN gains_NNS require_VBP almost_RB complete_JJ destruction_NN of_IN the_DT data-mining_JJ utility_NN ._.
In_IN most_JJS cases_NNS ,_, trivial_JJ sanitization_NN provides_VBZ equivalent_JJ utility_NN and_CC better_JJR privacy_NN than_IN k-anonymity_NN ,_, l-diversity_NN ,_, and_CC similar_JJ methods_NNS based_VBN on_IN generalization_NN and_CC suppression_NN ._.
