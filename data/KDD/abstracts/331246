Automatic_NNP multimedia_NNS cross-modal_JJ correlation_NN discovery_NN
Given_VBN an_DT image_NN -LRB-_-LRB- or_CC video_NN clip_NN ,_, or_CC audio_JJ song_NN -RRB-_-RRB- ,_, how_WRB do_VBP we_PRP automatically_RB assign_VBP keywords_NNS to_TO it_PRP ?_.
The_DT general_JJ problem_NN is_VBZ to_TO find_VB correlations_NNS across_IN the_DT media_NNS in_IN a_DT collection_NN of_IN multimedia_NNS objects_NNS like_IN video_NN clips_NNS ,_, with_IN colors_NNS ,_, and\/or_CC motion_NN ,_, and\/or_CC audio_NN ,_, and\/or_CC text_NN scripts_NNS ._.
We_PRP propose_VBP a_DT novel_JJ ,_, graph-based_JJ approach_NN ,_, ``_`` MMG_NNP ''_'' ,_, to_TO discover_VB such_JJ cross-modal_JJ correlations_NNS ._.
Our_PRP$ ``_`` MMG_NNP ''_'' method_NN requires_VBZ no_DT tuning_NN ,_, no_DT clustering_NN ,_, no_DT user-determined_JJ constants_NNS ;_: it_PRP can_MD be_VB applied_VBN to_TO any_DT multimedia_NNS collection_NN ,_, as_RB long_RB as_IN we_PRP have_VBP a_DT similarity_NN function_NN for_IN each_DT medium_NN ;_: and_CC it_PRP scales_NNS linearly_RB with_IN the_DT database_NN size_NN ._.
We_PRP report_VBP auto-captioning_JJ experiments_NNS on_IN the_DT ``_`` standard_JJ ''_'' Corel_NNP image_NN database_NN of_IN 680_CD MB_NN ,_, where_WRB it_PRP outperforms_VBZ domain_NN specific_JJ ,_, fine-tuned_JJ methods_NNS by_IN up_IN to_TO 10_CD percentage_NN points_NNS in_IN captioning_VBG accuracy_NN -LRB-_-LRB- 50_CD %_NN relative_JJ improvement_NN -RRB-_-RRB- ._.
