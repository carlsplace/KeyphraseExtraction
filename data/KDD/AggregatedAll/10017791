Learning_NNP optimal_JJ ranking_NN with_IN tensor_NN factorization_NN for_IN tag_NN recommendation_NN
Tag_NN recommendation_NN is_VBZ the_DT task_NN of_IN predicting_VBG a_DT personalized_JJ list_NN of_IN tags_NNS for_IN a_DT user_NN given_VBN an_DT item_NN ._.
This_DT is_VBZ important_JJ for_IN many_JJ websites_NNS with_IN tagging_VBG capabilities_NNS like_IN last_JJ ._.
fm_NN or_CC delicious_JJ ._.
In_IN this_DT paper_NN ,_, we_PRP propose_VBP a_DT method_NN for_IN tag_NN recommendation_NN based_VBN on_IN tensor_NN factorization_NN -LRB-_-LRB- TF_NN -RRB-_-RRB- ._.
In_IN contrast_NN to_TO other_JJ TF_NN methods_NNS like_IN higher_JJR order_NN singular_JJ value_NN decomposition_NN -LRB-_-LRB- HOSVD_NN -RRB-_-RRB- ,_, our_PRP$ method_NN RTF_NN -LRB-_-LRB- `_`` ranking_NN with_IN tensor_NN factorization_NN '_'' -RRB-_-RRB- directly_RB optimizes_VBZ the_DT factorization_NN model_NN for_IN the_DT best_JJS personalized_VBN ranking_NN ._.
RTF_NNP handles_VBZ missing_VBG values_NNS and_CC learns_VBZ from_IN pairwise_JJ ranking_JJ constraints_NNS ._.
Our_PRP$ optimization_NN criterion_NN for_IN TF_NN is_VBZ motivated_VBN by_IN a_DT detailed_JJ analysis_NN of_IN the_DT problem_NN and_CC of_IN interpretation_NN schemes_NNS for_IN the_DT observed_VBN data_NNS in_IN tagging_VBG systems_NNS ._.
In_IN all_DT ,_, RTF_NNP directly_RB optimizes_VBZ for_IN the_DT actual_JJ problem_NN using_VBG a_DT correct_JJ interpretation_NN of_IN the_DT data_NNS ._.
We_PRP provide_VBP a_DT gradient_NN descent_NN algorithm_NN to_TO solve_VB our_PRP$ optimization_NN problem_NN ._.
We_PRP also_RB provide_VBP an_DT improved_JJ learning_NN and_CC prediction_NN method_NN with_IN runtime_NN complexity_NN analysis_NN for_IN RTF_NNP ._.
The_DT prediction_NN runtime_NN of_IN RTF_NN is_VBZ independent_JJ of_IN the_DT number_NN of_IN observations_NNS and_CC only_RB depends_VBZ on_IN the_DT factorization_NN dimensions_NNS ._.
Besides_IN the_DT theoretical_JJ analysis_NN ,_, we_PRP empirically_RB show_VBP that_IN our_PRP$ method_NN outperforms_VBZ other_JJ state-of-the-art_JJ tag_NN recommendation_NN methods_NNS like_IN FolkRank_NNP ,_, PageRank_NNP and_CC HOSVD_NNP both_CC in_IN quality_NN and_CC prediction_NN runtime_NN ._.
r._JJ Such_JJ sites_NNS contain_VBP large_JJ amounts_NNS of_IN tagged_VBN data_NNS that_WDT can_MD be_VB clustered_VBN on_IN similarity_NN and_CC then_RB used_VBN in_IN information_NN retrieval_NN in_IN social-tagging_JJ systems_NNS ,_, for_IN the_DT formulation_NN of_IN recommendations_NNS in_IN them_PRP =_JJ -_: =[_NN 8,11_CD -RRB-_-RRB- -_: =_JJ -_: ,_, or_CC for_IN the_DT establishment_NN ⋆_NNP The_NNP first_JJ author_NN gratefully_RB acknowledges_VBZ the_DT partial_JJ co-funding_NN of_IN his_PRP$ work_NN through_IN the_DT European_NNP Commission_NNP FP7_NN project_NN MyMedia_NN -LRB-_-LRB- www.mymediaproject.org_NN -RRB-_-RRB- under_IN the_DT grant_NN ag_IN
the_DT user_NN a_DT personalized_JJ list_NN of_IN tags_NNS he_PRP might_MD want_VB to_TO use_VB for_IN this_DT item_NN ._.
Our_PRP$ approach_NN to_TO this_DT problem_NN is_VBZ a_DT pure_JJ statistical_JJ model_NN using_VBG no_DT content_NN information_NN ._.
It_PRP relies_VBZ on_IN a_DT factor_NN model_NN related_VBN to_TO =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: where_WRB the_DT model_NN parameters_NNS are_VBP optimized_VBN for_IN the_DT maximum_NN likelihood_NN estimator_NN for_IN personalized_JJ pairwise_JJ ranking_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
Furthermore_RB ,_, we_PRP use_VBP a_DT smoothing_NN method_NN for_IN reducing_VBG the_DT variance_NN in_IN the_DT factor_NN mod_NN
ithms_NNS ,_, the_DT best_JJS results_NNS ,_, were_VBD achieved_VBN by_IN the_DT FolkRank_NNP algorithm_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ,_, an_DT adaptation_NN of_IN PageRank_NNP for_IN retrieving_VBG information_NN and_CC recommending_VBG tags_NNS in_IN social_JJ tagging_NN systems_NNS ._.
More_RBR recently_RB Rendle_NNP et_FW al._FW =_SYM -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: introduced_VBN RTF_NN -LRB-_-LRB- Ranking_NN with_IN Tensor_NNP Factorization_NNP -RRB-_-RRB- ,_, a_DT method_NN for_IN learning_VBG a_DT tensor_NN factorization_NN model_NN optimized_VBN for_IN the_DT best_JJS personalized_VBN tag_NN ranking_NN ._.
The_DT model_NN also_RB handles_VBZ missing_VBG values_NNS by_IN introd_NN
arization_NN constant_NN corresponding_VBG to_TO σΘ_NN ._.
A_DT more_RBR detailed_JJ discussion_NN of_IN BPR_NNP for_IN the_DT related_JJ problem_NN of_IN item_NN recommendation_NN can_MD be_VB found_VBN in_IN -LRB-_-LRB- 17_CD -RRB-_-RRB- ._.
There_EX also_RB the_DT relationship_NN to_TO AUC_NN optimization_NN -LRB-_-LRB- like_IN in_IN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =--RRB-_NN is_VBZ shown_VBN ._.
4.2_CD BPR_NNP Learning_NNP Algorithm_NNP Secondly_RB ,_, we_PRP derive_VBP a_DT learning_VBG algorithm_NN to_TO optimize_VB the_DT model_NN parameters_NNS Θ_NN of_IN ˆyu_NN ,_, i_FW ,_, t_NN A_NN ,_, tB_NN for_IN BPR-Opt_NN ._.
In_IN general_JJ ,_, optimizing_VBG BPR-Opt_NN is_VBZ very_JJ time_NN consuming_NN ,_, a_DT
a_DT resource_NN into_IN a_DT user_NN 's_POS own_JJ tagging_NN language_NN ,_, producing_VBG more_RBR accurate_JJ predictions_NNS ._.
Tag_NN recommendation_NN is_VBZ probably_RB the_DT best-researched_JJ recommendation_NN scenario_NN in_IN the_DT context_NN of_IN folksonomies_NNS ,_, see_VB e.g._FW =_SYM -_: =[_NN 7,10,12,22,24,25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT scenario_NN therefore_RB allows_VBZ us_PRP the_DT evaluation_NN our_PRP$ approach_NN with_IN respect_NN to_TO previously_RB presented_VBN methods_NNS ._.
Social_NN search_NN ._.
Folksonomies_NNS have_VBP become_VBN important_JJ sources_NNS for_IN content_NN search_NN ,_, since_IN they_PRP a_DT
ure_NN 19.1_CD -RRB-_-RRB- ._.
Symeonidis_NNP et_FW al._FW -LRB-_-LRB- 35_CD -RRB-_-RRB- ,_, for_IN example_NN ,_, proposed_VBD to_TO interpret_VB Y_NN as_IN a_DT sparse_JJ tensor_NN in_IN which_WDT 1_CD indicates_VBZ positive_JJ feedback_NN and_CC 0_CD missing_JJ values_NNS :_: -LCB-_-LRB- 1_CD ,_, -LRB-_-LRB- u_NN ,_, t_NN ,_, r_NN -RRB-_-RRB- ∈_CD Y_NN au_NN ,_, t_NN ,_, r_NN =_JJ 0_CD ,_, else_RB Rendle_NNP et_FW al._FW =_SYM -_: =[_NN 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, on_IN the_DT other_JJ hand_NN ,_, distinguish_VBP between_IN positive\/negative_JJ examples_NNS and_CC missing_VBG values_NNS in_IN order_NN to_TO learn_VB personalized_JJ ranking_NN of_IN tags_NNS -LRB-_-LRB- see_VB Section_NNP 19.4_CD -RRB-_-RRB- ._.
The_DT idea_NN is_VBZ that_IN positive_JJ and_CC negative_JJ example_NN
ed_VBN methods_NNS typically_RB base_VBP their_PRP$ suggestions_NNS on_IN the_DT tagging_VBG history_NN of_IN the_DT given_VBN resource_NN and_CC user_NN ,_, without_IN considering_VBG resource_NN descriptions_NNS ._.
FolkRank_NNP -LRB-_-LRB- Jaschke_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- and_CC Matrix_NNP Factorization_NNP -LRB-_-LRB- =_JJ -_: =_JJ Rendle_FW et_FW al._FW ,_, 2009_CD -_: =--RRB-_NN are_VBP representative_JJ CF_NN methods_NNS for_IN social_JJ tag_NN suggestion_NN ._.
Most_JJS of_IN these_DT methods_NNS suffer_VBP from_IN the_DT cold-start_JJ problem_NN ,_, i.e._FW ,_, they_PRP are_VBP not_RB able_JJ to_TO perform_VB effective_JJ suggestions_NNS for_IN resources_NNS that_IN no_DT one_NN
ecommenders_NNS ._.
A_DT non-personalized_JJ tag_NN recommender_NN predicts_VBZ the_DT same_JJ list_NN of_IN tags_NNS for_IN the_DT same_JJ item_NN --_: i.e._FW it_PRP is_VBZ independent_JJ of_IN the_DT user_NN ._.
There_EX is_VBZ several_JJ work_NN on_IN non-personalized_JJ tag_NN recommenders_NNS ,_, e.g._FW =_JJ -_: =[_NN 2_CD ,_, 13_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, for_IN example_NN ,_, an_DT algorithm_NN based_VBN on_IN a_DT Poisson_NNP Mixture_NNP Model_NNP is_VBZ introduced_VBN ._.
Although_IN the_DT algorithm_NN is_VBZ able_JJ to_TO make_VB predictions_NNS nearly_RB in_IN linear_JJ time_NN ,_, it_PRP is_VBZ not_RB personalized_VBN since_IN the_DT training_NN
s_VBZ a_DT training_NN phase_NN ._.
But_CC training_NN is_VBZ usually_RB done_VBN offline_NN and_CC for_IN online_NN updating_VBG a_DT factorization_NN model_NN there_EX are_VBP very_RB promising_JJ results_NNS for_IN the_DT related_JJ model_NN class_NN of_IN regularized_VBN matrix_NN factorization_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
5.4.2_CD RTF_NN vs._FW HOSVD_FW The_DT prediction_NN quality_NN of_IN RTF_NN is_VBZ clearly_RB superior_JJ to_TO the_DT one_CD of_IN HOSVD_NN -LRB-_-LRB- figure_NN 7_CD -RRB-_-RRB- ._.
On_IN BibSonomy_NNP even_RB with_IN a_DT very_RB small_JJ number_NN of_IN 8_CD dimensions_NNS ,_, RTF_NN achieves_VBZ almost_RB similar_JJ results_NNS
or_CC factorization_NN -LRB-_-LRB- TF_NN -RRB-_-RRB- model_NN and_CC thus_RB can_MD exploit_VB directly_RB the_DT ternary_JJ relationship_NN in_IN tagging_VBG data_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
We_PRP will_MD show_VB that_IN other_JJ learning_VBG methods_NNS for_IN tensor_NN factorization_NN proposed_VBN by_IN now_RB --_: like_IN HOSVD_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: or_CC other_JJ least_JJS square_JJ methods_NNS -LRB-_-LRB- 8_CD -RRB-_-RRB- --_: are_VBP not_RB optimal_JJ for_IN learning_VBG a_DT TF_NN model_NN for_IN tag_NN recommendation_NN ._.
We_PRP will_MD discuss_VB this_DT in_IN detail_NN and_CC propose_VBP a_DT new_JJ optimization_NN criterion_NN and_CC learning_VBG algorithm_NN that_IN
ly_RB ,_, optimizing_VBG -LRB-_-LRB- 8_CD -RRB-_-RRB- directly_RB is_VBZ infeasible_JJ ._.
Instead_RB we_PRP use_VBP gradient_NN descent_NN to_TO minimize_VB the_DT objective_JJ function_NN ._.
As_IN the_DT AUC_NN is_VBZ not_RB differentiable_JJ because_IN of_IN the_DT Heaviside_NNP function_NN ,_, we_PRP replace_VBP H_NN like_IN in_IN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: by_IN the_DT s-shaped_JJ logistic_JJ function_NN s_NN :_: s_NN -LRB-_-LRB- x_NN -RRB-_-RRB- :_: =_JJ 1_CD 1_CD +_CC e_SYM −_CD x_CC The_DT overall_JJ algorithm_NN can_MD be_VB found_VBN in_IN figure_NN 5_CD ._.
This_DT algorithm_NN uses_VBZ a_DT stochastic_JJ update_VB approach_NN ,_, that_WDT means_VBZ for_IN each_DT post_NN -LRB-_-LRB- u_NN ,_, i_LS -RRB-_-RRB- ∈_NNP PS_NNP the_DT mode_NN
nalized_JJ tag_NN recommender_NN outperforms_VBZ any_DT non-personalized_JJ tag_NN recommender_NN ._.
Tensor_NNP Factorization_NNP ._.
While_IN the_DT idea_NN of_IN computing_VBG low_JJ rank_NN approximations_NNS for_IN tensors_NNS has_VBZ already_RB been_VBN used_VBN for_IN many_JJ purposes_NNS =_JJ -_: =[_NN 7_CD ,_, 11_CD ,_, 6_CD -RRB-_-RRB- -_: =_JJ -_: ,_, it_PRP has_VBZ just_RB recently_RB been_VBN applied_VBN for_IN the_DT problem_NN of_IN personalized_JJ tag_NN recommendations_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
In_IN this_DT approach_NN ,_, HOSVD_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- is_VBZ applied_VBN for_IN computing_VBG a_DT low_JJ rank_NN approximation_NN of_IN the_DT original_JJ tensor_NN ,_, thro_NN
ning_JJ error_NN but_CC a_DT large_JJ error_NN over_IN new_JJ \/_: unseen_JJ data_NNS ._.
A_DT common_JJ way_NN to_TO prevent_VB this_DT is_VBZ to_TO regularize_VB the_DT optimization_NN criterion_NN ._.
Regularization_NN is_VBZ very_RB successful_JJ in_IN related_JJ areas_NNS like_IN rating_NN prediction_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
us_PRP can_MD exploit_VB directly_RB the_DT ternary_JJ relationship_NN in_IN tagging_VBG data_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
We_PRP will_MD show_VB that_IN other_JJ learning_VBG methods_NNS for_IN tensor_NN factorization_NN proposed_VBN by_IN now_RB --_: like_IN HOSVD_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- or_CC other_JJ least_JJS square_JJ methods_NNS =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: --_: are_VBP not_RB optimal_JJ for_IN learning_VBG a_DT TF_NN model_NN for_IN tag_NN recommendation_NN ._.
We_PRP will_MD discuss_VB this_DT in_IN detail_NN and_CC propose_VBP a_DT new_JJ optimization_NN criterion_NN and_CC learning_NN algorithm_NN that_WDT directly_RB optimizes_VBZ a_DT TF_NN model_NN for_IN
ed_VBN in_IN O_NN -LRB-_-LRB- iter_NN ·_NNP |_NNP PS_NNP |_CD ·_NN -LRB-_-LRB- kT_NN ·_FW |_FW T_NN |_NN 2_CD +_CC kU_FW ·_FW kI_NN ·_CD kT_NN -RRB-_-RRB- -RRB-_-RRB- ._.
4.4.3_FW Runtime_FW Complexity_NN Comparison_NN We_PRP compare_VBP the_DT runtime_NN complexity_NN of_IN our_PRP$ RTF_NN method_NN to_TO the_DT state-of-the-art_JJ tag_NN recommendation_NN method_NN FolkRank_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Jäschke_NNP et_FW al._FW -LRB-_-LRB- 5_CD -RRB-_-RRB- have_VBP proven_VBN that_IN the_DT runtime_NN complexity_NN for_IN top-n_NN predictions_NNS with_IN FolkRank_NN is_VBZ O_NN -LRB-_-LRB- iter_NN ·_NN -LRB-_-LRB- |_CD S_NN |_NN +_CC |_NN U_NN |_CD +_CC |_CD I_NN |_NN +_CC |_NN T_NN |_CD -RRB-_-RRB- +_CC |_CD T_NN |_FW ·_FW N_NN -RRB-_-RRB- where_WRB iter_NN is_VBZ the_DT number_NN of_IN iterations_NNS ._.
That_DT means_VBZ for_IN
ecommenders_NNS ._.
A_DT non-personalized_JJ tag_NN recommender_NN predicts_VBZ the_DT same_JJ list_NN of_IN tags_NNS for_IN the_DT same_JJ item_NN --_: i.e._FW it_PRP is_VBZ independent_JJ of_IN the_DT user_NN ._.
There_EX is_VBZ several_JJ work_NN on_IN non-personalized_JJ tag_NN recommenders_NNS ,_, e.g._FW =_JJ -_: =[_NN 2_CD ,_, 13_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, for_IN example_NN ,_, an_DT algorithm_NN based_VBN on_IN a_DT Poisson_NNP Mixture_NNP Model_NNP is_VBZ introduced_VBN ._.
Although_IN the_DT algorithm_NN is_VBZ able_JJ to_TO make_VB predictions_NNS nearly_RB in_IN linear_JJ time_NN ,_, it_PRP is_VBZ not_RB personalized_VBN since_IN the_DT training_NN
ecommenders_NNS ._.
A_DT non-personalized_JJ tag_NN recommender_NN predicts_VBZ the_DT same_JJ list_NN of_IN tags_NNS for_IN the_DT same_JJ item_NN --_: i.e._FW it_PRP is_VBZ independent_JJ of_IN the_DT user_NN ._.
There_EX is_VBZ several_JJ work_NN on_IN non-personalized_JJ tag_NN recommenders_NNS ,_, e.g._FW =_JJ -_: =[_NN 2_CD ,_, 13_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, for_IN example_NN ,_, an_DT algorithm_NN based_VBN on_IN a_DT Poisson_NNP Mixture_NNP Model_NNP is_VBZ introduced_VBN ._.
Although_IN the_DT algorithm_NN is_VBZ able_JJ to_TO make_VB predictions_NNS nearly_RB in_IN linear_JJ time_NN ,_, it_PRP is_VBZ not_RB personalized_VBN since_IN the_DT training_NN
ity_NN of_IN Kassel_NNP -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
We_PRP will_MD provide_VB our_PRP$ Last_JJ ._.
fm_FW dataset_FW upon_IN request_NN by_IN email_NN ._.
FolkRank_NNP and_CC PageRank_NNP is_VBZ provided_VBN by_IN the_DT University_NNP of_IN Kassel_NNP within_IN the_DT Nepomuk_NNP project_NN 4_CD ._.
The_DT HOSVD_NN of_IN our_PRP$ experiments_NNS =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ available_JJ as_IN Mathlab_JJ package_NN 5_CD ._.
Our_PRP$ RTF_NN implementation_NN is_VBZ available_JJ upon_IN request_NN by_IN email_NN ._.
4_CD http:\/\/dev.nepomuk.semanticdesktop.org\/download\/_NN 5_CD http:\/\/csmr.ca.sandia.gov\/~tgkolda\/TensorToolbox\/_NN M_NN
ck_NN is_VBZ present_JJ in_IN a_DT tagging_NN system_NN ._.
In_IN this_DT paper_NN we_PRP present_VBP a_DT tag_NN recommender_NN that_WDT is_VBZ based_VBN on_IN a_DT tensor_NN factorization_NN -LRB-_-LRB- TF_NN -RRB-_-RRB- model_NN and_CC thus_RB can_MD exploit_VB directly_RB the_DT ternary_JJ relationship_NN in_IN tagging_VBG data_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP will_MD show_VB that_IN other_JJ learning_VBG methods_NNS for_IN tensor_NN factorization_NN proposed_VBN by_IN now_RB --_: like_IN HOSVD_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- or_CC other_JJ least_JJS square_JJ methods_NNS -LRB-_-LRB- 8_CD -RRB-_-RRB- --_: are_VBP not_RB optimal_JJ for_IN learning_VBG a_DT TF_NN model_NN for_IN tag_NN recommendation_NN ._.
RELATED_NNS WORK_VBP Personalized_VBN Tag_NN Recommenders_NNS ._.
The_DT literature_NN concerning_VBG the_DT problem_NN of_IN personalized_JJ tag_NN recommendation_NN is_VBZ still_RB young_JJ ,_, but_CC has_VBZ nevertheless_RB attracted_VBN significant_JJ attention_NN recently_RB ._.
In_IN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: a_DT comprehensive_JJ evaluation_NN and_CC comparison_NN of_IN several_JJ state-of-the-art_JJ tag_NN recommendation_NN algorithms_NNS in_IN three_CD different_JJ real_JJ world_NN datasets_NNS is_VBZ provided_VBN ._.
The_DT best_JJS results_NNS reported_VBN in_IN terms_NNS of_IN precision_NN
