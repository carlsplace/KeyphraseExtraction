The_DT application_NN of_IN AdaBoost_NNP for_IN distributed_VBN ,_, scalable_JJ and_CC on-line_JJ learning_NN
ensemble_NN approach_NN is_VBZ directly_RB applicable_JJ to_TO the_DT distributed_VBN scenario_NN ._.
Different_JJ models_NNS can_MD be_VB generated_VBN at_IN different_JJ sites_NNS and_CC ultimately_RB aggregated_VBN using_VBG ensemble_NN combining_VBG strategies_NNS ._.
Fan_NN ,_, et_FW al._FW -LRB-_-LRB- =_JJ -_: =_JJ Fan_NN ,_, Stolfo_NNP ,_, &_CC Zhang_NNP ,_, 1999_CD -_: =--RRB-_NN discussed_VBD an_DT AdaBoost-based_JJ ensemble_NN approach_NN in_IN this_DT perspective_NN ._.
Breiman_NNP -LRB-_-LRB- Breiman_NNP ,_, 1999_CD -RRB-_-RRB- considered_VBN Arcing_NNP as_IN a_DT mean_NN to_TO aggregate_JJ multiple_JJ blocks_NNS of_IN data_NNS ,_, especially_RB in_IN on-line_JJ setting_NN ._.
An_DT experim_NN
for_IN large-scale_JJ applications_NNS include_VBP the_DT Bootstrapping-based_JJ BOAT_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- and_CC the_DT Hoeding_NNP -LRB-_-LRB- additive_JJ Cherno_NNP bound_VBD -RRB-_-RRB- -LRB-_-LRB- 13_CD -RRB-_-RRB- tree-based_JJ VFDT_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- and_CC the_DT CVFDT_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
An_DT ensemble-based_JJ approach_NN is_VBZ proposed_VBN in_IN -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
It_PRP works_VBZ using_VBG a_DT Boosting-based_JJ approach_NN to_TO create_VB ensemble_NN of_IN models_NNS ._.
Dierent_JJ trees_NNS are_VBP generated_VBN from_IN dierent_JJ blocks_NNS of_IN data_NNS observed_VBN at_IN dierent_JJ time_NN intervals_NNS ._.
The_DT ensemble_NN classier_NN for_IN the_DT s_NN
n_NN models_NNS ,_, several_JJ generic_JJ remedies_NNS for_IN the_DT above_JJ problems_NNS have_VBP been_VBN proposed_VBN in_IN the_DT literature_NN ._.
They_PRP can_MD be_VB broadly_RB classified_VBN into_IN subsampling_JJ strategies_NNS -LRB-_-LRB- 8,13_CD -RRB-_-RRB- and_CC learning_NN using_VBG committee_NN machines_NNS =_JJ -_: =[_NN 11,3_CD ,_, 4,12,14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Of_IN these_DT two_CD strategies_NNS ,_, the_DT latter_JJ one_NN appears_VBZ to_TO be_VB particularly_RB promising_JJ because_IN -LRB-_-LRB- a_DT -RRB-_-RRB- it_PRP does_VBZ not_RB require_VB any_DT data_NNS to_TO be_VB discarded_VBN when_WRB building_VBG the_DT classifier_NN ,_, and_CC -LRB-_-LRB- b_LS -RRB-_-RRB- it_PRP allows_VBZ for_IN incremental_JJ
bined_VBN using_VBG the_DT proposed_VBN Fourier_NN spectrumbased_JJ approach_NN which_WDT the_DT regular_JJ ensemble_NN learning_NN techniques_NNS do_VBP not_RB offer_VB ._.
We_PRP also_RB performed_VBD experiments_NNS using_VBG an_DT AdaBoost-based_JJ approach_NN suggested_VBD elsewhere_RB =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, we_PRP choose_VBP not_RB to_TO report_VB that_IN since_IN its_PRP$ performance_NN appears_VBZ to_TO be_VB considerably_RB inferior_JJ to_TO those_DT of_IN Bagging_NNP and_CC Arcing_NNP for_IN the_DT data_NNS set_VBP we_PRP use_VBP ._.
Not_RB all_PDT the_DT models_NNS generated_VBN from_IN different_JJ da_NN
of_IN the_DT learning_NN algorithms_NNS -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
Moreover_RB ,_, many_JJ empirical_JJ investigations_NNS have_VBP shown_VBN that_IN ensemble_NN learning_NN methods_NNS often_RB lead_VBP to_TO significant_JJ improvements_NNS across_IN a_DT wide_JJ range_NN of_IN learning_VBG problems_NNS -LRB-_-LRB- 1_LS -RRB-_-RRB- -LRB-_-LRB- 3_LS -RRB-_-RRB- =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =-[_CD 9_CD -RRB-_-RRB- -LRB-_-LRB- 23_CD -RRB-_-RRB- ._.
Volume_NN 7_CD ,_, Issue_NN 2_CD Sort_NN categories_NNS by_IN voting_VBG score_NN Top_NNP k_NN Categories_NNP Page_NNP 105sWe_NN use_NN two_CD approaches_NNS to_TO training_VBG the_DT ensemble_NN classifiers_NNS ._.
The_DT first_JJ is_VBZ to_TO make_VB use_NN of_IN the_DT validation_NN data_NN set_NN whi_NN
mbine_VB the_DT outputs_NNS of_IN a_DT large_JJ number_NN of_IN trees_NNS for_IN producing_VBG the_DT overall_JJ output_NN ._.
Ensemblebased_JJ classification_NN and_CC outlier_NN detection_NN techniques_NNS are_VBP also_RB frequently_RB used_VBN in_IN mining_NN continuous_JJ data_NN streams_NNS =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
Large_JJ ensembles_NNS pose_VBP several_JJ problems_NNS to_TO a_DT data_NN miner_NN ._.
They_PRP are_VBP difficult_JJ to_TO understand_VB and_CC the_DT overall_JJ functional_JJ structure_NN of_IN the_DT ensemble_NN is_VBZ not_RB very_RB ``_`` actionable_JJ ''_'' since_IN it_PRP is_VBZ difficult_JJ to_TO ma_VB
t_NN published_JJ scores_NNS to_TO date_NN ._.
Other_JJ work_NN on_IN parallel_NN boosting_VBG includes_VBZ parallel_JJ boosting_VBG of_IN binary_JJ concepts_NNS using_VBG decision_NN trees_NNS -LRB-_-LRB- Fern_NNP and_CC Givan_NNP 2003_CD -RRB-_-RRB- ,_, and_CC boosting_VBG with_IN disjoint_JJ distributed_VBN data_NN sets_NNS -LRB-_-LRB- =_JJ -_: =_JJ Fan_NN et_FW al._FW 1999_CD -_: =_JJ -_: ;_: Lazarevic_NNP and_CC Obradovic_NNP 2001_CD ;_: Chawla_NNP et_FW al._FW 2002_CD -RRB-_-RRB- ._.
POCA_NN :_: Parallel_JJ Online_JJ Continuous_JJ Arcing_NN The_DT basic_JJ idea_NN behind_IN the_DT POCA_NNP algorithm_NN is_VBZ straightforward_JJ :_: Each_DT exemplar_NN is_VBZ received_VBN from_IN the_DT environment_NN
aller_JJR ,_, more_RBR easily_RB digestible_JJ chunks_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
For_IN classification_NN functions_NNS that_WDT change_VBP in_IN real_JJ time_NN ,_, new_JJ components_NNS can_MD be_VB continually_RB included_VBN in_IN the_DT ensemble_NN in_IN order_NN to_TO keep_VB the_DT model_NN up_IN to_TO date_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
1_LS -RRB-_-RRB- Merging_VBG a_DT Mixture_NN of_IN Domain_NN Experts_NNS :_: We_PRP note_VBP here_RB another_DT potentially_RB useful_JJ application_NN of_IN ensemble_NN classifiers_NNS can_MD be_VB seen_VBN if_IN data_NNS points_NNS are_VBP distributed_VBN across_IN multiple_JJ sites_NNS ,_, where_WRB each_DT site_NN
bine_VB the_DT outputs_NNS of_IN a_DT large_JJ number_NN of_IN trees_NNS for_IN producing_VBG the_DT overall_JJ output_NN ._.
Ensemble-based_JJ classification_NN and_CC outlier_NN detection_NN techniques_NNS are_VBP also_RB frequently_RB used_VBN in_IN mining_NN continuous_JJ data_NN streams_NNS =_JJ -_: =[_NN 96_CD ,_, 249_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Large_JJ ensembles_NNS pose_VBP several_JJ problems_NNS to_TO a_DT data_NN miner_NN ._.
They_PRP are_VBP difficult_JJ to_TO understand_VB and_CC the_DT overall_JJ functional_JJ structure_NN of_IN the_DT ensemble_NN is_VBZ not_RB very_RB ``_`` actionable_JJ ''_'' since_IN it_PRP is_VBZ difficult_JJ to_TO manuall_VB
ts_NNS are_VBP typically_RB more_RBR robust_JJ as_IN compared_VBN to_TO any_DT single_JJ classifier_NN ._.
General_JJ introductions_NNS of_IN ensembles_NNS of_IN classifiers_NNS are_VBP given_VBN in_IN -LRB-_-LRB- Hansen_NNP and_CC Salamon_NNP 1990_CD ;_: Bauer_NNP and_CC Kohavi_NNP 1999_CD ;_: Caruana_NNP et_FW al._FW 2004_CD ;_: =_JJ -_: =_JJ Fan_NN et_FW al._FW 1999_CD -_: =-]_CD ._.
We_PRP call_VBP our_PRP$ approach_NN query_NN enrichment_NN ._.
In_IN general_JJ ,_, query_JJ enrichment_NN consists_VBZ of_IN two_CD major_JJ steps_NNS :_: --_: First_JJ ,_, we_PRP replace_VBP a_DT query_NN by_IN a_DT set_NN of_IN objects_NNS ,_, where_WRB the_DT meanings_NNS of_IN the_DT query_NN are_VBP embedded_VBN in_IN the_DT
fied_VBN ,_, it_PRP is_VBZ too_RB inefficient_JJ to_TO resample_VB the_DT available_JJ data_NNS and_CC learn_VB new_JJ classifiers_NNS ._.
One_CD solution_NN is_VBZ to_TO rely_VB on_IN the_DT user_NN to_TO specify_VB the_DT number_NN of_IN examples_NNS from_IN the_DT input_NN stream_NN for_IN each_DT base_NN learner_NN =_JJ -_: =[_NN 24_CD -RRB-_-RRB- -_: =_JJ -_: ,_, but_CC this_DT approach_NN assumes_VBZ we_PRP know_VBP a_DT great_JJ deal_NN about_IN the_DT structure_NN of_IN the_DT data_NNS stream_NN and_CC is_VBZ likely_JJ to_TO be_VB impractical_JJ for_IN drifting_VBG concepts_NNS ._.
There_EX are_VBP on-line_JJ boosting_VBG algorithms_NNS that_WDT reweight_VBP class_NN
fied_VBN ,_, it_PRP is_VBZ too_RB inefficient_JJ to_TO resample_VB the_DT available_JJ data_NNS and_CC learn_VB new_JJ classifiers_NNS ._.
One_CD solution_NN is_VBZ to_TO rely_VB on_IN the_DT user_NN to_TO specify_VB the_DT number_NN of_IN examples_NNS from_IN the_DT input_NN stream_NN for_IN each_DT base_NN learner_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: ,_, but_CC this_DT approach_NN assumes_VBZ we_PRP know_VBP a_DT great_JJ deal_NN about_IN the_DT structure_NN of_IN the_DT data_NNS stream_NN and_CC is_VBZ likely_JJ to_TO be_VB impractical_JJ for_IN drifting_VBG concepts_NNS ._.
There_EX are_VBP on-line_JJ boosting_VBG algorithms_NNS that_WDT reweight_VBP class_NN
ng_NN when_WRB the_DT training_NN set_NN is_VBZ noisy_JJ ._.
Other_JJ noisy_JJ tolerant_JJ boosting_VBG algorithms_NNS include_VBP AdaBoostReg_NNP -LRB-_-LRB- 7_CD -RRB-_-RRB- ,_, AveBoost2_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- ,_, et_FW al._FW ._.
To_TO satisfy_VB the_DT requirement_NN of_IN rapid_JJ developing_VBG distributed_VBN applications_NNS ,_, Fan_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Lazarevic_NNP -LRB-_-LRB- 10_CD -RRB-_-RRB- -LRB-_-LRB- 11_CD -RRB-_-RRB- proposed_VBD the_DT distributed_VBN versions_NNS of_IN boosting_VBG for_IN parallel_NN and_CC distributed_VBN data_NNS mining_NN ._.
The_DT distributed_VBN boosting_VBG algorithms_NNS put_VBD more_JJR efforts_NNS on_IN the_DT disjoint_JJ partitions_NNS of_IN the_DT d_NN
to_TO weight_VB incoming_JJ instances_NNS for_IN the_DT second_JJ model_NN -LRB-_-LRB- at_IN level_NN one_CD -RRB-_-RRB- ._.
This_DT procedure_NN would_MD be_VB repeated_VBN until_IN the_DT level_NN was_VBD full_JJ ._.
Work_NN of_IN a_DT similar_JJ vein_NN for_IN data_NNS sources_NNS of_IN fixed_JJ size_NN has_VBZ been_VBN reported_VBN in_IN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: who_WP propose_VBP an_DT incremental_JJ version_NN of_IN AdaBoost_NNP ._.
Their_PRP$ method_NN retains_VBZ a_DT fixed-size_JJ window_NN of_IN weak_JJ classifiers_NNS that_WDT contains_VBZ the_DT k_NN most_RBS recently_RB built_VBN classifiers_NNS ._.
This_DT makes_VBZ the_DT method_NN applicable_JJ to_TO l_NN
pooling_VBG knowledge_NN in_IN the_DT form_NN of_IN an_DT ensemble_NN did_VBD increase_VB the_DT chance_NN of_IN hitting_VBG the_DT target_NN ._.
There_EX has_VBZ been_VBN other_JJ research_NN on_IN sharing_NN classifiers_NNS within_IN an_DT institution_NN or_CC among_IN different_JJ institutions_NNS =_JJ -_: =[_NN 9_CD ,_, 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, they_PRP all_DT required_VBD that_IN the_DT data_NNS be_VB from_IN the_DT same_JJ problem_NN domain_NN ,_, or_CC in_IN other_JJ words_NNS ,_, the_DT inducted_VBN classifiers_NNS are_VBP all_DT solving_VBG the_DT same_JJ classification_NN problem_NN ._.
Now_RB the_DT question_NN is_VBZ ,_, if_IN we_PRP are_VBP
-RRB-_-RRB- -RRB-_-RRB- and_CC rule_NN learner_NN -LRB-_-LRB- Clearwater_NNP ,_, Cheng_NNP ,_, Hirsh_NNP and_CC Buchanan_NNP -LRB-_-LRB- 7_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Other_JJ researchers_NNS have_VBP proposed_VBN methods_NNS to_TO parallelize_VB learning_NN algorithms_NNS ,_, for_IN example_NN ,_, parallel_JJ rule_NN induction_NN -LRB-_-LRB- Provost_NNP and_CC Hennesey_NNP =_SYM -_: =[_NN 18_CD -RRB-_-RRB- -_: =--RRB-_NN ,_, decision_NN tree_NN constructor_NN -LRB-_-LRB- Shafer_NNP ,_, Agrawal_NNP and_CC Mehta_NNP -LRB-_-LRB- 21_CD -RRB-_-RRB- and_CC Breiman_NNP and_CC Spector_NNP -LRB-_-LRB- 4_CD -RRB-_-RRB- -RRB-_-RRB- and_CC association_NN rules_NNS -LRB-_-LRB- Agrawal_NNP ,_, Mehta_NNP ,_, Shafer_NNP and_CC Srikant_NNP -LRB-_-LRB- 1_LS -RRB-_-RRB- ,_, and_CC Han_NNP ,_, Karypis_NNP and_CC Kumar_NNP -LRB-_-LRB- 14_CD -RRB-_-RRB- -RRB-_-RRB- ._.
An_DT alternat_NN
ch_NN round_NN ,_, AdaBoost_NNP increases_VBZ the_DT weight_NN of_IN a_DT wrongly_RB classified_VBN training_NN instance_NN and_CC decreases_VBZ that_DT of_IN a_DT correctly_RB predicted_VBN instance_NN ._.
AdaBoost_NNP has_VBZ received_VBN extensive_JJ theoretical_JJ and_CC empirical_JJ study_NN =_JJ -_: =[_NN 12_CD ,_, 15_CD ,_, 19_CD ,_, 20_CD ,_, 16_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Freund_NNP and_CC Schapire_NNP -LRB-_-LRB- alternatively_RB Schapire_NNP ,_, et_NNP al_NNP -LRB-_-LRB- 20_CD -RRB-_-RRB- -RRB-_-RRB- have_VBP shown_VBN an_DT upper_JJ bound_VBN on_IN AdaBoost_NNP 's_POS generalization_NN error_NN ._.
Breiman_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ,_, Friedman_NNP ,_, Hastie_NNP and_CC Tibshirani_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- explain_VBP boosting_VBG from_IN a_DT stati_NN
oposed_VBN methods_NNS to_TO parallelize_VB learning_NN algorithms_NNS ,_, for_IN example_NN ,_, parallel_JJ rule_NN induction_NN -LRB-_-LRB- Provost_NNP and_CC Hennesey_NNP -LRB-_-LRB- 18_CD -RRB-_-RRB- -RRB-_-RRB- ,_, decision_NN tree_NN constructor_NN -LRB-_-LRB- Shafer_NNP ,_, Agrawal_NNP and_CC Mehta_NNP -LRB-_-LRB- 21_CD -RRB-_-RRB- and_CC Breiman_NN and_CC Spector_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =--RRB-_NN and_CC association_NN rules_NNS -LRB-_-LRB- Agrawal_NNP ,_, Mehta_NNP ,_, Shafer_NNP and_CC Srikant_NNP -LRB-_-LRB- 1_LS -RRB-_-RRB- ,_, and_CC Han_NNP ,_, Karypis_NNP and_CC Kumar_NNP -LRB-_-LRB- 14_CD -RRB-_-RRB- -RRB-_-RRB- ._.
An_DT alternative_JJ and_CC general_JJ method_NN is_VBZ to_TO combine_VB multiple_JJ classifiers_NNS in_IN a_DT ``_`` blackbox_NN ''_'' manner_NN ._.
In_IN ``_`` met_VBD
-RRB-_-RRB- -RRB-_-RRB- ._.
Other_JJ researchers_NNS have_VBP proposed_VBN methods_NNS to_TO parallelize_VB learning_NN algorithms_NNS ,_, for_IN example_NN ,_, parallel_JJ rule_NN induction_NN -LRB-_-LRB- Provost_NNP and_CC Hennesey_NNP -LRB-_-LRB- 18_CD -RRB-_-RRB- -RRB-_-RRB- ,_, decision_NN tree_NN constructor_NN -LRB-_-LRB- Shafer_NNP ,_, Agrawal_NNP and_CC Mehta_NNP =_SYM -_: =[_NN 21_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Breiman_NNP and_CC Spector_NNP -LRB-_-LRB- 4_CD -RRB-_-RRB- -RRB-_-RRB- and_CC association_NN rules_NNS -LRB-_-LRB- Agrawal_NNP ,_, Mehta_NNP ,_, Shafer_NNP and_CC Srikant_NNP -LRB-_-LRB- 1_LS -RRB-_-RRB- ,_, and_CC Han_NNP ,_, Karypis_NNP and_CC Kumar_NNP -LRB-_-LRB- 14_CD -RRB-_-RRB- -RRB-_-RRB- ._.
An_DT alternative_JJ and_CC general_JJ method_NN is_VBZ to_TO combine_VB multiple_JJ classifiers_NNS in_IN
e-weighted_JJ ensemble_NN may_MD be_VB more_RBR accurate_JJ than_IN the_DT simply_RB pruned_VBN ensemble_NN ._.
An_DT alternative_JJ method_NN is_VBZ to_TO handle_VB redundancy_NN in_IN the_DT voted_VBN ensemble_NN and_CC only_RB keep_VB some_DT important_JJ components_NNS ._.
Merz_NN and_CC Pazzani_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP used_VBN principle_NN component_NN analysis_NN for_IN this_DT task_NN and_CC it_PRP may_MD be_VB applicable_JJ to_TO the_DT scenarios_NNS of_IN improving_VBG classification_NN efficiency_NN ._.
An_DT additional_JJ method_NN is_VBZ to_TO learn_VB a_DT single_JJ classifier_NN that_WDT has_VBZ si_FW
s_NN task_NN and_CC it_PRP may_MD be_VB applicable_JJ to_TO the_DT scenarios_NNS of_IN improving_VBG classification_NN efficiency_NN ._.
An_DT additional_JJ method_NN is_VBZ to_TO learn_VB a_DT single_JJ classifier_NN that_WDT has_VBZ similar_JJ accuracy_NN to_TO the_DT voted_VBN ensemble_NN ._.
Domingos_NNP =_SYM -_: =[_NN 11_CD -RRB-_-RRB- -_: =_JJ -_: provides_VBZ a_DT meta-learning_JJ method_NN ,_, ``_`` CMM_NNP ''_'' ,_, to_TO learn_VB correlations_NNS of_IN classifiers_NNS in_IN a_DT combined_JJ ensemble_NN and_CC re-learn_VB a_DT single_JJ classifier_NN that_WDT has_VBZ similar_JJ decision_NN boundaries_NNS ._.
Although_IN ,_, his_PRP$ method_NN is_VBZ orig_NN
ase_NN throughput_NN as_RB well_RB ._.
We_PRP have_VBP experimented_VBN with_IN the_DT idea_NN of_IN using_VBG the_DT weight_NN updating_VBG rule_NN as_IN a_DT way_NN of_IN reusing_VBG old_JJ classifiers_NNS ._.
The_DT same_JJ method_NN can_MD also_RB be_VB used_VBN for_IN ``_`` foreign_JJ knowledge_NN import_NN ''_'' ._.
Chan_NNP =_SYM -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: used_VBN meta-learning_JJ to_TO import_VB classifiers_NNS from_IN foreign_JJ sites_NNS to_TO improve_VB accuracy_NN on_IN the_DT local_JJ site_NN ._.
The_DT on-line_JJ AdaBoost_NNP algorithm_NN can_MD be_VB used_VBN in_IN this_DT situation_NN ,_, where_WRB the_DT imported_VBN hypotheses_NNS can_MD be_VB t_NN
ethods_NNS to_TO compose_VB the_DT predictions_NNS of_IN classifiers_NNS trained_VBN from_IN different_JJ partitions_NNS of_IN the_DT training_NN set_NN ._.
A_DT JAVA-based_JJ agent_NN system_NN implementing_VBG meta-learning_NN is_VBZ available_JJ -LRB-_-LRB- Stolfo_NNP ,_, et_FW al_FW -LRB-_-LRB- 22_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Breiman_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: has_VBZ recently_RB proposed_VBN a_DT statistics-based_JJ ``_`` paste_NN vote_NN ''_'' method_NN in_IN which_WDT he_PRP uses_VBZ simple_JJ voting_NN to_TO combine_VB classifiers_NNS trained_VBN from_IN an_DT ``_`` arcbite_NN ''_'' of_IN the_DT original_JJ training_NN set_NN ._.
The_DT advantage_NN of_IN combining_VBG i_FW
riginal_JJ training_NN set_NN ._.
The_DT advantage_NN of_IN combining_VBG is_VBZ that_IN it_PRP is_VBZ algorithm_NN independent_JJ ,_, and_CC can_MD be_VB used_VBN to_TO scale_VB up_RP many_JJ learning_VBG algorithms_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP will_MD study_VB a_DT new_JJ technique_NN using_VBG AdaBoost_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: to_TO combine_VB classifiers_NNS to_TO provide_VB scalable_JJ ,_, distributed_VBN and_CC on-line_JJ inductive_JJ learning_NN ._.
Freund_NNP and_CC Schapire_NNP 's_POS AdaBoost_NNP -LRB-_-LRB- 12_CD -RRB-_-RRB- learns_VBZ a_DT highly_RB accurate_JJ weighted_JJ voting_NN ensemble_NN of_IN many_JJ ``_`` weak_JJ ''_'' hypotheses_NNS
cal_JJ study_NN -LRB-_-LRB- 12_CD ,_, 15_CD ,_, 19_CD ,_, 20_CD ,_, 16_CD ,_, 10_CD -RRB-_-RRB- ._.
Freund_NNP and_CC Schapire_NNP -LRB-_-LRB- alternatively_RB Schapire_NNP ,_, et_NNP al_NNP -LRB-_-LRB- 20_CD -RRB-_-RRB- -RRB-_-RRB- have_VBP shown_VBN an_DT upper_JJ bound_VBN on_IN AdaBoost_NNP 's_POS generalization_NN error_NN ._.
Breiman_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ,_, Friedman_NNP ,_, Hastie_NNP and_CC Tibshirani_NNP =_SYM -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: explain_VB boosting_VBG from_IN a_DT statistical_JJ analysis_NN ._.
Margineantu_NNP and_CC Dietterich_NNP -LRB-_-LRB- 16_CD -RRB-_-RRB- have_VBP studied_VBN methods_NNS to_TO prune_VB the_DT voted_VBN ensemble_NN to_TO increase_VB classification_NN throughput_NN ._.
An_DT empirical_JJ study_NN among_IN AdaBoost_NNP
ch_NN round_NN ,_, AdaBoost_NNP increases_VBZ the_DT weight_NN of_IN a_DT wrongly_RB classified_VBN training_NN instance_NN and_CC decreases_VBZ that_DT of_IN a_DT correctly_RB predicted_VBN instance_NN ._.
AdaBoost_NNP has_VBZ received_VBN extensive_JJ theoretical_JJ and_CC empirical_JJ study_NN =_JJ -_: =[_NN 12_CD ,_, 15_CD ,_, 19_CD ,_, 20_CD ,_, 16_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Freund_NNP and_CC Schapire_NNP -LRB-_-LRB- alternatively_RB Schapire_NNP ,_, et_NNP al_NNP -LRB-_-LRB- 20_CD -RRB-_-RRB- -RRB-_-RRB- have_VBP shown_VBN an_DT upper_JJ bound_VBN on_IN AdaBoost_NNP 's_POS generalization_NN error_NN ._.
Breiman_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ,_, Friedman_NNP ,_, Hastie_NNP and_CC Tibshirani_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- explain_VBP boosting_VBG from_IN a_DT stati_NN
sed_VBN different_JJ methods_NNS to_TO compose_VB the_DT predictions_NNS of_IN classifiers_NNS trained_VBN from_IN different_JJ partitions_NNS of_IN the_DT training_NN set_NN ._.
A_DT JAVA-based_JJ agent_NN system_NN implementing_VBG meta-learning_NN is_VBZ available_JJ -LRB-_-LRB- Stolfo_NNP ,_, et_FW al_FW =_JJ -_: =[_NN 22_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Breiman_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- has_VBZ recently_RB proposed_VBN a_DT statistics-based_JJ ``_`` paste_NN vote_NN ''_'' method_NN in_IN which_WDT he_PRP uses_VBZ simple_JJ voting_NN to_TO combine_VB classifiers_NNS trained_VBN from_IN an_DT ``_`` arcbite_NN ''_'' of_IN the_DT original_JJ training_NN set_NN ._.
The_DT advantage_NN
ch_NN round_NN ,_, AdaBoost_NNP increases_VBZ the_DT weight_NN of_IN a_DT wrongly_RB classified_VBN training_NN instance_NN and_CC decreases_VBZ that_DT of_IN a_DT correctly_RB predicted_VBN instance_NN ._.
AdaBoost_NNP has_VBZ received_VBN extensive_JJ theoretical_JJ and_CC empirical_JJ study_NN =_JJ -_: =[_NN 12_CD ,_, 15_CD ,_, 19_CD ,_, 20_CD ,_, 16_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Freund_NNP and_CC Schapire_NNP -LRB-_-LRB- alternatively_RB Schapire_NNP ,_, et_NNP al_NNP -LRB-_-LRB- 20_CD -RRB-_-RRB- -RRB-_-RRB- have_VBP shown_VBN an_DT upper_JJ bound_VBN on_IN AdaBoost_NNP 's_POS generalization_NN error_NN ._.
Breiman_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ,_, Friedman_NNP ,_, Hastie_NNP and_CC Tibshirani_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- explain_VBP boosting_VBG from_IN a_DT stati_NN
ch_NN round_NN ,_, AdaBoost_NNP increases_VBZ the_DT weight_NN of_IN a_DT wrongly_RB classified_VBN training_NN instance_NN and_CC decreases_VBZ that_DT of_IN a_DT correctly_RB predicted_VBN instance_NN ._.
AdaBoost_NNP has_VBZ received_VBN extensive_JJ theoretical_JJ and_CC empirical_JJ study_NN =_JJ -_: =[_NN 12_CD ,_, 15_CD ,_, 19_CD ,_, 20_CD ,_, 16_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Freund_NNP and_CC Schapire_NNP -LRB-_-LRB- alternatively_RB Schapire_NNP ,_, et_NNP al_NNP -LRB-_-LRB- 20_CD -RRB-_-RRB- -RRB-_-RRB- have_VBP shown_VBN an_DT upper_JJ bound_VBN on_IN AdaBoost_NNP 's_POS generalization_NN error_NN ._.
Breiman_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ,_, Friedman_NNP ,_, Hastie_NNP and_CC Tibshirani_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- explain_VBP boosting_VBG from_IN a_DT stati_NN
en_IN from_IN 1_CD s_NN =_JJ 1_CD 32_CD to_TO 1_CD 256_CD of_IN the_DT entire_JJ training_NN set_NN ._.
At_IN the_DT start_NN of_IN the_DT flow_NN of_IN on-line_JJ data_NNS ,_, we_PRP do_VBP n't_RB have_VB k_NN classifiers_NNS ._.
In_IN this_DT case_NN ,_, we_PRP reuse_VBP all_DT available_JJ classifiers_NNS ._.
We_PRP used_VBD Cohen_NNP 's_POS RIPPER_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: as_IN the_DT ``_`` weak_JJ ''_'' learner_NN ._.
RIPPER_NN provides_VBZ an_DT easy_JJ way_NN to_TO change_VB the_DT distribution_NN of_IN the_DT training_NN set_NN -LRB-_-LRB- and_CC it_PRP is_VBZ publicly_RB available_JJ -RRB-_-RRB- ._.
Since_IN using_VBG the_DT training_NN set_VBN alone_RB usually_RB over-estimates_VBZ the_DT accurac_NN
o_NN solve_VB these_DT problems_NNS ._.
This_DT method_NN typically_RB involves_VBZ direct_JJ modification_NN to_TO standard_JJ algorithms_NNS ,_, such_JJ as_IN decision_NN tree_NN learning_NN -LRB-_-LRB- Utgoff_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- -RRB-_-RRB- and_CC rule_NN learner_NN -LRB-_-LRB- Clearwater_NNP ,_, Cheng_NNP ,_, Hirsh_NNP and_CC Buchanan_NNP =_SYM -_: =[_NN 7_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Other_JJ researchers_NNS have_VBP proposed_VBN methods_NNS to_TO parallelize_VB learning_NN algorithms_NNS ,_, for_IN example_NN ,_, parallel_JJ rule_NN induction_NN -LRB-_-LRB- Provost_NNP and_CC Hennesey_NNP -LRB-_-LRB- 18_CD -RRB-_-RRB- -RRB-_-RRB- ,_, decision_NN tree_NN constructor_NN -LRB-_-LRB- Shafer_NNP ,_, Agrawal_NNP and_CC Mehta_NNP -LRB-_-LRB-
ch_NN round_NN ,_, AdaBoost_NNP increases_VBZ the_DT weight_NN of_IN a_DT wrongly_RB classified_VBN training_NN instance_NN and_CC decreases_VBZ that_DT of_IN a_DT correctly_RB predicted_VBN instance_NN ._.
AdaBoost_NNP has_VBZ received_VBN extensive_JJ theoretical_JJ and_CC empirical_JJ study_NN =_JJ -_: =[_NN 12_CD ,_, 15_CD ,_, 19_CD ,_, 20_CD ,_, 16_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Freund_NNP and_CC Schapire_NNP -LRB-_-LRB- alternatively_RB Schapire_NNP ,_, et_NNP al_NNP -LRB-_-LRB- 20_CD -RRB-_-RRB- -RRB-_-RRB- have_VBP shown_VBN an_DT upper_JJ bound_VBN on_IN AdaBoost_NNP 's_POS generalization_NN error_NN ._.
Breiman_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ,_, Friedman_NNP ,_, Hastie_NNP and_CC Tibshirani_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- explain_VBP boosting_VBG from_IN a_DT stati_NN
Set_VB up_RP Four_CD data_NN sets_NNS -LRB-_-LRB- summarized_VBN in_IN Table_NNP 1_LS -RRB-_-RRB- are_VBP used_VBN in_IN this_DT study_NN ._.
ADULT_NN is_VBZ a_DT population_NN census_NN data_NNS downloaded_VBN from_IN the_DT UCI_NNP machine_NN learning_NN database_NN ._.
WHIRL_NN is_VBZ an_DT information_NN extraction_NN data_NNS set_VBD =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: that_WDT trains_VBZ wrappers_NNS to_TO correctly_RB extract_VB relevant_JJ information_NN from_IN a_DT web_NN page_NN ._.
BOOLEAN_NNP is_VBZ an_DT artificial_JJ boolean_JJ data_NNS set_NN that_WDT has_VBZ 15_CD boolean_JJ variables_NNS ._.
-LRB-_-LRB- The_DT data_NNS item_NN is_VBZ positive_JJ if_IN 4_CD or_CC 5_CD variables_NNS
me_PRP researchers_NNS have_VBP proposed_VBN incremental_JJ learning_VBG techniques_NNS to_TO solve_VB these_DT problems_NNS ._.
This_DT method_NN typically_RB involves_VBZ direct_JJ modification_NN to_TO standard_JJ algorithms_NNS ,_, such_JJ as_IN decision_NN tree_NN learning_NN -LRB-_-LRB- Utgoff_NN =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =--RRB-_NN and_CC rule_NN learner_NN -LRB-_-LRB- Clearwater_NNP ,_, Cheng_NNP ,_, Hirsh_NNP and_CC Buchanan_NNP -LRB-_-LRB- 7_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Other_JJ researchers_NNS have_VBP proposed_VBN methods_NNS to_TO parallelize_VB learning_NN algorithms_NNS ,_, for_IN example_NN ,_, parallel_JJ rule_NN induction_NN -LRB-_-LRB- Provost_NNP and_CC Hennesey_NNP -LRB-_-LRB-
parallel_JJ rule_NN induction_NN -LRB-_-LRB- Provost_NNP and_CC Hennesey_NNP -LRB-_-LRB- 18_CD -RRB-_-RRB- -RRB-_-RRB- ,_, decision_NN tree_NN constructor_NN -LRB-_-LRB- Shafer_NNP ,_, Agrawal_NNP and_CC Mehta_NNP -LRB-_-LRB- 21_CD -RRB-_-RRB- and_CC Breiman_NNP and_CC Spector_NNP -LRB-_-LRB- 4_CD -RRB-_-RRB- -RRB-_-RRB- and_CC association_NN rules_NNS -LRB-_-LRB- Agrawal_NNP ,_, Mehta_NNP ,_, Shafer_NNP and_CC Srikant_NNP =_SYM -_: =[_NN 1_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC Han_NNP ,_, Karypis_NNP and_CC Kumar_NNP -LRB-_-LRB- 14_CD -RRB-_-RRB- -RRB-_-RRB- ._.
An_DT alternative_JJ and_CC general_JJ method_NN is_VBZ to_TO combine_VB multiple_JJ classifiers_NNS in_IN a_DT ``_`` blackbox_NN ''_'' manner_NN ._.
In_IN ``_`` meta-learning_JJ ''_'' -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, Chan_NNP proposed_VBD different_JJ methods_NNS to_TO compose_VB the_DT
ation_NN rules_NNS -LRB-_-LRB- Agrawal_NNP ,_, Mehta_NNP ,_, Shafer_NNP and_CC Srikant_NNP -LRB-_-LRB- 1_LS -RRB-_-RRB- ,_, and_CC Han_NNP ,_, Karypis_NNP and_CC Kumar_NNP -LRB-_-LRB- 14_CD -RRB-_-RRB- -RRB-_-RRB- ._.
An_DT alternative_JJ and_CC general_JJ method_NN is_VBZ to_TO combine_VB multiple_JJ classifiers_NNS in_IN a_DT ``_`` blackbox_NN ''_'' manner_NN ._.
In_IN ``_`` meta-learning_JJ ''_'' =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Chan_NNP proposed_VBD different_JJ methods_NNS to_TO compose_VB the_DT predictions_NNS of_IN classifiers_NNS trained_VBN from_IN different_JJ partitions_NNS of_IN the_DT training_NN set_NN ._.
A_DT JAVA-based_JJ agent_NN system_NN implementing_VBG meta-learning_NN is_VBZ available_JJ -LRB-_-LRB- St_NNP
ived_VBN extensive_JJ theoretical_JJ and_CC empirical_JJ study_NN -LRB-_-LRB- 12_CD ,_, 15_CD ,_, 19_CD ,_, 20_CD ,_, 16_CD ,_, 10_CD -RRB-_-RRB- ._.
Freund_NNP and_CC Schapire_NNP -LRB-_-LRB- alternatively_RB Schapire_NNP ,_, et_NNP al_NNP -LRB-_-LRB- 20_CD -RRB-_-RRB- -RRB-_-RRB- have_VBP shown_VBN an_DT upper_JJ bound_VBN on_IN AdaBoost_NNP 's_POS generalization_NN error_NN ._.
Breiman_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Friedman_NNP ,_, Hastie_NNP and_CC Tibshirani_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- explain_VBP boosting_VBG from_IN a_DT statistical_JJ analysis_NN ._.
Margineantu_NNP and_CC Dietterich_NNP -LRB-_-LRB- 16_CD -RRB-_-RRB- have_VBP studied_VBN methods_NNS to_TO prune_VB the_DT voted_VBN ensemble_NN to_TO increase_VB classification_NN through_IN
ived_VBN extensive_JJ theoretical_JJ and_CC empirical_JJ study_NN -LRB-_-LRB- 12_CD ,_, 15_CD ,_, 19_CD ,_, 20_CD ,_, 16_CD ,_, 10_CD -RRB-_-RRB- ._.
Freund_NNP and_CC Schapire_NNP -LRB-_-LRB- alternatively_RB Schapire_NNP ,_, et_NNP al_NNP -LRB-_-LRB- 20_CD -RRB-_-RRB- -RRB-_-RRB- have_VBP shown_VBN an_DT upper_JJ bound_VBN on_IN AdaBoost_NNP 's_POS generalization_NN error_NN ._.
Breiman_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Friedman_NNP ,_, Hastie_NNP and_CC Tibshirani_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- explain_VBP boosting_VBG from_IN a_DT statistical_JJ analysis_NN ._.
Margineantu_NNP and_CC Dietterich_NNP -LRB-_-LRB- 16_CD -RRB-_-RRB- have_VBP studied_VBN methods_NNS to_TO prune_VB the_DT voted_VBN ensemble_NN to_TO increase_VB classification_NN through_IN
and_CC Hennesey_NNP -LRB-_-LRB- 18_CD -RRB-_-RRB- -RRB-_-RRB- ,_, decision_NN tree_NN constructor_NN -LRB-_-LRB- Shafer_NNP ,_, Agrawal_NNP and_CC Mehta_NNP -LRB-_-LRB- 21_CD -RRB-_-RRB- and_CC Breiman_NNP and_CC Spector_NNP -LRB-_-LRB- 4_CD -RRB-_-RRB- -RRB-_-RRB- and_CC association_NN rules_NNS -LRB-_-LRB- Agrawal_NNP ,_, Mehta_NNP ,_, Shafer_NNP and_CC Srikant_NNP -LRB-_-LRB- 1_LS -RRB-_-RRB- ,_, and_CC Han_NNP ,_, Karypis_NNP and_CC Kumar_NNP =_SYM -_: =[_NN 14_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
An_DT alternative_JJ and_CC general_JJ method_NN is_VBZ to_TO combine_VB multiple_JJ classifiers_NNS in_IN a_DT ``_`` blackbox_NN ''_'' manner_NN ._.
In_IN ``_`` meta-learning_JJ ''_'' -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, Chan_NNP proposed_VBD different_JJ methods_NNS to_TO compose_VB the_DT predictions_NNS of_IN classifiers_NNS traine_VBP
