Knowledge_NN base_NN maintenance_NN using_VBG knowledge_NN gap_NN analysis_NN
As_IN the_DT web_NN and_CC e-business_NN have_VBP proliferated_VBN ,_, the_DT practice_NN of_IN using_VBG customer_NN facing_VBG knowledge_NN bases_NNS to_TO augment_VB customer_NN service_NN and_CC support_NN operations_NNS has_VBZ increased_VBN ._.
This_DT can_MD be_VB a_DT very_RB efficient_JJ ,_, scalable_JJ and_CC cost_NN effective_JJ way_NN to_TO share_VB knowledge_NN ._.
The_DT effectiveness_NN and_CC cost_NN savings_NNS are_VBP proportional_JJ to_TO the_DT utility_NN of_IN the_DT information_NN within_IN the_DT knowledge_NN base_NN and_CC inversely_RB proportional_JJ to_TO the_DT amount_NN of_IN labor_NN required_VBN in_IN maintaining_VBG the_DT knowledge_NN ._.
To_TO address_VB this_DT issue_NN ,_, we_PRP have_VBP developed_VBN an_DT algorithm_NN and_CC methodology_NN to_TO increase_VB the_DT utility_NN of_IN the_DT information_NN within_IN a_DT knowledge_NN base_NN while_IN greatly_RB reducing_VBG the_DT labor_NN required_VBN ._.
In_IN this_DT paper_NN ,_, we_PRP describe_VBP an_DT implementation_NN of_IN an_DT algorithm_NN and_CC methodology_NN for_IN comparing_VBG a_DT knowledge_NN base_NN to_TO a_DT set_NN of_IN problem_NN tickets_NNS to_TO determine_VB which_WDT categories_NNS and_CC subcategories_NNS are_VBP not_RB well_RB addressed_VBN within_IN the_DT knowledge_NN base_NN ._.
We_PRP utilize_VBP text_NN clustering_NN on_IN problem_NN ticket_NN text_NN to_TO determine_VB a_DT set_NN of_IN problem_NN categories_NNS ._.
We_PRP then_RB compare_VBP each_DT knowledge_NN base_NN solution_NN document_NN to_TO each_DT problem_NN category_NN centroid_NN using_VBG a_DT cosine_NN distance_NN metric_NN ._.
The_DT distance_NN between_IN the_DT ``_`` closest_JJS ''_'' solution_NN document_NN and_CC the_DT corresponding_JJ centroid_NN becomes_VBZ the_DT basis_NN of_IN that_DT problem_NN category_NN 's_POS ``_`` knowledge_NN gap_NN ''_'' ._.
Our_PRP$ claim_NN is_VBZ that_IN this_DT gap_NN metric_NN serves_VBZ as_IN a_DT useful_JJ method_NN for_IN quickly_RB and_CC automatically_RB determining_VBG which_WDT problem_NN categories_NNS have_VBP no_DT relevant_JJ solutions_NNS in_IN a_DT knowledge_NN base_NN ._.
We_PRP have_VBP implemented_VBN our_PRP$ approach_NN ,_, and_CC we_PRP present_VBP the_DT results_NNS of_IN performing_VBG a_DT knowledge_NN gap_NN analysis_NN on_IN a_DT set_NN of_IN support_NN center_NN problem_NN tickets_NNS ._.
cy_NN -RRB-_-RRB- non-content-bearing_JJ words_NNS ,_, we_PRP represented_VBD the_DT text_NN data_NNS set_VBN as_IN a_DT vector_NN space_NN model_NN ,_, that_DT is_VBZ ,_, we_PRP represented_VBD each_DT problem_NN ticket_NN as_IN a_DT vector_NN of_IN certain_JJ weighted_JJ frequencies_NNS of_IN the_DT remaining_VBG words_NNS =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP used_VBD the_DT Ixn_NNP weighting_NN scheme_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
This_DT scheme_NN emphasizes_VBZ words_NNS with_IN high_JJ frequency_NN in_IN a_DT document_NN ,_, and_CC normalizes_VBZ each_DT document_NN vector_NN to_TO have_VB unit_NN Euclidean_JJ norm_NN ._.
For_IN example_NN ,_, if_IN a_DT document_NN were_VBD
esented_VBD the_DT text_NN data_NNS set_VBN as_IN a_DT vector_NN space_NN model_NN ,_, that_DT is_VBZ ,_, we_PRP represented_VBD each_DT problem_NN ticket_NN as_IN a_DT vector_NN of_IN certain_JJ weighted_JJ frequencies_NNS of_IN the_DT remaining_VBG words_NNS -LRB-_-LRB- 6_CD -RRB-_-RRB- ._.
We_PRP used_VBD the_DT Ixn_NNP weighting_NN scheme_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT scheme_NN emphasizes_VBZ words_NNS with_IN high_JJ frequency_NN in_IN a_DT document_NN ,_, and_CC normalizes_VBZ each_DT document_NN vector_NN to_TO have_VB unit_NN Euclidean_JJ norm_NN ._.
For_IN example_NN ,_, if_IN a_DT document_NN were_VBD the_DT sentence_NN ,_, ``_`` We_PRP have_VBP no_DT bananas_NNS ,_, we_PRP
oday_NN ''_'' ,_, then_RB the_DT unnormalized_JJ document_NN vector_NN would_MD be_VB -LRB-_-LRB- 2_CD 1_CD -RRB-_-RRB- -LRB-_-LRB- to_TO indicate_VB two_CD bananas_NNS and_CC one_CD today_NN -RRB-_-RRB- ,_, and_CC the_DT normalized_VBN As_IN our_PRP$ primary_JJ tool_NN for_IN automated_JJ classification_NN ,_, we_PRP used_VBD the_DT k-means_NN algorithm_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- 3_LS -RRB-_-RRB- using_VBG a_DT cosine_NN similarity_NN metric_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- to_TO automatically_RB partition_NN the_DT problem_NN tickets_NNS into_IN k_NN disjoint_NN clusters_NNS ._.
The_DT algorithm_NN is_VBZ very_RB fast_JJ and_CC easyto-implement_JJ ._.
See_VB -LRB-_-LRB- 5_CD -RRB-_-RRB- for_IN a_DT detailed_JJ discussion_NN of_IN
e_LS second_JJ case_NN the_DT denominator_NN is_VBZ also_RB set_VBN to_TO 1.0_CD ._.
For_IN this_DT evaluation_NN ,_, our_PRP$ test_NN sets_NNS are_VBP drawn_VBN from_IN three_CD distinct_JJ collections_NNS of_IN test_NN documents_NNS ._.
One_CD of_IN these_DT is_VBZ the_DT well-known_JJ Reuters-21578_NN data_NNS set_VBD =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: containing_VBG 9603_CD training_NN documents_NNS ,_, and_CC the_DT other_JJ two_CD are_VBP helpdesk_JJ problem_NN tickets_NNS from_IN two_CD different_JJ help_NN centers_NNS ._.
For_IN the_DT Reuters_NNP data_NN set_NN ,_, we_PRP made_VBD use_NN of_IN both_CC the_DT existing_VBG classification_NN of_IN the_DT da_NN
''_'' ,_, then_RB the_DT unnormalized_JJ document_NN vector_NN would_MD be_VB -LRB-_-LRB- 2_CD 1_CD -RRB-_-RRB- -LRB-_-LRB- to_TO indicate_VB two_CD bananas_NNS and_CC one_CD today_NN -RRB-_-RRB- ,_, and_CC the_DT normalized_VBN As_IN our_PRP$ primary_JJ tool_NN for_IN automated_JJ classification_NN ,_, we_PRP used_VBD the_DT k-means_NN algorithm_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: using_VBG a_DT cosine_NN similarity_NN metric_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- to_TO automatically_RB partition_NN the_DT problem_NN tickets_NNS into_IN k_NN disjoint_NN clusters_NNS ._.
The_DT algorithm_NN is_VBZ very_RB fast_JJ and_CC easyto-implement_JJ ._.
See_VB -LRB-_-LRB- 5_CD -RRB-_-RRB- for_IN a_DT detailed_JJ discussion_NN of_IN var_NN
or_CC providers_NNS of_IN electronic_JJ customer_NN services_NNS ._.
The_DT first_JJ step_NN in_IN automation_NN of_IN a_DT task_NN is_VBZ to_TO understand_VB it_PRP ,_, and_CC one_CD of_IN the_DT first_JJ steps_NNS in_IN understanding_NN is_VBZ to_TO segment_NN examples_NNS into_IN meaningful_JJ categories_NNS =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT thesis_NN of_IN this_DT paper_NN is_VBZ that_IN there_EX is_VBZ much_JJ value_NN derived_VBN from_IN using_VBG our_PRP$ algorithms_NNS and_CC methodology_NN to_TO automatically_RB leverage_NN the_DT text_NN within_IN problem_NN tickets_NNS to_TO identify_VB areas_NNS and_CC specific_JJ proble_NN
tor_NN would_MD be_VB -LRB-_-LRB- 2_CD 1_CD -RRB-_-RRB- -LRB-_-LRB- to_TO indicate_VB two_CD bananas_NNS and_CC one_CD today_NN -RRB-_-RRB- ,_, and_CC the_DT normalized_VBN As_IN our_PRP$ primary_JJ tool_NN for_IN automated_JJ classification_NN ,_, we_PRP used_VBD the_DT k-means_NN algorithm_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- -LRB-_-LRB- 3_CD -RRB-_-RRB- using_VBG a_DT cosine_NN similarity_NN metric_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: to_TO automatically_RB partition_NN the_DT problem_NN tickets_NNS into_IN k_NN disjoint_NN clusters_NNS ._.
The_DT algorithm_NN is_VBZ very_RB fast_JJ and_CC easyto-implement_JJ ._.
See_VB -LRB-_-LRB- 5_CD -RRB-_-RRB- for_IN a_DT detailed_JJ discussion_NN of_IN various_JJ other_JJ text_NN clustering_NN algorithms_NNS
