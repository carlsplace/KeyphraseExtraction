Active_JJ learning_NN using_VBG adaptive_JJ resampling_NN
rithm_NN and_CC noise-free_JJ data_NNS ._.
Several_JJ variations_NNS of_IN the_DT original_JJ QBC_NN algorithm_NN have_VBP been_VBN proposed_VBN ,_, such_JJ as_IN the_DT Query_NNP by_IN Bagging_NNP and_CC Query_NNP by_IN Boosting_VBG algorithms_NNS -LRB-_-LRB- 29_CD -RRB-_-RRB- and_CC the_DT adaptive_JJ resampling_NN approach_NN =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Saar-Tsechansky_NNP and_CC Provost_NNP apply_VBP active_JJ learning_VBG principles_NNS to_TO obtain_VB better_JJR class_NN -LRB-_-LRB- a_DT posteriori_NN -RRB-_-RRB- probability_NN estimates_NNS -LRB-_-LRB- 31_CD -RRB-_-RRB- ._.
Given_VBN a_DT probabilistic_JJ classifier_NN ,_, the_DT Bootstrap-LV_NN attempts_VBZ to_TO select_VB ˆ_NN
sult_NN in_IN oversimplified_JJ model_NN ._.
4_LS ._.
Selective_JJ sampling_NN methods_NNS In_IN the_DT context_NN of_IN pattern_NN classification_NN systems_NNS selective_JJ sampling_NN techniques_NNS have_VBP been_VBN most_RBS frequently_RB used_VBN in_IN active_JJ learning_NN approaches_VBZ =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB samples_NNS for_IN labeling_NN are_VBP selected_VBN in_IN a_DT dynamic_JJ manner_NN -LRB-_-LRB- one_CD at_IN a_DT time_NN -RRB-_-RRB- ._.
In_IN the_DT research_NN presented_VBN here_RB the_DT static_JJ -LRB-_-LRB- one-step_JJ -RRB-_-RRB- selection_NN techniques_NNS will_MD be_VB examined_VBN ._.
In_IN contrast_NN to_TO the_DT active_JJ se_FW
Sampling_NN :_: The_DT ability_NN to_TO actively_RB select_VB the_DT most_RBS useful_JJ training_NN samples_NNS is_VBZ an_DT important_JJ aspect_NN of_IN building_VBG an_DT efficient_JJ classifier_NN ._.
Boosting_VBG and_CC bagging_VBG are_VBP being_VBG increasingly_RB used_VBN for_IN this_DT purpose_NN =_JJ -_: =[_NN 5,10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Boosting_VBG uses_VBZ all_DT instances_NNS of_IN the_DT datasets_NNS at_IN each_DT iteration_NN ,_, but_CC associates_VBZ a_DT weight_NN for_IN each_DT sample_NN ._.
Bagging_NNP ,_, on_IN the_DT other_JJ hand_NN ,_, takes_VBZ the_DT available_JJ training_NN samples_NNS and_CC generates_VBZ a_DT new_JJ sample_NN se_FW
thm_NN and_CC noise-free_JJ data_NNS ._.
A_DT number_NN of_IN variations_NNS to_TO the_DT original_JJ QBC_NN algorithm_NN have_VBP been_VBN proposed_VBN ,_, such_JJ as_IN the_DT Query_NNP by_IN Bagging_NNP and_CC Query_NNP by_IN Boosting_VBG algorithm_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- and_CC the_DT adaptive_JJ resampling_NN approach_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Active_JJ learning_NN has_VBZ also_RB been_VBN applied_VBN in_IN the_DT multi-view_JJ setting_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ._.
In_IN the_DT multi-view_JJ problem_NN ,_, features_NNS can_MD be_VB partitioned_VBN into_IN subsets_NNS each_DT of_IN which_WDT is_VBZ sufficient_JJ for_IN learning_VBG the_DT mapping_NN from_IN th_DT
ampling_NN -LRB-_-LRB- 8_CD ,_, 9_CD -RRB-_-RRB- ._.
Since_IN its_PRP$ introduction_NN there_EX have_VBP been_VBN many_JJ enhancements_NNS to_TO the_DT basic_JJ algorithm_NN ._.
These_DT include_VBP Weighted_JJ Uncertainty_NN Sampling_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, Error_NN Reduction_NN Sampling_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, and_CC Adaptive_JJ Sampling_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_JJS of_IN these_DT perform_VBP additional_JJ computation_NN to_TO choose_VB a_DT better_JJR sample_NN in_IN order_NN to_TO reduce_VB the_DT number_NN of_IN queries_NNS required_VBN to_TO achieve_VB a_DT given_VBN error_NN rate_NN ._.
The_DT algorithm_NN described_VBN in_IN this_DT paper_NN could_MD be_VB
t_NN applications_NNS ,_, including_VBG combining_VBG active_JJ learning_NN and_CC semi-supervised_JJ learning_NN under_IN boosting_VBG -LRB-_-LRB- COMB_NN -RRB-_-RRB- for_IN spoken_VBN language_NN understanding_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- and_CC adaptive_JJ resampling_VBG approach_NN for_IN image_NN identification_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, there_EX still_RB remains_VBZ some_DT problems_NNS for_IN this_DT type_NN of_IN methods_NNS ._.
•_CD There_EX lacks_VBZ more_RBR theoretical_JJ analysis_NN for_IN these_DT boosting_VBG based_VBN active_JJ learning_NN methods_NNS ._.
There_EX is_VBZ no_DT explicit_JJ consistent_JJ objecti_NNS
oping_VBG with_IN both_DT types_NNS of_IN data_NNS ._.
3_CD Selective_JJ Sampling_NN Methods_NNS In_IN the_DT context_NN of_IN pattern_NN classification_NN systems_NNS selective_JJ sampling_NN techniques_NNS have_VBP been_VBN most_RBS frequently_RB used_VBN in_IN active_JJ learning_NN approaches_VBZ =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB samples_NNS for_IN labeling_NN are_VBP selected_VBN in_IN a_DT dynamic_JJ manner_NN -LRB-_-LRB- one_CD at_IN a_DT time_NN -RRB-_-RRB- ._.
In_IN the_DT research_NN presented_VBN here_RB the_DT preliminary_JJ selection_NN techniques_NNS will_MD be_VB examined_VBN ._.
In_IN contrast_NN to_TO the_DT active_JJ selectio_NN
and_CC noise-free_JJ data_NNS ._.
A_DT number_NN of_IN variations_NNS to_TO the_DT original_JJ QBC_NN algorithm_NN have_VBP been_VBN proposed_VBN ,_, such_JJ as_IN the_DT Query_NNP by_IN Bagging_NNP and_CC Query_NNP by_IN Boosting_VBG algorithm_NN -LRB-_-LRB- AM98_NN -RRB-_-RRB- and_CC the_DT adaptive_JJ resampling_NN approach_NN =_JJ -_: =_JJ -LRB-_-LRB- IAZ00_NN -RRB-_-RRB- -_: =_SYM -_: ._.
Tsechansky_NNP et_FW al._FW -LRB-_-LRB- STP01_NN -RRB-_-RRB- apply_VBP active_JJ learning_VBG principles_NNS to_TO obtain_VB bet23ster_NN class_NN -LRB-_-LRB- A_NN Posteriori_NN -RRB-_-RRB- probability_NN estimates_NNS ._.
Given_VBN a_DT probabilistic_JJ classifier_NN ,_, the_DT Bootstrap-LV_NN attempts_VBZ to_TO choose_VB the_DT d_NN
s_VBZ the_DT investigation_NN of_IN the_DT problem_NN of_IN the_DT sufficient_JJ level_NN of_IN labeled_JJ samples_NNS -LRB-_-LRB- SLLS_NNS -RRB-_-RRB- is_VBZ crucial_JJ for_IN minimizing_VBG the_DT cost_NN of_IN classification_NN ._.
Its_PRP$ existence_NN has_VBZ been_VBN mentioned_VBN by_IN some_DT researchers_NNS -LRB-_-LRB- -LRB-_-LRB- 16_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 45_CD -RRB-_-RRB- -_: =--RRB-_NN but_CC no_DT proper_JJ analysis_NN has_VBZ yet_RB been_VBN done_VBN ._.
There_EX is_VBZ a_DT '_POS catch_NN 22_CD '_'' associated_VBN with_IN this_DT problem_NN :_: on_IN one_CD side_NN we_PRP have_VBP to_TO estimate_VB the_DT sufficient_JJ level_NN based_VBN only_RB on_IN the_DT small_JJ labeled_JJ subset_NN available_JJ b_NN
iction_NN error_NN ._.
Abe_NN and_CC Mamitsuka_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- proposed_VBD two_CD variants_NNS of_IN the_DT QBC_NNP algorithm_NN ,_, query-by-bagging_JJ and_CC query-by-boosting_JJ ._.
Both_DT of_IN them_PRP did_VBD better_RBR than_IN QBC_NNP ,_, C4_NN .5_NN ,_, and_CC boosting_VBG with_IN C4_NN .5_CD ._.
Recent_JJ research_NN =_JJ -_: =[_NN 19_CD ,_, 16_CD ,_, 29_CD ,_, 30_CD -RRB-_-RRB- -_: =_SYM -_: concentrates_VBZ on_IN algorithms_NNS to_TO process_VB data_NNS automatically_RB and_CC algorithms_NNS that_WDT involve_VBP much_RB less_RBR human_JJ expert_NN involvement_NN ._.
A_DT variant_NN of_IN an_DT active_JJ learning_NN algorithm_NN has_VBZ been_VBN suggested_VBN -LRB-_-LRB- 19_CD -RRB-_-RRB- that_WDT learns_VBZ
was_VBD also_RB shown_VBN to_TO be_VB useful_JJ in_IN improving_VBG query_NN answering_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
The_DT authors_NNS demonstrated_VBD how_WRB selective_JJ sampling_NN can_MD be_VB approximately_RB implemented_VBN using_VBG neural_JJ networks_NNS ._.
Another_DT line_NN of_IN recent_JJ research_NN =_JJ -_: =[_NN 21_CD ,_, 18_CD ,_, 37_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: concentrates_VBZ on_IN developing_VBG algorithms_NNS to_TO process_VB data_NNS automatically_RB so_IN that_DT much_RB less_RBR expert_JJ involvement_NN is_VBZ needed_VBN ._.
A_DT variant_NN of_IN an_DT Active_JJ Learning_NNP algorithm_NN has_VBZ been_VBN suggested_VBN in_IN -LRB-_-LRB- 21_CD -RRB-_-RRB- to_TO learn_VB from_IN
In_IN addition_NN ,_, to_TO overcome_VB data_NNS sparseness_NN ,_, which_WDT is_VBZ often_RB a_DT problem_NN for_IN achieving_VBG semantic_JJ descriptions_NNS from_IN data_NNS mining_NN ,_, there_EX is_VBZ the_DT possibility_NN to_TO 4_CD actively_RB collect_VB data_NNS -LRB-_-LRB- also_RB cf._VBP Active_JJ Learning_NNP =_SYM -_: =[_NN 48_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
For_IN instance_NN ,_, data_NNS mining_NN based_VBN on_IN Web_NN resources_NNS to_TO achieve_VB emergent_JJ semantics_NNS uses_VBZ globally_RB available_JJ Web_NN data_NNS and_CC structures_NNS to_TO define_VB new_JJ local_JJ semantics_NNS ._.
Blueprints_NNS for_IN this_DT paradigm_NN are_VBP found_VBN
at_IN active_JJ learning_NN can_MD significantly_RB reduce_VB the_DT amount_NN of_IN labeled_JJ data_NNS required_VBN to_TO build_VB accurate_JJ models_NNS in_IN some_DT e-commerce_NN related_JJ domains_NNS ,_, such_JJ as_IN direct_JJ marketing_NN -LRB-_-LRB- 53_CD -RRB-_-RRB- and_CC identifying_VBG internet_NN ads_NNS =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
4.3_CD Active_JJ feature-value_JJ acquisition_NN In_IN the_DT active_JJ learning_NN setting_NN we_PRP assume_VBP we_PRP have_VBP unlabeled_JJ instances_NNS ,_, and_CC the_DT learner_NN dynamically_RB selects_VBZ the_DT instances_NNS to_TO be_VB labeled_VBN ._.
Consider_VB instead_RB the_DT follo_NN
and_CC their_PRP$ applications_NNS ,_, and_CC have_VBP observed_VBN dramatic_JJ improvements_NNS in_IN the_DT accuracy_NN results_VBZ in_IN many_JJ instances_NNS ._.
These_DT include_VBP financial_JJ portfolio_NN management_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, text_NN categorization_NN -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, active_JJ learning_NN =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC fast_JJ methods_NNS for_IN rule-based_JJ classification_NN and_CC regression_NN -LRB-_-LRB- 27_CD ,_, 28_CD -RRB-_-RRB- ._.
6_CD Conclusion_NN Increased_VBN attention_NN and_CC focus_NN on_IN decision_NN support_NN solutions_NNS using_VBG data_NN mining_NN techniques_NNS has_VBZ refueled_VBN a_DT big_JJ inter_NN
examples_NNS more_JJR Itkely_NNP to_TO be_VB informative_JJ regarding_VBG other_JJ examples_NNS in_IN the_DT space_NN ._.
Note_VB that_DT weight_NN sampling_NN also_RB is_VBZ employed_VBN in_IN the_DT ,_, ldaBoost_NN algorithm_NN -LRB-_-LRB- Freund_NNP and_CC Shapire_NNP ,_, 1996_CD -RRB-_-RRB- on_IN which_WDT Iyengar_NNP et_FW al._FW -LRB-_-LRB- =_JJ -_: =_JJ Iyengar_NNP et_FW al._FW ,_, 2000_CD -_: =--RRB-_NN base_VBP their_PRP$ active_JJ learning_NN approach_NN ._.
Their_PRP$ algorithm_NN results_VBZ in_IN an_DT ensemble_NN of_IN classif3ers_NNS where_WRB weight_NN sampling_NN is_VBZ used_VBN both_DT to_TO select_VB examples_NNS from_IN which_WDT successive_JJ classifiers_NNS in_IN the_DT ensemble_NN are_VBP
their_PRP$ applications_NNS ,_, and_CC have_VBP observed_VBN dramatic_JJ improvements_NNS in_IN the_DT accuracy_NN of_IN results_NNS in_IN many_JJ instances_NNS ._.
These_DT include_VBP financial_JJ portfolio_NN management_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, text_NN categorization_NN -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, active_JJ learning_NN =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC fast_JJ methods_NNS for_IN rule-based_JJ classification_NN and_CC regression_NN -LRB-_-LRB- 27_CD ,_, 28_CD -RRB-_-RRB- ._.
Conclusion_NN Increased_VBD attention_NN and_CC focus_NN on_IN decision_NN support_NN solutions_NNS using_VBG data_NN mining_NN techniques_NNS has_VBZ refueled_VBN interest_NN in_IN c_NN
ampling_NN -LRB-_-LRB- 7_CD ,_, 8_CD -RRB-_-RRB- ._.
Since_IN its_PRP$ introduction_NN there_EX have_VBP been_VBN many_JJ enhancements_NNS to_TO the_DT basic_JJ algorithm_NN ._.
These_DT include_VBP Weighted_JJ Uncertainty_NN Sampling_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, Error_NN Reduction_NN Sampling_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, and_CC Adaptive_JJ Sampling_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_JJS of_IN these_DT perform_VBP additional_JJ computation_NN to_TO choose_VB a_DT better_JJR sample_NN in_IN order_NN to_TO reduce_VB the_DT number_NN of_IN queries_NNS required_VBN to_TO achieve_VB a_DT given_VBN error_NN rate_NN ._.
The_DT algorithm_NN described_VBN in_IN this_DT paper_NN could_MD be_VB
._.
In_IN practice_NN ,_, however_RB ,_, these_DT heuristics_NNS are_VBP computationally_RB expensive_JJ since_IN they_PRP require_VBP that_IN the_DT SVM_NNP is_VBZ trained_VBN twice_RB using_VBG a_DT positive_JJ and_CC negative_JJ label_NN ._.
3.5_CD Reducing_VBG Future_JJ Error_NN Another_DT approach_NN =_JJ -_: =[_NN 8_CD ,_, 12_CD ,_, 15_CD ,_, 21_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ to_TO select_VB examples_NNS that_WDT are_VBP helpful_JJ in_IN building_VBG up_RP confidence_NN in_IN low_JJ future_JJ error_NN ._.
It_PRP is_VBZ impossible_JJ to_TO know_VB the_DT exact_JJ future_JJ error_NN without_IN knowing_VBG the_DT target_NN concept_NN ,_, but_CC approximations_NNS make_VBP this_DT
examples_NNS more_RBR likely_JJ to_TO be_VB informative_JJ regarding_VBG other_JJ examples_NNS in_IN the_DT space_NN ._.
Note_VB that_DT weight_NN sampling_NN also_RB is_VBZ employed_VBN in_IN the_DT AdaBoost_NNP algorithm_NN -LRB-_-LRB- Freund_NNP and_CC Shapire_NNP ,_, 1996_CD -RRB-_-RRB- on_IN which_WDT Iyengar_NNP et_FW al._FW -LRB-_-LRB- =_JJ -_: =_JJ Iyengar_NNP et_FW al._FW ,_, 2000_CD -_: =-]_CD base_NN their_PRP$ active_JJ learning_NN approach_NN ._.
Their_PRP$ algorithm_NN results_VBZ in_IN an_DT ensemble_NN of_IN classifiers_NNS where_WRB weight_NN sampling_NN is_VBZ used_VBN both_DT to_TO select_VB examples_NNS from_IN which_WDT successive_JJ classifiers_NNS in_IN the_DT ensemble_NN are_VBP
at_IN active_JJ learning_NN can_MD significantly_RB reduce_VB the_DT amount_NN of_IN labeled_JJ data_NNS required_VBN to_TO build_VB accurate_JJ models_NNS in_IN some_DT e-commerce_NN related_JJ domains_NNS ,_, such_JJ as_IN direct_JJ marketing_NN -LRB-_-LRB- 53_CD -RRB-_-RRB- and_CC identifying_VBG internet_NN ads_NNS =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
4.3_CD Active_JJ feature-value_JJ acquisition_NN In_IN the_DT active_JJ learning_NN setting_NN we_PRP assume_VBP we_PRP have_VBP unlabeled_JJ instances_NNS ,_, and_CC the_DT learner_NN dynamically_RB selects_VBZ the_DT instances_NNS to_TO be_VB labeled_VBN ._.
Consider_VB instead_RB the_DT follo_NN
learning_VBG and_CC learning_VBG from_IN labeled_JJ and_CC unlabeled_JJ data_NNS have_VBP been_VBN proposed_VBN ._.
In_IN active_JJ learning_VBG new_JJ samples_NNS to_TO be_VB labeled_VBN are_VBP typicallysselected_VBN to_TO maximize_VB the_DT performance_NN of_IN the_DT classifier_NN in_IN some_DT way_NN =_JJ -_: =[_NN 4_CD ,_, 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Some_DT attempts_NNS for_IN learning_VBG with_IN both_CC labeled_JJ and_CC unlabeled_JJ data_NNS sets_NNS have_VBP also_RB been_VBN done_VBN ._.
See_NNP ,_, for_IN example_NN ,_, a_DT review_NN of_IN Seeger_NNP -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
Our_PRP$ goal_NN is_VBZ label_NN textures_NNS with_IN only_RB a_DT small_JJ human_JJ effort_NN ._.
In_IN our_PRP$
m_NN unlabeled_JJ data_NNS ,_, where_WRB an_DT oracle_NN can_MD be_VB queried_VBN for_IN labels_NNS of_IN speci_NN c_NN instances_NNS ,_, with_IN the_DT goal_NN of_IN minimizing_VBG the_DT number_NN of_IN oracle_NN queries_NNS required_VBN ._.
Active_JJ learning_NN has_VBZ been_VBN proposed_VBN in_IN various_JJ forms_NNS =_JJ -_: =[_NN 2_CD ,_, 10_CD ,_, 11_CD ,_, 12_CD ,_, 17_CD ,_, 23_CD ,_, 24_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP will_MD discuss_VB in_IN more_JJR detail_NN the_DT earlier_JJR works_NNS in_IN active_JJ learning_NN related_VBN to_TO the_DT approach_NN used_VBN in_IN this_DT paper_NN ._.
One_CD approach_NN to_TO active_JJ learning_NN is_VBZ uncertainty_NN sampling_NN in_IN which_WDT instances_NNS in_IN the_DT data_NNS
e_LS misclassi_FW ed_FW points_NNS in_IN the_DT training_NN set_NN and_CC then_RB combine_VB the_DT predictions_NNS of_IN several_JJ classi_NNS ers_NNPS ._.
Various_JJ explanations_NNS have_VBP beenput_VBN forth_RB for_IN the_DT classi_JJ cation_NN accuracies_NNS achieved_VBN by_IN these_DT techniques_NNS =_JJ -_: =[_NN 26_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Adaptive_JJ resampling_VBG methods_NNS like_IN boosting_VBG are_VBP also_RB useful_JJ in_IN selecting_VBG relevant_JJ examples_NNS even_RB though_IN their_PRP$ original_JJ goal_NN was_VBD to_TO improve_VB the_DT performance_NN of_IN weak_JJ learning_NN algorithms_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
The_DT applicat_NN
m_NN unlabeled_JJ data_NNS ,_, where_WRB an_DT oracle_NN can_MD be_VB queried_VBN for_IN labels_NNS of_IN speci_NN c_NN instances_NNS ,_, with_IN the_DT goal_NN of_IN minimizing_VBG the_DT number_NN of_IN oracle_NN queries_NNS required_VBN ._.
Active_JJ learning_NN has_VBZ been_VBN proposed_VBN in_IN various_JJ forms_NNS =_JJ -_: =[_NN 2_CD ,_, 10_CD ,_, 11_CD ,_, 12_CD ,_, 17_CD ,_, 23_CD ,_, 24_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP will_MD discuss_VB in_IN more_JJR detail_NN the_DT earlier_JJR works_NNS in_IN active_JJ learning_NN related_VBN to_TO the_DT approach_NN used_VBN in_IN this_DT paper_NN ._.
One_CD approach_NN to_TO active_JJ learning_NN is_VBZ uncertainty_NN sampling_NN in_IN which_WDT instances_NNS in_IN the_DT data_NNS
ly_RB seen_VBN in_IN many_JJ real_JJ life_NN applications_NNS ._.
Active_JJ learning_NN is_VBZ a_DT term_NN coined_VBN to_TO represent_VB methods_NNS where_WRB the_DT learning_NN algorithm_NN assumes_VBZ some_DT control_NN over_IN the_DT subset_NN of_IN the_DT input_NN space_NN used_VBN in_IN the_DT modeling_NN =_JJ -_: =[_NN 9_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, active_JJ learning_NN will_MD mean_VB learning_VBG from_IN unlabeled_JJ data_NNS ,_, where_WRB an_DT oracle_NN can_MD be_VB queried_VBN for_IN labels_NNS of_IN speci_NN c_NN instances_NNS ,_, with_IN the_DT goal_NN of_IN minimizing_VBG the_DT number_NN of_IN oracle_NN queries_NNS requir_VBP
s_NNS are_VBP added_VBN to_TO the_DT training_NN set_NN and_CC a_DT classier_JJR generated_VBN using_VBG this_DT larger_JJR training_NN set_NN ._.
This_DT iterative_JJ process_NN continues_VBZ until_IN the_DT training_NN set_NN reaches_VBZ a_DT speci_FW ed_FW size_NN ._.
This_DT method_NN is_VBZ generalized_VBN in_IN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: by_IN using_VBG two_CD classi_NNS ers_NNPS ,_, the_DT rst_NN one_CD to_TO determine_VB the_DT degree_NN of_IN uncertainty_NN and_CC the_DT second_JJ one_CD to_TO do_VB the_DT classi_NN cation_NN ._.
In_IN this_DT work_NN ,_, a_DT probabilistic_JJ classi_NN er_NN was_VBD chosen_VBN for_IN the_DT rst_NN task_NN based_VBN on_IN e_SYM
asis_NN here_RB has_VBZ been_VBN to_TO prove_VB theoretical_JJ results_NNS about_IN this_DT approach_NN ._.
Adaptive_JJ resampling_NN methods_NNS are_VBP being_VBG increasingly_RB used_VBN to_TO solve_VB the_DT classi_JJ cation_NN problem_NN in_IN various_JJ domains_NNS with_IN high_JJ accuracies_NNS =_JJ -_: =[_NN 15_CD ,_, 7_CD ,_, 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, we_PRP usetheterm_VBP adaptive_JJ resampling_NN to_TO refer_VB to_TO methods_NNS like_IN boosting_VBG that_IN adaptively_RB resample_JJ data_NNS biased_VBN towards_IN the_DT misclassi_FW ed_FW points_NNS in_IN the_DT training_NN set_NN and_CC then_RB combine_VB the_DT predi_NN
orithmic_JJ details_NNS or_CC experimental_JJ results_NNS ._.
A_DT related_JJ application_NN of_IN boosting_VBG to_TO select_VB a_DT subset_NN of_IN labeled_JJ instances_NNS for_IN nearest_JJS neighbor_NN classi_NNS ers_NNPS has_VBZ been_VBN explored_VBN in_IN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
The_DT closest_JJS related_JJ work_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: combines_VBZ the_DT Query_NNP by_IN Committee_NNP approach_NN with_IN bagging_VBG and_CC boosting_VBG techniques_NNS ._.
In_IN this_DT paper_NN we_PRP use_VBP a_DT more_RBR general_JJ formulation_NN that_WDT separates_VBZ the_DT two_CD roles_NNS for_IN a_DT classi_FW er_FW in_IN such_JJ approaches_NNS ._.
This_DT al_FW
are_VBP shown_VBN in_IN Figure_NNP 5_CD ._.
Both_CC ALAR-3-nn_NN and_CC ALAR-vote-E_NN achieve_VBP the_DT accuracy_NN goal_NN with_IN only_RB 8000_CD labeled_VBN instances_NNS ._.
The_DT last_JJ benchmark_NN used_VBN is_VBZ the_DT Mod-Apte_NNP split_NN of_IN the_DT Reuters_NNP data_NNS set_VBP available_JJ from_IN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Only_RB the_DT top_JJ ten_CD categories_NNS are_VBP considered_VBN ._.
For_IN each_DT ofthemwe_NN solve_VB the_DT binary_JJ classi_NN cation_NN problem_NN of_IN being_VBG in_IN or_CC out_IN of_IN that_DT category_NN ._.
Weused_VBD the_DT notion_NN of_IN information_NN gain_NN -LRB-_-LRB- 31_CD -RRB-_-RRB- to_TO select_VB a_DT set_VBN o_NN
m_NN unlabeled_JJ data_NNS ,_, where_WRB an_DT oracle_NN can_MD be_VB queried_VBN for_IN labels_NNS of_IN speci_NN c_NN instances_NNS ,_, with_IN the_DT goal_NN of_IN minimizing_VBG the_DT number_NN of_IN oracle_NN queries_NNS required_VBN ._.
Active_JJ learning_NN has_VBZ been_VBN proposed_VBN in_IN various_JJ forms_NNS =_JJ -_: =[_NN 2_CD ,_, 10_CD ,_, 11_CD ,_, 12_CD ,_, 17_CD ,_, 23_CD ,_, 24_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP will_MD discuss_VB in_IN more_JJR detail_NN the_DT earlier_JJR works_NNS in_IN active_JJ learning_NN related_VBN to_TO the_DT approach_NN used_VBN in_IN this_DT paper_NN ._.
One_CD approach_NN to_TO active_JJ learning_NN is_VBZ uncertainty_NN sampling_NN in_IN which_WDT instances_NNS in_IN the_DT data_NNS
ped_VBN by_IN detecting_VBG diminishing_VBG improvement_NN in_IN the_DT quality_NN of_IN the_DT models_NNS being_VBG built_VBN ._.
Convergence_NN detection_NN has_VBZ been_VBN studied_VBN for_IN the_DT case_NN of_IN random_JJ sampling_NN by_IN estimating_VBG the_DT slope_NN of_IN the_DT learning_NN curve_NN =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT learning_VBG curve_NN maynotbewell_NN behaved_VBD in_IN the_DT active_JJ learning_NN case_NN making_VBG this_DT task_NN more_RBR complicated_JJ ._.
This_DT also_RB makes_VBZ the_DT more_RBR general_JJ problem_NN of_IN determining_VBG a_DT good_JJ schedule_NN for_IN adding_VBG labeled_JJ poin_NN
m_NN unlabeled_JJ data_NNS ,_, where_WRB an_DT oracle_NN can_MD be_VB queried_VBN for_IN labels_NNS of_IN speci_NN c_NN instances_NNS ,_, with_IN the_DT goal_NN of_IN minimizing_VBG the_DT number_NN of_IN oracle_NN queries_NNS required_VBN ._.
Active_JJ learning_NN has_VBZ been_VBN proposed_VBN in_IN various_JJ forms_NNS =_JJ -_: =[_NN 2_CD ,_, 10_CD ,_, 11_CD ,_, 12_CD ,_, 17_CD ,_, 23_CD ,_, 24_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP will_MD discuss_VB in_IN more_JJR detail_NN the_DT earlier_JJR works_NNS in_IN active_JJ learning_NN related_VBN to_TO the_DT approach_NN used_VBN in_IN this_DT paper_NN ._.
One_CD approach_NN to_TO active_JJ learning_NN is_VBZ uncertainty_NN sampling_NN in_IN which_WDT instances_NNS in_IN the_DT data_NNS
echniques_NNS -LRB-_-LRB- 26_CD ,_, 18_CD -RRB-_-RRB- ._.
Adaptive_JJ resampling_VBG methods_NNS like_IN boosting_VBG are_VBP also_RB useful_JJ in_IN selecting_VBG relevant_JJ examples_NNS even_RB though_IN their_PRP$ original_JJ goal_NN was_VBD to_TO improve_VB the_DT performance_NN of_IN weak_JJ learning_NN algorithms_NNS =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT application_NN of_IN boosting_VBG to_TO selective_JJ labeling_NN has_VBZ been_VBN suggested_VBN in_IN -LRB-_-LRB- 14_CD -RRB-_-RRB- without_IN algorithmic_JJ details_NNS or_CC experimental_JJ results_NNS ._.
A_DT related_JJ application_NN of_IN boosting_VBG to_TO select_VB a_DT subset_NN of_IN labeled_JJ inst_NN
relating_VBG importance_NN of_IN selecting_VBG an_DT instance_NN to_TO some_DT measure_NN of_IN error_NN ._.
The_DT adaptive_JJ resampling_JJ literature_NN has_VBZ explored_VBN this_DT and_CC the_DT related_JJ subject_NN of_IN over_IN tting_VBG any_DT noisy_JJ labels_NNS in_IN the_DT training_NN set_NN =_JJ -_: =[_NN 4_CD ,_, 13_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT concern_NN over_IN over_IN tting_NN of_IN noise_NN labels_NNS is_VBZ not_RB directly_RB applicable_JJ in_IN the_DT active_JJ learning_NN context_NN since_IN the_DT error_NN measure_NN is_VBZ computed_VBN using_VBG guessed_VBN labels_NNS ._.
5_CD ._.
CONCLUSIONS_NNS Dealing_VBG with_IN vast_JJ amoun_NN
._.
For_IN each_DT training_NN set_VBD created_VBN ,_, two_CD types_NNS of_IN classi_JJ cation_NN models_NNS are_VBP constructed_VBN and_CC evaluated_VBN against_IN the_DT test_NN set_NN ._.
The_DT rst_NN type_NN of_IN model_NN is_VBZ a_DT decision_NN tree_NN constructed_VBN using_VBG the_DT tree_NN package_NN DMSK_NN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT second_JJ type_NN of_IN model_NN is_VBZ created_VBN using_VBG adaptive_JJ resampling_NN of_IN the_DT training_NN set_VBN with_IN 100_CD DMSK_NN trees_NNS ._.
Figure_NN 2_CD shows_VBZ the_DT results_NNS averaged_VBD over_IN ten_CD experiments_NNS for_IN each_DT partition_NN in_IN the_DT 10-fold_JJ cros_NNS
e_LS misclassi_FW ed_FW points_NNS in_IN the_DT training_NN set_NN and_CC then_RB combine_VB the_DT predictions_NNS of_IN several_JJ classi_NNS ers_NNPS ._.
Various_JJ explanations_NNS have_VBP beenput_VBN forth_RB for_IN the_DT classi_JJ cation_NN accuracies_NNS achieved_VBN by_IN these_DT techniques_NNS =_JJ -_: =[_NN 26_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Adaptive_JJ resampling_VBG methods_NNS like_IN boosting_VBG are_VBP also_RB useful_JJ in_IN selecting_VBG relevant_JJ examples_NNS even_RB though_IN their_PRP$ original_JJ goal_NN was_VBD to_TO improve_VB the_DT performance_NN of_IN weak_JJ learning_NN algorithms_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
The_DT applicat_NN
relating_VBG importance_NN of_IN selecting_VBG an_DT instance_NN to_TO some_DT measure_NN of_IN error_NN ._.
The_DT adaptive_JJ resampling_JJ literature_NN has_VBZ explored_VBN this_DT and_CC the_DT related_JJ subject_NN of_IN over_IN tting_VBG any_DT noisy_JJ labels_NNS in_IN the_DT training_NN set_NN =_JJ -_: =[_NN 4_CD ,_, 13_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT concern_NN over_IN over_IN tting_NN of_IN noise_NN labels_NNS is_VBZ not_RB directly_RB applicable_JJ in_IN the_DT active_JJ learning_NN context_NN since_IN the_DT error_NN measure_NN is_VBZ computed_VBN using_VBG guessed_VBN labels_NNS ._.
5_CD ._.
CONCLUSIONS_NNS Dealing_VBG with_IN vast_JJ amoun_NN
asis_NN here_RB has_VBZ been_VBN to_TO prove_VB theoretical_JJ results_NNS about_IN this_DT approach_NN ._.
Adaptive_JJ resampling_NN methods_NNS are_VBP being_VBG increasingly_RB used_VBN to_TO solve_VB the_DT classi_JJ cation_NN problem_NN in_IN various_JJ domains_NNS with_IN high_JJ accuracies_NNS =_JJ -_: =[_NN 15_CD ,_, 7_CD ,_, 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, we_PRP usetheterm_VBP adaptive_JJ resampling_NN to_TO refer_VB to_TO methods_NNS like_IN boosting_VBG that_IN adaptively_RB resample_JJ data_NNS biased_VBN towards_IN the_DT misclassi_FW ed_FW points_NNS in_IN the_DT training_NN set_NN and_CC then_RB combine_VB the_DT predi_NN
m_NN unlabeled_JJ data_NNS ,_, where_WRB an_DT oracle_NN can_MD be_VB queried_VBN for_IN labels_NNS of_IN speci_NN c_NN instances_NNS ,_, with_IN the_DT goal_NN of_IN minimizing_VBG the_DT number_NN of_IN oracle_NN queries_NNS required_VBN ._.
Active_JJ learning_NN has_VBZ been_VBN proposed_VBN in_IN various_JJ forms_NNS =_JJ -_: =[_NN 2_CD ,_, 10_CD ,_, 11_CD ,_, 12_CD ,_, 17_CD ,_, 23_CD ,_, 24_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP will_MD discuss_VB in_IN more_JJR detail_NN the_DT earlier_JJR works_NNS in_IN active_JJ learning_NN related_VBN to_TO the_DT approach_NN used_VBN in_IN this_DT paper_NN ._.
One_CD approach_NN to_TO active_JJ learning_NN is_VBZ uncertainty_NN sampling_NN in_IN which_WDT instances_NNS in_IN the_DT data_NNS
m_NN unlabeled_JJ data_NNS ,_, where_WRB an_DT oracle_NN can_MD be_VB queried_VBN for_IN labels_NNS of_IN speci_NN c_NN instances_NNS ,_, with_IN the_DT goal_NN of_IN minimizing_VBG the_DT number_NN of_IN oracle_NN queries_NNS required_VBN ._.
Active_JJ learning_NN has_VBZ been_VBN proposed_VBN in_IN various_JJ forms_NNS =_JJ -_: =[_NN 2_CD ,_, 10_CD ,_, 11_CD ,_, 12_CD ,_, 17_CD ,_, 23_CD ,_, 24_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP will_MD discuss_VB in_IN more_JJR detail_NN the_DT earlier_JJR works_NNS in_IN active_JJ learning_NN related_VBN to_TO the_DT approach_NN used_VBN in_IN this_DT paper_NN ._.
One_CD approach_NN to_TO active_JJ learning_NN is_VBZ uncertainty_NN sampling_NN in_IN which_WDT instances_NNS in_IN the_DT data_NNS
ling_NN is_VBZ clearly_RB ine_FW ective_FW since_IN the_DT various_JJ classes_NNS can_MD have_VB very_RB skewed_JJ distributions_NNS in_IN the_DT data_NNS and_CC instances_NNS of_IN the_DT infrequent_JJ classes_NNS can_MD get_VB omitted_VBN from_IN the_DT random_JJ samples_NNS ._.
Strati_FW ed_FW sampling_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ a_DT method_NN developed_VBN to_TO address_VB this_DT problem_NN with_IN random_JJ samples_NNS ._.
The_DT unlabeled_JJ data_NN is_VBZ partitioned_VBN based_VBN on_IN the_DT attributes_NNS of_IN each_DT instance_NN in_IN the_DT data_NNS ._.
Sampling_NN is_VBZ done_VBN separately_RB from_IN each_DT partit_NN
ting_NN ,_, and_CC healthcare_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
Classi_JJ cation_NN techniques_NNS have_VBP beendeveloped_VBN within_IN several_JJ scienti_JJ c_NN disciplines_NNS ,_, including_VBG statistics_NNS ,_, pattern_NN recognition_NN ,_, machine_NN learning_NN ,_, neural_JJ nets_NNS and_CC expert_NN systems_NNS =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT quality_NN and_CC the_DT quantity_NN of_IN training_NN data_NNS used_VBN by_IN these_DT supervised_JJ methods_NNS is_VBZ an_DT important_JJ factor_NN in_IN the_DT prediction_NN accuracy_NN of_IN the_DT derived_VBN models_NNS ._.
In_IN many_JJ applications_NNS ,_, getting_VBG data_NNS with_IN the_DT cl_NN
ider_NN is_VBZ based_VBN on_IN an_DT application_NN to_TO identify_VB images_NNS that_WDT are_VBP Internet_NNP advertisements_NNS -LRB-_-LRB- 6_CD -RRB-_-RRB- ._.
An_DT application_NN to_TO remove_VB advertisements_NNS after_IN identi_JJ cation_NN was_VBD evaluated_VBN using_VBG this_DT benchmark_NN by_IN its_PRP$ donor_NN in_IN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Three_CD of_IN the_DT 1558_CD features_NNS encode_VBP the_DT geometry_NN of_IN the_DT image_NN ._.
Most_JJS of_IN the_DT remaining_VBG binary_JJ features_NNS capture_VBP occurrences_NNS of_IN phrases_NNS in_IN the_DT URL_NN ,_, the_DT anchor_NN text_NN ,_, and_CC text_NN near_IN the_DT anchor_NN text_NN ._.
In_IN this_DT
ly_RB seen_VBN in_IN many_JJ real_JJ life_NN applications_NNS ._.
Active_JJ learning_NN is_VBZ a_DT term_NN coined_VBN to_TO represent_VB methods_NNS where_WRB the_DT learning_NN algorithm_NN assumes_VBZ some_DT control_NN over_IN the_DT subset_NN of_IN the_DT input_NN space_NN used_VBN in_IN the_DT modeling_NN =_JJ -_: =[_NN 9_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, active_JJ learning_NN will_MD mean_VB learning_VBG from_IN unlabeled_JJ data_NNS ,_, where_WRB an_DT oracle_NN can_MD be_VB queried_VBN for_IN labels_NNS of_IN speci_NN c_NN instances_NNS ,_, with_IN the_DT goal_NN of_IN minimizing_VBG the_DT number_NN of_IN oracle_NN queries_NNS requir_VBP
nts_VBZ the_DT results_NNS of_IN applying_VBG our_PRP$ method_NN to_TO benchmarks_NNS in_IN various_JJ domains_NNS ._.
The_DT rst_NN benchmark_NN internet-ads_NNS we_PRP will_MD consider_VB is_VBZ based_VBN on_IN an_DT application_NN to_TO identify_VB images_NNS that_WDT are_VBP Internet_NNP advertisements_NNS =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
An_DT application_NN to_TO remove_VB advertisements_NNS after_IN identi_JJ cation_NN was_VBD evaluated_VBN using_VBG this_DT benchmark_NN by_IN its_PRP$ donor_NN in_IN -LRB-_-LRB- 19_CD -RRB-_-RRB- ._.
Three_CD of_IN the_DT 1558_CD features_NNS encode_VBP the_DT geometry_NN of_IN the_DT image_NN ._.
Most_JJS of_IN the_DT remainin_NN
n_NN earlier_RB works_VBZ -LRB-_-LRB- 24_CD -RRB-_-RRB- ._.
An_DT internally_RB available_JJ decision_NN tree_NN package_NN customized_VBN for_IN text_NN applications_NNS was_VBD used_VBN for_IN this_DT benchmark_NN ._.
As_IN is_VBZ customary_JJ with_IN this_DT benchmark_NN ,_, we_PRP use_VBP the_DT micro-average_JJ measure_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, in_IN which_WDT the_DT confusion_NN matrices_NNS for_IN the_DT ten_CD categories_NNS are_VBP added_VBN and_CC overall_JJ precision_NN and_CC recall_NN computed_VBD ._.
Ten_CD random_JJ runs_NNS were_VBD performed_VBN and_CC the_DT micro-average_NN of_IN the_DT arithmetic_NN mean_NN of_IN recall_NN and_CC
et_CC available_JJ from_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Only_RB the_DT top_JJ ten_CD categories_NNS are_VBP considered_VBN ._.
For_IN each_DT ofthemwe_NN solve_VB the_DT binary_JJ classi_NN cation_NN problem_NN of_IN being_VBG in_IN or_CC out_IN of_IN that_DT category_NN ._.
Weused_VBD the_DT notion_NN of_IN information_NN gain_NN =_JJ -_: =[_NN 31_CD -RRB-_-RRB- -_: =_SYM -_: to_TO select_VB a_DT set_NN of_IN 500_CD attributes_NNS for_IN each_DT of_IN the_DT ten_CD binary_JJ classi_NN cation_NN problems_NNS ._.
sAverage_NN of_IN Recall_VB and_CC Precision_NN -LRB-_-LRB- percentage_NN -RRB-_-RRB- 95_CD 90_CD 85_CD 80_CD 75_CD 70_CD 65_CD 60_CD −_CD o_NN −_FW ALAR_FW −_FW oracle_FW −_FW ._.
−_FW ALAR_FW −_FW vote_NN −_NNP E_NNP −_NNP \*_SYM −_FW ALAR_FW −_FW 3_CD −_CD nn_NN
asis_NN here_RB has_VBZ been_VBN to_TO prove_VB theoretical_JJ results_NNS about_IN this_DT approach_NN ._.
Adaptive_JJ resampling_NN methods_NNS are_VBP being_VBG increasingly_RB used_VBN to_TO solve_VB the_DT classi_JJ cation_NN problem_NN in_IN various_JJ domains_NNS with_IN high_JJ accuracies_NNS =_JJ -_: =[_NN 15_CD ,_, 7_CD ,_, 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, we_PRP usetheterm_VBP adaptive_JJ resampling_NN to_TO refer_VB to_TO methods_NNS like_IN boosting_VBG that_IN adaptively_RB resample_JJ data_NNS biased_VBN towards_IN the_DT misclassi_FW ed_FW points_NNS in_IN the_DT training_NN set_NN and_CC then_RB combine_VB the_DT predi_NN
Yorktown_NNP Heights_NNP ,_, NY_NNP 10598_CD ,_, USA_NN tzhang@watson.ibm.com_NN 1_CD ._.
INTRODUCTION_NN Supervised_VBD learning_NN methods_NNS are_VBP being_VBG used_VBN to_TO build_VB classication_NN models_NNS in_IN various_JJ domains_NNS like_IN nance_NN ,_, marketing_NN ,_, and_CC healthcare_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Classi_JJ cation_NN techniques_NNS have_VBP beendeveloped_VBN within_IN several_JJ scienti_JJ c_NN disciplines_NNS ,_, including_VBG statistics_NNS ,_, pattern_NN recognition_NN ,_, machine_NN learning_NN ,_, neural_JJ nets_NNS and_CC expert_NN systems_NNS -LRB-_-LRB- 30_CD -RRB-_-RRB- ._.
The_DT quality_NN and_CC th_DT
