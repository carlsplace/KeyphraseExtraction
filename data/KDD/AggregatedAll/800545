Non-linear_JJ dimensionality_NN reduction_NN techniques_NNS for_IN classification_NN and_CC visualization_NN
In_IN this_DT paper_NN we_PRP address_VBP the_DT issue_NN of_IN using_VBG local_JJ embeddings_NNS for_IN data_NNS visualization_NN in_IN two_CD and_CC three_CD dimensions_NNS ,_, and_CC for_IN classification_NN ._.
We_PRP advocate_VBP their_PRP$ use_NN on_IN the_DT basis_NN that_IN they_PRP provide_VBP an_DT efficient_JJ mapping_NN procedure_NN from_IN the_DT original_JJ dimension_NN of_IN the_DT data_NNS ,_, to_TO a_DT lower_JJR intrinsic_JJ dimension_NN ._.
We_PRP depict_VBP how_WRB they_PRP can_MD accurately_RB capture_VB the_DT user_NN 's_POS perception_NN of_IN similarity_NN in_IN high-dimensional_JJ data_NNS for_IN visualization_NN purposes_NNS ._.
Moreover_RB ,_, we_PRP exploit_VBP the_DT low-dimensional_JJ mapping_NN provided_VBN by_IN these_DT embeddings_NNS ,_, to_TO develop_VB new_JJ classification_NN techniques_NNS ,_, and_CC we_PRP show_VBP experimentally_RB that_IN the_DT classification_NN accuracy_NN is_VBZ comparable_JJ -LRB-_-LRB- albeit_IN using_VBG fewer_JJR dimensions_NNS -RRB-_-RRB- to_TO a_DT number_NN of_IN other_JJ classification_NN procedures_NNS ._.
s_NN and_CC their_PRP$ good_JJ reconstruction_NN is_VBZ not_RB crucial_JJ ._.
In_IN contrast_NN ,_, we_PRP found_VBD that_IN in_IN cases_NNS of_IN disjoint_JJ manifolds_NNS it_PRP is_VBZ preferable_JJ to_TO apply_VB LLE_NNP on_IN one_CD connected_JJ component_NN and_CC then_RB map_VB the_DT remaining_VBG data_NNS ._.
In_IN -LRB-_-LRB- =_JJ -_: =_JJ Vlachos_NNP et_FW al._FW 2002_CD -_: =--RRB-_NN ,_, an_DT alternative_NN to_TO connect_VB the_DT graph_NN of_IN neighbors_NNS is_VBZ proposed_VBN ._.
It_PRP consists_VBZ of_IN using_VBG k\/2_NN nearest_IN neighbors_NNS and_CC also_RB k\/2_VBP farthest_JJS neighbors_NNS in_IN order_NN to_TO gather_VB the_DT clusters_NNS in_IN the_DT same_JJ global_JJ coordinat_NN
e_LS vectors_NNS ._.
Several_JJ reduction_NN techniques_NNS were_VBD proposed_VBN for_IN time-series_NNS -LRB-_-LRB- 2_CD ,_, 20_CD ,_, 30_CD -RRB-_-RRB- ,_, image_NN -LRB-_-LRB- 17_CD ,_, 26_CD ,_, 34_CD ,_, 43_CD -RRB-_-RRB- ,_, and_CC document_NN data_NNS -LRB-_-LRB- 11_CD --_: 13_CD -RRB-_-RRB- ._.
And_CC recently_RB a_DT nonlinear_JJ dimensionality_NN reduction_NN was_VBD proposed_VBN i_LS =_JJ -_: =_JJ n_NN -LRB-_-LRB- 40_CD -RRB-_-RRB- -_: =_SYM -_: ._.
sIf_NN the_DT distance_NN between_IN the_DT transformed_VBN vectors_NNS is_VBZ a_DT lower_JJR bound_VBN to_TO the_DT distance_NN between_IN the_DT original_JJ feature_NN vectors_NNS ,_, then_RB the_DT lower-bound_JJ filtering_VBG property_NN is_VBZ said_VBN to_TO hold_VB -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
When_WRB the_DT lower-bo_NN
-RRB-_-RRB- ,_, -LRB-_-LRB- 13_CD -RRB-_-RRB- ._.
Theoretical_JJ results_NNS and_CC experiments_NNS on_IN noisy_JJ image_NN data_NNS demonstrate_VBP the_DT ability_NN of_IN this_DT method_NN in_IN preserving_VBG the_DT distances_NNS ._.
And_CC ,_, finally_RB ,_, a_DT nonlinear_JJ dimensionality_NN reduction_NN was_VBD proposed_VBN in_IN =_JJ -_: =[_NN 40_CD -RRB-_-RRB- ._.
-_: =_SYM -_: If_IN the_DT distance_NN between_IN the_DT transformed_VBN vectors_NNS is_VBZ a_DT lower_JJR 1041-4347\/04_CD \/_: $_$ 20.00_CD ß_NN 2004_CD IEEE_NN Published_VBN by_IN the_DT IEEE_NNP Computer_NNP SocietysEGECIOGLU_NNP ET_NNP AL._NNP :_: DIMENSIONALITY_NNP REDUCTION_NNP AND_NNP SIMILARITY_NNP COMPUTATIO_NNP
sed_VBN for_IN dimensionality_NN reduction_NN using_VBG ISOMAP_NN ._.
For_IN example_NN ,_, Prem_NNP et_FW al._FW using_VBG an_DT autonomous_JJ mobile_JJ robot_NN ,_, showed_VBD how_WRB ISOMAP_NN can_MD be_VB used_VBN to_TO detect_VB and_CC properly_RB classify_VBP time-series_NNS of_IN sensory_JJ data_NNS ._.
In_IN =_JJ -_: =[_NN 38_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Vlachos_NNP et_FW al._FW analyzed_VBD the_DT LLE_NN and_CC ISOMAP_NN visualization_NN power_NN ._.
They_PRP showed_VBD that_IN LLE_NN and_CC ISOMAP_NN perform_VBP well_RB only_RB when_WRB the_DT data_NN is_VBZ comprised_VBN of_IN one_CD well_RB sampled_VBN cluster_NN and_CC that_IN the_DT mapping_NN gets_VBZ sig_NN
In_IN addition_NN to_TO being_VBG useful_JJ as_IN a_DT preprocessing_VBG step_NN for_IN supervised_JJ or_CC semi-supervised_JJ learning_NN ,_, linear_JJ and_CC non-linear_JJ dimensionality_NN reduction_NN is_VBZ often_RB used_VBN for_IN data_NN analysis_NN and_CC visualization_NN ,_, e.g._FW -LRB-_-LRB- =_JJ -_: =_JJ Vlachos_NNP et_FW al._FW ,_, 2002_CD -_: =--RRB-_NN ,_, since_IN visualizing_VBG the_DT projected_VBN data_NNS -LRB-_-LRB- two_CD or_CC three_CD dimensions_NNS at_IN a_DT time_NN -RRB-_-RRB- can_MD help_VB to_TO better_RBR understand_VB them_PRP ._.
In_IN the_DT last_JJ few_JJ years_NNS ,_, many_JJ unsupervised_JJ learning_NN algorithms_NNS have_VBP been_VBN proposed_VBN which_WDT sh_VBP
al_FW embedding_NN of_IN high-dimensional_JJ data_NNS ._.
So_RB far_RB ,_, these_DT methods_NNS have_VBP mostly_RB been_VBN used_VBN for_IN exploratory_JJ tasks_NNS such_JJ as_IN visualization_NN ,_, but_CC they_PRP have_VBP also_RB been_VBN successfully_RB applied_VBN to_TO classification_NN problems_NNS =_JJ -_: =[_NN 5_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT dimension_NN of_IN the_DT embedding_NN is_VBZ a_DT key_JJ parameter_NN for_IN manifold_NN projection_NN methods_NNS :_: if_IN the_DT dimension_NN is_VBZ too_RB small_JJ ,_, important_JJ data_NNS features_NNS are_VBP ``_`` collapsed_JJ ''_'' onto_IN the_DT same_JJ dimension_NN ,_, and_CC if_IN the_DT dimensio_NN
possible_JJ the_DT local_JJ neighborhood_NN of_IN each_DT object_NN while_IN trying_VBG to_TO obtain_VB highly_RB nonlinear_JJ embeddings_NNS ._.
So_RB they_PRP are_VBP categorized_VBN as_IN a_DT new_JJ kind_NN of_IN dimensionality_NN reduction_NN techniques_NNS called_VBN Local_NNP Embeddings_NNPS =_SYM -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT central_JJ idea_NN of_IN Local_NNP Embeddings_NNP is_VBZ using_VBG the_DT locally_RB linear_JJ fitting_NN to_TO solve_VB the_DT globally_RB nonlinear_JJ problems_NNS ,_, which_WDT is_VBZ based_VBN on_IN the_DT assumption_NN that_IN data_NNS lying_VBG on_IN a_DT nonlinear_JJ manifold_NN can_MD be_VB vie_NN
e._NN 1_CD ._.
Introduction_NN Dimensionality_NN reduction_NN is_VBZ an_DT important_JJ procedure_NN in_IN various_JJ high-dimensional_JJ data_NNS analysis_NN problems_NNS ._.
Applications_NNS range_VBP from_IN image_NN compression_NN -LRB-_-LRB- Ye_NN et_FW al._FW ,_, 2004_CD -RRB-_-RRB- to_TO visualization_NN -LRB-_-LRB- =_JJ -_: =_JJ Vlachos_NNP et_FW al._FW ,_, 2002_CD -_: =--RRB-_NN ._.
Often_RB the_DT data_NN lies_VBZ on_IN a_DT low_JJ dimensional_JJ manifold_NN embedded_VBN in_IN a_DT high_JJ dimensional_JJ space_NN and_CC the_DT dimensionality_NN of_IN the_DT data_NNS can_MD be_VB reduced_VBN without_IN significant_JJ loss_NN of_IN information_NN ._.
However_RB ,_, in_IN many_JJ ca_MD
mall_NN subset_NN of_IN dimensions_NNS keeps_VBZ a_DT high_JJ portion_NN of_IN the_DT information_NN about_IN the_DT feature_NN vectors_NNS ._.
Several_JJ other_JJ dimensionality_NN reduction_NN based_VBN techniques_NNS are_VBP proposed_VBN -LRB-_-LRB- 34,48,49_CD -RRB-_-RRB- and_CC applied_VBN to_TO time-series_NNS =_JJ -_: =[_NN 50,51_CD -RRB-_-RRB- -_: =_JJ -_: ,_, image_NN -LRB-_-LRB- 29_CD -RRB-_-RRB- ,_, and_CC document_NN data_NNS -LRB-_-LRB- 52_CD --_: 54_CD -RRB-_-RRB- ._.
For_IN dynamic_JJ data_NNS sets_NNS ,_, approximate_JJ KLT_NNP has_VBZ been_VBN shown_VBN to_TO be_VB an_DT effective_JJ technique_NN compared_VBN to_TO the_DT techniques_NNS based_VBN on_IN exact_JJ transformations_NNS -LRB-_-LRB- 55_CD -RRB-_-RRB- ._.
VA-file_JJ and_CC
dimensional_JJ data_NNS are_VBP represented_VBN in_IN the_DT embedded_JJ space_NN ._.
Hence_RB ,_, the_DT optimal_JJ value_NN for_IN K_NNP ,_, Kopt_NNP can_MD be_VB determined_VBN as_IN :_: 2_CD K_NN opt_VBP arg_NN min_NN -LRB-_-LRB- 1_CD D_NN -RRB-_-RRB- -LRB-_-LRB- 5_CD -RRB-_-RRB- K_NN Although_IN a_DT few_JJ techniques_NNS are_VBP given_VBN in_IN literature_NN =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: like_IN linear_JJ interpolations_NNS and_CC training_VBG a_DT neural_JJ network_NN or_CC RBF_NN network_NN for_IN mapping_VBG a_DT new_JJ -LRB-_-LRB- previously_RB unseen_JJ -RRB-_-RRB- sample_NN ,_, we_PRP have_VBP preferred_VBN a_DT simple_JJ strategy_NN of_IN concatenating_VBG the_DT new_JJ sample_NN with_IN given_VBN sa_NN
5_CD guibas@cs.stanford.edu_NN Steve_NNP Y._NNP Oudot_NNP Computer_NNP Science_NNP Dept._NNP ._.
Stanford_NNP University_NNP Stanford_NNP ,_, CA_NNP 94305_CD steve.oudot@stanford.edu_NN machine_NN learning_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, pattern_NN recognition_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, scientific_JJ visualization_NN =_JJ -_: =[_NN 28_CD -RRB-_-RRB- -_: =_JJ -_: ,_, image_NN or_CC signal_NN processing_NN -LRB-_-LRB- 22_CD -RRB-_-RRB- ,_, and_CC neural_JJ computation_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- ._.
The_DT nature_NN of_IN the_DT sought-for_JJ information_NN is_VBZ very_RB application-dependent_JJ ,_, and_CC sometimes_RB it_PRP is_VBZ enough_JJ to_TO inquire_VB about_IN the_DT topological_JJ inva_NN
rone_NN to_TO local_JJ minima_NN ._.
Despite_IN the_DT appealing_JJ properties_NNS of_IN these_DT new_JJ NLDR_NN methods_NNS ,_, they_PRP are_VBP not_RB robust_JJ against_IN outliers_NNS in_IN the_DT data_NNS ._.
Although_IN some_DT extensions_NNS have_VBP been_VBN proposed_VBN to_TO the_DT original_JJ methods_NNS =_JJ -_: =[_NN 10_CD ,_, 11_CD ,_, 12_CD ,_, 13_CD ,_, 14_CD ,_, 15_CD ,_, 16_CD ,_, 6_CD ,_, 17_CD ,_, 18_CD ,_, 19_CD ,_, 20_CD -RRB-_-RRB- -_: =_JJ -_: ,_, very_RB little_JJ has_VBZ yet_RB been_VBN done_VBN to_TO address_VB the_DT outlier_NN problem_NN ._.
Among_IN the_DT extensions_NNS proposed_VBN is_VBZ an_DT interesting_JJ extension_NN of_IN LLE_NN proposed_VBN by_IN Teh_NNP and_CC Roweis_NNP ,_, called_VBD locally_RB linear_JJ coordination_NN -LRB-_-LRB- LLC_NN -RRB-_-RRB- -LRB-_-LRB- 1_CD
rrorSingle_NN Moreover_RB ,_, to_TO compare_VB the_DT robustness_NN of_IN these_DT algorithms_NNS ,_, that_DT is_VBZ ,_, how_WRB well_RB the_DT particular_JJ algorithm_NN algo_NN performs_VBZ in_IN different_JJ situations_NNS ,_, a_DT criterion_NN is_VBZ defined_VBN similar_JJ to_TO the_DT one_CD used_VBN in_IN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN detail_NN ,_, the_DT relative_JJ performance_NN of_IN algorithm_NN algo_NN on_IN a_DT particular_JJ data_NN set_NN is_VBZ expressed_VBN by_IN dividing_VBG its_PRP$ error_NN erroralgo_NN by_IN the_DT biggest_JJS error_NN among_IN all_PDT the_DT compared_VBN algorithms_NNS ,_, as_IN shown_VBN in_IN Eq_NN ._.
6_CD ._.
them_PRP are_VBP shown_VBN in_IN Table_NNP VIII_NNP ._.
To_TO compare_VB the_DT robustness_NN of_IN these_DT methods_NNS ,_, that_DT is_VBZ ,_, how_WRB well_RB the_DT particular_JJ method_NN α_NN performs_VBZ in_IN different_JJ situations_NNS ,_, a_DT criterion_NN is_VBZ defined_VBN similar_JJ to_TO the_DT one_CD used_VBN in_IN =_JJ -_: =[_NN 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN detail_NN ,_, the_DT relative_JJ performance_NN of_IN algorithm_NN α_NN on_IN a_DT particular_JJ data_NN set_NN is_VBZ expressed_VBN by_IN dividing_VBG its_PRP$ average_JJ cost_NN costα_NN by_IN the_DT biggest_JJS average_JJ cost_NN among_IN all_PDT the_DT compared_VBN methods_NNS ,_, as_IN shown_VBN in_IN Eq_NN
,_, which_WDT is_VBZ at_IN the_DT core_NN of_IN non-linear_JJ dimensionality_NN reduction_NN techniques_NNS -LRB-_-LRB- 30_CD ,_, 32_CD -RRB-_-RRB- ,_, finds_VBZ applications_NNS in_IN many_JJ areas_NNS ,_, including_VBG machine_NN learning_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- ,_, pattern_NN recognition_NN -LRB-_-LRB- 31_CD -RRB-_-RRB- ,_, scientific_JJ visualization_NN =_JJ -_: =[_NN 33_CD -RRB-_-RRB- -_: =_JJ -_: ,_, image_NN or_CC signal_NN processing_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, and_CC neural_JJ computation_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- ._.
The_DT nature_NN of_IN the_DT sought-for_JJ information_NN is_VBZ very_RB application-dependent_JJ ,_, and_CC sometimes_RB it_PRP is_VBZ enough_JJ to_TO inquire_VB about_IN the_DT topological_JJ inva_NN
that_IN they_PRP still_RB make_VBP use_NN of_IN simple_JJ linear_JJ algebraic_JJ techniques_NNS that_WDT are_VBP easy_JJ to_TO implement_VB and_CC are_VBP not_RB prone_JJ to_TO local_JJ minima_NN ._.
Many_JJ extensions_NNS of_IN the_DT original_JJ methods_NNS have_VBP been_VBN proposed_VBN by_IN researchers_NNS =_JJ -_: =[_NN 6_CD ,_, 8_CD ,_, 18_CD ,_, 20_CD ,_, 21_CD ,_, 45_CD ,_, 52_CD ,_, 56_CD ,_, 62_CD ,_, 65_CD ,_, 66_CD ,_, 74_CD ,_, 7_CD ,_, 35_CD ,_, 42_CD -RRB-_-RRB- -_: =_SYM -_: ._.
There_EX also_RB some_DT other_JJ effective_JJ methods_NNS for_IN NLDR_NNP ,_, such_JJ as_IN -LRB-_-LRB- 55_CD ,_, 38_CD -RRB-_-RRB- ._.
More_RBR 36srecently_RB ,_, Ham_NN et_FW al._FW and_CC Weinberger_NNP et_FW al._FW established_VBD the_DT relationship_NN between_IN NLDR_NN and_CC kernel_NN matrix_NN learning_NN -LRB-_-LRB- 33_CD ,_, 71_CD -RRB-_-RRB- ._.
the_DT number_NN ofsfree_NN parameters_NNS which_WDT it_PRP involves_VBZ :_: only_RB k_NN ,_, the_DT number_NN of_IN neighbors_NNS has_VBZ to_TO be_VB set_VBN ._.
These_DT virtues_NNS have_VBP attracted_VBN already_RB several_JJ applications_NNS in_IN visualization_NN -LRB-_-LRB- 1,2,13,14_CD -RRB-_-RRB- ,_, classification_NN =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_JJ -_: and_CC other_JJ purposes_NNS -LRB-_-LRB- 1,2,16_CD -RRB-_-RRB- ._.
One_CD type_NN of_IN high_JJ dimensional_JJ data_NNS where_WRB LLE_NNP has_VBZ shown_VBN very_RB successful_JJ results_NNS is_VBZ a_DT set_NN of_IN different_JJ views_NNS of_IN the_DT same_JJ 3D_NN object_NN ._.
When_WRB these_DT images_NNS are_VBP well_RB sampled_VBN and_CC li_FW
