Fast_JJ approximate_JJ spectral_JJ clustering_NN
Spectral_JJ clustering_NN refers_VBZ to_TO a_DT flexible_JJ class_NN of_IN clustering_NN procedures_NNS that_WDT can_MD produce_VB high-quality_JJ clusterings_NNS on_IN small_JJ data_NNS sets_NNS but_CC which_WDT has_VBZ limited_VBN applicability_NN to_TO large-scale_JJ problems_NNS due_JJ to_TO its_PRP$ computational_JJ complexity_NN of_IN O_NN -LRB-_-LRB- n3_NN -RRB-_-RRB- in_IN general_JJ ,_, with_IN n_NN the_DT number_NN of_IN data_NNS points_NNS ._.
We_PRP extend_VBP the_DT range_NN of_IN spectral_JJ clustering_NN by_IN developing_VBG a_DT general_JJ framework_NN for_IN fast_JJ approximate_JJ spectral_JJ clustering_NN in_IN which_WDT a_DT distortion-minimizing_JJ local_JJ transformation_NN is_VBZ first_RB applied_VBN to_TO the_DT data_NNS ._.
This_DT framework_NN is_VBZ based_VBN on_IN a_DT theoretical_JJ analysis_NN that_WDT provides_VBZ a_DT statistical_JJ characterization_NN of_IN the_DT effect_NN of_IN local_JJ distortion_NN on_IN the_DT mis-clustering_JJ rate_NN ._.
We_PRP develop_VBP two_CD concrete_JJ instances_NNS of_IN our_PRP$ general_JJ framework_NN ,_, one_CD based_VBN on_IN local_JJ k-means_NN clustering_NN -LRB-_-LRB- KASP_NN -RRB-_-RRB- and_CC one_CD based_VBN on_IN random_JJ projection_NN trees_NNS -LRB-_-LRB- RASP_NN -RRB-_-RRB- ._.
Extensive_JJ experiments_NNS show_VBP that_IN these_DT algorithms_NNS can_MD achieve_VB significant_JJ speedups_NNS with_IN little_JJ degradation_NN in_IN clustering_NN accuracy_NN ._.
Specifically_RB ,_, our_PRP$ algorithms_NNS outperform_VBP k-means_NN by_IN a_DT large_JJ margin_NN in_IN terms_NNS of_IN accuracy_NN ,_, and_CC run_VB several_JJ times_NNS faster_RBR than_IN approximate_JJ spectral_JJ clustering_NN based_VBN on_IN the_DT Nystrom_NNP method_NN ,_, with_IN comparable_JJ accuracy_NN and_CC significantly_RB smaller_JJR memory_NN footprint_NN ._.
Remarkably_RB ,_, our_PRP$ algorithms_NNS make_VBP it_PRP possible_JJ for_IN a_DT single_JJ machine_NN to_TO spectral_JJ cluster_NN data_NNS sets_VBZ with_IN a_DT million_CD observations_NNS within_IN several_JJ minutes_NNS ._.
site_NN direction_NN to_TO our_PRP$ work_NN ,_, clustering_NN can_MD be_VB approximated_VBN by_IN finding_VBG representative_JJ objects_NNS ,_, clustering_VBG them_PRP ,_, and_CC assigning_VBG the_DT remaining_VBG objects_NNS to_TO the_DT clusters_NNS of_IN their_PRP$ representatives_NNS ._.
Yan_NNP et_FW al._FW =_SYM -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: use_VB k-means_NN or_CC RP_NN trees_NNS to_TO find_VB representative_JJ points_NNS ,_, Kaufman_NNP and_CC Rousseeuw_NNP -LRB-_-LRB- 3_CD -RRB-_-RRB- k-medoids_NNS ,_, and_CC Ester_NNP et_FW al._FW -LRB-_-LRB- 4_LS -RRB-_-RRB- the_DT most_RBS central_JJ object_NN of_IN a_DT data_NN page_NN ._.
Representatives_NNS are_VBP also_RB used_VBN to_TO reduce_VB the_DT nu_NN
que-like_JJ structures_NNS also_RB exist_VBP -LRB-_-LRB- 23_CD ,_, 30_CD ,_, 29_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN we_PRP propose_VBP an_DT algorithm_NN that_WDT can_MD handle_VB large_JJ datasets_NNS ,_, particularly_RB those_DT with_IN a_DT high_JJ number_NN of_IN objects_NNS ;_: we_PRP also_RB allow_VBP overlap_VB ._.
The_DT work_NN in_IN =_JJ -_: =[_NN 22_CD ,_, 28_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ similar_JJ to_TO ours_PRP in_IN that_IN the_DT first_JJ step_NN in_IN our_PRP$ algorithm_NN is_VBZ spectral_JJ ,_, similar_JJ to_TO multi-dimensional_JJ scaling_NN -LRB-_-LRB- MDS_NN -RRB-_-RRB- ;_: their_PRP$ algorithm_NN is_VBZ based_VBN on_IN spectral_JJ properties_NNS of_IN the_DT Laplacian_NN of_IN a_DT graph_NN which_WDT t_NN
ely_RB expensive_JJ in_IN both_CC storage_NN space_NN and_CC algorithm_NN runtime_NN ._.
Prior_JJ work_NN have_VBP tried_VBN to_TO address_VB these_DT issues_NNS along_IN three_CD directions_NNS :_: -LRB-_-LRB- a_LS -RRB-_-RRB- sample_NN the_DT data_NN points_NNS and_CC do_VBP computation_NN on_IN a_DT much_RB smaller_JJR matrix_NN =_JJ -_: =[_NN 6,20_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- b_NN -RRB-_-RRB- sparsify_VBP the_DT matrix_NN by_IN a_DT k-nearest_NN neighbor_NN technique_NN and_CC do_VBP computation_NN on_IN a_DT much_RB sparser_JJR matrix_NN -LRB-_-LRB- 1_CD ,_, 4_CD ,_, 19_CD -RRB-_-RRB- ,_, and_CC -LRB-_-LRB- c_LS -RRB-_-RRB- do_VBP computation_NN on_IN lots_NNS of_IN machines_NNS at_IN the_DT same_JJ time_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ._.
Sampling_NN and_CC sparsi_NNS
e_LS clustering_NN problem_NN as_IN a_DT normalized_VBN mincut_NN problem_NN ._.
Unfortunately_RB the_DT spectral_JJ approach_NN is_VBZ not_RB really_RB scalable_JJ ,_, requiring_VBG O_NN -LRB-_-LRB- N3_NN -RRB-_-RRB- time_NN ._.
Recently_RB ,_, a_DT scalable_JJ approximate_JJ spectral_JJ method_NN was_VBD introduced_VBN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT first_RB selects_VBZ representative_JJ points_NNS on_IN which_WDT the_DT full_JJ spectral_JJ clustering_NN is_VBZ performed_VBN ._.
Many_JJ efforts_NNS have_VBP focused_VBN on_IN scaling_VBG spatial_JJ cluster-ing_NN ._.
For_IN scaling_VBG hierarchical_JJ clustering_NN further_RBR ,_,
e_LS ,_, the_DT change_NN in_IN the_DT resulting_VBG coefficient_NN matrix_NN is_VBZ bounded_VBN by_IN a_DT constant_JJ multiple_NN of_IN the_DT small_JJ noise_NN variance_NN ._.
Approximations_NNS to_TO the_DT moments_NNS of_IN the_DT perturbation_NN dW_NN =_JJ ˜_CD W_NN −_NN W_NN are_VBP also_RB given_VBN in_IN -LRB-_-LRB- 28_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 47_CD -RRB-_-RRB- -_: =_JJ -_: :_: E_NN -LRB-_-LRB- dW_NN -RRB-_-RRB- ≈_NN E_NN -LRB-_-LRB- dD_NN -RRB-_-RRB- D_NN −_NN 2_CD K_NN −_NN D_NN −_NN 1_CD E_NN -LRB-_-LRB- dK_NN -RRB-_-RRB- ,_, E_NN -LRB-_-LRB- dW_NN 2_CD -RRB-_-RRB- ≈_NN E_NN -LRB-_-LRB- dD_NN 2_CD -RRB-_-RRB- D_NN −_NN 4_CD K_NN 2_CD +_CC D_NN −_NN 2_CD E_NN -LRB-_-LRB- dK_NN 2_CD -RRB-_-RRB- −_NN E_NN -LRB-_-LRB- dDdK_NN -RRB-_-RRB- D_NN −_NN 3_CD ◦_NNP K._NNP where_WRB dD_NN =_JJ ˜_NN D_NN −_NN D_NN ,_, and_CC dK_NN =_JJ ˜_CD K_NNP −_NNP K_NNP ,_, and_CC ◦_NN denotes_VBZ element-wise_JJ product_NN ._.
A_DT thorough_JJ descript_NN
s_NNS not_RB provide_VBP any_DT performance_NN guarantees_NNS ._.
More_RBR importantly_RB ,_, the_DT choice_NN of_IN the_DT subset_NN is_VBZ often_RB based_VBN on_IN knowledge_NN of_IN the_DT entire_JJ data_NNS matrix_NN ,_, an_DT unrealistic_JJ assumption_NN in_IN our_PRP$ setting_NN ._.
A_DT good_JJ example_NN is_VBZ =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB the_DT subset_NN is_VBZ chosen_VBN by_IN partitioning_VBG the_DT data_NNS space_NN using_VBG k-means_NN or_CC random_JJ projection_NN trees_NNS ._.
Note_VB that_IN this_DT algorithm_NN is_VBZ not_RB relevant_JJ when_WRB we_PRP do_VBP not_RB have_VB a-priori_NN access_NN to_TO the_DT entire_JJ dataset_NN
o_NN a_DT different_JJ notion_NN ∗_NNP Work_NNP done_VBN as_IN an_DT undergraduate_JJ student_NN at_IN IIT_NNP Kanpur_NNP 1of_JJ intrinsic_JJ dimensionality_NN ._.
Both_DT variants_NNS have_VBP already_RB found_VBN numerous_JJ applications_NNS in_IN regression_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- ,_, spectral_JJ clustering_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, face_NN recognition_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- and_CC image_NN super-resolution_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
1.1_CD Contributions_NNS The_DT RPTREE_NN structures_NNS are_VBP new_JJ entrants_NNS in_IN a_DT large_JJ family_NN of_IN space_NN partitioning_VBG data_NNS structures_NNS such_JJ as_IN k-d_NN trees_NNS -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, BBD_NN tre_NN
Limited_JJ apriori_NN knowledge_NN is_VBZ needed_VBN ._.
SSDE-Cluster_NN discovers_VBZ the_DT community_NN structure_NN given_VBN only_RB the_DT number_NN of_IN communities_NNS in_IN the_DT network_NN ._.
We_PRP also_RB discuss_VBP how_WRB to_TO estimate_VB this_DT number_NN ._.
The_DT work_NN in_IN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ similar_JJ to_TO ours_PRP in_IN that_IN it_PRP starts_VBZ with_IN spectral_JJ properties_NNS ,_, similar_JJ to_TO multi-dimensional_JJ scaling_NN -LRB-_-LRB- MDS_NN -RRB-_-RRB- ._.
However_RB ,_, they_PRP construct_VBP the_DT Laplacian_NNP ,_, which_WDT has_VBZ Ω_NN -LRB-_-LRB- n_NN 2_CD -RRB-_-RRB- runtime_NN ._.
A_DT comprehensive_JJ review_NN of_IN
tcomings_NNS ._.
First_RB ,_, finding_VBG eigenvectors_NNS of_IN a_DT matrix_NN takes_VBZ O_NN -LRB-_-LRB- n3_NN -RRB-_-RRB- in_IN general_JJ where_WRB n_NN is_VBZ the_DT number_NN of_IN data_NNS points_NNS ._.
Which_WDT recent_JJ work_NN has_VBZ tried_VBN to_TO address_VB this_DT with_IN multilevel_JJ -LRB-_-LRB- 17_CD -RRB-_-RRB- and_CC data_NNS preprocessing_VBG =_JJ -_: =[_NN 6_CD ,_, 20_CD -RRB-_-RRB- -_: =_JJ -_: techniques_NNS ._.
Second_JJ ,_, simply_RB using_VBG the_DT first_JJ k_NN eigenvectors_NNS seems_VBZ to_TO fail_VB on_IN many_JJ real_JJ datasets_NNS because_IN they_PRP often_RB turns_VBZ out_RP to_TO be_VB uninformative_JJ ,_, especially_RB in_IN the_DT presence_NN of_IN noise_NN ._.
This_DT prompted_VBD work_NN
igenvalue_NN -RRB-_-RRB- ._.
The_DT components_NNS of_IN this_DT vector_NN are_VBP thresholded_VBN to_TO define_VB the_DT class_NN memberships_NNS of_IN the_DT data_NNS points_NNS ._.
Although_IN spectral_JJ clustering_NN algorithms_NNS that_WDT work_VBP directly_RB with_IN multiway_JJ partitions_NNS exist_VBP =_JJ -_: =[_NN 4_CD ,_, 39_CD -RRB-_-RRB- -_: =_JJ -_: ,_, in_IN the_DT current_JJ paper_NN we_PRP will_MD focus_VB on_IN the_DT classical_JJ recursive_JJ Ncut_NN algorithm_NN ._.
We_PRP assume_VBP that_IN the_DT number_NN of_IN clusters_NNS is_VBZ given_VBN a_DT priori_FW and_CC we_PRP run_VBP the_DT recursion_NN until_IN the_DT desired_VBN number_NN of_IN clusters_NNS is_VBZ
tions_NNS in_IN data_NNS mining_NN in_IN which_WDT a_DT computational_JJ bottleneck_NN is_VBZ involved_VBN ,_, we_PRP aim_VBP to_TO find_VB an_DT effective_JJ preprocessor_NN that_WDT reduces_VBZ the_DT size_NN of_IN the_DT data_NNS structure_NN that_WDT is_VBZ input_NN to_TO that_DT bottleneck_NN -LRB-_-LRB- see_VB ,_, e.g._FW ,_, =_JJ -_: =[_NN 25_CD ,_, 27_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
There_EX are_VBP many_JJ options_NNS that_WDT can_MD be_VB considered_VBN for_IN this_DT preprocessing_VBG step_NN ._.
One_CD option_NN is_VBZ to_TO perform_VB various_JJ forms_NNS of_IN subsampling_NN of_IN the_DT data_NNS ,_, selecting_VBG data_NNS points_NNS at_IN random_JJ or_CC according_VBG to_TO some_DT fo_NN
constraints_NNS ,_, computational_JJ efficiency_NN or_CC privacy_NN considerations_NNS ._.
Data_NN perturbation_NN can_MD be_VB modeled_VBN in_IN several_JJ different_JJ ways_NNS ,_, including_VBG contaminated_VBN distribution_NN models_NNS -LRB-_-LRB- 36_CD -RRB-_-RRB- ,_, measurement_NN error_NN models_NNS =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_JJ -_: and_CC mixture_NN modeling_NN ._.
We_PRP choose_VBP to_TO work_VB with_IN an_DT additive_JJ noise_NN model_NN ,_, due_JJ to_TO its_PRP$ simplicity_NN and_CC its_PRP$ proven_JJ value_NN in_IN a_DT number_NN of_IN problem_NN areas_NNS such_JJ as_IN data_NNS filtering_VBG ,_, quantization_NN and_CC compression_NN ._.
We_PRP
sing_VB techniques_NNS to_TO overcome_VB computational_JJ bottlenecks_NNS in_IN mining_NN large-scale_JJ data_NNS ._.
Examples_NNS include_VBP -LRB-_-LRB- 28_CD -RRB-_-RRB- ,_, who_WP proposed_VBD a_DT nonparametric_JJ data_NN reduction_NN scheme_NN based_VBN on_IN multiscale_JJ density_NN estimation_NN ,_, and_CC =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: ,_, who_WP proposed_VBD a_DT fast_JJ algorithm_NN to_TO extract_VB small_JJ ``_`` core-sets_NNS ''_'' from_IN the_DT input_NN data_NNS ,_, based_VBN on_IN which_WDT -LRB-_-LRB- 1_CD +_CC ǫ_NN -RRB-_-RRB- -_: approximation_NN algorithms_NNS for_IN the_DT k-center_NN clustering_NN have_VBP been_VBN developed_VBN ._.
Our_PRP$ work_NN is_VBZ also_RB rela_NN
ng_NN is_VBZ to_TO partition_NN the_DT data_NNS into_IN m_NN disjoint_NN classes_NNS such_JJ that_IN each_DT xi_NN belongs_VBZ to_TO one_CD and_CC only_RB one_CD class_NN ._.
Different_JJ spectral_JJ clustering_NN algorithms_NNS formalize_VBP this_DT partitioning_VBG problem_NN in_IN different_JJ ways_NNS =_JJ -_: =[_NN 33_CD ,_, 27_CD ,_, 29_CD ,_, 39_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN the_DT current_JJ paper_NN we_PRP adopt_VBP the_DT normalized_VBN cuts_NNS -LRB-_-LRB- Ncut_NN -RRB-_-RRB- formulation_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
1_CD Define_VB W_NN -LRB-_-LRB- V1_NN ,_, V2_NN -RRB-_-RRB- =_JJ ∑_FW i_FW ∈_FW V1_NN ,_, j_FW ∈_FW V2_NN aij_NN for_IN two_CD -LRB-_-LRB- possibly_RB overlapping_VBG -RRB-_-RRB- subsets_NNS V1_NN and_CC V2_NN of_IN V_NN ._.
Let_VB V_NN =_JJ 1_CD We_PRP use_VBP Ncut_NNP only_RB for_IN
linear_JJ algebra_NN in_IN which_WDT a_DT matrix_NN is_VBZ replaced_VBN with_IN a_DT low-rank_JJ approximation_NN ._.
These_DT methods_NNS have_VBP been_VBN widely_RB adopted_VBN ,_, particularly_RB in_IN the_DT context_NN of_IN approximations_NNS for_IN the_DT support_NN vector_NN machine_NN -LRB-_-LRB- SVM_NN -RRB-_-RRB- =_JJ -_: =[_NN 9_CD ,_, 38_CD ,_, 10_CD ,_, 34_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT affinity_NN matrix_NN of_IN spectral_JJ clustering_NN is_VBZ a_DT natural_JJ target_NN for_IN rank_JJ reduction_NN ._.
In_IN particular_JJ ,_, -LRB-_-LRB- 11_CD -RRB-_-RRB- have_VBP used_VBN the_DT Nyström_NNP approximation_NN ,_, which_WDT samples_NNS columns_NNS of_IN the_DT affinity_NN matrix_NN and_CC approxima_NN
ad_NN ,_, to_TO provide_VB a_DT rough_JJ upper_JJ bound_VBN ,_, we_PRP treat_VBP the_DT clustering_NN problem_NN as_IN a_DT classification_NN problem_NN and_CC present_JJ results_NNS from_IN a_DT state-of-the-art_JJ classification_NN algorithm_NN ,_, the_DT Random_JJ Forests_NNS -LRB-_-LRB- RF_NN -RRB-_-RRB- algorithm_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
These_DT results_NNS suggest_VBP that_IN the_DT data_NNS reduction_NN in_IN KASP_NN and_CC RASP_NN have_VBP not_RB seriously_RB degraded_VBD the_DT clustering_NN accuracy_NN ._.
We_PRP also_RB performed_VBD a_DT further_JJ comparison_NN of_IN k-means_NN and_CC our_PRP$ methods_NNS in_IN which_WDT we_PRP incr_VBP
cently_RB a_DT variety_NN of_IN approaches_NNS have_VBP been_VBN proposed_VBN for_IN the_DT initialization_NN of_IN k-means_NN -LRB-_-LRB- 22_CD ,_, 1_CD ,_, 31_CD ,_, 25_CD ,_, 6_CD -RRB-_-RRB- ._.
We_PRP chose_VBD to_TO study_VB three_CD initialization_NN methods_NNS ,_, based_VBN on_IN their_PRP$ documented_JJ favorable_JJ performance_NN =_JJ -_: =[_NN 6_CD ,_, 30_CD ,_, 31_CD ,_, 25_CD -RRB-_-RRB- -_: =_JJ -_: ,_, as_RB well_RB as_IN their_PRP$ relatively_RB straightforward_JJ implementation_NN :_: the_DT Hartigan-Wong_JJ algorithm_NN -LRB-_-LRB- KM-1_NN -RRB-_-RRB- -LRB-_-LRB- 16_CD -RRB-_-RRB- ,_, the_DT samplingbased_JJ two-stage_JJ algorithm_NN -LRB-_-LRB- KM-2_NN -RRB-_-RRB- -LRB-_-LRB- i.e._FW ,_, the_DT Matlab_NNP implementation_NN of_IN k-means_NNS with_IN the_DT
es_VBZ to_TO solve_VB clustering_NN problems_NNS -LRB-_-LRB- 15_CD ,_, 20_CD -RRB-_-RRB- ._.
A_DT relatively_RB recent_JJ area_NN of_IN focus_NN has_VBZ been_VBN spectral_JJ clustering_NN ,_, a_DT class_NN of_IN methods_NNS based_VBN on_IN eigendecompositions_NNS of_IN affinity_NN ,_, dissimilarity_NN or_CC kernel_NN matrices_NNS =_JJ -_: =[_NN 21_CD ,_, 29_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Whereas_IN many_JJ clustering_NN methods_NNS are_VBP strongly_RB tied_VBN to_TO Euclidean_JJ geometry_NN ,_, making_VBG explicit_JJ or_CC implicit_JJ assumptions_NNS that_IN clusters_NNS form_VBP convex_NN regions_NNS in_IN Euclidean_JJ space_NN ,_, spectral_JJ methods_NNS are_VBP more_JJR flexi_NNS
averaged_VBD over_IN 100_CD runs_NNS ._.
The_DT performance_NN of_IN k-means_NNS can_MD vary_VB significantly_RB depending_VBG on_IN the_DT initialization_NN method_NN ._.
Recently_RB a_DT variety_NN of_IN approaches_NNS have_VBP been_VBN proposed_VBN for_IN the_DT initialization_NN of_IN k-means_NN =_JJ -_: =[_NN 22_CD ,_, 1_CD ,_, 31_CD ,_, 25_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP chose_VBD to_TO study_VB three_CD initialization_NN methods_NNS ,_, based_VBN on_IN their_PRP$ documented_JJ favorable_JJ performance_NN -LRB-_-LRB- 6_CD ,_, 30_CD ,_, 31_CD ,_, 25_CD -RRB-_-RRB- ,_, as_RB well_RB as_IN their_PRP$ relatively_RB straightforward_JJ implementation_NN :_: the_DT Hartigan-Wong_JJ algorit_NN
h_NN L0B_NN ,_, and_CC -LRB-_-LRB- 18_CD -RRB-_-RRB- with_IN -LRB-_-LRB- 19_CD -RRB-_-RRB- ,_, we_PRP verify_VBP the_DT claims_NNS stated_VBN in_IN Lemma_NNP 7_CD and_CC Lemma_NNP 8_CD as_RB well_RB as_IN in_IN their_PRP$ proofs_NNS ._.
⎤_FW ⎦_FW ,_, ⎤_FW ⎥_FW ⎦_FW ⎤_FW ⎥_FW ⎦_FW 177.3_CD Performance_NNP analysis_NN for_IN KASP_NN Existing_VBG work_NN from_IN vector_NN quantization_NN =_JJ -_: =[_NN 40_CD ,_, 13_CD -RRB-_-RRB- -_: =_SYM -_: allows_VBZ us_PRP to_TO characterize_VB precisely_RB the_DT amount_NN of_IN distortion_NN when_WRB the_DT representative_NN points_NNS are_VBP computed_VBN by_IN k-means_NN clustering_NN if_IN the_DT probability_NN distribution_NN of_IN the_DT original_JJ data_NNS is_VBZ given_VBN ._.
Let_VB a_DT qua_NN
representative_NN for_IN the_DT data_NNS points_NNS in_IN that_DT cell_NN ._.
RP_NN trees_NNS are_VBP based_VBN on_IN k-d_NN trees_NNS ,_, which_WDT are_VBP spatial_JJ data_NNS structures_NNS that_IN partition_NN a_DT data_NN space_NN by_IN recursively_RB splitting_JJ along_IN one_CD coordinate_NN at_IN a_DT time_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Rather_RB than_IN splitting_NN along_IN coordinate_JJ directions_NNS ,_, RP_NN tree_NN splits_VBZ are_VBP made_VBN according_VBG to_TO randomly_RB chosen_VBN directions_NNS ._.
All_DT points_NNS in_IN the_DT current_JJ cell_NN are_VBP projected_VBN along_IN the_DT random_JJ direction_NN and_CC the_DT ce_NN
e_LS on_IN low-rank_JJ matrix_NN approximations_NNS ._.
This_DT last_JJ approach_NN has_VBZ been_VBN particularly_RB prominent_JJ in_IN the_DT literature_NN ;_: in_IN particular_JJ ,_, several_JJ researchers_NNS have_VBP proposed_VBN using_VBG the_DT Nyström_NNP method_NN for_IN rank_JJ reduction_NN =_JJ -_: =[_NN 9_CD ,_, 38_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
While_IN it_PRP is_VBZ useful_JJ to_TO define_VB such_JJ preprocessors_NNS ,_, simply_RB possessing_VBG a_DT knob_NN that_WDT can_MD adjust_VB computational_JJ complexity_NN does_VBZ not_RB constitute_VB a_DT solution_NN to_TO the_DT problem_NN of_IN fast_JJ spectral_JJ clustering_NN ._.
What_WP is_VBZ
n_NN successfully_RB deployed_VBN in_IN numerous_JJ applications_NNS in_IN areas_NNS such_JJ as_IN computer_NN vision_NN ,_, bioinformatics_NNS ,_, and_CC robotics_NNS ._.
Moreover_RB ,_, there_EX is_VBZ a_DT substantial_JJ theoretical_JJ literature_NN supporting_VBG spectral_JJ clustering_NN =_JJ -_: =[_NN 21_CD ,_, 37_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Despite_IN these_DT virtues_NNS ,_, spectral_JJ clustering_NN is_VBZ not_RB widely_RB viewed_VBN as_IN a_DT competitor_NN to_TO classical_JJ algorithms_NNS such_JJ as_IN hierarchical_JJ clustering_NN and_CC k-means_NN for_IN large-scale_JJ data_NNS mining_NN problems_NNS ._.
The_DT reason_NN i_FW
ix_NN approximations_NNS ._.
Indeed_RB ,_, this_DT last_JJ approach_NN has_VBZ been_VBN the_DT approach_NN most_RBS commonly_RB pursued_VBN in_IN the_DT literature_NN ;_: in_IN particular_JJ ,_, several_JJ researchers_NNS have_VBP proposed_VBN using_VBG the_DT Nyström_NNP method_NN for_IN this_DT purpose_NN =_JJ -_: =[_NN 10_CD ,_, 35_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
While_IN it_PRP is_VBZ useful_JJ to_TO define_VB such_JJ preprocessors_NNS ,_, simply_RB possessing_VBG a_DT knob_NN that_WDT can_MD adjust_VB computational_JJ complexity_NN does_VBZ not_RB constitute_VB a_DT solution_NN to_TO the_DT problem_NN of_IN fast_JJ spectral_JJ clustering_NN ._.
What_WP is_VBZ
primary_JJ importance_NN in_IN data_NNS mining_NN ,_, statistical_JJ machine_NN learning_NN and_CC scientific_JJ discovery_NN ._.
An_DT enormous_JJ variety_NN of_IN methods_NNS have_VBP been_VBN developed_VBN over_IN the_DT past_JJ several_JJ decades_NNS to_TO solve_VB clustering_NN problems_NNS =_JJ -_: =[_NN 15_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT relatively_RB recent_JJ area_NN of_IN focus_NN has_VBZ been_VBN spectral_JJ clustering_NN ,_, a_DT class_NN of_IN methods_NNS based_VBN on_IN eigendecompositions_NNS of_IN affinity_NN ,_, dissimilarity_NN or_CC kernel_NN matrices_NNS -LRB-_-LRB- 21_CD ,_, 29_CD ,_, 33_CD -RRB-_-RRB- ._.
Whereas_IN many_JJ clustering_NN me_PRP
ng_NN is_VBZ to_TO partition_NN the_DT data_NNS into_IN m_NN disjoint_NN classes_NNS such_JJ that_IN each_DT xi_NN belongs_VBZ to_TO one_CD and_CC only_RB one_CD class_NN ._.
Different_JJ spectral_JJ clustering_NN algorithms_NNS formalize_VBP this_DT partitioning_VBG problem_NN in_IN different_JJ ways_NNS =_JJ -_: =[_NN 33_CD ,_, 27_CD ,_, 29_CD ,_, 39_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN the_DT current_JJ paper_NN we_PRP adopt_VBP the_DT normalized_VBN cuts_NNS -LRB-_-LRB- Ncut_NN -RRB-_-RRB- formulation_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
1_CD Define_VB W_NN -LRB-_-LRB- V1_NN ,_, V2_NN -RRB-_-RRB- =_JJ ∑_FW i_FW ∈_FW V1_NN ,_, j_FW ∈_FW V2_NN aij_NN for_IN two_CD -LRB-_-LRB- possibly_RB overlapping_VBG -RRB-_-RRB- subsets_NNS V1_NN and_CC V2_NN of_IN V_NN ._.
Let_VB V_NN =_JJ 1_CD We_PRP use_VBP Ncut_NNP only_RB for_IN
averaged_VBD over_IN 100_CD runs_NNS ._.
The_DT performance_NN of_IN k-means_NNS can_MD vary_VB significantly_RB depending_VBG on_IN the_DT initialization_NN method_NN ._.
Recently_RB a_DT variety_NN of_IN approaches_NNS have_VBP been_VBN proposed_VBN for_IN the_DT initialization_NN of_IN k-means_NN =_JJ -_: =[_NN 22_CD ,_, 1_CD ,_, 31_CD ,_, 25_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP chose_VBD to_TO study_VB three_CD initialization_NN methods_NNS ,_, based_VBN on_IN their_PRP$ documented_JJ favorable_JJ performance_NN -LRB-_-LRB- 6_CD ,_, 30_CD ,_, 31_CD ,_, 25_CD -RRB-_-RRB- ,_, as_RB well_RB as_IN their_PRP$ relatively_RB straightforward_JJ implementation_NN :_: the_DT Hartigan-Wong_JJ algorit_NN
averaged_VBD over_IN 100_CD runs_NNS ._.
The_DT performance_NN of_IN k-means_NNS can_MD vary_VB significantly_RB depending_VBG on_IN the_DT initialization_NN method_NN ._.
Recently_RB a_DT variety_NN of_IN approaches_NNS have_VBP been_VBN proposed_VBN for_IN the_DT initialization_NN of_IN k-means_NN =_JJ -_: =[_NN 22_CD ,_, 1_CD ,_, 31_CD ,_, 25_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP chose_VBD to_TO study_VB three_CD initialization_NN methods_NNS ,_, based_VBN on_IN their_PRP$ documented_JJ favorable_JJ performance_NN -LRB-_-LRB- 6_CD ,_, 30_CD ,_, 31_CD ,_, 25_CD -RRB-_-RRB- ,_, as_RB well_RB as_IN their_PRP$ relatively_RB straightforward_JJ implementation_NN :_: the_DT Hartigan-Wong_JJ algorit_NN
sets_NNS as_RB large_JJ as_IN one_CD million_CD data_NN points_NNS ;_: the_DT largest_JJS experiment_NN that_IN we_PRP are_VBP aware_JJ of_IN for_IN spectral_JJ algorithms_NNS involves_VBZ the_DT MNIST_NNP data_NNS set_NN ,_, which_WDT consists_VBZ of_IN 60,000_CD handwritten_JJ digits_NNS ._.
In_IN particular_JJ ,_, =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: reported_VBD experiments_NNS using_VBG this_DT data_NN set_NN ,_, where_WRB a_DT total_NN running_VBG time_NN of_IN about_RB 30_CD hours_NNS was_VBD required_VBN when_WRB using_VBG a_DT fast_JJ iterative_JJ algorithm_NN ._.
5.1_CD Evaluation_NN metrics_NNS We_PRP used_VBD two_CD quantities_NNS to_TO assess_VB the_DT
n_NN decisions_NNS reflecting_VBG resource_NN constraints_NNS ,_, computational_JJ efficiency_NN or_CC privacy_NN considerations_NNS ._.
Data_NN perturbation_NN can_MD be_VB modeled_VBN in_IN several_JJ different_JJ ways_NNS ,_, including_VBG contaminated_VBN distribution_NN models_NNS =_JJ -_: =[_NN 36_CD -RRB-_-RRB- -_: =_JJ -_: ,_, measurement_NN error_NN models_NNS -LRB-_-LRB- 12_CD -RRB-_-RRB- and_CC mixture_NN modeling_NN ._.
We_PRP choose_VBP to_TO work_VB with_IN an_DT additive_JJ noise_NN model_NN ,_, due_JJ to_TO its_PRP$ simplicity_NN and_CC its_PRP$ proven_JJ value_NN in_IN a_DT number_NN of_IN problem_NN areas_NNS such_JJ as_IN data_NNS filtering_VBG ,_, qu_FW
es_VBZ to_TO solve_VB clustering_NN problems_NNS -LRB-_-LRB- 15_CD ,_, 20_CD -RRB-_-RRB- ._.
A_DT relatively_RB recent_JJ area_NN of_IN focus_NN has_VBZ been_VBN spectral_JJ clustering_NN ,_, a_DT class_NN of_IN methods_NNS based_VBN on_IN eigendecompositions_NNS of_IN affinity_NN ,_, dissimilarity_NN or_CC kernel_NN matrices_NNS =_JJ -_: =[_NN 21_CD ,_, 29_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Whereas_IN many_JJ clustering_NN methods_NNS are_VBP strongly_RB tied_VBN to_TO Euclidean_JJ geometry_NN ,_, making_VBG explicit_JJ or_CC implicit_JJ assumptions_NNS that_IN clusters_NNS form_VBP convex_NN regions_NNS in_IN Euclidean_JJ space_NN ,_, spectral_JJ methods_NNS are_VBP more_JJR flexi_NNS
current_JJ paper_NN we_PRP provide_VBP two_CD examples_NNS of_IN such_JJ preprocessors_NNS ._.
The_DT first_JJ is_VBZ classical_JJ kmeans_NNS ,_, used_VBN in_IN this_DT context_NN as_IN a_DT local_JJ data_NN reduction_NN step_NN ._.
The_DT second_JJ is_VBZ the_DT Random_NNP Projection_NNP tree_NN -LRB-_-LRB- RP_NN tree_NN -RRB-_-RRB- of_IN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN either_DT case_NN ,_, the_DT overall_JJ approximate_JJ spectral_JJ clustering_NN algorithm_NN takes_VBZ the_DT following_JJ form_NN :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- coarsen_VB the_DT affinity_NN graph_NN by_IN using_VBG the_DT preprocessor_NN to_TO collapse_VB neighboring_JJ data_NNS points_NNS into_IN a_DT se_FW
linear_JJ algebra_NN in_IN which_WDT a_DT matrix_NN is_VBZ replaced_VBN with_IN a_DT low-rank_JJ approximation_NN ._.
These_DT methods_NNS have_VBP been_VBN widely_RB adopted_VBN ,_, particularly_RB in_IN the_DT context_NN of_IN approximations_NNS for_IN the_DT support_NN vector_NN machine_NN -LRB-_-LRB- SVM_NN -RRB-_-RRB- =_JJ -_: =[_NN 9_CD ,_, 38_CD ,_, 10_CD ,_, 34_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT affinity_NN matrix_NN of_IN spectral_JJ clustering_NN is_VBZ a_DT natural_JJ target_NN for_IN rank_JJ reduction_NN ._.
In_IN particular_JJ ,_, -LRB-_-LRB- 11_CD -RRB-_-RRB- have_VBP used_VBN the_DT Nyström_NNP approximation_NN ,_, which_WDT samples_NNS columns_NNS of_IN the_DT affinity_NN matrix_NN and_CC approxima_NN
tions_NNS in_IN data_NNS mining_NN in_IN which_WDT a_DT computational_JJ bottleneck_NN is_VBZ involved_VBN ,_, we_PRP aim_VBP to_TO find_VB an_DT effective_JJ preprocessor_NN that_WDT reduces_VBZ the_DT size_NN of_IN the_DT data_NNS structure_NN that_WDT is_VBZ input_NN to_TO that_DT bottleneck_NN -LRB-_-LRB- see_VB ,_, e.g._FW ,_, =_JJ -_: =[_NN 26_CD ,_, 28_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
There_EX are_VBP many_JJ options_NNS that_WDT can_MD be_VB considered_VBN for_IN this_DT preprocessing_VBG step_NN ._.
One_CD option_NN is_VBZ to_TO perform_VB various_JJ forms_NNS of_IN subsampling_NN of_IN the_DT data_NNS ,_, selecting_VBG data_NNS points_NNS at_IN random_JJ or_CC according_VBG to_TO some_DT fo_NN
es_VBZ to_TO solve_VB clustering_NN problems_NNS -LRB-_-LRB- 15_CD ,_, 20_CD -RRB-_-RRB- ._.
A_DT relatively_RB recent_JJ area_NN of_IN focus_NN has_VBZ been_VBN spectral_JJ clustering_NN ,_, a_DT class_NN of_IN methods_NNS based_VBN on_IN eigendecompositions_NNS of_IN affinity_NN ,_, dissimilarity_NN or_CC kernel_NN matrices_NNS =_JJ -_: =[_NN 21_CD ,_, 29_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Whereas_IN many_JJ clustering_NN methods_NNS are_VBP strongly_RB tied_VBN to_TO Euclidean_JJ geometry_NN ,_, making_VBG explicit_JJ or_CC implicit_JJ assumptions_NNS that_IN clusters_NNS form_VBP convex_NN regions_NNS in_IN Euclidean_JJ space_NN ,_, spectral_JJ methods_NNS are_VBP more_JJR flexi_NNS
e_LS on_IN low-rank_JJ matrix_NN approximations_NNS ._.
This_DT last_JJ approach_NN has_VBZ been_VBN particularly_RB prominent_JJ in_IN the_DT literature_NN ;_: in_IN particular_JJ ,_, several_JJ researchers_NNS have_VBP proposed_VBN using_VBG the_DT Nyström_NNP method_NN for_IN rank_JJ reduction_NN =_JJ -_: =[_NN 9_CD ,_, 38_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
While_IN it_PRP is_VBZ useful_JJ to_TO define_VB such_JJ preprocessors_NNS ,_, simply_RB possessing_VBG a_DT knob_NN that_WDT can_MD adjust_VB computational_JJ complexity_NN does_VBZ not_RB constitute_VB a_DT solution_NN to_TO the_DT problem_NN of_IN fast_JJ spectral_JJ clustering_NN ._.
What_WP is_VBZ
primary_JJ importance_NN in_IN data_NNS mining_NN ,_, statistical_JJ machine_NN learning_NN and_CC scientific_JJ discovery_NN ._.
An_DT enormous_JJ variety_NN of_IN methods_NNS have_VBP been_VBN developed_VBN over_IN the_DT past_JJ several_JJ decades_NNS to_TO solve_VB clustering_NN problems_NNS =_JJ -_: =[_NN 15_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT relatively_RB recent_JJ area_NN of_IN focus_NN has_VBZ been_VBN spectral_JJ clustering_NN ,_, a_DT class_NN of_IN methods_NNS based_VBN on_IN eigendecompositions_NNS of_IN affinity_NN ,_, dissimilarity_NN or_CC kernel_NN matrices_NNS -LRB-_-LRB- 21_CD ,_, 29_CD ,_, 33_CD -RRB-_-RRB- ._.
Whereas_IN many_JJ clustering_NN me_PRP
ches_VBZ the_DT partitioning_VBG problem_NN by_IN reducing_VBG the_DT size_NN of_IN the_DT graph_NN by_IN collapsing_VBG vertices_NNS and_CC edges_NNS ,_, partitioning_VBG the_DT smaller_JJR graph_NN ,_, and_CC then_RB uncoarsening_VBG to_TO construct_VB a_DT partition_NN for_IN the_DT original_JJ graph_NN =_JJ -_: =[_NN 17_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Our_PRP$ work_NN is_VBZ similar_JJ in_IN spirit_NN to_TO this_DT multiscale_JJ approach_NN ;_: we_PRP provide_VBP 3rigorous_JJ theoretical_JJ analysis_NN for_IN a_DT particular_JJ kind_NN of_IN coarsening_VBG and_CC uncoarsening_VBG methodology_NN ._.
More_RBR generally_RB ,_, our_PRP$ work_NN is_VBZ re_FW
ches_VBZ the_DT partitioning_VBG problem_NN by_IN reducing_VBG the_DT size_NN of_IN the_DT graph_NN by_IN collapsing_VBG vertices_NNS and_CC edges_NNS ,_, partitioning_VBG the_DT smaller_JJR graph_NN ,_, and_CC then_RB uncoarsening_VBG to_TO construct_VB a_DT partition_NN for_IN the_DT original_JJ graph_NN =_JJ -_: =[_NN 17_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Our_PRP$ work_NN is_VBZ similar_JJ in_IN spirit_NN to_TO this_DT multiscale_JJ approach_NN ;_: we_PRP provide_VBP 3rigorous_JJ theoretical_JJ analysis_NN for_IN a_DT particular_JJ kind_NN of_IN coarsening_VBG and_CC uncoarsening_VBG methodology_NN ._.
More_RBR generally_RB ,_, our_PRP$ work_NN is_VBZ re_FW
sis_NN allows_VBZ us_PRP to_TO bound_VBD the_DT perturbation_NN of_IN the_DT Laplacian_JJ matrix_NN expressed_VBN in_IN terms_NNS of_IN a_DT Frobenius_NNP norm_NN ._.
To_TO connect_VB that_DT analysis_NN to_TO Theorem_NNP 1_CD ,_, we_PRP make_VBP use_NN of_IN the_DT following_JJ standard_JJ lemma_NN ._.
12Lemma_NN 2_CD -LRB-_-LRB- =_JJ -_: =[_NN 35_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Let_VB g_NN denote_VB the_DT eigengap_NN between_IN the_DT second_JJ and_CC the_DT third_JJ eigenvalues_NNS of_IN L._NNP Then_RB the_DT following_NN holds_VBZ :_: ‖_FW ˜v_FW 2_CD −_FW v2_FW ‖_FW ≤_FW 1_CD g_NN ‖_FW ˜_FW -LRB-_-LRB- L_NNP −_NNP L_NNP |_NNP |_NNP +_CC O_NNP ‖_NNP ˜_NNP L_NNP −_NNP L_NNP |_NNP |_NNP 2_CD -RRB-_-RRB- ._.
With_IN these_DT links_NNS in_IN the_DT chain_NN of_IN the_DT argumen_NN
Algorithm_NN 2_CD ._.
The_DT computational_JJ complexity_NN of_IN step_NN 1_CD ,_, k-means_NN ,_, is_VBZ O_NN -LRB-_-LRB- knt_NN -RRB-_-RRB- ,_, where_WRB t_NN is_VBZ the_DT number_NN of_IN iterations_NNS 2_CD ._.
Given_VBN 2_CD There_EX also_RB exist_VBP approximate_JJ k-means_NN algorithms_NNS -LRB-_-LRB- e.g._FW ,_, the_DT -LRB-_-LRB- 1_CD +_CC ǫ_NN -RRB-_-RRB- k-means_NN in_IN =_JJ -_: =[_NN 24_CD -RRB-_-RRB- -_: =--RRB-_NN with_IN a_DT running_VBG time_NN of_IN O_NN -LRB-_-LRB- nt_NN -RRB-_-RRB- ._.
5Algorithm_NN 2_CD KASP_NN -LRB-_-LRB- x1_NN ,_, ..._: ,_, xn_NN ,_, k_NN -RRB-_-RRB- n_NN data_NN points_NNS -LCB-_-LRB- xi_NNS -RCB-_-RRB- n_NN i_LS =_JJ 1_CD ,_, number_NN of_IN representative_JJ points_NNS k_NN Input_NN :_: Output_NN :_: m-way_NN partition_NN of_IN the_DT input_NN data_NN 1_CD ._.
Perform_FW k-means_FW w_NN
given_VBN our_PRP$ focus_NN on_IN practical_JJ error_NN bounds_NNS ._.
It_PRP is_VBZ also_RB worth_JJ noting_VBG that_IN this_DT analysis_NN has_VBZ applications_NNS beyond_IN the_DT design_NN of_IN fast_JJ approximations_NNS to_TO spectral_JJ clustering_NN ._.
In_IN particular_JJ ,_, as_IN discussed_VBN by_IN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, our_PRP$ perturbation_NN analysis_NN can_MD be_VB used_VBN for_IN developing_VBG distributed_VBN versions_NNS of_IN spectral_JJ clustering_NN and_CC for_IN analyzing_VBG robustness_NN to_TO noise_NN ._.
The_DT remainder_NN of_IN the_DT paper_NN is_VBZ organized_VBN as_IN follows_VBZ ._.
We_PRP begin_VBP w_NN
averaged_VBD over_IN 100_CD runs_NNS ._.
The_DT performance_NN of_IN k-means_NNS can_MD vary_VB significantly_RB depending_VBG on_IN the_DT initialization_NN method_NN ._.
Recently_RB a_DT variety_NN of_IN approaches_NNS have_VBP been_VBN proposed_VBN for_IN the_DT initialization_NN of_IN k-means_NN =_JJ -_: =[_NN 22_CD ,_, 1_CD ,_, 31_CD ,_, 25_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP chose_VBD to_TO study_VB three_CD initialization_NN methods_NNS ,_, based_VBN on_IN their_PRP$ documented_JJ favorable_JJ performance_NN -LRB-_-LRB- 6_CD ,_, 30_CD ,_, 31_CD ,_, 25_CD -RRB-_-RRB- ,_, as_RB well_RB as_IN their_PRP$ relatively_RB straightforward_JJ implementation_NN :_: the_DT Hartigan-Wong_JJ algorit_NN
averaged_VBD over_IN 100_CD runs_NNS ._.
The_DT performance_NN of_IN k-means_NNS can_MD vary_VB significantly_RB depending_VBG on_IN the_DT initialization_NN method_NN ._.
Recently_RB a_DT variety_NN of_IN approaches_NNS have_VBP been_VBN proposed_VBN for_IN the_DT initialization_NN of_IN k-means_NN =_JJ -_: =[_NN 22_CD ,_, 1_CD ,_, 31_CD ,_, 25_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP chose_VBD to_TO study_VB three_CD initialization_NN methods_NNS ,_, based_VBN on_IN their_PRP$ documented_JJ favorable_JJ performance_NN -LRB-_-LRB- 6_CD ,_, 30_CD ,_, 31_CD ,_, 25_CD -RRB-_-RRB- ,_, as_RB well_RB as_IN their_PRP$ relatively_RB straightforward_JJ implementation_NN :_: the_DT Hartigan-Wong_JJ algorit_NN
