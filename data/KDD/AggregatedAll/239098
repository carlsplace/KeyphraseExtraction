Shrinkage_NN estimator_NN generalizations_NNS of_IN Proximal_JJ Support_NN Vector_NNP Machines_NNP
We_PRP give_VBP a_DT statistical_JJ interpretation_NN of_IN Proximal_JJ Support_NN Vector_NNP Machines_NNP -LRB-_-LRB- PSVM_NNP -RRB-_-RRB- proposed_VBN at_IN KDD2001_NN as_IN linear_JJ approximaters_NNS to_TO -LRB-_-LRB- nonlinear_JJ -RRB-_-RRB- Support_NN Vector_NNP Machines_NNP -LRB-_-LRB- SVM_NNP -RRB-_-RRB- ._.
We_PRP prove_VBP that_IN PSVM_NN using_VBG a_DT linear_JJ kernel_NN is_VBZ identical_JJ to_TO ridge_VB regression_NN ,_, a_DT biased-regression_NN method_NN known_VBN in_IN the_DT statistical_JJ community_NN for_IN more_JJR than_IN thirty_CD years_NNS ._.
Techniques_NNS from_IN the_DT statistical_JJ literature_NN to_TO estimate_VB the_DT tuning_NN constant_NN that_WDT appears_VBZ in_IN the_DT SVM_NN and_CC PSVM_NN framework_NN are_VBP discussed_VBN ._.
Better_NNP shrinkage_NN strategies_NNS that_WDT incorporate_VBP more_JJR than_IN one_CD tuning_NN constant_NN are_VBP suggested_VBN ._.
For_IN nonlinear_JJ kernels_NNS ,_, the_DT minimization_NN problem_NN posed_VBD in_IN the_DT PSVM_NN framework_NN is_VBZ equivalent_JJ to_TO finding_VBG the_DT posterior_JJ mode_NN of_IN a_DT Bayesian_JJ model_NN defined_VBN through_IN a_DT Gaussian_JJ process_NN on_IN the_DT predictor_NN space_NN ._.
Apart_RB from_IN providing_VBG new_JJ insights_NNS ,_, these_DT interpretations_NNS help_VBP us_PRP attach_VB an_DT estimate_NN of_IN uncertainty_NN to_TO our_PRP$ predictions_NNS and_CC enable_VB us_PRP to_TO build_VB richer_JJR classes_NNS of_IN models_NNS ._.
In_IN particular_JJ ,_, we_PRP propose_VBP a_DT new_JJ algorithm_NN called_VBN PSVMMIX_NNP which_WDT is_VBZ a_DT combination_NN of_IN ridge_NN regression_NN and_CC a_DT Gaussian_JJ process_NN model_NN ._.
Extension_NNP to_TO the_DT case_NN of_IN continuous_JJ response_NN is_VBZ straightforward_JJ and_CC illustrated_JJ with_IN example_NN datasets_NNS ._.
s._NN According_VBG to_TO -LRB-_-LRB- 41_CD -RRB-_-RRB- ,_, it_PRP would_MD take_VB years_NNS to_TO train_VB SVM_NNP on_IN a_DT data_NN set_NN consisting_VBG of_IN one_CD million_CD records_NNS ._.
Many_JJ proposals_NNS have_VBP been_VBN submitted_VBN to_TO enhance_VB SVM_NN in_IN order_NN to_TO increase_VB its_PRP$ training_NN performance_NN =_JJ -_: =[_NN 1_CD ,_, 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, either_CC through_IN random_JJ selection_NN or_CC approximation_NN of_IN the_DT marginal_JJ classifier_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
However_RB ,_, such_JJ approaches_NNS are_VBP still_RB not_RB feasible_JJ with_IN large_JJ data_NNS sets_NNS where_WRB even_RB multiple_JJ scans_NNS of_IN entire_JJ data_NNS set_VBN ar_IN
′_NNP A_NNP De_NNP ν_NN +_CC m_NN −_CD e_SYM ′_CD I_NN =_JJ De_NNP ν_NN +_CC E_NN ′_NN E_NN E_NN =_JJ -LRB-_-LRB- A_DT −_NN e_LS -RRB-_-RRB- ,_, E_NN ∈_NN R_NN m_NN ×_NN -LRB-_-LRB- n_NN +1_NN -RRB-_-RRB- −_NN 1_CD A_NN −_NN 1_CD E_NN ′_NN De_NNP B_NNP Agarwal_NNP has_VBZ showed_VBN that_IN the_DT Proximal_JJ SVM_NN is_VBZ directly_RB transferable_JJ to_TO a_DT ridge_JJ regression_NN expression_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Fung_NNP and_CC Mangasarian_NNP -LRB-_-LRB- 6_CD -RRB-_-RRB- later_RB showed_VBD that_IN -LRB-_-LRB- 3_LS -RRB-_-RRB- can_MD be_VB rewritten_VBN to_TO handle_VB increments_NNS -LRB-_-LRB- E_NN i_LS ,_, d_FW i_FW -RRB-_-RRB- and_CC decrements_NNS -LRB-_-LRB- E_NN d_NN ,_, d_NN d_NN -RRB-_-RRB- ,_, as_IN shown_VBN in_IN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
This_DT decremental_JJ approach_NN is_VBZ based_VBN on_IN time_NN windows_NNS ._.
−_NN 1_CD -LRB-_-LRB- ′_NN A_NN De_NNP −_NNP e_SYM ′_CD -RRB-_-RRB- -LRB-_-LRB- I_NN =_JJ De_NNP ν_NNP +_CC E_NNP ′_NNP E_NNP -RRB-_-RRB- −_NN 1_CD -RCB-_-RRB- -LCB-_-LRB- -LCB-_-LRB- -RCB-_-RRB- A_DT −_NN 1_CD E_NN ′_NN -RCB-_-RRB- -LCB-_-LRB- -LCB-_-LRB- De_NNP -RCB-_-RRB- B_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- E_NN =_JJ -LRB-_-LRB- A_DT −_NN e_LS -RRB-_-RRB- ,_, E_NN ∈_NN R_NN m_NN ×_NN -LRB-_-LRB- n_NN +1_CD -RRB-_-RRB- Agarwal_NNP has_VBZ showed_VBN that_IN the_DT Proximal_JJ SVM_NN is_VBZ directly_RB transferable_JJ to_TO a_DT ridge_JJ regression_NN expression_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Fung_NNP and_CC Mangasarian_NNP -LRB-_-LRB- 10_CD -RRB-_-RRB- later_RB showed_VBD that_IN -LRB-_-LRB- 3_LS -RRB-_-RRB- can_MD be_VB rewritten_VBN to_TO handle_VB increments_NNS -LRB-_-LRB- E_NN i_LS ,_, d_FW i_FW -RRB-_-RRB- and_CC decrements_NNS -LRB-_-LRB- E_NN d_NN ,_, d_NN d_NN -RRB-_-RRB- ,_, as_IN shown_VBN in_IN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
This_DT decremental_JJ approach_NN is_VBZ based_VBN on_IN time_NN windows_NNS ._.
-LRB-_-LRB-
g_NN the_DT SVs_NNS with_IN the_DT corresponding_JJ weights_NNS to_TO describe_VB the_DT class_NN boundary_NN ._.
There_EX have_VBP been_VBN many_JJ attempts_NNS to_TO revise_VB the_DT original_JJ QP_NN formulation_NN such_JJ that_IN it_PRP can_MD be_VB solved_VBN by_IN a_DT QP_NN solver_VBZ more_RBR efficiently_RB =_JJ -_: =[_NN 8_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
-LRB-_-LRB- See_NNP Section_NNP 6_CD for_IN more_JJR details_NNS ._. -RRB-_-RRB-
We_PRP do_VBP not_RB revise_VB the_DT original_JJ QP_NN formulation_NN of_IN SVMs_NNS ._.
Instead_RB ,_, we_PRP try_VBP to_TO provide_VB a_DT smallerbut_JJ high_JJ quality_NN data_NNS set_NN that_WDT is_VBZ beneficial_JJ to_TO computing_VBG the_DT SVM_NN boundar_NN
sed_VBN for_IN text_NN classification_NN :_: see_VB ,_, e.g._FW ,_, Zhang_NNP and_CC Peng_NNP -LRB-_-LRB- 41_CD -RRB-_-RRB- ,_, Poggio_NNP and_CC Smale_NNP -LRB-_-LRB- 25_CD -RRB-_-RRB- ,_, Rifkin_NNP ,_, et_NNP ._.
al._FW -LRB-_-LRB- 27_CD -RRB-_-RRB- ,_, Fung_NNP and_CC Mangasarian_NNP -LRB-_-LRB- who_WP call_VBP the_DT procedure_NN a_DT Proximal_JJ Support_NN Vector_NNP Machine_NNP -RRB-_-RRB- -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, Agarwal_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Zhang_NNP and_CC Oles_NNP -LRB-_-LRB- 42_CD -RRB-_-RRB- ,_, and_CC Suykens_NNP and_CC Vandewalle_NNP -LRB-_-LRB- who_WP call_VBP the_DT procedure_NN a_DT Least_FW Squares_FW Support_NN Vector_NNP Machine_NNP -RRB-_-RRB- -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
In_IN particular_JJ ,_, RLSC_NN performs_VBZ comparable_JJ to_TO the_DT popular_JJ Support_NN Vector_NNP Machines_NNP -LRB-_-LRB-
sed_VBN for_IN text_NN classification_NN :_: see_VB ,_, e.g._FW ,_, Zhang_NNP and_CC Peng_NNP -LRB-_-LRB- 41_CD -RRB-_-RRB- ,_, Poggio_NNP and_CC Smale_NNP -LRB-_-LRB- 25_CD -RRB-_-RRB- ,_, Rifkin_NNP ,_, et_NNP ._.
al._FW -LRB-_-LRB- 27_CD -RRB-_-RRB- ,_, Fung_NNP and_CC Mangasarian_NNP -LRB-_-LRB- who_WP call_VBP the_DT procedure_NN a_DT Proximal_JJ Support_NN Vector_NNP Machine_NNP -RRB-_-RRB- -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, Agarwal_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Zhang_NNP and_CC Oles_NNP -LRB-_-LRB- 42_CD -RRB-_-RRB- ,_, and_CC Suykens_NNP and_CC Vandewalle_NNP -LRB-_-LRB- who_WP call_VBP the_DT procedure_NN a_DT Least_FW Squares_FW Support_NN Vector_NNP Machine_NNP -RRB-_-RRB- -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
In_IN particular_JJ ,_, RLSC_NN performs_VBZ comparable_JJ to_TO the_DT popular_JJ Support_NN Vector_NNP Machines_NNP -LRB-_-LRB-
D_NN KNOWLEDGE_NN DISCOVERY_NN :_: AN_DT INTERNATIONAL_NNP JOURNAL_NNP ,_, MAY_NNP ._.
2005_CD 104_CD There_EX have_VBP been_VBN many_JJ attempts_NNS to_TO revise_VB the_DT original_JJ QP_NN formulation_NN so_IN that_IN it_PRP can_MD be_VB solved_VBN by_IN a_DT QP_NN solver_VBZ more_RBR efficiently_RB -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
-LRB-_-LRB- See_NNP Section_NNP VII_NNP for_IN more_JJR details_NNS ._. -RRB-_-RRB-
In_IN contrast_NN to_TO those_DT works_NNS ,_, we_PRP do_VBP not_RB revise_VB the_DT original_JJ QP_NN formulation_NN of_IN SVM_NNP ._.
Instead_RB ,_, we_PRP try_VBP to_TO provide_VB a_DT smaller_JJR but_CC high_JJ quality_NN data_NNS set_NN that_WDT is_VBZ beneficial_JJ
the_DT primal_JJ variable_NN -RRB-_-RRB- ,_, such_JJ as_IN QR_NN factorization_NN ,_, involve_VBP O_NN -LRB-_-LRB- dn2_NN -RRB-_-RRB- floating_JJ point_NN operations_NNS -LRB-_-LRB- flops_NNS -RRB-_-RRB- 10_CD ._.
When_WRB d_FW ≫_FW n_NN ,_, one_PRP can_MD reduce_VB the_DT computational_JJ complexity_NN by_IN working_VBG with_IN the_DT kernel_NN version_NN of_IN Eq_NN ._.
=_SYM -_: =-LRB-_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: instead_RB ._.
Assuming_VBG that_DT ˆw_NN can_MD be_VB rewritten_VBN as_IN a_DT linear_JJ combination_NN of_IN the_DT training_NN data_NNS ,_, i.e._FW ,_, ˆw_NN =_JJ ˆ_FW Xβ_FW ,_, β_FW ∈_FW Rn_NN ,_, β_NN -LRB-_-LRB- hereafter_RB referred_VBN to_TO as_IN the_DT dual_JJ variable_NN -RRB-_-RRB- can_MD be_VB determined_VBN instead_RB :_: min_NN ˆw_NN
sed_VBN for_IN text_NN classification_NN :_: see_VB ,_, e.g._FW ,_, Zhang_NNP and_CC Peng_NNP -LRB-_-LRB- 41_CD -RRB-_-RRB- ,_, Poggio_NNP and_CC Smale_NNP -LRB-_-LRB- 25_CD -RRB-_-RRB- ,_, Rifkin_NNP ,_, et_NNP ._.
al._FW -LRB-_-LRB- 27_CD -RRB-_-RRB- ,_, Fung_NNP and_CC Mangasarian_NNP -LRB-_-LRB- who_WP call_VBP the_DT procedure_NN a_DT Proximal_JJ Support_NN Vector_NNP Machine_NNP -RRB-_-RRB- -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, Agarwal_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Zhang_NNP and_CC Oles_NNP -LRB-_-LRB- 42_CD -RRB-_-RRB- ,_, and_CC Suykens_NNP and_CC Vandewalle_NNP -LRB-_-LRB- who_WP call_VBP the_DT procedure_NN a_DT Least_FW Squares_FW Support_NN Vector_NNP Machine_NNP -RRB-_-RRB- -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
In_IN particular_JJ ,_, RLSC_NN performs_VBZ comparable_JJ to_TO the_DT popular_JJ Support_NN Vector_NNP Machines_NNP -LRB-_-LRB-
