Boosting_VBG with_IN structure_NN information_NN in_IN the_DT functional_JJ space_NN :_: an_DT application_NN to_TO graph_NN classification_NN
Boosting_VBG is_VBZ a_DT very_RB successful_JJ classification_NN algorithm_NN that_WDT produces_VBZ a_DT linear_JJ combination_NN of_IN ``_`` weak_JJ ''_'' classifiers_NNS -LRB-_-LRB- a.k.a._NN base_NN learners_NNS -RRB-_-RRB- to_TO obtain_VB high_JJ quality_NN classification_NN models_NNS ._.
In_IN this_DT paper_NN we_PRP propose_VBP a_DT new_JJ boosting_VBG algorithm_NN where_WRB base_NN learners_NNS have_VBP structure_NN relationships_NNS in_IN the_DT functional_JJ space_NN ._.
Though_IN such_JJ relationships_NNS are_VBP generic_JJ ,_, our_PRP$ work_NN is_VBZ particularly_RB motivated_VBN by_IN the_DT emerging_VBG topic_NN of_IN pattern_NN based_JJ classification_NN for_IN semi-structured_JJ data_NNS including_VBG graphs_NNS ._.
Towards_IN an_DT efficient_JJ incorporation_NN of_IN the_DT structure_NN information_NN ,_, we_PRP have_VBP designed_VBN a_DT general_JJ model_NN where_WRB we_PRP use_VBP an_DT undirected_JJ graph_NN to_TO capture_VB the_DT relationship_NN of_IN subgraph-based_JJ base_NN learners_NNS ._.
In_IN our_PRP$ method_NN ,_, we_PRP combine_VBP both_CC L1_NN norm_NN and_CC Laplacian_JJ based_VBN L2_NN norm_NN penalty_NN with_IN Logit_JJ loss_NN function_NN of_IN Logit_NNP Boost_NNP ._.
In_IN this_DT approach_NN ,_, we_PRP enforce_VBP model_NN sparsity_NN and_CC smoothness_NN in_IN the_DT functional_JJ space_NN spanned_VBN by_IN the_DT basis_NN functions_NNS ._.
We_PRP have_VBP derived_VBN efficient_JJ optimization_NN algorithms_NNS based_VBN on_IN coordinate_NN decent_JJ for_IN the_DT new_JJ boosting_VBG formulation_NN and_CC theoretically_RB prove_VBP that_IN it_PRP exhibits_VBZ a_DT natural_JJ grouping_NN effect_NN for_IN nearby_JJ spatial_JJ or_CC overlapping_JJ features_NNS ._.
Using_VBG comprehensive_JJ experimental_JJ study_NN ,_, we_PRP have_VBP demonstrated_VBN the_DT effectiveness_NN of_IN the_DT proposed_VBN learning_NN methods_NNS ._.
ion_NN of_IN the_DT distributed_VBN security_NN sensor_NN networks_NNS ._.
Two_CD of_IN these_DT aspects_NNS we_PRP consider_VBP are_VBP incorporating_VBG additional_JJ information_NN about_IN the_DT sensor_NN network_NN structure_NN -LRB-_-LRB- topology_NN in_IN the_DT dimensions_NNS being_VBG sensed_VBN -RRB-_-RRB- =_JJ -_: =[_NN 1_CD ,_, 5_CD ,_, 6_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC addressing_VBG the_DT dynamic_JJ nature_NN of_IN the_DT sensor_NN networks_NNS -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
The_DT work_NN of_IN data_NN analysis_NN fits_VBZ into_IN the_DT sensor_NN network_NN architecture_NN being_VBG developed_VBN by_IN the_DT SensorNet_NNP group_NN at_IN the_DT University_NNP of_IN Kansas_NNP ._.
recently_RB applied_VBN boosting_VBG to_TO graph_NN classification_NN using_VBG subgraphs_NNS as_IN base_NN learners_NNS and_CC showed_VBD the_DT connection_NN of_IN graph_NN boosting_VBG to_TO support_VB vector_NN machine_NN with_IN the_DT R-convolution_NN kernel_NN ._.
Nowozin_NNP et_FW al._FW =_SYM -_: =[_NN 28_CD ,_, 32_CD -RRB-_-RRB- -_: =_JJ -_: combined_JJ subgraph_JJ mining_NN and_CC graph_NN boosting_VBG for_IN classifying_VBG graphs_NNS representing_VBG images_NNS ._.
Though_IN graph_NN boosting_VBG has_VBZ demonstrated_VBN promising_JJ results_NNS ,_, the_DT limitations_NNS of_IN the_DT current_JJ algorithms_NNS are_VBP that_IN th_DT
ture_NN information_NN among_IN features_NNS as_RB well_RB ._.
Recently_RB ,_, a_DT significant_JJ amount_NN of_IN progress_NN has_VBZ been_VBN made_VBN on_IN developing_VBG supervised_JJ learning_NN algorithms_NNS for_IN feature_NN selection_NN from_IN data_NNS with_IN structured_JJ features_NNS =_JJ -_: =[_NN 4_CD ,_, 15_CD ,_, 18_CD ,_, 22_CD ,_, 33_CD ,_, 37_CD ,_, 41_CD ,_, 42_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN these_DT models_NNS ,_, features_NNS may_MD be_VB naturally_RB partitioned_VBN into_IN groups_NNS -LRB-_-LRB- 4_CD ,_, 15_CD ,_, 41_CD -RRB-_-RRB- or_CC ordered_VBN in_IN some_DT meaningful_JJ way_NN ,_, such_JJ as_IN a_DT chain_NN -LRB-_-LRB- 18_CD ,_, 37_CD -RRB-_-RRB- ,_, a_DT tree_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- or_CC a_DT graph_NN -LRB-_-LRB- 22_CD ,_, 33_CD -RRB-_-RRB- ._.
These_DT approaches_NNS demonstr_VBP
lution_NN is_VBZ not_RB constrained_VBN in_IN L1_NN and_CC L2_NN penalty_NN ,_, but_CC can_MD be_VB extended_VBN to_TO L_NNP ∞_NNP ,_, which_WDT recently_RB attracted_VBD research_NN interest_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, since_IN L_NNP ∞_NNP norm_NN is_VBZ differentiable_JJ everywhere_RB except_IN singular_JJ points_NNS -LRB-_-LRB- β_NN =_JJ 0_CD -RRB-_-RRB- =_JJ -_: =[_NN 45_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP summarize_VBP what_WP is_VBZ discussed_VBN previously_RB in_IN the_DT algorithm_NN called_VBN LPGB_NNP ._.
Given_VBN the_DT training_NN data_NNS T_NN =_JJ -LCB-_-LRB- X_NN ,_, y_NN -RCB-_-RRB- ,_, the_DT n_NN by_IN p_NN object-prediction_NN matrix_NN H_NN =_JJ -LCB-_-LRB- hi_UH ,_, j_NN -RCB-_-RRB- =_JJ -LCB-_-LRB- hj_NN -LRB-_-LRB- xi_NN -RRB-_-RRB- -RCB-_-RRB- constructed_VBN from_IN base_NN learners_NNS
e_LS base_NN learners_NNS have_VBP structure_NN relationships_NNS in_IN the_DT functional_JJ space_NN ._.
Our_PRP$ work_NN is_VBZ particularly_RB motivated_VBN by_IN the_DT emerging_VBG topic_NN of_IN pattern_NN based_JJ classification_NN for_IN semi-structure_JJ data_NNS including_VBG graphs_NNS =_JJ -_: =[_NN 16_CD ,_, 31_CD ,_, 36_CD ,_, 38_CD ,_, 40_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, Kudo_NNP et_FW al._FW -LRB-_-LRB- 20_CD -RRB-_-RRB- recently_RB applied_VBD boosting_VBG to_TO graph_NN classification_NN using_VBG subgraphs_NNS as_IN base_NN learners_NNS and_CC showed_VBD the_DT connection_NN of_IN graph_NN boosting_VBG to_TO support_VB vector_NN machine_NN with_IN the_DT R-conv_NN
n_NN an_DT algebraic_JJ framework_NN for_IN measuring_VBG the_DT structure_NN similarity_NN of_IN graph_NN adjacency_NN matrices_NNS ._.
In_IN addition_NN ,_, recently_RB developed_VBD association_NN net_NN uses_VBZ a_DT graph_NN model_NN to_TO represent_VB a_DT set_NN of_IN association_NN rules_NNS =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, these_DT work_NN could_MD not_RB be_VB directly_RB applied_VBN in_IN our_PRP$ current_JJ framework_NN since_IN the_DT graphlet_NN spectrum_NN method_NN models_NNS the_DT spatial_JJ relationship_NN of_IN graphlet_NN in_IN an_DT implicit_JJ approach_NN and_CC the_DT association_NN
ation_NN models_NNS -LRB-_-LRB- 7_CD ,_, 9_CD ,_, 34_CD ,_, 35_CD -RRB-_-RRB- ._.
Recently_RB ,_, the_DT boosting_VBG algorithm_NN has_VBZ been_VBN successfully_RB extended_VBN to_TO tasks_NNS such_JJ as_IN multi-class_JJ classification_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, multi-label_JJ classification_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- ,_, cost_NN sensitive_JJ learning_NN =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, semi-supervised_JJ learning_NN -LRB-_-LRB- 43_CD -RRB-_-RRB- ,_, manifold_RB learning_VBG -LRB-_-LRB- 24_CD -RRB-_-RRB- ,_, classification_NN with_IN missing-value_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, and_CC transfer_NN learning_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- among_IN others_NNS ._.
In_IN this_DT paper_NN we_PRP propose_VBP a_DT new_JJ boosting_VBG algorithm_NN where_WRB base_NN le_FW
ectrum_NN method_NN models_NNS the_DT spatial_JJ relationship_NN of_IN graphlet_NN in_IN an_DT implicit_JJ approach_NN and_CC the_DT association_NN rule_NN net_NN only_RB explore_VBP the_DT overlapping_VBG relationship_NN of_IN features_NNS ._.
Here_RB we_PRP adopted_VBD our_PRP$ previous_JJ work_NN =_JJ -_: =[_NN 5_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: to_TO construct_VB feature_NN graphs_NNS ._.
In_IN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, we_PRP formalize_VBP a_DT concept_NN which_WDT we_PRP called_VBD ``_`` feature_NN consistency_NN map_NN ''_'' ._.
A_DT feature_NN consistency_NN map_NN is_VBZ a_DT undirected_JJ graph_NN in_IN which_WDT each_DT node_NN represents_VBZ a_DT feature_NN and_CC each_DT
ture_NN information_NN among_IN features_NNS as_RB well_RB ._.
Recently_RB ,_, a_DT significant_JJ amount_NN of_IN progress_NN has_VBZ been_VBN made_VBN on_IN developing_VBG supervised_JJ learning_NN algorithms_NNS for_IN feature_NN selection_NN from_IN data_NNS with_IN structured_JJ features_NNS =_JJ -_: =[_NN 4_CD ,_, 15_CD ,_, 18_CD ,_, 22_CD ,_, 33_CD ,_, 37_CD ,_, 41_CD ,_, 42_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN these_DT models_NNS ,_, features_NNS may_MD be_VB naturally_RB partitioned_VBN into_IN groups_NNS -LRB-_-LRB- 4_CD ,_, 15_CD ,_, 41_CD -RRB-_-RRB- or_CC ordered_VBN in_IN some_DT meaningful_JJ way_NN ,_, such_JJ as_IN a_DT chain_NN -LRB-_-LRB- 18_CD ,_, 37_CD -RRB-_-RRB- ,_, a_DT tree_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- or_CC a_DT graph_NN -LRB-_-LRB- 22_CD ,_, 33_CD -RRB-_-RRB- ._.
These_DT approaches_NNS demonstr_VBP
urrence_NN -LRB-_-LRB- COM_NN -RRB-_-RRB- -LRB-_-LRB- 16_CD -RRB-_-RRB- ._.
We_PRP obtained_VBD the_DT SVM-RFE_NN executable_JJ along_IN with_IN the_DT spider_NN machine_NN learning_VBG toolbox_NN from_IN http:\/\/www.kyb.tuebingen.mpg.de\/_NN bs\/people\/spider_NN \/_: ._.
For_IN gBoosting_NN ,_, we_PRP use_VBP the_DT gboost_JJ toolbox_NN =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP obtained_VBD gPLS_NN and_CC COM_NN directly_RB from_IN the_DT original_JJ authors_NNS of_IN the_DT methods_NNS ._.
All_PDT the_DT experiments_NNS were_VBD conducted_VBN on_IN a_DT PC_NN with_IN a_DT 2.8_CD Ghz_NN duo_NN core_NN CPU_NN and_CC 3GB_NN memory_NN ._.
5.1_CD Data_NNP sets_VBZ To_TO evaluate_VB our_PRP$ method_NN
recently_RB applied_VBN boosting_VBG to_TO graph_NN classification_NN using_VBG subgraphs_NNS as_IN base_NN learners_NNS and_CC showed_VBD the_DT connection_NN of_IN graph_NN boosting_VBG to_TO support_VB vector_NN machine_NN with_IN the_DT R-convolution_NN kernel_NN ._.
Nowozin_NNP et_FW al._FW =_SYM -_: =[_NN 28_CD ,_, 32_CD -RRB-_-RRB- -_: =_JJ -_: combined_JJ subgraph_JJ mining_NN and_CC graph_NN boosting_VBG for_IN classifying_VBG graphs_NNS representing_VBG images_NNS ._.
Though_IN graph_NN boosting_VBG has_VBZ demonstrated_VBN promising_JJ results_NNS ,_, the_DT limitations_NNS of_IN the_DT current_JJ algorithms_NNS are_VBP that_IN th_DT
ture_NN information_NN among_IN features_NNS as_RB well_RB ._.
Recently_RB ,_, a_DT significant_JJ amount_NN of_IN progress_NN has_VBZ been_VBN made_VBN on_IN developing_VBG supervised_JJ learning_NN algorithms_NNS for_IN feature_NN selection_NN from_IN data_NNS with_IN structured_JJ features_NNS =_JJ -_: =[_NN 4_CD ,_, 15_CD ,_, 18_CD ,_, 22_CD ,_, 33_CD ,_, 37_CD ,_, 41_CD ,_, 42_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN these_DT models_NNS ,_, features_NNS may_MD be_VB naturally_RB partitioned_VBN into_IN groups_NNS -LRB-_-LRB- 4_CD ,_, 15_CD ,_, 41_CD -RRB-_-RRB- or_CC ordered_VBN in_IN some_DT meaningful_JJ way_NN ,_, such_JJ as_IN a_DT chain_NN -LRB-_-LRB- 18_CD ,_, 37_CD -RRB-_-RRB- ,_, a_DT tree_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- or_CC a_DT graph_NN -LRB-_-LRB- 22_CD ,_, 33_CD -RRB-_-RRB- ._.
These_DT approaches_NNS demonstr_VBP
form_NN of_IN h_NN β_NN -LRB-_-LRB- xi_NN -RRB-_-RRB- =_JJ sgn_NN -LRB-_-LRB- ∑_CD p_NN j_NN =_JJ 1_CD βjhj_NN -LRB-_-LRB- xi_NN -RRB-_-RRB- -RRB-_-RRB- such_JJ that_IN the_DT following_JJ empirical_JJ loss_NN function_NN ℓ_NN -LRB-_-LRB- X_NN ,_, y_NN ;_: β_NN -RRB-_-RRB- is_VBZ minimized_VBN ._.
L_NN -LRB-_-LRB- X_NN ,_, Y_NN ,_, β_NN -RRB-_-RRB- =_JJ n_NN ∑_CD l_NN -LRB-_-LRB- yi_NN ,_, h_NN β_NN -LRB-_-LRB- xi_NN -RRB-_-RRB- -RRB-_-RRB- -LRB-_-LRB- 1_LS -RRB-_-RRB- i_LS =_JJ 1_CD where_WRB l_NN is_VBZ a_DT loss_NN function_NN ._.
AdaBoost_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: takes_VBZ the_DT exponential_JJ loss_NN function_NN :_: p_NN ∑_CD l_NN -LRB-_-LRB- yi_NN ,_, h_NN β_NN -LRB-_-LRB- xi_NN -RRB-_-RRB- =_JJ exp_NN -LRB-_-LRB- −_FW yi_FW βjhj_NN -LRB-_-LRB- xi_NN -RRB-_-RRB- -RRB-_-RRB- -RRB-_-RRB- -LRB-_-LRB- 2_LS -RRB-_-RRB- j_NN =_JJ 1_CD and_CC LogitBoost_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- takes_VBZ the_DT logit_JJ loss_NN function_NN :_: l_NN -LRB-_-LRB- yi_NN ,_, h_NN β_NN -LRB-_-LRB- xi_NN -RRB-_-RRB- =_JJ log_NN -LRB-_-LRB- 1_CD +_CC exp_NN -LRB-_-LRB- −_FW yi_FW p_NN ∑_NN βjhj_NN -LRB-_-LRB- xi_NN -RRB-_-RRB- -RRB-_-RRB- -RRB-_-RRB- -LRB-_-LRB- 3_LS -RRB-_-RRB- j_NN =_JJ 1_CD Duchi_FW et_FW
G_NN 3_CD Figure_NNP 1_CD :_: Three_CD subgraph_JJ features_NNS in_IN three_CD graphs_NNS ._.
Dashed_VBN edge_NN means_VBZ that_IN the_DT two_CD nodes_NNS are_VBP connected_VBN by_IN a_DT path_NN with_IN varying_VBG length_NN -RRB-_-RRB- 1_CD ._.
base_NN learners_NNS -RRB-_-RRB- to_TO obtain_VB high_JJ quality_NN classification_NN models_NNS =_JJ -_: =[_NN 7_CD ,_, 9_CD ,_, 34_CD ,_, 35_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Recently_RB ,_, the_DT boosting_VBG algorithm_NN has_VBZ been_VBN successfully_RB extended_VBN to_TO tasks_NNS such_JJ as_IN multi-class_JJ classification_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, multi-label_JJ classification_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- ,_, cost_NN sensitive_JJ learning_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, semi-supervised_JJ learn_VBP
,_, any_DT convex_JJ loss_NN function_NN may_MD degenerate_VB to_TO random_JJ guess_NN with_IN a_DT certain_JJ level_NN of_IN random_JJ classification_NN noise_NN ._.
L2_NN regularization_NN in_IN linear_JJ regression_NN has_VBZ been_VBN shown_VBN to_TO stabilize_VB the_DT learning_NN function_NN =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN our_PRP$ algorithm_NN design_NN ,_, we_PRP used_VBD the_DT Laplacian_NNP based_VBN L2_NN regularization_NN and_CC this_DT may_MD reduce_VB the_DT boosting_VBG algorithms_NNS '_POS sensitivity_NN to_TO outliers_NNS and_CC random_JJ classification_NN noise_NN ._.
To_TO test_VB the_DT robustness_NN of_IN
the_DT functional_JJ space_NN ._.
Our_PRP$ work_NN is_VBZ particularly_RB motivated_VBN by_IN the_DT emerging_VBG topic_NN of_IN pattern_NN based_JJ classification_NN for_IN semi-structure_JJ data_NNS including_VBG graphs_NNS -LRB-_-LRB- 16_CD ,_, 31_CD ,_, 36_CD ,_, 38_CD ,_, 40_CD -RRB-_-RRB- ._.
For_IN example_NN ,_, Kudo_NNP et_FW al._FW =_SYM -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: recently_RB applied_VBD boosting_VBG to_TO graph_NN classification_NN using_VBG subgraphs_NNS as_IN base_NN learners_NNS and_CC showed_VBD the_DT connection_NN of_IN graph_NN boosting_VBG to_TO support_VB vector_NN machine_NN with_IN the_DT R-convolution_NN kernel_NN ._.
Nowozin_NNP et_FW al._FW ._.
G_NN 3_CD Figure_NNP 1_CD :_: Three_CD subgraph_JJ features_NNS in_IN three_CD graphs_NNS ._.
Dashed_VBN edge_NN means_VBZ that_IN the_DT two_CD nodes_NNS are_VBP connected_VBN by_IN a_DT path_NN with_IN varying_VBG length_NN -RRB-_-RRB- 1_CD ._.
base_NN learners_NNS -RRB-_-RRB- to_TO obtain_VB high_JJ quality_NN classification_NN models_NNS =_JJ -_: =[_NN 7_CD ,_, 9_CD ,_, 34_CD ,_, 35_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Recently_RB ,_, the_DT boosting_VBG algorithm_NN has_VBZ been_VBN successfully_RB extended_VBN to_TO tasks_NNS such_JJ as_IN multi-class_JJ classification_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, multi-label_JJ classification_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- ,_, cost_NN sensitive_JJ learning_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, semi-supervised_JJ learn_VBP
ple_NN as_IN a_DT binary_JJ feature_NN vector_NN ,_, indexed_VBN by_IN the_DT mined_VBN subgraphs_NNS ,_, with_IN values_NNS indicate_VBP the_DT presence_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- or_CC absence_NN -LRB-_-LRB- 0_CD -RRB-_-RRB- of_IN the_DT related_JJ features_NNS ._.
We_PRP perform_VBP feature_NN selection_NN using_VBG SVM_NNP RFE_NNP and_CC use_VB LibSVM_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: with_IN linear_JJ kernel_NN to_TO construct_VB the_DT best_JJS model_NN ._.
We_PRP use_VBP 5-fold_RB cross_JJ validation_NN in_IN the_DT training_NN data_NNS set_VBN to_TO select_VB important_JJ parameter_NN C_NN for_IN SVM_NNP ._.
For_IN COM_NNP ,_, we_PRP set_VBD tp_NN =_JJ 0.3_CD and_CC tn_NN =_JJ 0_CD as_IN proposed_VBN in_IN -LRB-_-LRB- 16_CD
e_LS base_NN learners_NNS have_VBP structure_NN relationships_NNS in_IN the_DT functional_JJ space_NN ._.
Our_PRP$ work_NN is_VBZ particularly_RB motivated_VBN by_IN the_DT emerging_VBG topic_NN of_IN pattern_NN based_JJ classification_NN for_IN semi-structure_JJ data_NNS including_VBG graphs_NNS =_JJ -_: =[_NN 16_CD ,_, 31_CD ,_, 36_CD ,_, 38_CD ,_, 40_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, Kudo_NNP et_FW al._FW -LRB-_-LRB- 20_CD -RRB-_-RRB- recently_RB applied_VBD boosting_VBG to_TO graph_NN classification_NN using_VBG subgraphs_NNS as_IN base_NN learners_NNS and_CC showed_VBD the_DT connection_NN of_IN graph_NN boosting_VBG to_TO support_VB vector_NN machine_NN with_IN the_DT R-conv_NN
trix_NN of_IN W_NN ,_, defined_VBN -LCB-_-LRB- ∑_CD p_NN k_NN =_JJ 1_CD Wi_NN ,_, k_NN if_IN i_FW =_JJ j_NN 0_CD otherwise_RB as_IN D_NN =_JJ -LRB-_-LRB- di_FW ,_, j_NN -RRB-_-RRB- p_NN i_FW ,_, j_NN =_JJ 1_CD where_WRB di_FW ,_, j_NN =_JJ To_TO avoid_VB having_VBG any_DT feature_NN ``_`` dominate_VB ''_'' the_DT penalization_NN function_NN ,_, we_PRP use_VBP the_DT normalized_VBN Laplacian_NN L_NN following_VBG =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: to_TO normalize_VB the_DT weight_NN of_IN each_DT feature_NN ,_, where_WRB the_DT elements_NNS of_IN L_NN are_VBP defined_VBN by_IN ⎧_FW ⎨_FW 1_CD −_FW wi_FW ,_, j\/di_NN ,_, i_FW if_IN i_FW =_JJ j_NN and_CC di_FW ,_, i_FW ̸_FW =_JJ 0_CD Li_NNP ,_, j_NN =_JJ −_FW wi_FW ,_, j_NN \/_: ⎩_FW √_FW di_FW ,_, idj_NN ,_, j_NN if_IN i_FW and_CC j_NN are_VBP adjacent_JJ 0_CD otherwise_RB Tikhonov_NNP regula_NN
ture_NN information_NN among_IN features_NNS as_RB well_RB ._.
Recently_RB ,_, a_DT significant_JJ amount_NN of_IN progress_NN has_VBZ been_VBN made_VBN on_IN developing_VBG supervised_JJ learning_NN algorithms_NNS for_IN feature_NN selection_NN from_IN data_NNS with_IN structured_JJ features_NNS =_JJ -_: =[_NN 4_CD ,_, 15_CD ,_, 18_CD ,_, 22_CD ,_, 33_CD ,_, 37_CD ,_, 41_CD ,_, 42_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN these_DT models_NNS ,_, features_NNS may_MD be_VB naturally_RB partitioned_VBN into_IN groups_NNS -LRB-_-LRB- 4_CD ,_, 15_CD ,_, 41_CD -RRB-_-RRB- or_CC ordered_VBN in_IN some_DT meaningful_JJ way_NN ,_, such_JJ as_IN a_DT chain_NN -LRB-_-LRB- 18_CD ,_, 37_CD -RRB-_-RRB- ,_, a_DT tree_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- or_CC a_DT graph_NN -LRB-_-LRB- 22_CD ,_, 33_CD -RRB-_-RRB- ._.
These_DT approaches_NNS demonstr_VBP
ture_NN information_NN among_IN features_NNS as_RB well_RB ._.
Recently_RB ,_, a_DT significant_JJ amount_NN of_IN progress_NN has_VBZ been_VBN made_VBN on_IN developing_VBG supervised_JJ learning_NN algorithms_NNS for_IN feature_NN selection_NN from_IN data_NNS with_IN structured_JJ features_NNS =_JJ -_: =[_NN 4_CD ,_, 15_CD ,_, 18_CD ,_, 22_CD ,_, 33_CD ,_, 37_CD ,_, 41_CD ,_, 42_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN these_DT models_NNS ,_, features_NNS may_MD be_VB naturally_RB partitioned_VBN into_IN groups_NNS -LRB-_-LRB- 4_CD ,_, 15_CD ,_, 41_CD -RRB-_-RRB- or_CC ordered_VBN in_IN some_DT meaningful_JJ way_NN ,_, such_JJ as_IN a_DT chain_NN -LRB-_-LRB- 18_CD ,_, 37_CD -RRB-_-RRB- ,_, a_DT tree_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- or_CC a_DT graph_NN -LRB-_-LRB- 22_CD ,_, 33_CD -RRB-_-RRB- ._.
These_DT approaches_NNS demonstr_VBP
G_NN 3_CD Figure_NNP 1_CD :_: Three_CD subgraph_JJ features_NNS in_IN three_CD graphs_NNS ._.
Dashed_VBN edge_NN means_VBZ that_IN the_DT two_CD nodes_NNS are_VBP connected_VBN by_IN a_DT path_NN with_IN varying_VBG length_NN -RRB-_-RRB- 1_CD ._.
base_NN learners_NNS -RRB-_-RRB- to_TO obtain_VB high_JJ quality_NN classification_NN models_NNS =_JJ -_: =[_NN 7_CD ,_, 9_CD ,_, 34_CD ,_, 35_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Recently_RB ,_, the_DT boosting_VBG algorithm_NN has_VBZ been_VBN successfully_RB extended_VBN to_TO tasks_NNS such_JJ as_IN multi-class_JJ classification_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, multi-label_JJ classification_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- ,_, cost_NN sensitive_JJ learning_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, semi-supervised_JJ learn_VBP
G_NN 3_CD Figure_NNP 1_CD :_: Three_CD subgraph_JJ features_NNS in_IN three_CD graphs_NNS ._.
Dashed_VBN edge_NN means_VBZ that_IN the_DT two_CD nodes_NNS are_VBP connected_VBN by_IN a_DT path_NN with_IN varying_VBG length_NN -RRB-_-RRB- 1_CD ._.
base_NN learners_NNS -RRB-_-RRB- to_TO obtain_VB high_JJ quality_NN classification_NN models_NNS =_JJ -_: =[_NN 7_CD ,_, 9_CD ,_, 34_CD ,_, 35_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Recently_RB ,_, the_DT boosting_VBG algorithm_NN has_VBZ been_VBN successfully_RB extended_VBN to_TO tasks_NNS such_JJ as_IN multi-class_JJ classification_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, multi-label_JJ classification_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- ,_, cost_NN sensitive_JJ learning_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, semi-supervised_JJ learn_VBP
arameter_FW mar_FW var_NN is_VBZ revealed_VBN ._.
When_WRB max_NN var_NN is_VBZ quite_RB small_JJ ,_, the_DT structure_NN information_NN among_IN features_NNS is_VBZ ignored_VBN and_CC our_PRP$ method_NN will_MD degenerate_VB to_TO regular_JJ logit_NN boosting_VBG with_IN elastic_JJ net_JJ regularization_NN =_JJ -_: =[_NN 44_CD -RRB-_-RRB- -_: =_JJ -_: ;_: when_WRB max_NN var_NN is_VBZ large_JJ ,_, the_DT feature_NN graph_NN will_MD be_VB a_DT complete_JJ graph_NN and_CC our_PRP$ method_NN may_MD possibly_RB introduce_VB less_RBR discriminative_JJ features_NNS hence_RB undermine_VBP the_DT performance_NN ._.
Overall_RB ,_, the_DT regularized_VBN boostin_NN
obtain_VB high_JJ quality_NN classification_NN models_NNS -LRB-_-LRB- 7_CD ,_, 9_CD ,_, 34_CD ,_, 35_CD -RRB-_-RRB- ._.
Recently_RB ,_, the_DT boosting_VBG algorithm_NN has_VBZ been_VBN successfully_RB extended_VBN to_TO tasks_NNS such_JJ as_IN multi-class_JJ classification_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, multi-label_JJ classification_NN =_JJ -_: =[_NN 39_CD -RRB-_-RRB- -_: =_JJ -_: ,_, cost_NN sensitive_JJ learning_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, semi-supervised_JJ learning_NN -LRB-_-LRB- 43_CD -RRB-_-RRB- ,_, manifold_RB learning_VBG -LRB-_-LRB- 24_CD -RRB-_-RRB- ,_, classification_NN with_IN missing-value_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, and_CC transfer_NN learning_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- among_IN others_NNS ._.
In_IN this_DT paper_NN we_PRP propose_VBP a_DT new_JJ bo_NN
lassification_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, multi-label_JJ classification_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- ,_, cost_NN sensitive_JJ learning_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, semi-supervised_JJ learning_NN -LRB-_-LRB- 43_CD -RRB-_-RRB- ,_, manifold_RB learning_VBG -LRB-_-LRB- 24_CD -RRB-_-RRB- ,_, classification_NN with_IN missing-value_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, and_CC transfer_NN learning_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: among_IN others_NNS ._.
In_IN this_DT paper_NN we_PRP propose_VBP a_DT new_JJ boosting_VBG algorithm_NN where_WRB base_NN learners_NNS have_VBP structure_NN relationships_NNS in_IN the_DT functional_JJ space_NN ._.
Our_PRP$ work_NN is_VBZ particularly_RB motivated_VBN by_IN the_DT emerging_VBG topic_NN of_IN p_NN
wo_MD approaches_NNS to_TO model_VB the_DT spatial_JJ correlation_NN of_IN base_NN learners_NNS -LRB-_-LRB- i.e._FW subgraphs_NNS -RRB-_-RRB- ._.
The_DT first_JJ approach_NN ,_, LPGBK_NN ,_, is_VBZ to_TO construct_VB a_DT kernel_NN function_NN for_IN the_DT subgraphs_NNS ,_, utilizing_VBG the_DT the_DT Marginalized_NNP kernel_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT second_JJ approach_NN ,_, LPGBCMP_NN ,_, is_VBZ to_TO construct_VB the_DT feature_NN consistency_NN map_NN ,_, as_IN investigated_VBN in_IN -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
We_PRP fix_VBP max_NN var_NN =_JJ 1_CD for_IN feature_NN consistency_NN map_NN building_NN threshold_NN and_CC δ_NN =_JJ 0.25_CD for_IN overlapping_VBG thre_NN
oposed_VBN method_NN can_MD be_VB naturally_RB extended_VBN to_TO other_JJ semi-structured_JJ data_NNS such_JJ as_IN sequences_NNS and_CC trees_NNS where_WRB patterns_NNS such_JJ as_IN frequent_JJ subsequences_NNS and_CC frequent_JJ subtrees_NNS are_VBP widely_RB used_VBN for_IN classification_NN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: ._.
1.1_CD Related_NNP Work_NNP Subgraph_NNP based_VBD supervised_VBN learning_VBG on_IN graphs_NNS has_VBZ recently_RB attracted_VBN extensive_JJ research_NN interest_NN -LRB-_-LRB- 16_CD ,_, 31_CD ,_, 36_CD ,_, 38_CD ,_, 40_CD -RRB-_-RRB- ._.
For_IN example_NN ,_, Yan_NNP et_NNP ._.
al_FW -LRB-_-LRB- 40_CD -RRB-_-RRB- proposed_VBN Leap_NNP algorithm_NN with_IN two_CD c_NN
tive_JJ models_NNS ._.
In_IN Table_NNP 1_CD ,_, we_PRP summarize_VBP the_DT characteristics_NNS of_IN the_DT 6_CD protein-structure_JJ graph_NN data_NNS sets_NNS ._.
For_IN each_DT data_NNS set_VBN ,_, we_PRP list_VBP the_DT data_NNS set_VBP index_NN ,_, the_DT related_JJ protein_NN family_NN ID_NN in_IN the_DT SCOP_NN database_NN =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT description_NN of_IN the_DT protein_NN family_NN ,_, the_DT number_NN of_IN positive_JJ samples_NNS and_CC the_DT number_NN of_IN negative_JJ samples_NNS ._.
See_VB -LRB-_-LRB- 16_CD -RRB-_-RRB- for_IN a_DT comprehensive_JJ description_NN of_IN the_DT data_NNS collection_NN process_NN ._.
Table_NNP 1_CD :_: Data_NN set_NN :_:
56251_CD Proteasome_NNP subunits_NNS 35_CD 35_CD P6_NN 88854_CD Protein_NN kinases_NNS ,_, catalytic_JJ subunit_NN 41_CD 41_CD 5.2_CD Experimental_JJ Protocol_NNP We_PRP use_VBP standard_JJ cross_JJ validation_NN to_TO generate_VB training_NN and_CC testing_NN data_NNS sets_NNS ._.
We_PRP apply_VBP FFSM_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: to_TO generating_VBG frequent_JJ subgraphs_NNS from_IN the_DT training_NN data_NNS set_VBN with_IN min_NN sup_NN =_JJ 0.30_CD and_CC with_IN subgraph_JJ size_NN between_IN 2_CD and_CC 6_CD ._.
Such_JJ subgraphs_NNS are_VBP used_VBN as_IN feature_NN for_IN feature_NN based_JJ classification_NN -LRB-_-LRB- e.g._FW SVM_NNP ,_, S_NNP
β_NN -RRB-_-RRB- -RRB-_-RRB- −_FW y_FW ∗_FW i_FW Hi_FW β_FW -RRB-_-RRB- +_CC λ1_FW |_FW |_FW β_FW |_FW |_FW 1_CD +_CC 1_CD 2_CD λ2_FW β_FW T_NN L_NN β_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- After_IN transforming_VBG logit_JJ loss_NN to_TO negative_JJ binomial_JJ loglikelihood_NN ,_, we_PRP followed_VBD the_DT general_JJ framework_NN of_IN coordinated_VBN decent_JJ algorithm_NN proposed_VBN in_IN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: recently_RB proposed_VBN by_IN Friedman_NNP et_FW al._FW for_IN L1_NN norm_NN regularized_VBD logistic_JJ regression_NN ._.
Their_PRP$ approach_NN relies_VBZ on_IN the_DT connection_NN between_IN the_DT Newton_NNP 's_POS method_NN for_IN optimizing_VBG logistic_JJ regression_NN and_CC the_DT least_JJS
ectrum_NN method_NN models_NNS the_DT spatial_JJ relationship_NN of_IN graphlet_NN in_IN an_DT implicit_JJ approach_NN and_CC the_DT association_NN rule_NN net_NN only_RB explore_VBP the_DT overlapping_VBG relationship_NN of_IN features_NNS ._.
Here_RB we_PRP adopted_VBD our_PRP$ previous_JJ work_NN =_JJ -_: =[_NN 5_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: to_TO construct_VB feature_NN graphs_NNS ._.
In_IN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, we_PRP formalize_VBP a_DT concept_NN which_WDT we_PRP called_VBD ``_`` feature_NN consistency_NN map_NN ''_'' ._.
A_DT feature_NN consistency_NN map_NN is_VBZ a_DT undirected_JJ graph_NN in_IN which_WDT each_DT node_NN represents_VBZ a_DT feature_NN and_CC each_DT
e_LS base_NN learners_NNS have_VBP structure_NN relationships_NNS in_IN the_DT functional_JJ space_NN ._.
Our_PRP$ work_NN is_VBZ particularly_RB motivated_VBN by_IN the_DT emerging_VBG topic_NN of_IN pattern_NN based_JJ classification_NN for_IN semi-structure_JJ data_NNS including_VBG graphs_NNS =_JJ -_: =[_NN 16_CD ,_, 31_CD ,_, 36_CD ,_, 38_CD ,_, 40_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, Kudo_NNP et_FW al._FW -LRB-_-LRB- 20_CD -RRB-_-RRB- recently_RB applied_VBD boosting_VBG to_TO graph_NN classification_NN using_VBG subgraphs_NNS as_IN base_NN learners_NNS and_CC showed_VBD the_DT connection_NN of_IN graph_NN boosting_VBG to_TO support_VB vector_NN machine_NN with_IN the_DT R-conv_NN
ture_NN information_NN among_IN features_NNS as_RB well_RB ._.
Recently_RB ,_, a_DT significant_JJ amount_NN of_IN progress_NN has_VBZ been_VBN made_VBN on_IN developing_VBG supervised_JJ learning_NN algorithms_NNS for_IN feature_NN selection_NN from_IN data_NNS with_IN structured_JJ features_NNS =_JJ -_: =[_NN 4_CD ,_, 15_CD ,_, 18_CD ,_, 22_CD ,_, 33_CD ,_, 37_CD ,_, 41_CD ,_, 42_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN these_DT models_NNS ,_, features_NNS may_MD be_VB naturally_RB partitioned_VBN into_IN groups_NNS -LRB-_-LRB- 4_CD ,_, 15_CD ,_, 41_CD -RRB-_-RRB- or_CC ordered_VBN in_IN some_DT meaningful_JJ way_NN ,_, such_JJ as_IN a_DT chain_NN -LRB-_-LRB- 18_CD ,_, 37_CD -RRB-_-RRB- ,_, a_DT tree_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- or_CC a_DT graph_NN -LRB-_-LRB- 22_CD ,_, 33_CD -RRB-_-RRB- ._.
These_DT approaches_NNS demonstr_VBP
ying_JJ length_NN -RRB-_-RRB- 1_CD ._.
base_NN learners_NNS -RRB-_-RRB- to_TO obtain_VB high_JJ quality_NN classification_NN models_NNS -LRB-_-LRB- 7_CD ,_, 9_CD ,_, 34_CD ,_, 35_CD -RRB-_-RRB- ._.
Recently_RB ,_, the_DT boosting_VBG algorithm_NN has_VBZ been_VBN successfully_RB extended_VBN to_TO tasks_NNS such_JJ as_IN multi-class_JJ classification_NN =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_JJ -_: ,_, multi-label_JJ classification_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- ,_, cost_NN sensitive_JJ learning_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, semi-supervised_JJ learning_NN -LRB-_-LRB- 43_CD -RRB-_-RRB- ,_, manifold_RB learning_VBG -LRB-_-LRB- 24_CD -RRB-_-RRB- ,_, classification_NN with_IN missing-value_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, and_CC transfer_NN learning_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- among_IN others_NNS ._.
method_NN is_VBZ usually_RB sensitive_JJ to_TO outliers_NNS and_CC errors_NNS in_IN the_DT training_NN data_NNS set_VBP due_JJ to_TO the_DT exponential_JJ loss_NN function_NN ._.
We_PRP use_VBP logit_JJ loss_NN function_NN that_WDT is_VBZ less_RBR sensitive_JJ to_TO outliers_NNS ._.
However_RB ,_, as_IN claimed_VBN in_IN =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_JJ -_: ,_, any_DT convex_JJ loss_NN function_NN may_MD degenerate_VB to_TO random_JJ guess_NN with_IN a_DT certain_JJ level_NN of_IN random_JJ classification_NN noise_NN ._.
L2_NN regularization_NN in_IN linear_JJ regression_NN has_VBZ been_VBN shown_VBN to_TO stabilize_VB the_DT learning_NN function_NN
orithm_NN has_VBZ been_VBN successfully_RB extended_VBN to_TO tasks_NNS such_JJ as_IN multi-class_JJ classification_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, multi-label_JJ classification_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- ,_, cost_NN sensitive_JJ learning_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, semi-supervised_JJ learning_NN -LRB-_-LRB- 43_CD -RRB-_-RRB- ,_, manifold_RB learning_VBG =_JJ -_: =[_NN 24_CD -RRB-_-RRB- -_: =_JJ -_: ,_, classification_NN with_IN missing-value_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, and_CC transfer_NN learning_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- among_IN others_NNS ._.
In_IN this_DT paper_NN we_PRP propose_VBP a_DT new_JJ boosting_VBG algorithm_NN where_WRB base_NN learners_NNS have_VBP structure_NN relationships_NNS in_IN the_DT functional_JJ s_NN
tasks_NNS such_JJ as_IN multi-class_JJ classification_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, multi-label_JJ classification_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- ,_, cost_NN sensitive_JJ learning_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, semi-supervised_JJ learning_NN -LRB-_-LRB- 43_CD -RRB-_-RRB- ,_, manifold_RB learning_VBG -LRB-_-LRB- 24_CD -RRB-_-RRB- ,_, classification_NN with_IN missing-value_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC transfer_NN learning_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- among_IN others_NNS ._.
In_IN this_DT paper_NN we_PRP propose_VBP a_DT new_JJ boosting_VBG algorithm_NN where_WRB base_NN learners_NNS have_VBP structure_NN relationships_NNS in_IN the_DT functional_JJ space_NN ._.
Our_PRP$ work_NN is_VBZ particularly_RB motivated_VBN
ture_NN information_NN among_IN features_NNS as_RB well_RB ._.
Recently_RB ,_, a_DT significant_JJ amount_NN of_IN progress_NN has_VBZ been_VBN made_VBN on_IN developing_VBG supervised_JJ learning_NN algorithms_NNS for_IN feature_NN selection_NN from_IN data_NNS with_IN structured_JJ features_NNS =_JJ -_: =[_NN 4_CD ,_, 15_CD ,_, 18_CD ,_, 22_CD ,_, 33_CD ,_, 37_CD ,_, 41_CD ,_, 42_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN these_DT models_NNS ,_, features_NNS may_MD be_VB naturally_RB partitioned_VBN into_IN groups_NNS -LRB-_-LRB- 4_CD ,_, 15_CD ,_, 41_CD -RRB-_-RRB- or_CC ordered_VBN in_IN some_DT meaningful_JJ way_NN ,_, such_JJ as_IN a_DT chain_NN -LRB-_-LRB- 18_CD ,_, 37_CD -RRB-_-RRB- ,_, a_DT tree_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- or_CC a_DT graph_NN -LRB-_-LRB- 22_CD ,_, 33_CD -RRB-_-RRB- ._.
These_DT approaches_NNS demonstr_VBP
ture_NN information_NN among_IN features_NNS as_RB well_RB ._.
Recently_RB ,_, a_DT significant_JJ amount_NN of_IN progress_NN has_VBZ been_VBN made_VBN on_IN developing_VBG supervised_JJ learning_NN algorithms_NNS for_IN feature_NN selection_NN from_IN data_NNS with_IN structured_JJ features_NNS =_JJ -_: =[_NN 4_CD ,_, 15_CD ,_, 18_CD ,_, 22_CD ,_, 33_CD ,_, 37_CD ,_, 41_CD ,_, 42_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN these_DT models_NNS ,_, features_NNS may_MD be_VB naturally_RB partitioned_VBN into_IN groups_NNS -LRB-_-LRB- 4_CD ,_, 15_CD ,_, 41_CD -RRB-_-RRB- or_CC ordered_VBN in_IN some_DT meaningful_JJ way_NN ,_, such_JJ as_IN a_DT chain_NN -LRB-_-LRB- 18_CD ,_, 37_CD -RRB-_-RRB- ,_, a_DT tree_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- or_CC a_DT graph_NN -LRB-_-LRB- 22_CD ,_, 33_CD -RRB-_-RRB- ._.
These_DT approaches_NNS demonstr_VBP
We_PRP notice_VBP a_DT few_JJ recent_JJ studies_NNS that_WDT are_VBP moving_VBG towards_IN the_DT direction_NN of_IN defining_VBG the_DT relationship_NN among_IN features_NNS in_IN graphs_NNS and_CC sets_NNS ._.
For_IN example_NN in_IN the_DT recently_RB defined_VBN graph_NN Graphlet_NN Spectrum_NN kernel_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT spatial_JJ relationship_NN of_IN graph_NN feature_NN -LRB-_-LRB- called_VBN graphlets_NNS -RRB-_-RRB- are_VBP explored_VBN in_IN an_DT algebraic_JJ framework_NN for_IN measuring_VBG the_DT structure_NN similarity_NN of_IN graph_NN adjacency_NN matrices_NNS ._.
In_IN addition_NN ,_, recently_RB develope_VB
cently_RB ,_, the_DT boosting_VBG algorithm_NN has_VBZ been_VBN successfully_RB extended_VBN to_TO tasks_NNS such_JJ as_IN multi-class_JJ classification_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, multi-label_JJ classification_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- ,_, cost_NN sensitive_JJ learning_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, semi-supervised_JJ learning_NN =_JJ -_: =[_NN 43_CD -RRB-_-RRB- -_: =_JJ -_: ,_, manifold_RB learning_VBG -LRB-_-LRB- 24_CD -RRB-_-RRB- ,_, classification_NN with_IN missing-value_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, and_CC transfer_NN learning_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- among_IN others_NNS ._.
In_IN this_DT paper_NN we_PRP propose_VBP a_DT new_JJ boosting_VBG algorithm_NN where_WRB base_NN learners_NNS have_VBP structure_NN relations_NNS
e_LS base_NN learners_NNS have_VBP structure_NN relationships_NNS in_IN the_DT functional_JJ space_NN ._.
Our_PRP$ work_NN is_VBZ particularly_RB motivated_VBN by_IN the_DT emerging_VBG topic_NN of_IN pattern_NN based_JJ classification_NN for_IN semi-structure_JJ data_NNS including_VBG graphs_NNS =_JJ -_: =[_NN 16_CD ,_, 31_CD ,_, 36_CD ,_, 38_CD ,_, 40_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, Kudo_NNP et_FW al._FW -LRB-_-LRB- 20_CD -RRB-_-RRB- recently_RB applied_VBD boosting_VBG to_TO graph_NN classification_NN using_VBG subgraphs_NNS as_IN base_NN learners_NNS and_CC showed_VBD the_DT connection_NN of_IN graph_NN boosting_VBG to_TO support_VB vector_NN machine_NN with_IN the_DT R-conv_NN
e_LS base_NN learners_NNS have_VBP structure_NN relationships_NNS in_IN the_DT functional_JJ space_NN ._.
Our_PRP$ work_NN is_VBZ particularly_RB motivated_VBN by_IN the_DT emerging_VBG topic_NN of_IN pattern_NN based_JJ classification_NN for_IN semi-structure_JJ data_NNS including_VBG graphs_NNS =_JJ -_: =[_NN 16_CD ,_, 31_CD ,_, 36_CD ,_, 38_CD ,_, 40_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, Kudo_NNP et_FW al._FW -LRB-_-LRB- 20_CD -RRB-_-RRB- recently_RB applied_VBD boosting_VBG to_TO graph_NN classification_NN using_VBG subgraphs_NNS as_IN base_NN learners_NNS and_CC showed_VBD the_DT connection_NN of_IN graph_NN boosting_VBG to_TO support_VB vector_NN machine_NN with_IN the_DT R-conv_NN
