Mining_NN reference_NN tables_NNS for_IN automatic_JJ text_NN segmentation_NN
Automatically_RB segmenting_VBG unstructured_JJ text_NN strings_NNS into_IN structured_JJ records_NNS is_VBZ necessary_JJ for_IN importing_VBG the_DT information_NN contained_VBN in_IN legacy_NN sources_NNS and_CC text_NN collections_NNS into_IN a_DT data_NN warehouse_NN for_IN subsequent_JJ querying_NN ,_, analysis_NN ,_, mining_NN and_CC integration_NN ._.
In_IN this_DT paper_NN ,_, we_PRP mine_VBP tables_NNS present_JJ in_IN data_NN warehouses_NNS and_CC relational_JJ databases_NNS to_TO develop_VB an_DT automatic_JJ segmentation_NN system_NN ._.
Thus_RB ,_, we_PRP overcome_VBD limitations_NNS of_IN existing_VBG supervised_JJ text_NN segmentation_NN approaches_NNS ,_, which_WDT require_VBP comprehensive_JJ manually_RB labeled_VBN training_NN data_NNS ._.
Our_PRP$ segmentation_NN system_NN is_VBZ robust_JJ ,_, accurate_JJ ,_, and_CC efficient_JJ ,_, and_CC requires_VBZ no_DT additional_JJ manual_JJ effort_NN ._.
Thorough_JJ evaluation_NN on_IN real_JJ datasets_NNS demonstrates_VBZ the_DT robustness_NN and_CC accuracy_NN of_IN our_PRP$ system_NN ,_, with_IN segmentation_NN accuracy_NN exceeding_VBG state_NN of_IN the_DT art_NN supervised_JJ approaches_NNS ._.
ealing_VBG with_IN that_DT uncertainty_NN ,_, a_DT probabilistic_JJ model_NN like_IN HMM_NNP has_VBZ been_VBN shown_VBN to_TO be_VB effective_JJ ,_, for_IN general_JJ text_NN -LRB-_-LRB- -LRB-_-LRB- 5_CD -RRB-_-RRB- -RRB-_-RRB- as_RB well_RB as_IN specific_JJ -_: meaning_VBG phrases_NNS like_IN postal_JJ addresses_NNS or_CC bibliography_NN records_NNS -LRB-_-LRB- =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 3_CD -RRB-_-RRB- -RRB-_-RRB- ._.
-_: 1_CD -_: However_RB ,_, firstly_RB ,_, the_DT above-mentioned_JJ HMMs_NNS did_VBD not_RB consider_VB the_DT synonymous_JJ words_NNS in_IN counting_VBG their_PRP$ common_JJ occurrence_NN probabilities_NNS ._.
That_DT affects_VBZ not_RB only_RB the_DT performance_NN of_IN text_NN segmenta_NN
s_NN research_NN papers_NNS fit_VBP into_IN a_DT well_RB defined_VBN template_NN ,_, we_PRP have_VBP used_VBN a_DT template-based_JJ reference_NN extraction_NN of_IN research_NN papers_NNS ._.
Machine_NN learning_NN approaches_NNS discover_VBP patterns_NNS from_IN a_DT dataset_NN as_IN discussed_VBN in_IN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 19_CD -RRB-_-RRB- ._.
Such_JJ approaches_NNS as_IN used_VBN for_IN CiteSeer_NNP -LRB-_-LRB- 6_CD -RRB-_-RRB- take_VBP advantage_NN of_IN probabilistic_JJ estimation_NN ,_, based_VBN on_IN training_NN sets_NNS of_IN tagged_VBN bibliographic_JJ data_NNS ._.
Although_IN this_DT technique_NN has_VBZ a_DT good_JJ adaptability_NN ,_, it_PRP nee_VBD
en_IN the_DT rhetorical_JJ relations_NNS that_WDT hold_VBP among_IN these_DT units_NNS are_VBP determined_VBN to_TO connect_VB related_JJ spans_NNS ._.
Determining_VBG the_DT potential_JJ relations_NNS that_WDT connects_VBZ related_JJ spans_NNS could_MD be_VB done_VBN using_VBG several_JJ techniques_NNS =_JJ -_: =[_NN 2,5,6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN such_JJ techniques_NNS is_VBZ through_IN the_DT use_NN of_IN cue_NN phrases_NNS -LRB-_-LRB- 16_CD -RRB-_-RRB- ._.
Marcu_NNP -LRB-_-LRB- 15_CD -RRB-_-RRB- has_VBZ given_VBN several_JJ cue_NN phrases_NNS that_WDT can_MD be_VB used_VBN in_IN the_DT English_JJ language_NN processing_NN ._.
Cue_NN phrases_NNS have_VBP been_VBN used_VBN in_IN various_JJ a_DT
research_NN papers_NNS fit_VBP into_IN a_DT well_RB defined_VBN template_NN ,_, we_PRP have_VBP used_VBN a_DT template-based_JJ reference_NN extraction_NN of_IN research_NN papers_NNS ._.
Machine_NN learning_NN approaches_NNS discover_VBP patterns_NNS from_IN a_DT dataset_NN as_IN discussed_VBN in_IN -LRB-_-LRB- =_JJ -_: =_JJ Agichtein_NNP and_CC Ganti_NNP ,_, 2004_CD -_: =--RRB-_NN -LRB-_-LRB- Borkar_NNP et_FW al._FW ,_, 2001_CD -RRB-_-RRB- ._.
3_CD http:\/\/scientific.thomsonreuters.com\/free\/essays\/selectionofmaterial\/_NN journalselection_NN \/_: 4_CD http:\/\/citeseer.ist.psu.edu\/_NN 5_CD www.scholar.google.com_NN 6_CD http:\/\/scholar.google.at\/in_NN
d_NN extract_NN the_DT entity_NN names_NNS -LRB-_-LRB- such_JJ as_IN of_IN company_NN ,_, people_NNS ,_, locations_NNS -LRB-_-LRB- Li_NNP ,_, et_NNP ._.
al._FW ,_, 2003_CD -RRB-_-RRB- ,_, biological_JJ terms_NNS -LRB-_-LRB- Goutte_NNP ,_, et_NNP ._.
al._FW ,_, 2002_CD -RRB-_-RRB- ,_, etc._NN -RRB-_-RRB- ,_, dates_NNS -LRB-_-LRB- Mckay_NNP &_CC Cunningham_NNP ,_, 2001_CD -RRB-_-RRB- ,_, monetary_JJ amounts_NNS ,_, references_NNS -LRB-_-LRB- =_JJ -_: =_JJ Agichtein_NNP &_CC Ganti_NNP ,_, 2004_CD -_: =--RRB-_NN and_CC other_JJ similar_JJ entities_NNS in_IN unstructured_JJ text_NN ._.
In_IN early_JJ systems_NNS usually_RB a_DT domainspecific_JJ dictionary_NN and_CC a_DT pattern\/rule_NN base_NN are_VBP built_VBN manually_RB and_CC tuned_VBN for_IN a_DT particular_JJ corpus_NN ._.
Extraction_NN quality_NN
ibutes_JJ WHIRL_NN is_VBZ exception_NN ,_, used_VBN in_IN experiments_NNS Data_NNP Cleaning_NNP Tuple-to-tuple_JJ transformations_NNS -LRB-_-LRB- 13,14_CD -RRB-_-RRB- Info_NNP ._.
Extraction_NN -LRB-_-LRB- for_IN Annotation_NNP -RRB-_-RRB- Conditional_NNP Random_NNP Fields_NNP -LRB-_-LRB- Simple_JJ Tagger_NN -RRB-_-RRB- Datamold_NN \/_: CRAM_NN =_JJ -_: =[_NN 15,16_CD -RRB-_-RRB- -_: =_SYM -_: Require_VB all_DT tokens_NNS to_TO receive_VB label_NN \/_: no_DT junk_NN NER_NN with_IN Dictionary_NNP -LRB-_-LRB- 17_CD -RRB-_-RRB- Whole_JJ segments_NNS receive_VBP same_JJ label_NN --_: attributes_NNS ca_MD n't_RB be_VB interruptedOutline_NN 1_CD ._.
Introduction_NN 2_CD ._.
Alignment_NN 3_CD ._.
Extraction_NN 4_CD ._.
ecomposing_VBG unstructured_JJ text_NN include_VBP splitting_NN the_DT unstructured_JJ text_NN along_IN a_DT predefined_JJ set_NN of_IN delimiters_NNS or_CC into_IN word_NN chunks_NNS using_VBG NLP-based_JJ methods_NNS ._.
Statistical_JJ methods_NNS such_JJ as_IN Hidden_NNP Markov_NNP Models_NNS =_JJ -_: =[_NN 1_CD ,_, 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, MaximumEntropy-based_JJ methods_NNS -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, and_CC Conditional_NNP Random_NNP Fields_NNP -LRB-_-LRB- 18_CD -RRB-_-RRB- are_VBP popular_JJ for_IN labeling_VBG the_DT decomposed_VBN text_NN ._.
Since_IN multiple_JJ extracted_VBN entities_NNS may_MD represent_VB the_DT same_JJ physical_JJ entity_NN -LRB-_-LRB- e.g._FW ,_, Int_NN
Related_JJ Work_NN Much_JJ previous_JJ work_NN has_VBZ shown_VBN that_IN dictionaries_NNS and_CC lists_NNS can_MD improve_VB language_NN segmentation_NN tasks_NNS ._.
Lists_NNS extracted_VBN from_IN structured_JJ databases_NNS provide_VBP gains_NNS in_IN information_NN extraction_NN tasks_NNS =_JJ -_: =[_NN 6_CD ,_, 7_CD -RRB-_-RRB- -_: =_JJ -_: and_CC named_VBN entities_NNS help_VBP in_IN dialog_NN systems_NNS -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
More_RBR recent_JJ work_NN has_VBZ shown_VBN that_IN unsupervised_JJ extraction_NN from_IN websites_NNS and_CC query_NN logs_NNS provides_VBZ valuable_JJ features_NNS for_IN information_NN extraction_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- and_CC weigh_VB
es_NNS for_IN improved_VBN segmentation_NN ._.
Their_PRP$ results_NNS indicate_VBP that_IN Datamold_NNP consistently_RB performs_VBZ better_JJR than_IN the_DT rule-base_NN system_NN Rapier_NNP ._.
An_DT automatic_JJ system_NN that_WDT only_RB uses_VBZ external_JJ databases_NNS is_VBZ presented_VBN in_IN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT authors_NNS describe_VBP attribute_NN recognition_NN models_NNS -LRB-_-LRB- ARMs_NNS -RRB-_-RRB- ,_, based_VBN on_IN HMMs_NNS ,_, which_WDT capture_VBP the_DT characteristics_NNS of_IN the_DT values_NNS stored_VBN in_IN large_JJ reference_NN tables_NNS ._.
The_DT topology_NN for_IN an_DT ARM_NN consists_VBZ of_IN the_DT thr_NN
n_NN of_IN the_DT candidate_NN entities_NNS with_IN the_DT document_NN and_CC finds_VBZ the_DT best_JJS matching_NN entities_NNS and_CC their_PRP$ embeddings_NNS ._.
This_DT task_NN performed_VBN by_IN EROCS_NN is_VBZ similar_JJ in_IN spirit_NN to_TO dictionary-based_JJ named-entity_NN recognition_NN =_JJ -_: =[_NN 7_CD ,_, 1_CD ,_, 12_CD ,_, 17_CD -RRB-_-RRB- -_: =_JJ -_: ,_, but_CC differs_VBZ in_IN the_DT following_JJ crucial_JJ and_CC challenging_JJ aspects_NNS ._.
•_FW EROCS_FW identifies_VBZ an_DT entity_NN even_RB if_IN it_PRP is_VBZ not_RB explicitly_RB mentioned_VBN in_IN the_DT document_NN ;_: it_PRP exploits_VBZ the_DT available_JJ context_NN information_NN to_TO ma_FW
apply_VB it_PRP in_IN a_DT conditional_JJ setting_NN ;_: it_PRP is_VBZ highly_RB sensitive_JJ to_TO misspellings_NNS within_IN a_DT token_JJ ;_: and_CC when_WRB the_DT dictionary_NN is_VBZ too_RB large_JJ or_CC too_RB different_JJ from_IN the_DT training_NN text_NN ,_, it_PRP may_MD degrade_VB performance_NN ._.
In_IN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_JJ -_: ,_, some_DT of_IN these_DT drawbacks_NNS are_VBP addressed_VBN by_IN more_RBR carefully_RB training_VBG a_DT HMM_NN so_RB as_IN to_TO allow_VB small_JJ variations_NNS in_IN the_DT extracted_VBN entities_NNS ,_, but_CC this_DT approach_NN being_VBG generative_JJ is_VBZ still_RB restricted_JJ in_IN its_PRP$ scope_NN
V_NN alidCorner_NN -LRB-_-LRB- C_NN ,_, S_NN −_NN -RRB-_-RRB- return_NN v_LS =_JJ Coverage_NNP -LRB-_-LRB- urect_NN -LRB-_-LRB- C_NN -RRB-_-RRB- ,_, ∆_NN +_CC -RRB-_-RRB- \/_: \*_NN Recursion_NN \*_NN \/_: -LRB-_-LRB- 3_LS -RRB-_-RRB- Else_RB ,_, randomly_RB pick_VBP a_DT point_NN p_NN ∈_CD S_NN −_NN which_WDT strongly_RB dominates_VBZ C._NN -LRB-_-LRB- 4_CD -RRB-_-RRB- v_LS ∗_NN =_JJ 0_CD ;_: C_NN ∗_NN =_JJ null_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- foreach_JJ dimension_NN i_FW ,_, C_NN ′_NN =_JJ -LRB-_-LRB- C_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_JJ -_: ,_, ..._: ,_, p_NN -LRB-_-LRB- i_LS -RRB-_-RRB- ,_, ..._: ,_, C_NN -LRB-_-LRB- D_NN -RRB-_-RRB- -RRB-_-RRB- d_FW ′_FW ′_NN =_JJ d_FW ′_FW if_IN -LRB-_-LRB- C_NN -LRB-_-LRB- i_LS -RRB-_-RRB- =_JJ =_JJ −_FW ε_FW -RRB-_-RRB- d_FW ′_FW ′_NN =_JJ d_NN ′_CD +_CC 1_CD v_LS =_JJ QuickCorners_NNS -LRB-_-LRB- ∆_NN +_CC ,_, ∆_NNP −_NNP ,_, S_NNP −_NNP ,_, C_NNP ′_NNP ,_, d_NN ,_, d_FW ′_FW ′_FW -RRB-_-RRB- if_IN -LRB-_-LRB- v_LS -RRB-_-RRB- v_LS ∗_NN -RRB-_-RRB- thenv_JJ ∗_NN =_JJ v_LS ;_: C_NN ∗_NN =_JJ C_NN ′_FW endif_FW end_NN foreach_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- C_NN =_JJ C_NN ∗_FW ValidCorner_FW
tation_NN styles_NNS ._.
Moreover_RB ,_, the_DT training_NN data_NNS we_PRP can_MD collect_VB from_IN the_DT Internet_NNP may_MD contain_VB a_DT variety_NN of_IN errors_NNS ,_, such_JJ as_IN missing_VBG values_NNS ,_, spelling_NN errors_NNS ,_, inconsistent_JJ abbreviations_NNS ,_, and_CC extraneous_JJ tokens_NNS =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Another_DT challenge_NN is_VBZ that_IN different_JJ publication_NN types_NNS use_VBP a_DT variety_NN of_IN information_NN fields_NNS ._.
It_PRP is_VBZ difficult_JJ to_TO extract_VB all_PDT the_DT information_NN fields_NNS from_IN each_DT of_IN the_DT publication_NN types_NNS ._.
Therefore_RB ,_, in_FW thi_FW
nstrate_VB a_DT significant_JJ improvement_NN over_IN a_DT baseline_NN that_WDT only_RB relies_VBZ on_IN database_NN records_NNS during_IN training_NN ._.
For_IN the_DT baseline_NN we_PRP implemented_VBD an_DT enhanced_VBN version_NN of_IN the_DT state-ofthe-art_JJ system_NN presented_VBN in_IN -LRB-_-LRB- =_JJ -_: =_JJ Agichtein_NNP &_CC Ganti_NNP 2004_CD -_: =--RRB-_NN ._.
We_PRP generate_VBP ``_`` pseudo_NN ''_'' -_: textual_JJ records_NNS from_IN a_DT database_NN by_IN artificially_RB concatenating_VBG fields_NNS in_IN the_DT order_NN in_IN which_WDT they_PRP may_MD appear_VB in_IN the_DT real-world_NN ._.
Furthermore_RB ,_, real-world_JJ noise_NN -LRB-_-LRB- e.g._FW spelling_NN erro_NN
f_LS interest_NN from_IN Web_NN documents_NNS ._.
Several_JJ machine_NN learning_NN methods_NNS have_VBP been_VBN developed_VBN for_IN automatic_JJ wrapper_NN generation_NN by_IN learning_VBG extraction_NN models_NNS from_IN training_NN examples_NNS and_CC achieve_VB promising_JJ results_NNS =_JJ -_: =[_NN 11_CD ,_, 12_CD ,_, 13_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
All_DT these_DT methods_NNS suffer_VBP from_IN one_CD common_JJ shortcoming_NN in_IN that_IN the_DT learned_VBN wrapper_NN can_MD only_RB extract_VB the_DT attributes_NNS specified_VBN in_IN the_DT training_NN examples_NNS ._.
For_IN example_NN ,_, if_IN we_PRP just_RB annotate_VBP the_DT start_NN time_NN ,_,
ta_NN in_IN guiding_VBG extraction_NN ,_, and_CC therefore_RB apply_VB more_RBR IE-based_JJ approaches_NNS ._.
First_RB ,_, to_TO use_VB domain_NN models_NNS ,_, -LRB-_-LRB- 24_CD -RRB-_-RRB- applies_VBZ IE_NN by_IN training_VBG statistical_JJ models_NNS like_IN HMM_NNP or_CC CRF_NNP ._.
Second_RB ,_, to_TO leverage_NN existing_VBG data_NNS ,_, =_JJ -_: =[_NN 1_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: convert_VB the_DT clean_JJ reference_NN table_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- as_IN extraction_NN models_NNS ._.
In_IN comparison_NN ,_, our_PRP$ work_NN aims_VBZ at_IN a_DT broader_JJR notion_NN of_IN ``_`` context_NN ,_, ''_'' which_WDT accounts_VBZ for_IN not_RB only_RB prior_JJ knowledge_NN -LRB-_-LRB- domain_NN models_NNS and_CC existing_VBG wrapp_NN
ta_NN integration_NN and_CC bio-informatics_NNS ._.
For_IN example_NN ,_, during_IN warehouse_NN data_NNS cleaning_VBG a_DT common_JJ operation_NN is_VBZ to_TO extract_VB from_IN address_NN strings_NNS structured_VBD attributes_NNS like_IN street_NN names_NNS ,_, city_NN names_NNS and_CC addresses_VBZ =_JJ -_: =[_NN 2_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT lot_NN of_IN work_NN has_VBZ been_VBN done_VBN in_IN this_DT area_NN starting_VBG from_IN early_JJ rule-based_JJ systems_NNS -LRB-_-LRB- 4_CD -RRB-_-RRB- to_TO the_DT current_JJ highly_RB flexible_JJ and_CC powerful_JJ conditional_JJ graphical_JJ models_NNS -LRB-_-LRB- 18_CD -RRB-_-RRB- ._.
Typical_JJ NER_NN 1_CD systems_NNS rely_VBP on_IN vario_NN
._.
,_, name_NN ,_, co-authors_NNS ,_, and_CC pub-venues_NNS -RRB-_-RRB- ._.
Attributes_NNS can_MD be_VB atomic_JJ -LRB-_-LRB- e.g._FW ,_, name_NN -RRB-_-RRB- ,_, or_CC set-valued_JJ -LRB-_-LRB- e.g._FW ,_, co-authors_NNS -RRB-_-RRB- ._.
Many_JJ algorithms_NNS have_VBP been_VBN proposed_VBN to_TO extract_VB mention_NN attributes_NNS from_IN the_DT raw_JJ data_NNS -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 1_CD ,_, 7_CD ,_, 33_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Hence_RB ,_, similar_JJ to_TO recent_JJ work_NN on_IN mention_NN matching_NN -LRB-_-LRB- 5_CD ,_, 13_CD ,_, 24_CD ,_, 10_CD -RRB-_-RRB- ,_, we_PRP assume_VBP that_IN the_DT attributes_NNS have_VBP been_VBN extracted_VBN ,_, and_CC focus_VB on_IN the_DT problem_NN of_IN matching_VBG the_DT mentions_VBZ ._.
Figure_NN 3_CD ._.
a_DT shows_VBZ an_DT example_NN
Knoblock_NNP repository_NN 's_POS effectiveness_NN ,_, because_IN it_PRP always_RB returns_VBZ all_DT of_IN our_PRP$ sets_NNS ._.
Information_NN extraction_NN has_VBZ previously_RB incorporated_VBN outside_JJ information_NN to_TO aid_NN extraction_NN ._.
For_IN example_NN ,_, the_DT CRAM_NNP system_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ unsupervised_JJ ,_, and_CC uses_VBZ reference_NN sets_NNS ._.
However_RB ,_, unlike_IN this_DT paper_NN ,_, CRAM_NNP is_VBZ given_VBN the_DT reference_NN set_NN and_CC requires_VBZ that_IN all_DT tokens_NNS receive_VBP a_DT label_NN ,_, not_RB allowing_VBG for_IN `_`` junk_NN '_'' in_IN the_DT text_NN ._.
Other_JJ work_NN in_IN
ing_NN of_IN name_NN and_CC address_NN components_NNS into_IN consistent_JJ packets_NNS of_IN information_NN is_VBZ a_DT crucial_JJ part_NN in_IN the_DT data_NNS cleaning_NN process_NN ._.
Multiple_JJ parsing_NN methods_NNS have_VBP been_VBN proposed_VBN recently_RB in_IN the_DT literature_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 53_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 71_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 84_CD -RRB-_-RRB- -RRB-_-RRB- and_CC the_DT area_NN continues_VBZ to_TO be_VB an_DT active_JJ eld_NN of_IN research_NN ._.
Data_NN transformation_NN refers_VBZ to_TO simple_JJ conversions_NNS that_WDT can_MD be_VB applied_VBN to_TO the_DT data_NNS in_IN order_NN for_IN August_NNP 13_CD ,_, 2006_CD DRAFTAH_NN
