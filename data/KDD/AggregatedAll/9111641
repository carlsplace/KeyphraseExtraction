Spectral_JJ domain-transfer_JJ learning_NN
Traditional_JJ spectral_JJ classification_NN has_VBZ been_VBN proved_VBN to_TO be_VB effective_JJ in_IN dealing_VBG with_IN both_CC labeled_JJ and_CC unlabeled_JJ data_NNS when_WRB these_DT data_NNS are_VBP from_IN the_DT same_JJ domain_NN ._.
In_IN many_JJ real_JJ world_NN applications_NNS ,_, however_RB ,_, we_PRP wish_VBP to_TO make_VB use_NN of_IN the_DT labeled_JJ data_NNS from_IN one_CD domain_NN -LRB-_-LRB- called_VBN in-domain_JJ -RRB-_-RRB- to_TO classify_VB the_DT unlabeled_JJ data_NNS in_IN a_DT different_JJ domain_NN -LRB-_-LRB- out-of-domain_NN -RRB-_-RRB- ._.
This_DT problem_NN often_RB happens_VBZ when_WRB obtaining_VBG labeled_VBN data_NNS in_IN one_CD domain_NN is_VBZ difficult_JJ while_IN there_EX are_VBP plenty_NN of_IN labeled_JJ data_NNS from_IN a_DT related_JJ but_CC different_JJ domain_NN ._.
In_IN general_JJ ,_, this_DT is_VBZ a_DT transfer_NN learning_NN problem_NN where_WRB we_PRP wish_VBP to_TO classify_VB the_DT unlabeled_JJ data_NNS through_IN the_DT labeled_VBN data_NNS even_RB though_IN these_DT data_NNS are_VBP not_RB from_IN the_DT same_JJ domain_NN ._.
In_IN this_DT paper_NN ,_, we_PRP formulate_VBP this_DT domain-transfer_JJ learning_NN problem_NN under_IN a_DT novel_JJ spectral_JJ classification_NN framework_NN ,_, where_WRB the_DT objective_JJ function_NN is_VBZ introduced_VBN to_TO seek_VB consistency_NN between_IN the_DT in-domain_JJ supervision_NN and_CC the_DT out-of-domain_JJ intrinsic_JJ structure_NN ._.
Through_IN optimization_NN of_IN the_DT cost_NN function_NN ,_, the_DT label_NN information_NN from_IN the_DT in-domain_JJ data_NNS is_VBZ effectively_RB transferred_VBN to_TO help_VB classify_VB the_DT unlabeled_JJ data_NNS from_IN the_DT out-of-domain_NN ._.
We_PRP conduct_VBP extensive_JJ experiments_NNS to_TO evaluate_VB our_PRP$ method_NN and_CC show_VBP that_IN our_PRP$ algorithm_NN achieves_VBZ significant_JJ improvements_NNS on_IN classification_NN performance_NN over_IN many_JJ state-of-the-art_JJ algorithms_NNS ._.
xample_RB ,_, -LRB-_-LRB- 5_CD -RRB-_-RRB- adopts_VBZ the_DT boosting_VBG weight_NN formula_NN as_IN the_DT re-weighting_JJ scheme_NN ._.
Some_DT other_JJ methods_NNS base_VBP on_IN dimension_NN reduction_NN ,_, which_WDT usually_RB map_VBP data_NNS to_TO a_DT new_JJ representation_NN facilitating_VBG domain_NN transfer_NN -LRB-_-LRB- =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Recently_RB ,_, -LRB-_-LRB- 9_CD -RRB-_-RRB- proposes_VBZ a_DT locally_RB weighted_JJ ensemble_NN framework_NN to_TO combine_VB multiple_JJ models_NNS for_IN transfer_NN learning_NN by_IN dynamically_RB assigning_VBG weights_NNS of_IN a_DT model_NN according_VBG to_TO a_DT model_NN 's_POS predictive_JJ power_NN on_IN
ptation_NN techniques_NNS specifically_RB developed_VBD for_IN text_NN and_CC sentiment_NN classification_NN -LRB-_-LRB- e.g._FW ,_, Blitzer_NNP ,_, McDonald_NNP ,_, &_CC Pereira_NNP ,_, 2006_CD ;_: Finn_NNP &_CC Kushmerick_NNP ,_, 2006_CD ;_: Blitzer_NNP et_FW al._FW ,_, 2007_CD ;_: Gao_NNP ,_, Fan_NNP ,_, Jiang_NNP ,_, &_CC Han_NNP ,_, 2008_CD ;_: =_JJ -_: =_JJ Ling_NNP ,_, Dai_NNP ,_, Xue_NNP ,_, Yang_NNP ,_, &_CC Yu_NNP ,_, 2008_CD -_: =_JJ -_: ;_: Tan_NNP ,_, Cheng_NNP ,_, Wang_NNP ,_, &_CC Xu_NNP ,_, 2009_CD -RRB-_-RRB- ._.
It_PRP is_VBZ worth_JJ noting_VBG that_IN our_PRP$ domain_NN adaptation_NN setting_NN is_VBZ different_JJ from_IN the_DT traditional_JJ setting_NN ._.
Traditionally_RB ,_, sophisticated_JJ classifiers_NNS and\/or_CC an_DT automatically_RB const_VBN
fined_VBN objective_JJ functions_NNS ,_, including_VBG maximizing_VBG the_DT empirical_JJ likelihood_NN -LRB-_-LRB- Dai_NNP et_FW al._FW 2007_CD ;_: Zhuang_NNP et_FW al._FW 2010_CD ;_: Wang_NNP et_FW al._FW 2011_CD ;_: Zhuang_NNP et_FW al._FW 2011_CD -RRB-_-RRB- ,_, and_CC preserving_VBG the_DT intrinsic_JJ geometric_JJ structure_NN -LRB-_-LRB- =_JJ -_: =_JJ Ling_NNP et_FW al._FW 2008_CD -_: =_JJ -_: ;_: Pan_NNP et_FW al._FW 2011_CD ;_: Wang_NNP and_CC Mahadevan_NNP 2009_CD ;_: 2011_CD -RRB-_-RRB- ._.
Actually_RB ,_, these_DT objective_NN functions_VBZ focus_NN on_IN different_JJ aspects_NNS of_IN the_DT data_NNS and_CC are_VBP complementary_JJ to_TO each_DT other_JJ to_TO some_DT extent_NN -LRB-_-LRB- Zhu_NNP and_CC Lafferty_NNP 2005_CD -RRB-_-RRB-
st_IN importantly_RB ,_, it_PRP outperforms_VBZ ,_, by_IN up_IN to_TO 10_CD %_NN in_IN accuracy_NN ,_, several_JJ state-of-art_JJ approaches_NNS proposed_VBN to_TO solve_VB specific_JJ category_NN of_IN distribution_NN difference_NN ,_, i._NNP e_LS ,_, BRSD_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- for_IN sample_NN selection_NN bias_NN ,_, CDSC_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: for_IN transfer_NN learning_NN ,_, etc._NN ._.
The_DT main_JJ claim_NN is_VBZ that_IN the_DT adaptive_JJ graph_NN transduction_NN is_VBZ a_DT general_JJ and_CC competitive_JJ method_NN to_TO solve_VB distribution_NN differences_NNS implicitly_RB without_IN knowing_VBG and_CC worrying_VBG about_IN
eral_NN works_VBZ about_IN supervised_JJ spectral_JJ methods_NNS have_VBP been_VBN proposed_VBN to_TO apply_VB the_DT labeled_JJ examples_NNS to_TO help_VB find_VB the_DT eigenspace_NN of_IN the_DT target_NN data_NNS drawn_VBN from_IN the_DT same_JJ or_CC very_RB similar_JJ distributions_NNS ,_, such_JJ as_IN =_JJ -_: =[_NN 11,15,23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Unlike_IN most_JJS of_IN these_DT works_NNS ,_, in_IN this_DT paper_NN ,_, we_PRP generate_VBP a_DT partition_NN of_IN the_DT unlabeled_JJ data_NNS by_IN transferring_VBG knowledge_NN from_IN the_DT given_VBN labeled_JJ data_NNS that_WDT may_MD have_VB very_RB different_JJ distributions_NNS and_CC class_NN ca_MD
re_IN selected_VBN nonrandomly_RB ._.
Originated_VBN from_IN the_DT Nobel-prize_JJ work_NN in_IN 2000_CD ,_, -LRB-_-LRB- 17_CD -RRB-_-RRB- made_VBD his_PRP$ contributions_NNS on_IN correction_NN of_IN sample_NN selection_NN bias_NN in_IN econometrics_NNS ._.
Recent_JJ researches_VBZ on_IN covariate_NN shift_NN include_VBP =_JJ -_: =[_NN 35_CD ,_, 29_CD ,_, 18_CD ,_, 4_CD ,_, 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
They_PRP used_VBD the_DT instance_NN weighting_NN method_NN to_TO correct_VB the_DT bias_NN ._.
Although_IN correcting_VBG sample_NN selection_NN bias_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- can_MD solve_VB the_DT classification_NN when_WRB training_NN and_CC test_NN data_NNS are_VBP governed_VBN by_IN different_JJ selecti_NNS
tives_NNS are_VBP simultaneously_RB being_VBG followed_VBN ._.
On_IN one_CD hand_NN ,_, we_PRP seek_VBP an_DT optimal_JJ partition_NN of_IN the_DT data_NNS that_WDT respect_VBP the_DT label_NN information_NN ,_, where_WRB the_DT labels_NNS are_VBP considered_VBN in_IN the_DT form_NN of_IN must-link_JJ constraints_NNS =_JJ -_: =[_NN 31_CD -RRB-_-RRB- -_: =_JJ -_: ;_: that_DT is_VBZ ,_, the_DT corresponding_JJ data_NN points_NNS with_IN respect_NN to_TO each_DT constraint_NN must_MD be_VB with_IN the_DT same_JJ label_NN ._.
On_IN the_DT other_JJ hand_NN ,_, the_DT test_NN data_NNS are_VBP split_VBN as_RB separately_RB as_IN possible_JJ in_IN terms_NNS of_IN the_DT cut_NN size_NN with_IN
luster_NN similarity_NN and_CC maximizing_VBG the_DT intra-cluster_JJ connection_NN ._.
Several_JJ criteria_NNS were_VBD proposed_VBN to_TO quantify_VB the_DT objective_JJ function_NN ,_, such_JJ as_IN Ratio_NNP Cut_NNP -LRB-_-LRB- 8_CD -RRB-_-RRB- ,_, Normalized_VBN Cut_NNP -LRB-_-LRB- NCut_NN -RRB-_-RRB- -LRB-_-LRB- 28_CD -RRB-_-RRB- ,_, Min-Max_NNP Cut_NNP -LRB-_-LRB- MCut_NN -RRB-_-RRB- =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Using_VBG graph_NN theory_NN terminology_NN ,_, the_DT data_NNS are_VBP modeled_VBN as_IN vertices_NNS and_CC the_DT edges_NNS are_VBP valued_VBN using_VBG the_DT similarity_NN of_IN the_DT endpoints_NNS ._.
We_PRP denote_VBP V_NN as_IN the_DT universe_NN of_IN all_DT examples_NNS and_CC V_NN =_JJ A_NN ∪_NN B_NN where_WRB -LCB-_-LRB- A_NN ,_, B_NN
fy_IN the_DT effectiveness_NN of_IN our_PRP$ classifier_NN ,_, the_DT supervised_JJ learner_NN SVM_NN is_VBZ set_VBN as_IN the_DT baseline_NN method_NN ._.
Our_PRP$ method_NN is_VBZ also_RB compared_VBN to_TO several_JJ semi-supervised_JJ classifiers_NNS ,_, including_VBG Transductive_JJ SVM_NN -LRB-_-LRB- TSVM_NN -RRB-_-RRB- =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Spectral_JJ Graph_NN Transducer_NN -LRB-_-LRB- SGT_NN -RRB-_-RRB- -LRB-_-LRB- 21_CD -RRB-_-RRB- and_CC Spectral_JJ Classifier_NN -LRB-_-LRB- SC_NN -RRB-_-RRB- -LRB-_-LRB- 22_CD -RRB-_-RRB- ._.
Note_VB that_DT -LRB-_-LRB- 22_CD -RRB-_-RRB- is_VBZ approximately_RB a_DT special_JJ case_NN CDSC_NN with_IN λ_NN =_JJ 0_CD ._.
We_PRP also_RB compare_VBP to_TO the_DT co-clustering_JJ based_JJ classification_NN -LRB-_-LRB- CoCC_NN
ned_VBN in_IN Section_NN 4.1_CD ,_, we_PRP have_VBP conducted_VBN preprocessing_VBG procedures_NNS including_VBG tokenizing_VBG text_NN into_IN bag-of-words_NNS ,_, converting_VBG text_NN into_IN low-case_JJ words_NNS ,_, stopword_NN removal_NN and_CC stemming_VBG using_VBG the_DT Porter_NNP stemmer_NN =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Each_DT document_NN di_FW in_IN S_NN is_VBZ represented_VBN by_IN a_DT feature_NN vector_NN using_VBG Vector_NNP Space_NNP Model_NNP ._.
Each_DT feature_NN represents_VBZ a_DT term_NN ,_, whichisweightedbyitstf-idf_JJ value_NN ._.
Feature_NN selection_NN is_VBZ carried_VBN out_RP by_IN thresholding_VBG
cal_JJ classifier_NN under_IN the_DT Conditional_JJ Expectation-Maximization_NN framework_NN ._.
Those_DT ``_`` in-domain_JJ ''_'' data_NNS play_VBP a_DT role_NN as_IN auxiliary_JJ data_NNS in_IN tackling_VBG the_DT scarcity_NN of_IN ``_`` out-of-domain_JJ ''_'' training_NN data_NNS ._.
In_IN these_DT works_NNS =_JJ -_: =[_NN 32_CD ,_, 23_CD ,_, 14_CD ,_, 13_CD ,_, 12_CD -RRB-_-RRB- -_: =_JJ -_: ,_, auxiliary_JJ data_NNS serve_VBP as_IN a_DT supplement_NN to_TO the_DT ordinary_JJ training_NN data_NNS ._.
In_IN contrast_NN to_TO these_DT works_NNS ,_, our_PRP$ work_NN focuses_VBZ on_IN the_DT second_JJ category_NN of_IN domain-transfer_JJ learning_NN ,_, where_WRB the_DT problem_NN is_VBZ classificati_NNS
labeled_VBN and_CC unlabeled_JJ data_NNS come_VBP from_IN different_JJ domains_NNS ._.
There_EX are_VBP several_JJ reasons_NNS for_IN why_WRB it_PRP is_VBZ important_JJ to_TO consider_VB this_DT domain-transfer_JJ learning_NN problem_NN ,_, which_WDT is_VBZ an_DT instance_NN of_IN transfer_NN learning_NN =_JJ -_: =[_NN 27_CD ,_, 30_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
First_RB ,_, the_DT labeled_JJ information_NN is_VBZ often_RB scarce_JJ in_IN a_DT target_NN domain_NN ,_, while_IN a_DT lot_NN of_IN available_JJ labeled_JJ data_NNS may_MD exist_VB from_IN a_DT different_JJ but_CC related_JJ domain_NN ._.
In_IN this_DT case_NN ,_, it_PRP would_MD be_VB desired_VBN to_TO make_VB maxi_NNS
o_NN classify_VB the_DT test_NN data_NNS from_IN out-of-domain_JJ Dout_NNP as_RB accurately_RB as_IN possible_JJ using_VBG the_DT training_NN data_NNS from_IN indomain_JJ Din_NN ._.
Although_IN several_JJ cross-domain_JJ classification_NN algorithms_NNS have_VBP been_VBN proposed_VBN ,_, e.g._FW ,_, =_JJ -_: =[_NN 10_CD ,_, 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, they_PRP are_VBP all_DT based_VBN on_IN localoptimization_NN ._.
When_WRB the_DT labeled_JJ and_CC unlabeled_JJ data_NNS are_VBP not_RB sufficiently_RB large_JJ ,_, their_PRP$ optimization_NN function_NN may_MD have_VB a_DT lot_NN of_IN local_JJ minima_NN and_CC bring_VB much_JJ difficulty_NN for_IN cla_NN
g_NN the_DT information_NN in_IN the_DT eigenvectors_NNS of_IN a_DT data_NN similarity_NN matrix_NN to_TO find_VB the_DT intrinsic_JJ structure_NN ,_, spectral_JJ methods_NNS have_VBP been_VBN extended_VBN from_IN unsupervised_JJ learning_NN to_TO supervised\/semisupervised_JJ learning_NN =_JJ -_: =[_NN 22_CD ,_, 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB a_DT unified_JJ framework_NN is_VBZ Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN all_DT or_CC part_NN of_IN this_DT work_NN for_IN personal_JJ or_CC classroom_NN use_NN is_VBZ granted_VBN without_IN fee_NN provided_VBN that_IN copies_NNS are_VBP not_RB made_VBN or_CC distribut_NN
re_IN selected_VBN nonrandomly_RB ._.
Originated_VBN from_IN the_DT Nobel-prize_JJ work_NN in_IN 2000_CD ,_, -LRB-_-LRB- 17_CD -RRB-_-RRB- made_VBD his_PRP$ contributions_NNS on_IN correction_NN of_IN sample_NN selection_NN bias_NN in_IN econometrics_NNS ._.
Recent_JJ researches_VBZ on_IN covariate_NN shift_NN include_VBP =_JJ -_: =[_NN 35_CD ,_, 29_CD ,_, 18_CD ,_, 4_CD ,_, 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
They_PRP used_VBD the_DT instance_NN weighting_NN method_NN to_TO correct_VB the_DT bias_NN ._.
Although_IN correcting_VBG sample_NN selection_NN bias_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- can_MD solve_VB the_DT classification_NN when_WRB training_NN and_CC test_NN data_NNS are_VBP governed_VBN by_IN different_JJ selecti_NNS
le_DT the_DT domain-transfer_NN problem_NN through_IN spectral_JJ learning_NN ._.
As_IN we_PRP showed_VBD in_IN the_DT experiments_NNS ,_, our_PRP$ algorithm_NN shows_VBZ superiority_NN over_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, when_WRB the_DT data_NNS size_NN is_VBZ not_RB sufficiently_RB large_JJ ._.
Other_JJ work_NN includes_VBZ =_JJ -_: =[_NN 6_CD ,_, 1_CD ,_, 11_CD ,_, 33_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Covariate_JJ shift_NN -LRB-_-LRB- 29_CD -RRB-_-RRB- -LRB-_-LRB- or_CC sample_NN selection_NN bias_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- -RRB-_-RRB- is_VBZ a_DT similar_JJ problem_NN which_WDT occurs_VBZ when_WRB samples_NNS are_VBP selected_VBN nonrandomly_RB ._.
Originated_VBN from_IN the_DT Nobel-prize_JJ work_NN in_IN 2000_CD ,_, -LRB-_-LRB- 17_CD -RRB-_-RRB- made_VBD his_PRP$ contribution_NN
le_DT the_DT domain-transfer_NN problem_NN through_IN spectral_JJ learning_NN ._.
As_IN we_PRP showed_VBD in_IN the_DT experiments_NNS ,_, our_PRP$ algorithm_NN shows_VBZ superiority_NN over_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, when_WRB the_DT data_NNS size_NN is_VBZ not_RB sufficiently_RB large_JJ ._.
Other_JJ work_NN includes_VBZ =_JJ -_: =[_NN 6_CD ,_, 1_CD ,_, 11_CD ,_, 33_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Covariate_JJ shift_NN -LRB-_-LRB- 29_CD -RRB-_-RRB- -LRB-_-LRB- or_CC sample_NN selection_NN bias_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- -RRB-_-RRB- is_VBZ a_DT similar_JJ problem_NN which_WDT occurs_VBZ when_WRB samples_NNS are_VBP selected_VBN nonrandomly_RB ._.
Originated_VBN from_IN the_DT Nobel-prize_JJ work_NN in_IN 2000_CD ,_, -LRB-_-LRB- 17_CD -RRB-_-RRB- made_VBD his_PRP$ contribution_NN
CDSC_NN with_IN λ_NN =_JJ 0_CD ._.
We_PRP also_RB compare_VBP to_TO the_DT co-clustering_JJ based_JJ classification_NN -LRB-_-LRB- CoCC_NN -RRB-_-RRB- -LRB-_-LRB- 10_CD -RRB-_-RRB- as_IN the_DT state-of-the-art_JJ domain-transfer_JJ learning_NN algorithm_NN and_CC one_CD representative_JJ selection_NN bias_NN correction_NN -LRB-_-LRB- KDE_NN -RRB-_-RRB- =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_SYM -_: ._.
CoCC_NN builds_VBZ connection_NN between_IN in-domain_NN and_CC out-of-domain_NN through_IN feature_NN clustering_NN ,_, and_CC is_VBZ formulated_VBN under_IN the_DT co-clustering_JJ framework_NN ._.
KDE_NNP corrects_VBZ the_DT domain_NN bias_NN in_IN the_DT in-domain_NN ,_, and_CC then_RB ad_NN
,_, the_DT supervised_JJ learner_NN SVM_NN is_VBZ set_VBN as_IN the_DT baseline_NN method_NN ._.
Our_PRP$ method_NN is_VBZ also_RB compared_VBN to_TO several_JJ semi-supervised_JJ classifiers_NNS ,_, including_VBG Transductive_JJ SVM_NN -LRB-_-LRB- TSVM_NN -RRB-_-RRB- -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, Spectral_JJ Graph_NN Transducer_NN -LRB-_-LRB- SGT_NN -RRB-_-RRB- =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Spectral_JJ Classifier_NN -LRB-_-LRB- SC_NN -RRB-_-RRB- -LRB-_-LRB- 22_CD -RRB-_-RRB- ._.
Note_VB that_DT -LRB-_-LRB- 22_CD -RRB-_-RRB- is_VBZ approximately_RB a_DT special_JJ case_NN CDSC_NN with_IN λ_NN =_JJ 0_CD ._.
We_PRP also_RB compare_VBP to_TO the_DT co-clustering_JJ based_JJ classification_NN -LRB-_-LRB- CoCC_NN -RRB-_-RRB- -LRB-_-LRB- 10_CD -RRB-_-RRB- as_IN the_DT state-of-the-art_JJ domain_NN -_:
g_NN the_DT information_NN in_IN the_DT eigenvectors_NNS of_IN a_DT data_NN similarity_NN matrix_NN to_TO find_VB the_DT intrinsic_JJ structure_NN ,_, spectral_JJ methods_NNS have_VBP been_VBN extended_VBN from_IN unsupervised_JJ learning_NN to_TO supervised\/semisupervised_JJ learning_NN =_JJ -_: =[_NN 22_CD ,_, 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB a_DT unified_JJ framework_NN is_VBZ Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN all_DT or_CC part_NN of_IN this_DT work_NN for_IN personal_JJ or_CC classroom_NN use_NN is_VBZ granted_VBN without_IN fee_NN provided_VBN that_IN copies_NNS are_VBP not_RB made_VBN or_CC distribut_NN
Dx_NN =_JJ xT_NN -LRB-_-LRB- -LRB-_-LRB- D_NN −_NN W_NN -RRB-_-RRB- +_CC λ_NN -LRB-_-LRB- Ds_NNS −_FW Ws_FW -RRB-_-RRB- -RRB-_-RRB- x_NN xT_NN +_CC β_FW |_FW |_FW U_NN Dx_NN T_NN x_NN |_FW |_FW 2_CD ._.
-LRB-_-LRB- 6_CD -RRB-_-RRB- The_DT similarity_NN matrix_NN is_VBZ thus_RB modified_VBN by_IN amplifying_VBG the_DT similarity_NN inside_IN the_DT test_NN data_NNS submatrix_NN ._.
In_IN the_DT interpretation_NN through_IN random_JJ walk_NN =_JJ -_: =[_NN 24_CD -RRB-_-RRB- -_: =_JJ -_: ,_, this_DT modification_NN can_MD be_VB seen_VBN as_IN increasing_VBG the_DT transition_NN probability_NN inside_IN the_DT test_NN data_NNS ._.
Replacing_VBG y_NN T_NN =_JJ x_NN T_NN D_NN 1\/2_CD \/_: |_FW |_FW x_NN T_NN D_NN 1\/2_CD |_FW |_FW ,_, x_NN T_NN -LRB-_-LRB- D_NN −_NN W_NN -RRB-_-RRB- x_NN xT_NN Dx_NN Similarly_RB ,_, x_NN T_NN -LRB-_-LRB- Ds_NNS −_FW Ws_FW -RRB-_-RRB- x_NN xT_NN Dx_NN With_IN Equat_NN
e_LS discretization_NN ,_, linear_JJ order_NN search_NN -LRB-_-LRB- 28_CD -RRB-_-RRB- and_CC other_JJ variant_JJ search_NN methods_NNS -LRB-_-LRB- e.g._FW linkage_NN differential_JJ order_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- -RRB-_-RRB- are_VBP commonly_RB used_VBN to_TO derive_VB the_DT cluster_NN membership_NN ._.
Another_DT approach_NN was_VBD proposed_VBN in_IN =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_SYM -_: which_WDT first_RB normalizes_VBZ the_DT eigenvectors_NNS and_CC then_RB applies_VBZ the_DT K-Means_JJ clustering_NN method_NN ._.
3_LS ._.
CROSS-DOMAIN_FW SPECTRAL_FW CLASSIFICATION_NN 3.1_CD Problem_NNP Definition_NNP For_IN conciseness_NN and_CC clarity_NN ,_, in_IN this_DT paper_NN we_PRP ma_FW
le_DT the_DT domain-transfer_NN problem_NN through_IN spectral_JJ learning_NN ._.
As_IN we_PRP showed_VBD in_IN the_DT experiments_NNS ,_, our_PRP$ algorithm_NN shows_VBZ superiority_NN over_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, when_WRB the_DT data_NNS size_NN is_VBZ not_RB sufficiently_RB large_JJ ._.
Other_JJ work_NN includes_VBZ =_JJ -_: =[_NN 6_CD ,_, 1_CD ,_, 11_CD ,_, 33_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Covariate_JJ shift_NN -LRB-_-LRB- 29_CD -RRB-_-RRB- -LRB-_-LRB- or_CC sample_NN selection_NN bias_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- -RRB-_-RRB- is_VBZ a_DT similar_JJ problem_NN which_WDT occurs_VBZ when_WRB samples_NNS are_VBP selected_VBN nonrandomly_RB ._.
Originated_VBN from_IN the_DT Nobel-prize_JJ work_NN in_IN 2000_CD ,_, -LRB-_-LRB- 17_CD -RRB-_-RRB- made_VBD his_PRP$ contribution_NN
le_DT the_DT domain-transfer_NN problem_NN through_IN spectral_JJ learning_NN ._.
As_IN we_PRP showed_VBD in_IN the_DT experiments_NNS ,_, our_PRP$ algorithm_NN shows_VBZ superiority_NN over_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, when_WRB the_DT data_NNS size_NN is_VBZ not_RB sufficiently_RB large_JJ ._.
Other_JJ work_NN includes_VBZ =_JJ -_: =[_NN 6_CD ,_, 1_CD ,_, 11_CD ,_, 33_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Covariate_JJ shift_NN -LRB-_-LRB- 29_CD -RRB-_-RRB- -LRB-_-LRB- or_CC sample_NN selection_NN bias_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- -RRB-_-RRB- is_VBZ a_DT similar_JJ problem_NN which_WDT occurs_VBZ when_WRB samples_NNS are_VBP selected_VBN nonrandomly_RB ._.
Originated_VBN from_IN the_DT Nobel-prize_JJ work_NN in_IN 2000_CD ,_, -LRB-_-LRB- 17_CD -RRB-_-RRB- made_VBD his_PRP$ contribution_NN
ier_NN to_TO learn_VB to_TO play_VB chess_NN ._.
Previous_JJ works_NNS in_IN transfer_NN learning_NN include_VBP ``_`` learning_VBG how_WRB to_TO learn_VB ''_'' -LRB-_-LRB- 27_CD -RRB-_-RRB- ,_, ``_`` learning_VBG one_CD more_JJR thing_NN ''_'' -LRB-_-LRB- 30_CD -RRB-_-RRB- and_CC ``_`` multi-task_JJ learning_NN ''_'' -LRB-_-LRB- 7_CD -RRB-_-RRB- ,_, which_WDT laid_VBD the_DT initial_JJ foundations_NNS ._.
=_SYM -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: presented_VBD the_DT notion_NN of_IN relatedness_NN between_IN learning_VBG tasks_NNS ,_, which_WDT provided_VBD theoretical_JJ justifications_NNS for_IN transfer_NN learning_NN ._.
In_IN our_PRP$ problem_NN setting_NN ,_, we_PRP aim_VBP to_TO accomplish_VB the_DT same_JJ task_NN -LRB-_-LRB- i.e._FW learn_VB wit_NN
le_DT the_DT domain-transfer_NN problem_NN through_IN spectral_JJ learning_NN ._.
As_IN we_PRP showed_VBD in_IN the_DT experiments_NNS ,_, our_PRP$ algorithm_NN shows_VBZ superiority_NN over_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, when_WRB the_DT data_NNS size_NN is_VBZ not_RB sufficiently_RB large_JJ ._.
Other_JJ work_NN includes_VBZ =_JJ -_: =[_NN 6_CD ,_, 1_CD ,_, 11_CD ,_, 33_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Covariate_JJ shift_NN -LRB-_-LRB- 29_CD -RRB-_-RRB- -LRB-_-LRB- or_CC sample_NN selection_NN bias_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- -RRB-_-RRB- is_VBZ a_DT similar_JJ problem_NN which_WDT occurs_VBZ when_WRB samples_NNS are_VBP selected_VBN nonrandomly_RB ._.
Originated_VBN from_IN the_DT Nobel-prize_JJ work_NN in_IN 2000_CD ,_, -LRB-_-LRB- 17_CD -RRB-_-RRB- made_VBD his_PRP$ contribution_NN
cal_JJ classifier_NN under_IN the_DT Conditional_JJ Expectation-Maximization_NN framework_NN ._.
Those_DT ``_`` in-domain_JJ ''_'' data_NNS play_VBP a_DT role_NN as_IN auxiliary_JJ data_NNS in_IN tackling_VBG the_DT scarcity_NN of_IN ``_`` out-of-domain_JJ ''_'' training_NN data_NNS ._.
In_IN these_DT works_NNS =_JJ -_: =[_NN 32_CD ,_, 23_CD ,_, 14_CD ,_, 13_CD ,_, 12_CD -RRB-_-RRB- -_: =_JJ -_: ,_, auxiliary_JJ data_NNS serve_VBP as_IN a_DT supplement_NN to_TO the_DT ordinary_JJ training_NN data_NNS ._.
In_IN contrast_NN to_TO these_DT works_NNS ,_, our_PRP$ work_NN focuses_VBZ on_IN the_DT second_JJ category_NN of_IN domain-transfer_JJ learning_NN ,_, where_WRB the_DT problem_NN is_VBZ classificati_NNS
re_IN selected_VBN nonrandomly_RB ._.
Originated_VBN from_IN the_DT Nobel-prize_JJ work_NN in_IN 2000_CD ,_, -LRB-_-LRB- 17_CD -RRB-_-RRB- made_VBD his_PRP$ contributions_NNS on_IN correction_NN of_IN sample_NN selection_NN bias_NN in_IN econometrics_NNS ._.
Recent_JJ researches_VBZ on_IN covariate_NN shift_NN include_VBP =_JJ -_: =[_NN 35_CD ,_, 29_CD ,_, 18_CD ,_, 4_CD ,_, 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
They_PRP used_VBD the_DT instance_NN weighting_NN method_NN to_TO correct_VB the_DT bias_NN ._.
Although_IN correcting_VBG sample_NN selection_NN bias_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- can_MD solve_VB the_DT classification_NN when_WRB training_NN and_CC test_NN data_NNS are_VBP governed_VBN by_IN different_JJ selecti_NNS
ll_NN parameters_NNS are_VBP set_VBN default_NN by_IN the_DT software_NN ._.
The_DT Spectral_JJ Classifier_NN -LRB-_-LRB- SC_NN -RRB-_-RRB- is_VBZ implemented_VBN according_VBG to_TO -LRB-_-LRB- 22_CD -RRB-_-RRB- ._.
CoCC_NN uses_VBZ the_DT same_JJ initialization_NN and_CC parameters_NNS in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
KDE_NNP is_VBZ implemented_VBN according_VBG to_TO =_JJ -_: =[_NN 29_CD ,_, 35_CD -RRB-_-RRB- -_: =_SYM -_: ._.
4.4_CD Experimental_JJ Results_NNS 4.4.1_CD Performance_NNP By_IN comparing_VBG with_IN the_DT traditional_JJ supervised_JJ classifier_NN ,_, it_PRP is_VBZ observed_VBN that_IN the_DT cross-domain_JJ data_NNS present_VBP much_JJ difficulty_NN in_IN classification_NN ,_, where_WRB SVM_NN -LRB-_-LRB- tr_NN
art_NN algorithms_NNS ._.
Categories_NNS and_CC Subject_NNP Descriptors_NNP I._NNP 2.6_CD -LRB-_-LRB- Artificial_JJ Intelligence_NNP -RRB-_-RRB- :_: Learning_NNP General_NNP Terms_NNS Algorithms_NNS ,_, Experimentation_NN 1_CD ._.
INTRODUCTION_NN Spectral_JJ learning_NN methods_NNS such_JJ as_IN normalized_VBN cut_NN =_JJ -_: =[_NN 28_CD -RRB-_-RRB- -_: =_SYM -_: are_VBP increasingly_RB being_VBG applied_VBN to_TO many_JJ learning_VBG tasks_NNS such_JJ as_IN document_NN clustering_NN and_CC image_NN segmentation_NN ._.
Exploiting_VBG the_DT information_NN in_IN the_DT eigenvectors_NNS of_IN a_DT data_NN similarity_NN matrix_NN to_TO find_VB the_DT intrin_NN
in_IN S_NN is_VBZ represented_VBN by_IN a_DT feature_NN vector_NN using_VBG Vector_NNP Space_NNP Model_NNP ._.
Each_DT feature_NN represents_VBZ a_DT term_NN ,_, whichisweightedbyitstf-idf_JJ value_NN ._.
Feature_NN selection_NN is_VBZ carried_VBN out_RP by_IN thresholding_VBG Document_NNP Frequency_NN =_JJ -_: =[_NN 34_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN our_PRP$ experiments_NNS ,_, Document_NNP Frequency_NNP threshold_NN is_VBZ set_VBN to_TO 3_CD ,_, and_CC the_DT final_JJ result_NN is_VBZ not_RB sensitive_JJ to_TO it_PRP ._.
The_DT cosine_NN similarity_NN measure_NN x_NN i_FW ·_FW x_NN j_NN |_CD x_NN i_FW |_FW |_FW x_NN j_NN |_CD is_VBZ adopted_VBN when_WRB constructing_VBG the_DT similari_NN
o_NN classify_VB the_DT test_NN data_NNS from_IN out-of-domain_JJ Dout_NNP as_RB accurately_RB as_IN possible_JJ using_VBG the_DT training_NN data_NNS from_IN indomain_JJ Din_NN ._.
Although_IN several_JJ cross-domain_JJ classification_NN algorithms_NNS have_VBP been_VBN proposed_VBN ,_, e.g._FW ,_, =_JJ -_: =[_NN 10_CD ,_, 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, they_PRP are_VBP all_DT based_VBN on_IN localoptimization_NN ._.
When_WRB the_DT labeled_JJ and_CC unlabeled_JJ data_NNS are_VBP not_RB sufficiently_RB large_JJ ,_, their_PRP$ optimization_NN function_NN may_MD have_VB a_DT lot_NN of_IN local_JJ minima_NN and_CC bring_VB much_JJ difficulty_NN for_IN cla_NN
labeled_VBN and_CC unlabeled_JJ data_NNS come_VBP from_IN different_JJ domains_NNS ._.
There_EX are_VBP several_JJ reasons_NNS for_IN why_WRB it_PRP is_VBZ important_JJ to_TO consider_VB this_DT domain-transfer_JJ learning_NN problem_NN ,_, which_WDT is_VBZ an_DT instance_NN of_IN transfer_NN learning_NN =_JJ -_: =[_NN 27_CD ,_, 30_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
First_RB ,_, the_DT labeled_JJ information_NN is_VBZ often_RB scarce_JJ in_IN a_DT target_NN domain_NN ,_, while_IN a_DT lot_NN of_IN available_JJ labeled_JJ data_NNS may_MD exist_VB from_IN a_DT different_JJ but_CC related_JJ domain_NN ._.
In_IN this_DT case_NN ,_, it_PRP would_MD be_VB desired_VBN to_TO make_VB maxi_NNS
includes_VBZ -LRB-_-LRB- 6_CD ,_, 1_CD ,_, 11_CD ,_, 33_CD ,_, 5_CD -RRB-_-RRB- ._.
Covariate_JJ shift_NN -LRB-_-LRB- 29_CD -RRB-_-RRB- -LRB-_-LRB- or_CC sample_NN selection_NN bias_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- -RRB-_-RRB- is_VBZ a_DT similar_JJ problem_NN which_WDT occurs_VBZ when_WRB samples_NNS are_VBP selected_VBN nonrandomly_RB ._.
Originated_VBN from_IN the_DT Nobel-prize_JJ work_NN in_IN 2000_CD ,_, =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: made_VBD his_PRP$ contributions_NNS on_IN correction_NN of_IN sample_NN selection_NN bias_NN in_IN econometrics_NNS ._.
Recent_JJ researches_VBZ on_IN covariate_NN shift_NN include_VBP -LRB-_-LRB- 35_CD ,_, 29_CD ,_, 18_CD ,_, 4_CD ,_, 3_CD -RRB-_-RRB- ._.
They_PRP used_VBD the_DT instance_NN weighting_NN method_NN to_TO correct_VB the_DT
cal_JJ classifier_NN under_IN the_DT Conditional_JJ Expectation-Maximization_NN framework_NN ._.
Those_DT ``_`` in-domain_JJ ''_'' data_NNS play_VBP a_DT role_NN as_IN auxiliary_JJ data_NNS in_IN tackling_VBG the_DT scarcity_NN of_IN ``_`` out-of-domain_JJ ''_'' training_NN data_NNS ._.
In_IN these_DT works_NNS =_JJ -_: =[_NN 32_CD ,_, 23_CD ,_, 14_CD ,_, 13_CD ,_, 12_CD -RRB-_-RRB- -_: =_JJ -_: ,_, auxiliary_JJ data_NNS serve_VBP as_IN a_DT supplement_NN to_TO the_DT ordinary_JJ training_NN data_NNS ._.
In_IN contrast_NN to_TO these_DT works_NNS ,_, our_PRP$ work_NN focuses_VBZ on_IN the_DT second_JJ category_NN of_IN domain-transfer_JJ learning_NN ,_, where_WRB the_DT problem_NN is_VBZ classificati_NNS
