Exploiting_VBG dictionaries_NNS in_IN named_VBN entity_NN extraction_NN :_: combining_VBG semi-Markov_JJ extraction_NN processes_NNS and_CC data_NNS integration_NN methods_NNS
We_PRP consider_VBP the_DT problem_NN of_IN improving_VBG named_VBN entity_NN recognition_NN -LRB-_-LRB- NER_NN -RRB-_-RRB- systems_NNS by_IN using_VBG external_JJ dictionaries_NNS --_: more_RBR specifically_RB ,_, the_DT problem_NN of_IN extending_VBG state-of-the-art_JJ NER_NN systems_NNS by_IN incorporating_VBG information_NN about_IN the_DT similarity_NN of_IN extracted_VBN entities_NNS to_TO entities_NNS in_IN an_DT external_JJ dictionary_NN ._.
This_DT is_VBZ difficult_JJ because_IN most_JJS high-performance_JJ named_VBN entity_NN recognition_NN systems_NNS operate_VBP by_IN sequentially_RB classifying_VBG words_NNS as_IN to_TO whether_IN or_CC not_RB they_PRP participate_VBP in_IN an_DT entity_NN name_NN ;_: however_RB ,_, the_DT most_RBS useful_JJ similarity_NN measures_NNS score_VBP entire_JJ candidate_NN names_NNS ._.
To_TO correct_VB this_DT mismatch_NN we_PRP formalize_VBP a_DT semi-Markov_JJ extraction_NN process_NN ,_, which_WDT is_VBZ based_VBN on_IN sequentially_RB classifying_VBG segments_NNS of_IN several_JJ adjacent_JJ words_NNS ,_, rather_RB than_IN single_JJ words_NNS ._.
In_IN addition_NN to_TO allowing_VBG a_DT natural_JJ way_NN of_IN coupling_NN high-performance_JJ NER_NN methods_NNS and_CC high-performance_JJ similarity_NN functions_NNS ,_, this_DT formalism_NN also_RB allows_VBZ the_DT direct_JJ use_NN of_IN other_JJ useful_JJ entity-level_JJ features_NNS ,_, and_CC provides_VBZ a_DT more_RBR natural_JJ formulation_NN of_IN the_DT NER_NN problem_NN than_IN sequential_JJ word_NN classification_NN ._.
Experiments_NNS in_IN multiple_JJ domains_NNS show_VBP that_IN the_DT new_JJ model_NN can_MD substantially_RB improve_VB extraction_NN performance_NN over_IN previous_JJ methods_NNS for_IN using_VBG external_JJ dictionaries_NNS in_IN NER_NN ._.
aches_NNS for_IN entity_NN extraction_NN are_VBP based_VBN on_IN the_DT use_NN of_IN external_JJ resources_NNS ,_, such_JJ as_IN an_DT ontology_NN or_CC a_DT dictionary_NN ._.
Popov_NNP et_FW al._FW -LRB-_-LRB- 23_CD -RRB-_-RRB- use_VBP a_DT populated_JJ ontology_NN for_IN entity_NN extraction_NN ,_, while_IN Cohen_NNP and_CC Sarawagi_NNP =_SYM -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: exploit_VB a_DT dictionary_NN for_IN named_VBN entity_NN extraction_NN ._.
Tenier_NNP et_FW al._FW -LRB-_-LRB- 27_CD -RRB-_-RRB- use_VBP an_DT ontology_NN for_IN automatic_JJ semantic_JJ annotation_NN of_IN web_NN pages_NNS ._.
Their_PRP$ system_NN firstly_RB identifies_VBZ the_DT syntactic_JJ structure_NN that_IN chara_NN
We_PRP also_RB study_VBD person_NN name_NN extraction_NN from_IN the_DT email_JJ message_NN corpus_NN ._.
The_DT CSpace_NN corpus_NN we_PRP used_VBD in_IN this_DT paper_NN contains_VBZ 216_CD email_NN messages_NNS collected_VBN from_IN a_DT management_NN course_NN at_IN Carnegie_NNP Mellon_NNP University_NNP =_SYM -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP use_VBP conditional_JJ random_JJ fields_NNS -LRB-_-LRB- 18_CD -RRB-_-RRB- as_IN the_DT base_NN learner_NN and_CC the_DT feature_NN set_NN described_VBN in_IN our_PRP$ previous_JJ paper_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- for_IN protein_NN name_NN extraction_NN and_CC the_DT feature_NN set_NN described_VBN in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- for_IN person_NN name_NN e_SYM
We_PRP also_RB study_VBD person_NN name_NN extraction_NN from_IN the_DT email_JJ message_NN corpus_NN ._.
The_DT CSpace_NN corpus_NN we_PRP used_VBD in_IN this_DT paper_NN contains_VBZ 216_CD email_NN messages_NNS collected_VBN from_IN a_DT management_NN course_NN at_IN Carnegie_NNP Mellon_NNP University_NNP =_SYM -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP use_VBP conditional_JJ random_JJ fields_NNS -LRB-_-LRB- 18_CD -RRB-_-RRB- as_IN the_DT base_NN learner_NN and_CC the_DT feature_NN set_NN described_VBN in_IN our_PRP$ previous_JJ paper_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- for_IN protein_NN name_NN extraction_NN and_CC the_DT feature_NN set_NN described_VBN in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- for_IN person_NN name_NN e_SYM
horizontal_JJ time_NN --_: lines_NNS ._.
We_PRP are_VBP also_RB currently_RB testing_VBG information_NN extraction_NN software_NN LingPipe_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- to_TO extend_VB our_PRP$ information_NN extraction_NN phase_NN by_IN employing_VBG the_DT Named_VBN Entity_NN Recognition_NN -LRB-_-LRB- NER_NN -RRB-_-RRB- algorithm_NN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: to_TO locate_VB and_CC classify_VB atomic_JJ elements_NNS ._.
For_IN instance_NN ,_, NER_NN can_MD be_VB used_VBN to_TO arrange_VB these_DT elements_NNS into_IN predefined_JJ categories_NNS such_JJ as_IN the_DT names_NNS of_IN persons_NNS ,_, organizations_NNS ,_, locations_NNS ,_, times_NNS ,_, quantities_NNS ,_, a_DT
ning_JJ popularity_NN in_IN text_NN mining_NN as_IN researchers_NNS pay_VBP more_JJR attention_NN to_TO relations_NNS and_CC context_NN of_IN entities_NNS -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
HMM_NNP has_VBZ been_VBN widely_RB used_VBN for_IN segmentation_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- ,_, text_NN classification_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, and_CC entity_NN extraction_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN details_NNS about_IN HMM_NNP ,_, please_VBP refer_VB to_TO -LRB-_-LRB- 1_CD -RRB-_-RRB- ._.
4.1_CD Formalizing_VBG text_NN analysis_NN process_NN with_IN a_DT Hidden_NNP Markov_NNP Model_NNP In_NNP SenseNet_NNP ,_, the_DT text_NN analysis_NN process_NN is_VBZ the_DT process_NN of_IN selecting_VBG appropriate_JJ senses_NNS for_IN
ber_NN of_IN tasks_NNS ,_, and_CC in_IN particular_JJ ,_, there_EX has_VBZ been_VBN recent_JJ interest_NN on_IN using_VBG reference_NN sets_NNS as_IN background_NN knowledge_NN for_IN information_NN extraction_NN -LRB-_-LRB- Michelson_NNP &_CC Knoblock_NNP ,_, 2007_CD ,_, 2008_CD ;_: Mansuri_NNP &_CC Sarawagi_NNP ,_, 2006_CD ;_: =_JJ -_: =_JJ Cohen_NNP &_CC Sarawagi_NNP ,_, 2004_CD -_: =--RRB-_NN ._.
For_IN completeness_NN ,_, we_PRP describe_VBP previous_JJ work_NN on_IN reference-set-based_JJ information_NN extraction_NN in_IN more_JJR detail_NN in_IN Section_NN 2_CD ._.
Our_PRP$ goal_NN is_VBZ to_TO exploit_VB the_DT dense_JJ information_NN content_NN of_IN posts_NNS to_TO construct_VB ref_NN
e_LS process_NN and_CC the_DT whole_JJ inference_NN is_VBZ approximate_JJ ._.
But_CC our_PRP$ HCRF_NN model_NN can_MD find_VB the_DT optimal_JJ labeling_NN results_NNS ._.
Other_JJ work_NN ,_, such_JJ as_IN collective_JJ information_NN extraction_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- and_CC Semi-Markov_NNP extraction_NN models_NNS =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =-[_NN 25_CD -RRB-_-RRB- ,_, could_MD achieve_VB higher_JJR performance_NN in_IN named_VBN entity_NN extraction_NN problems_NNS on_IN flat_JJ text_NN documents_NNS ._.
However_RB ,_, for_IN the_DT integrated_VBN Web_NN data_NNS extraction_NN ,_, where_WRB the_DT data_NNS are_VBP hierarchically_RB represented_VBN ,_, the_DT p_NN
erence_NN table_NN would_MD cause_VB these_DT product_NN mentions_VBZ to_TO be_VB missed_VBN ._.
Therefore_RB ,_, it_PRP is_VBZ very_RB important_JJ to_TO consider_VB approximate_JJ matches_NNS between_IN sub-strings_NNS in_IN a_DT document_NN and_CC an_DT entity_NN name_NN in_IN a_DT reference_NN table_NN =_JJ -_: =[_NN 16_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP overcome_VBP this_DT limitation_NN by_IN first_RB identifying_VBG a_DT set_NN of_IN ``_`` synonyms_NNS ''_'' for_IN each_DT entity_NN in_IN the_DT reference_NN table_NN ._.
Each_DT synonym_NN for_IN an_DT entity_NN e_SYM is_VBZ an_DT identifying_VBG set_NN of_IN tokens_NNS ,_, which_WDT when_WRB mentioned_VBN contig_NN
._.
However_RB ,_, this_DT approach_NN does_VBZ not_RB model_VB context_NN ,_, errors_NNS or_CC different_JJ formats_NNS of_IN fields_NNS in_IN text_NN ,_, and_CC requires_VBZ large_JJ number_NN of_IN database_NN entries_NNS to_TO learn_VB an_DT accurate_JJ language_NN model_NN ._.
The_DT second_JJ approach_NN -LRB-_-LRB- =_JJ -_: =_JJ Sarawagi_NNP and_CC Cohen_NNP ,_, 2004_CD -_: =_JJ -_: ;_: Michelson_NNP and_CC Knoblock_NNP ,_, 2005_CD ;_: Mansuri_NNP and_CC Sarawagi_NNP ,_, 2006_CD -RRB-_-RRB- uses_VBZ database_NN or_CC dictionary_NN lookups_NNS in_IN combination_NN with_IN similarity_NN measures_NNS to_TO add_VB features_NNS to_TO the_DT text_NN sequence_NN ._.
Although_IN these_DT features_NNS ar_IN
nym_NN with_IN the_DT corresponding_JJ definition_NN ._.
Record_VB linkage_NN -LRB-_-LRB- Cohen_NNP &_CC Richman_NNP 2001_CD -RRB-_-RRB- is_VBZ the_DT task_NN of_IN matching_VBG named_VBN entities_NNS across_IN databases_NNS ._.
It_PRP involves_VBZ the_DT use_NN of_IN clustering_NN and_CC string_NN matching_NN techniques_NNS -LRB-_-LRB- =_JJ -_: =_JJ Cohen_NNP &_CC Sarawagi_NNP 2004_CD -_: =--RRB-_NN in_IN order_NN to_TO map_VB database_NN entries_NNS having_VBG slight_JJ variations_NNS -LRB-_-LRB- e.g._FW ,_, Frederick_NNP Mason_NNP and_CC F._NNP Mason_NNP -RRB-_-RRB- ._.
It_PRP is_VBZ used_VBN in_IN database_NN cleaning_NN and_CC in_IN data_NNS mining_NN on_IN multiple_JJ databases_NNS ._.
Case_NN restoration_NN -LRB-_-LRB- Agbago_FW et_FW
raining_VBG and_CC consistency_NN of_IN documents_NNS within_IN the_DT corpus_NN ._.
Recently_RB more_JJR systems_NNS utilize_VBP context_NN information_NN to_TO deal_VB better_RBR with_IN inconsistency_NN among_IN documents_NNS ,_, which_WDT results_VBZ in_IN a_DT more_RBR robust_JJ system_NN ._.
In_IN -LRB-_-LRB- =_JJ -_: =_JJ Cohen_NNP &_CC Sarawagi_NNP ,_, 2004_CD -_: =--RRB-_NN a_DT semi-Markov_JJ model_NN is_VBZ proposed_VBN to_TO make_VB better_JJR use_NN of_IN external_JJ dictionaries_NNS ._.
In_IN -LRB-_-LRB- McCallum_NNP ,_, Freitag_NNP ,_, &_CC Pereira_NNP ,_, 2000_CD -RRB-_-RRB- a_DT maximum_NN entropy_JJ Markov_NNP model_NN is_VBZ introduced_VBN to_TO segment_NN FAQ_NNP 's_POS ._.
Maximum_NNP entropy_NN -LRB-_-LRB- M_NN
e_LS transformations_NNS -LRB-_-LRB- 13,14_CD -RRB-_-RRB- Info_NNP ._.
Extraction_NN -LRB-_-LRB- for_IN Annotation_NNP -RRB-_-RRB- Conditional_NNP Random_NNP Fields_NNP -LRB-_-LRB- Simple_JJ Tagger_NN -RRB-_-RRB- Datamold_NN \/_: CRAM_NN -LRB-_-LRB- 15,16_CD -RRB-_-RRB- Require_VB all_DT tokens_NNS to_TO receive_VB label_NN \/_: no_DT junk_NN NER_NN with_IN Dictionary_NNP =_SYM -_: =[_NN 17_CD -RRB-_-RRB- -_: =_JJ -_: Whole_JJ segments_NNS receive_VBP same_JJ label_NN --_: attributes_NNS ca_MD n't_RB be_VB interruptedOutline_NN 1_CD ._.
Introduction_NN 2_CD ._.
Alignment_NN 3_CD ._.
Extraction_NN 4_CD ._.
Results_NNS 5_CD ._.
Discussion_NN 6_CD ._.
Related_NNP Work_NNP 7_CD ._.
ConclusionConclusion_NNP Annotate_NNP
rns_NNS out_IN that_DT while_IN problems_NNS of_IN coverage_NN and_CC ambiguity_NN prevent_VBP straightforward_JJ lookup_NN ,_, injection_NN of_IN gazetteer_NN matches_NNS as_IN features_NNS in_IN machine-learning_JJ based_JJ approaches_NNS is_VBZ critical_JJ for_IN good_JJ performance_NN -LRB-_-LRB- =_JJ -_: =_JJ Cohen_NNP ,_, 2004_CD -_: =_JJ -_: ;_: Kazama_NNP and_CC Torisawa_NNP ,_, 2007a_CD ;_: Toral_NNP and_CC Munoz_NNP ,_, 2006_CD ;_: Florian_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- ._.
Given_VBN these_DT findings_NNS ,_, several_JJ approaches_NNS have_VBP been_VBN proposed_VBN to_TO automatically_RB extract_VB comprehensive_JJ gazetteers_NNS from_IN the_DT web_NN a_DT
ping_NN criterion_NN for_IN the_DT bootstrapping_NN procedure_NN ,_, perhaps_RB through_IN the_DT detection_NN of_IN semantic_JJ drift_NN -LRB-_-LRB- 28_CD ,_, 34_CD -RRB-_-RRB- ._.
Gazetteer_NN resources_NNS have_VBP proven_VBN to_TO be_VB a_DT powerful_JJ knowledge_NN base_NN for_IN improving_VBG NER_NN performance_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT only_JJ gazetteer_NN in_IN CDB_NNP now_RB is_VBZ a_DT country_NN and_CC US_NNP state_NN list_NN ._.
So_RB another_DT promising_JJ research_NN avenue_NN is_VBZ to_TO study_VB how_WRB to_TO automatically_RB learn_VB or_CC mine_VB a_DT target_NN domain_NN named_VBN entity_NN dictionary_NN to_TO further_VB i_LS
s_NN and_CC analyze_VB effectiveness_NN of_IN the_DT different_JJ sources_NNS for_IN these_DT statistics_NNS ,_, such_JJ as_IN the_DT user_NN and_CC the_DT database_NN context_NN ._.
3.7_CD Named_VBN Entity_NN Recognition_NN Dictionary-based_JJ named-entity_NN recognition_NN -LRB-_-LRB- NER_NN -RRB-_-RRB- e.g._FW =_SYM -_: =[_NN 11_CD ,_, 31_CD -RRB-_-RRB- -_: =_SYM -_: focuses_VBZ on_IN identifying_VBG sequences_NNS of_IN terms_NNS within_IN the_DT documents_NNS as_IN named-entities_NNS such_JJ as_IN person_NN name_NN ,_, company_NN name_NN ,_, location_NN ,_, etc._NN by_IN exploiting_VBG explicit_JJ lists_NNS -LRB-_-LRB- dictionaries_NNS -RRB-_-RRB- of_IN single_JJ and_CC multi-word_JJ
aches_NNS for_IN entity_NN extraction_NN are_VBP based_VBN on_IN the_DT use_NN of_IN external_JJ resources_NNS ,_, such_JJ as_IN an_DT ontology_NN or_CC a_DT dictionary_NN ._.
Popov_NNP et_FW al._FW -LRB-_-LRB- 24_CD -RRB-_-RRB- use_VBP a_DT populated_JJ ontology_NN for_IN entity_NN extraction_NN ,_, while_IN Cohen_NNP and_CC Sarawagi_NNP =_SYM -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: exploit_VB a_DT dictionary_NN for_IN named_VBN entity_NN extraction_NN ._.
Tenier_NNP et_FW al._FW -LRB-_-LRB- 28_CD -RRB-_-RRB- use_VBP an_DT ontology_NN for_IN automatic_JJ semantic_JJ annotation_NN of_IN web_NN pages_NNS ._.
Their_PRP$ system_NN firstly_RB identifies_VBZ the_DT syntactic_JJ structure_NN that_IN chara_NN
non-Markovian_JJ --_: i.e._FW ,_, the_DT distance-based_JJ segment_NN features_NNS can_MD not_RB be_VB decomposed_VBN into_IN sums_NNS of_IN local_JJ features_NNS ._.
More_JJR detail_NN on_IN the_DT distance_NN metrics_NNS ,_, feature_NN sets_NNS ,_, and_CC datasets_NNS above_IN can_MD be_VB found_VBN elsewher_NN =_JJ -_: =_JJ e_LS -LRB-_-LRB- 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP also_RB extended_VBD the_DT semi-CRF_JJ algorithm_NN to_TO construct_NN ,_, on_IN the_DT fly_NN ,_, an_DT internal_JJ segment_NN dictionary_NN of_IN segments_NNS labeled_VBN as_IN entities_NNS in_IN the_DT training_NN data_NNS ._.
To_TO make_VB measurements_NNS on_IN training_NN data_NNS similar_JJ t_NN
ormation_NN extraction_NN from_IN text_NN and_CC HTML_NNP data_NNS is_VBZ an_DT area_NN with_IN intensive_JJ work_NN ._.
The_DT approaches_NNS mostly_RB follow_VBP a_DT rule-based_JJ paradigm_NN -LRB-_-LRB- 7_CD ,_, 17_CD ,_, 23_CD ,_, 36_CD -RRB-_-RRB- ,_, or_CC employ_VB learning_NN techniques_NNS and\/or_CC linguistic_JJ methods_NNS =_JJ -_: =[_NN 3_CD ,_, 16_CD ,_, 18_CD ,_, 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
But_CC actually_RB using_VBG automatically_RB converted_VBN and_CC ``_`` semantically_RB ''_'' enhanced_VBN Web_NN data_NNS in_IN a_DT search_NN engine_NN has_VBZ not_RB been_VBN pursued_VBN in_IN the_DT literature_NN on_IN information_NN extraction_NN ._.
Ranked_VBN retrieval_NN over_IN graph-struc_NN
ne_NN currently_RB includes_VBZ plain_JJ text_NN parsers_NNS that_WDT use_VBP ad-hoc_JJ ,_, but_CC well_RB tuned_VBN ,_, parsing_VBG techniques_NNS ,_, rather_RB than_IN the_DT more_RBR advanced_JJ techniques_NNS from_IN the_DT fields_NNS of_IN information_NN extraction_NN or_CC text_NN classification_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT current_JJ parsers_NNS look_VBP for_IN individual_JJ fields_NNS of_IN structured_JJ information_NN by_IN checking_VBG for_IN patterns_NNS ,_, such_JJ as_IN the_DT number_NN pattern_NN of_IN a_DT phone_NN number_NN ,_, and_CC keywords_NNS ,_, such_JJ as_IN ``_`` Fax_NN ,_, ''_'' ``_`` Researcher_NNP ,_, ''_'' or_CC ``_`` Univer_NNP
,_, information_NN retrieval_NN and_CC natural_JJ language_NN processing_NN ._.
Current_JJ techniques_NNS are_VBP mainly_RB based_VBN on_IN machine_NN learning_NN and_CC natural_JJ language_NN processing_NN to_TO learn_VB extraction_NN rules_NNS from_IN manual_JJ labeled_JJ examples_NNS =_JJ -_: =[_NN 6_CD ,_, 7_CD ,_, 14_CD ,_, 24_CD ,_, 29_CD ,_, 46_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Recently_RB ,_, a_DT number_NN of_IN researchers_NNS also_RB make_VBP use_NN of_IN common_JJ language_NN patterns_NNS -LRB-_-LRB- common_JJ sentence_NN structures_NNS used_VBN to_TO express_VB certain_JJ facts_NNS or_CC relations_NNS -RRB-_-RRB- and_CC redundancy_NN of_IN information_NN on_IN the_DT Web_NN to_TO find_VB c_NN
od_NN in_IN a_DT ML_NN or_CC MAP_NN setting_NN ,_, based_VBN on_IN the_DT gradient_NN formula_NN in_IN Equation_NN 14_CD ._.
Compared_VBN with_IN CRFs_NNS ,_, this_DT has_VBZ the_DT additional_JJ benefit_NN of_IN allowing_VBG the_DT incorporation_NN of_IN phrase-based_JJ features_NNS ._.
In_IN a_DT recent_JJ work_NN ,_, -LRB-_-LRB- =_JJ -_: =_JJ Cohen_NNP &_CC Sarawagi_NNP ,_, 2004_CD -_: =--RRB-_NN have_VBP introduced_VBN a_DT conditional_JJ version_NN for_IN segmental_JJ semi-Markov_JJ models_NNS -LRB-_-LRB- Ge_NN ,_, 2002_CD -RRB-_-RRB- to_TO achieve_VB a_DT similar_JJ aim_NN ,_, showing_VBG that_IN the_DT phrase_NN classification_NN approach_NN can_MD lead_VB to_TO better_JJR performance_NN vs._FW CRFs_FW ,_, e_SYM
We_PRP also_RB study_VBD person_NN name_NN extraction_NN from_IN the_DT email_JJ message_NN corpus_NN ._.
The_DT CSpace_NN corpus_NN we_PRP used_VBD in_IN this_DT paper_NN contains_VBZ 216_CD email_NN messages_NNS collected_VBN from_IN a_DT management_NN course_NN at_IN Carnegie_NNP Mellon_NNP University_NNP =_SYM -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT feature_NN sets_NNS and_CC relational_JJ templates_NNS for_IN named_VBN entity_NN extraction_NN are_VBP the_DT same_JJ as_IN the_DT previous_JJ work_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
The_DT relational_JJ template_NN will_MD retrieve_VB the_DT predictions_NNS for_IN the_DT adjacent_JJ words_NNS -LRB-_-LRB- with_IN window_NN
porate_VB the_DT lessons_NNS learned_VBD from_IN earlier_JJR work_NN on_IN AI_NNP and_CC Legal_NNP reasoning_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, as_RB well_RB as_IN Information_NNP Extraction_NNP -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
Also_RB ,_, as_IN we_PRP include_VBP other_JJ information_NN types_NNS for_IN extraction_NN ,_, the_DT methods_NNS described_VBN in_IN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: and_CC -LRB-_-LRB- 7_CD -RRB-_-RRB- will_MD become_VB useful_JJ ._.
3_CD Our_NNP Prototype_NNP 3.1_CD Overall_NNP Design_NNP The_DT main_JJ objective_NN of_IN the_DT prototype_NN is_VBZ to_TO develop_VB the_DT building_NN blocks_VBZ necessary_JJ to_TO perform_VB privacy_NN compliance_NN enforcement_NN in_IN email_NN ._.
The_DT
e_LS been_VBN investigated_VBN across_IN a_DT number_NN of_IN diverse_JJ fields_NNS -LRB-_-LRB- 37_CD ,_, 62_CD ,_, 80_CD ,_, 83_CD -RRB-_-RRB- ,_, specifically_RB focusing_VBG on_IN those_DT which_WDT apply_VBP to_TO the_DT tasks_NNS of_IN scene_NN population_NN ._.
In_IN particular_JJ ,_, named_VBN entity_NN recognition_NN techniques_NNS =_JJ -_: =[_NN 1_CD ,_, 8_CD ,_, 9_CD ,_, 11_CD ,_, 20_CD ,_, 52_CD ,_, 60_CD ,_, 81_CD -RRB-_-RRB- -_: =_JJ -_: ,_, script_NN extraction_NN techniques_NNS -LRB-_-LRB- 85_CD -RRB-_-RRB- and_CC inductive_JJ pattern_NN matching_NN techniques_NNS -LRB-_-LRB- 15_CD ,_, 18_CD ,_, 23_CD ,_, 25_CD ,_, 30_CD ,_, 57_CD ,_, 69_CD ,_, 68_CD ,_, 84_CD -RRB-_-RRB- have_VBP been_VBN comprehensively_RB surveyed_VBN ._.
•_CD Existing_VBG Text-to-Scene_JJ conversion_NN systems_NNS :_: A_DT co_NN
ified_VBN entities_NNS in_IN the_DT document_NN ;_: these_DT embeddings_NNS are_VBP essentially_RB linkages_NNS that_WDT interrelate_VBP relevant_JJ structured_JJ data_NNS with_IN segments_NNS within_IN the_DT given_VBN document_NN ._.
Unlike_IN prior_JJ entity_NN recognition_NN approaches_VBZ =_JJ -_: =[_NN 20_CD ,_, 7_CD ,_, 12_CD -RRB-_-RRB- -_: =_JJ -_: ,_, EROCS_NN identifies_VBZ such_JJ linkages_NNS even_RB when_WRB the_DT relevant_JJ entity_NN is_VBZ not_RB explicitly_RB mentioned_VBN in_IN the_DT document_NN ._.
As_IN an_DT example_NN ,_, consider_VB a_DT retail_JJ organization_NN where_WRB the_DT Permission_NN to_TO copy_VB without_IN fee_NN all_DT o_NN
e_LS process_NN and_CC the_DT whole_JJ inference_NN is_VBZ approximate_JJ ._.
But_CC our_PRP$ HCRF_NN model_NN can_MD find_VB the_DT optimal_JJ labeling_NN results_NNS ._.
Other_JJ work_NN ,_, such_JJ as_IN collective_JJ information_NN extraction_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- and_CC Semi-Markov_NNP extraction_NN models_NNS =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =-[_NN 25_CD -RRB-_-RRB- ,_, could_MD achieve_VB higher_JJR performance_NN in_IN named_VBN entity_NN extraction_NN problems_NNS on_IN flat_JJ text_NN documents_NNS ._.
However_RB ,_, for_IN the_DT integrated_VBN Web_NN data_NNS extraction_NN ,_, where_WRB the_DT data_NNS are_VBP hierarchically_RB represented_VBN ,_, the_DT p_NN
not_RB dominate_VB features_NNS that_WDT capture_VBP contextual_JJ words_NNS and_CC positional_JJ information_NN from_IN the_DT limited_JJ labeled_JJ data_NNS ._.
We_PRP design_VBP a_DT data_NN integration_NN system_NN that_WDT builds_VBZ upon_IN state-of-the-art_JJ semi-Markov_JJ models_NNS =_JJ -_: =[_NN 7_CD ,_, 16_CD -RRB-_-RRB- -_: =_SYM -_: for_IN information_NN extraction_NN to_TO exploit_VB useful_JJ information_NN in_IN both_CC structured_JJ data_NNS and_CC labeled_VBN unstructured_JJ data_NNS in_IN spite_NN of_IN their_PRP$ format_NN ,_, structure_NN and_CC size_NN variations_NNS ._.
Our_PRP$ experiments_NNS show_VBP that_IN our_PRP$ p_NN
aarbrücken_NN \/_: Germany_NNP weikum@mpii.mpg.de_NN Furthermore_RB ,_, ontological_JJ knowledge_NN structures_NNS play_VBP an_DT important_JJ role_NN in_IN data_NN cleaning_NN -LRB-_-LRB- e.g._FW ,_, for_IN a_DT data_NN warehouse_NN -RRB-_-RRB- -LRB-_-LRB- 6_CD -RRB-_-RRB- ,_, record_NN linkage_NN -LRB-_-LRB- aka_NN ._.
entity_NN resolution_NN -RRB-_-RRB- =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC information_NN integration_NN in_IN general_JJ -LRB-_-LRB- 19_CD -RRB-_-RRB- ._.
But_CC the_DT existing_VBG applications_NNS typically_RB use_VBP only_RB a_DT single_JJ source_NN of_IN background_NN knowledge_NN -LRB-_-LRB- mostly_RB WordNet_NNP -LRB-_-LRB- 10_CD -RRB-_-RRB- or_CC Wikipedia_NNP -RRB-_-RRB- ._.
They_PRP could_MD boost_VB their_PRP$ perfo_NN
ning_JJ popularity_NN in_IN text_NN mining_NN as_IN researchers_NNS pay_VBP more_JJR attention_NN to_TO relations_NNS and_CC context_NN of_IN entities_NNS -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
HMM_NNP has_VBZ been_VBN widely_RB used_VBN for_IN segmentation_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- ,_, text_NN classification_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, and_CC entity_NN extraction_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN details_NNS about_IN HMM_NNP ,_, please_VBP refer_VB to_TO -LRB-_-LRB- 1_CD -RRB-_-RRB- ._.
4.1_CD Formalizing_VBG text_NN analysis_NN process_NN with_IN a_DT Hidden_NNP Markov_NNP Model_NNP In_NNP SenseNet_NNP ,_, the_DT text_NN analysis_NN process_NN is_VBZ the_DT process_NN of_IN selecting_VBG appropriate_JJ senses_NNS for_IN
nditional_JJ Random_NNP Fields_NNP -LRB-_-LRB- 16_CD -RRB-_-RRB- and_CC Max-margin_JJ markov_NN networks_NNS -LRB-_-LRB- 26_CD -RRB-_-RRB- ._.
We_PRP will_MD present_VB various_JJ graphical_JJ models_NNS for_IN extraction_NN ,_, starting_VBG with_IN traditional_JJ chain_NN models_NNS for_IN plain_JJ text_NN to_TO segmentation_NN models_NNS =_JJ -_: =[_NN 24_CD ,_, 3_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: for_IN exploiting_VBG matches_NNS with_IN existing_VBG entities_NNS ,_, and_CC general_JJ graph_NN models_NNS for_IN extracting_VBG from_IN visual_JJ 2D_NN layouts_NNS as_IN in_IN web_NN pages_NNS ._.
•_NNP Sensor_NNP data_NNS management_NN :_: Many_JJ common_JJ sensor_NN processing_NN tasks_NNS can_MD be_VB see_VB
high_JJ confidence_NN may_MD not_RB be_VB possible_JJ in_IN general_JJ ._.
We_PRP address_VBP this_DT limitation_NN in_IN our_PRP$ work_NN by_IN requiring_VBG only_RB a_DT subset_NN of_IN tokens_NNS to_TO be_VB labeled_VBN with_IN high-precision_NN ._.
Other_JJ approaches_NNS -LRB-_-LRB- Sarawagi_NNP &_CC Cohen_NNP 2005_CD ;_: =_JJ -_: =_JJ Sarawagi_NNP &_CC Cohen_NNP 2004_CD -_: =--RRB-_NN employ_VBP database_NN or_CC created_VBN through_IN heuristic_NN methods_NNS or_CC the_DT use_NN of_IN an_DT inverted_JJ index_NN ._.
These_DT associations_NNS may_MD also_RB be_VB created_VBN by_IN asking_VBG the_DT user_NN for_IN a_DT match\/non-match_NN label_NN ._.
dictionary_NN lookups_NNS in_IN com_NN
even_RB degrade_VB the_DT model_NN performance_NN -LRB-_-LRB- Nigam_NNP et_FW al._FW ,_, 2000_CD -RRB-_-RRB- ._.
In_IN many_JJ cases_NNS ,_, improving_VBG semi-supervised_JJ models_NNS was_VBD done_VBN by_IN seeding_VBG these_DT models_NNS with_IN domain_NN information_NN taken_VBN from_IN dictionaries_NNS or_CC ontology_JJ -LRB-_-LRB- =_JJ -_: =_JJ Cohen_NNP and_CC Sarawagi_NNP ,_, 2004_CD -_: =_JJ -_: ;_: Collins_NNP and_CC Singer_NNP ,_, 1999_CD ;_: Haghighi_NNP and_CC Klein_NNP ,_, 2006_CD ;_: Thelen_NNP and_CC Riloff_NNP ,_, 2002_CD -RRB-_-RRB- ._.
On_IN the_DT other_JJ hand_NN ,_, in_IN the_DT supervised_JJ setting_NN ,_, it_PRP has_VBZ been_VBN shown_VBN that_IN incorporating_VBG domain_NN and_CC problem_NN specific_JJ structure_NN
at_IN position_NN j_NN with_IN the_DT input_NN sequence_NN i270_FW i_FW around_IN position_NN j_NN ,_, λi_FW is_VBZ the_DT corresponding_JJ feature_NN weight_NN ,_, and_CC Z_NN -LRB-_-LRB- x_NN -RRB-_-RRB- is_VBZ the_DT normalization_NN factor_NN ._.
2.7_CD SemiCRFs_NNS with_IN dictionary_NN features_NNS Two_CD recent_JJ papers_NNS -LRB-_-LRB- =_JJ -_: =_JJ Cohen_NNP and_CC Sarawagi_NNP ,_, 2004_CD -_: =_JJ -_: ;_: Sarawagi_NNP and_CC Cohen_NNP ,_, 2004_CD -RRB-_-RRB- compared_VBD a_DT number_NN of_IN methods_NNS for_IN using_VBG dictionaries_NNS with_IN CRF-like_JJ learning_NN methods_NNS ._.
The_DT best_JJS results_NNS were_VBD obtained_VBN with_IN a_DT new_JJ learning_NN method_NN called_VBN semiCRFs_NNP ._.
SemiCRFs_NN cons_NNS
e_LS find_VB the_DT bestsmethod_NN of_IN segmenting_VBG the_DT text_NN and_CC assign_VB labels_NNS for_IN each_DT segment_NN ._.
Although_IN ,_, computationally_RB this_DT appears_VBZ formidable_JJ ,_, we_PRP can_MD design_VB efficient_JJ dynamic_JJ programming_NN algorithms_NNS as_IN shown_VBN in_IN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_JJ -_: and_CC -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Experimental_JJ results_NNS on_IN five_CD real-life_JJ extraction_NN tasks_NNS in_IN the_DT presence_NN of_IN large_JJ database_NN of_IN entity_NN names_NNS show_VBP that_IN the_DT semi-markov_JJ models_NNS along_IN with_IN the_DT use_NN of_IN similarity_NN features_NNS increase_VBP
IDES_NNP Information_NNP Extraction-Entity_NNP Recognition_NN -LRB-_-LRB- IEER-99_NN -RRB-_-RRB- technology_NN evaluation_NN project_NN ._.
Current_JJ research_NN on_IN NER_NN has_VBZ focused_VBN on_IN machine_NN learning_NN approaches_NNS ,_, including_VBG hidden_JJ Markov_NNP models_NNS -LRB-_-LRB- HMMs_NNS -RRB-_-RRB- -LRB-_-LRB- 1_LS -RRB-_-RRB- -LRB-_-LRB- 2_LS -RRB-_-RRB- =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, maximum_NN entropy_NN -LRB-_-LRB- ME_NN -RRB-_-RRB- -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, transformation-based_JJ error-driven_JJ learning_NN -LRB-_-LRB- TBL_NN -RRB-_-RRB- -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVMs_NNS -RRB-_-RRB- -LRB-_-LRB- 6_CD -RRB-_-RRB- ._.
In_IN comparison_NN with_IN rule-based_JJ methods_NNS ,_, machine-learning_JJ approaches_NNS are_VBP more_JJR ad_NN
l_NN pages_NNS ,_, match_NN of_IN a_DT text_NN string_NN with_IN author_NN ,_, journal_NN and_CC title_NN entities_NNS of_IN existing_VBG structured_JJ databases_NNS like_IN DBLP_NN 2_CD and_CC Bibtex_NNP servers_NNS 3_CD ,_, can_MD provide_VB strong_JJ evidence_NN 1_CD NER_NN -_: Named_VBN Entity_NN Recognition_NN =_JJ -_: =[_NN 3_CD ,_, 15_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: 2_CD http:\/\/dblp.uni-trier.de_NN 3_CD http:\/\/citeseer.ist.psu.edu_NNP P._NNP C._NNP Nagesh_NNP nagesh@it.iitb.ac.in_NNP IIT_NNP Bombay_NNP 1_CD Sunita_NNP Sarawagi_NNP sunita@iitb.ac.in_NNP IIT_NNP Bombay_NNP about_IN the_DT entity_NN type_NN of_IN the_DT string_NN ._.
Several_JJ indep_NN
distinction_NN between_IN the_DT movie_NN ``_`` 60_CD seconds_NNS ''_'' versus_CC a_DT phrase_NN ``_`` 60_CD seconds_NNS ''_'' -LRB-_-LRB- in_IN reference_NN to_TO time_NN -RRB-_-RRB- is_VBZ important_JJ while_IN extracting_VBG a_DT set_NN of_IN movies_NNS ._.
We_PRP apply_VBP known_JJ techniques_NNS for_IN the_DT entity_NN recognition_NN step_NN =_JJ -_: =[_NN 10_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, we_PRP focus_VBP on_IN the_DT first_JJ step_NN of_IN document_NN filtering_VBG for_IN entity_NN extraction_NN ._.
We_PRP now_RB consider_VBP two_CD simple_JJ approaches_NNS for_IN ad-hoc_JJ entity_NN extraction_NN ._.
Document_NNP Scan_NNP Approach_NNP :_: A_DT basic_JJ approach_NN ,_, a_DT
aches_NNS for_IN entity_NN extraction_NN are_VBP based_VBN on_IN the_DT use_NN of_IN external_JJ resources_NNS ,_, such_JJ as_IN an_DT ontology_NN or_CC a_DT dictionary_NN ._.
Popov_NNP et_FW al._FW -LRB-_-LRB- 23_CD -RRB-_-RRB- use_VBP a_DT populated_JJ ontology_NN for_IN entity_NN extraction_NN ,_, while_IN Cohen_NNP and_CC Sarawagi_NNP =_SYM -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: exploit_VB a_DT dictionary_NN for_IN named_VBN entity_NN extraction_NN ._.
Tenier_NNP et_FW al._FW -LRB-_-LRB- 27_CD -RRB-_-RRB- use_VBP an_DT ontology_NN for_IN automatic_JJ semantic_JJ annotation_NN of_IN web_NN pages_NNS ._.
Their_PRP$ system_NN firstly_RB identifies_VBZ the_DT syntactic_JJ structure_NN that_IN chara_NN
mply_RB adding_VBG the_DT local_JJ totals_NNS ,_, the_DT employee_NN would_MD be_VB counted_VBN twice_RB ,_, and_CC one_CD of_IN the_DT records_NNS counted_VBN would_MD have_VB old_JJ or_CC stale_JJ data_NNS ._.
Researchers_NNS have_VBP considered_VBN methods_NNS for_IN discovering_VBG such_JJ duplicate_VBP data_NN =_JJ -_: =[_NN 23_CD ,_, 5_CD ,_, 29_CD ,_, 8_CD ,_, 12_CD -RRB-_-RRB- -_: =_JJ -_: and_CC for_IN efficiently_RB handling_VBG this_DT problem_NN in_IN a_DT centralized_JJ environment_NN -LRB-_-LRB- 14_CD ,_, 1_CD ,_, 7_CD -RRB-_-RRB- ._.
However_RB ,_, what_WP has_VBZ not_RB been_VBN addressed_VBN is_VBZ how_WRB to_TO extend_VB these_DT methods_NNS to_TO the_DT real-life_JJ situation_NN where_WRB they_PRP are_VBP most_JJS a_DT
hat_NN all_DT tokens_NNS receive_VBP a_DT label_NN ,_, not_RB allowing_VBG for_IN `_`` junk_NN '_'' in_IN the_DT text_NN ._.
Other_JJ work_NN in_IN information_NN extraction_NN incorporates_VBZ reference_NN sets_NNS with_IN machine_NN learning_NN ,_, for_IN example_NN the_DT work_NN of_IN Cohen_NNP and_CC Sarawagi_NNP =_SYM -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, this_DT work_NN requires_VBZ human_JJ selected_VBN reference_NN sets_NNS and_CC this_DT technique_NN relies_VBZ on_IN supervised_JJ machine_NN learning_NN ._.
5_CD Conclusion_NN We_PRP introduce_VBP a_DT technique_NN for_IN unsupervised_JJ information_NN extraction_NN from_IN
ctionaries_NNS of_IN known_JJ entities_NNS ._.
This_DT approach_NN has_VBZ been_VBN shown_VBN to_TO substantially_RB improve_VB the_DT extraction_NN performance_NN over_IN traditional_JJ NER_NN systems_NNS due_JJ to_TO the_DT extra_JJ domain_NN knowledge_NN encoded_VBN in_IN the_DT dictionary_NN =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Since_IN entities_NNS in_IN the_DT dictionary_NN are_VBP represented_VBN as_IN strings_NNS ,_, the_DT dictionary-based_JJ named_VBN entity_NN extraction_NN problem_NN can_MD be_VB modeled_VBN as_IN an_DT approximate_JJ dictionary_NN matching_NN problem_NN ,_, that_DT is_VBZ ,_, given_VBN a_DT dicti_NN
rns_NNS out_IN that_DT while_IN problems_NNS of_IN coverage_NN and_CC ambiguity_NN prevent_VBP straightforward_JJ lookup_NN ,_, injection_NN of_IN gazetteer_NN matches_NNS as_IN features_NNS in_IN machine-learning_JJ based_JJ approaches_NNS is_VBZ critical_JJ for_IN good_JJ performance_NN -LRB-_-LRB- =_JJ -_: =_JJ Cohen_NNP ,_, 2004_CD -_: =_JJ -_: ;_: Kazama_NNP and_CC Torisawa_NNP ,_, 2007a_CD ;_: Toral_NNP and_CC Munoz_NNP ,_, 2006_CD ;_: Florian_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- ._.
Given_VBN these_DT findings_NNS ,_, several_JJ approaches_NNS have_VBP been_VBN proposed_VBN to_TO automatically_RB extract_VB comprehensive_JJ gazetteers_NNS from_IN the_DT web_NN a_DT
ence_NN pairs_NNS of_IN rule-based_JJ approaches_NNS is_VBZ to_TO recognize_VB email_NN addresses_NNS where_WRB entities_NNS are_VBP clearly_RB defined_VBN through_IN capital_NN letters_NNS ,_, symbols_NNS ,_, and_CC digits_NNS ._.
Dictionary-based_JJ Checking_NN approaches_VBZ Specification_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: use_VB a_DT large_JJ collection_NN of_IN 4_CD ._.
Google_NNP code_NN relevant_JJ code_NN specification_NN names_NNS as_IN a_DT dictionary_NN for_IN entities_NNS ._.
A_DT typical_JJ application_NN of_IN search_NN snippets_NNS dictionary-based_JJ approaches_NNS is_VBZ to_TO recognize_VB baseball_NN
wagi_FW ∗_FW IIT_NNP Bombay_NNP Mumbai-400076_NNP India_NNP sunita@iitb.ac.in_NN identifying_VBG personal_JJ names_NNS and_CC company_NN names_NNS in_IN newswire_NN text_NN -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 5_CD -RRB-_-RRB- -RRB-_-RRB- ,_, identifying_VBG gene_NN and_CC protein_NN names_NNS in_IN biomedical_JJ publications_NNS -LRB-_-LRB- e.g._FW =_JJ -_: =_JJ ,_, -LRB-_-LRB- 7_CD ,_, 20_CD -RRB-_-RRB- -_: =--RRB-_NN ,_, and_CC identifying_VBG titles_NNS and_CC authors_NNS in_IN on-line_JJ publications_NNS -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 25_CD ,_, 29_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Named_VBN entity_NN recognition_NN is_VBZ an_DT important_JJ step_NN in_IN deriving_VBG structured_JJ database_NN records_NNS from_IN text_NN ._.
In_IN many_JJ cases_NNS ,_, the_DT ulti_NN
ington_RB ,_, USA_NNP ._.
Copyright_NN 2004_CD ACM_NNP 1-58113-888-1_CD \/_: 04\/0008_CD ..._: $_$ 5.00_CD ._.
Sunita_NNP Sarawagi_NNP ∗_NNP IIT_NNP Bombay_NNP Mumbai-400076_NNP India_NNP sunita@iitb.ac.in_NN identifying_VBG personal_JJ names_NNS and_CC company_NN names_NNS in_IN newswire_NN text_NN -LRB-_-LRB- e.g._FW =_JJ -_: =_JJ ,_, -LRB-_-LRB- 5_CD -RRB-_-RRB- -_: =--RRB-_NN ,_, identifying_VBG gene_NN and_CC protein_NN names_NNS in_IN biomedical_JJ publications_NNS -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 7_CD ,_, 20_CD -RRB-_-RRB- -RRB-_-RRB- ,_, and_CC identifying_VBG titles_NNS and_CC authors_NNS in_IN on-line_JJ publications_NNS -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 25_CD ,_, 29_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Named_VBN entity_NN recognition_NN is_VBZ an_DT important_JJ
hes_NNS also_RB have_VBP the_DT disadvantage_NN that_IN they_PRP may_MD extract_VB entities_NNS that_WDT overlap_VBP ._.
Another_DT mechanism_NN of_IN exploiting_VBG a_DT dictionary_NN is_VBZ to_TO use_VB it_PRP to_TO bootstrap_VB a_DT search_NN for_IN extraction_NN patterns_NNS from_IN unlabeled_JJ data_NN =_JJ -_: =[_NN 1_CD ,_, 12_CD ,_, 14_CD ,_, 31_CD ,_, 38_CD -RRB-_-RRB- ._.
In_IN -_: =_JJ -_: these_DT systems_NNS ,_, dictionary_NN entries_NNS are_VBP matched_VBN on_IN unlabeled_JJ instances_NNS to_TO provide_VB ``_`` seed_NN ''_'' positive_JJ examples_NNS ,_, which_WDT are_VBP then_RB used_VBN to_TO learn_VB extraction_NN patterns_NNS that_WDT provide_VBP additional_JJ entries_NNS to_TO the_DT d_NN
f_LS students_NNS in_IN a_DT major_JJ university_NN in_IN India_NNP ._.
The_DT addresses_NNS in_IN this_DT set_NN are_VBP much_RB less_RBR regular_JJ than_IN US_NNP addresses_NNS ,_, and_CC therefore_RB extracting_VBG even_RB relatively_RB structured_JJ fields_NNS like_IN city_NN names_NNS is_VBZ challenging_VBG =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP found_VBD two_CD external_JJ dictionaries_NNS ,_, a_DT list_NN of_IN cities_NNS in_IN India_NNP and_CC a_DT list_NN of_IN state_NN names_NNS in_IN India_NNP ,_, and_CC defined_VBN two_CD corresponding_JJ extraction_NN tasks_NNS :_: to_TO identify_VB city_NN names_NNS ,_, and_CC to_TO identify_VB state_NN names_NNS ._.
the_DT sentence_NN would_MD be_VB Fred_NNP please_VB stop_NN by_IN my_PRP$ office_NN this_DT afternoon_NN Person_NN Oth_NNP Oth_NNP Oth_NNP Loc_NNP Loc_NNP Time_NNP Time_NNP A_NNP common_JJ way_NN of_IN constructing_VBG such_PDT a_DT tagging_NN system_NN is_VBZ to_TO learn_VB a_DT mapping_NN from_IN x_NN to_TO y_NN from_IN data_NN =_JJ -_: =[_NN 3_CD ,_, 5_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Typically_RB this_DT data_NN is_VBZ in_IN the_DT form_NN of_IN annotated_JJ documents_NNS ,_, which_WDT can_MD be_VB readily_RB converted_VBN to_TO -LRB-_-LRB- x_NN ,_, y_NN -RRB-_-RRB- pairs_NNS ._.
Most_JJS methods_NNS for_IN learning_NN taggers_NNS exploit_VBP ,_, in_IN some_DT way_NN ,_, the_DT sequential_JJ nature_NN of_IN the_DT classif_NN
ter_NN training_NN ,_, one_CD takes_VBZ as_IN the_DT final_JJ learned_VBN weight_NN vector_NN W_NN the_DT average_JJ value_NN of_IN Wt_NN over_IN all_DT time_NN steps_NNS t._VBP This_DT simple_JJ algorithm_NN has_VBZ performed_VBN well_RB on_IN a_DT number_NN of_IN important_JJ sequential_JJ learning_NN tasks_NNS =_JJ -_: =[_NN 11_CD ,_, 2_CD ,_, 34_CD -RRB-_-RRB- ,_, -_: =_JJ -_: including_VBG NER_NN ._.
It_PRP can_MD also_RB be_VB proved_VBN to_TO converge_VB under_IN certain_JJ plausible_JJ assumptions_NNS -LRB-_-LRB- 11_CD -RRB-_-RRB- ._.
The_DT natural_JJ extension_NN of_IN this_DT algorithm_NN to_TO SMM_NNP 's_POS assumes_VBZ training_NN data_NNS in_IN the_DT form_NN of_IN pairs_NNS -LRB-_-LRB- x_NN ,_, S_NN -RRB-_-RRB- ,_, where_WRB S_NN
