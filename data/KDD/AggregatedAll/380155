Data_NN mining_NN criteria_NNS for_IN tree-based_JJ regression_NN and_CC classification_NN
This_DT paper_NN is_VBZ concerned_VBN with_IN the_DT construction_NN of_IN regression_NN and_CC classification_NN trees_NNS that_WDT are_VBP more_RBR adapted_VBN to_TO data_NN mining_NN applications_NNS than_IN conventional_JJ trees_NNS ._.
To_TO this_DT end_NN ,_, we_PRP propose_VBP new_JJ splitting_NN criteria_NNS for_IN growing_VBG trees_NNS ._.
Conventional_JJ splitting_NN criteria_NNS attempt_VBP to_TO perform_VB well_RB on_IN both_DT sides_NNS of_IN a_DT split_NN by_IN attempting_VBG a_DT compromise_NN in_IN the_DT quality_NN of_IN fit_NN between_IN the_DT left_NN and_CC the_DT right_JJ side_NN ._.
By_IN contrast_NN ,_, we_PRP adopt_VBP a_DT data_NN mining_NN point_NN of_IN view_NN by_IN proposing_VBG criteria_NNS that_WDT search_VBP for_IN interesting_JJ subsets_NNS of_IN the_DT data_NNS ,_, as_IN opposed_VBN to_TO modeling_NN all_DT of_IN the_DT data_NNS equally_RB well_RB ._.
The_DT new_JJ criteria_NNS do_VBP not_RB split_VB based_VBN on_IN a_DT compromise_NN between_IN the_DT left_NN and_CC the_DT right_JJ bucket_NN ;_: they_PRP effectively_RB pick_VBP the_DT more_RBR interesting_JJ bucket_NN and_CC ignore_VB the_DT other_JJ ._.
As_IN expected_VBN ,_, the_DT result_NN is_VBZ often_RB a_DT simpler_JJR characterization_NN of_IN interesting_JJ subsets_NNS of_IN the_DT data_NNS ._.
Less_RBR expected_VBN is_VBZ that_IN the_DT new_JJ criteria_NNS often_RB yield_VBP whole_JJ trees_NNS that_WDT provide_VBP more_RBR interpretable_JJ data_NN descriptions_NNS ._.
Surprisingly_RB ,_, it_PRP is_VBZ a_DT ``_`` flaw_NN ''_'' that_WDT works_VBZ to_TO their_PRP$ advantage_NN :_: The_DT new_JJ criteria_NNS have_VBP an_DT increased_VBN tendency_NN to_TO accept_VB splits_VBZ near_IN the_DT boundaries_NNS of_IN the_DT predictor_NN ranges_NNS ._.
This_DT so-called_JJ ``_`` end-cut_JJ problem_NN ''_'' leads_VBZ to_TO the_DT repeated_JJ peeling_NN of_IN small_JJ layers_NNS of_IN data_NNS and_CC results_VBZ in_IN very_RB unbalanced_JJ but_CC highly_RB expressive_JJ and_CC interpretable_JJ trees_NNS ._.
-RRB-_-RRB- ._.
Thus_RB ,_, we_PRP can_MD guarantee_VB that_IN Ld_NN -LRB-_-LRB- D1_NN ,_, ·_FW ·_FW ·_NN ,_, Dn_NN -RRB-_-RRB- =_JJ H_NN -LRB-_-LRB- C_NN -LRB-_-LRB- Id_NN -LRB-_-LRB- D1_NN -RRB-_-RRB- ,_, ·_FW ·_FW ·_NN ,_, Id_NN -LRB-_-LRB- Dn_NN -RRB-_-RRB- -RRB-_-RRB- -RRB-_-RRB- will_MD be_VB exact_JJ with_IN respect_NN to_TO L_NN -LRB-_-LRB- D_NN -RRB-_-RRB- =_JJ H_NN -LRB-_-LRB- I_NN -LRB-_-LRB- D_NN -RRB-_-RRB- -RRB-_-RRB- ._.
3_CD Decision_NN Tree_NN Induction_NN from_IN Distributed_VBN Data_NN Decision_NN tree_NN algorithms_NNS =_JJ -_: =[_NN 4_CD ,_, 5_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: represent_VBP a_DT widely_RB used_VBN family_NN of_IN machine_NN learning_NN algorithms_NNS for_IN building_NN pattern_NN classifiers_NNS from_IN labeled_JJ training_NN data_NNS ._.
They_PRP can_MD also_RB be_VB used_VBN to_TO learn_VB associations_NNS among_IN different_JJ attributes_NNS of_IN th_DT
st_IN for_IN 55sassigning_JJ scores_NNS to_TO splits_VBZ based_VBN on_IN how_WRB well_RB they_PRP partition_NN the_DT training_NN data_NNS into_IN categories_NNS containing_VBG high_JJ percentages_NNS of_IN object_NN and_CC background_NN pixels_NNS respectively_RB -LRB-_-LRB- see_VB ,_, for_IN example_NN ,_, -LRB-_-LRB- 62_CD -RRB-_-RRB- =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =-[_NN 79_CD -RRB-_-RRB- -RRB-_-RRB- ._.
The_DT split_NN with_IN the_DT highest_JJS score_NN is_VBZ selected_VBN for_IN the_DT root_NN of_IN the_DT tree_NN ;_: then_RB ,_, we_PRP partition_NN A_NN and_CC B_NN by_IN high-scoring_NN splits_VBZ ,_, and_CC repeat_VB the_DT partitioning_NN of_IN the_DT training_NN examples_NNS until_IN no_DT splits_VBZ wi_RB
ful_NN in_IN data_NN mining_NN ._.
For_IN example_NN ,_, the_DT most_RBS popular_JJ data_NNS mining_NN tools_NNS --_: CART_NNP and_CC MARS_NNP -LRB-_-LRB- Salford_NNP Systems_NNP 2004_CD -RRB-_-RRB- --_: are_VBP based_VBN on_IN tree_NN methods_NNS ._.
Various_JJ issues_NNS in_IN building_VBG an_DT ``_`` optimal_JJ ''_'' tree_NN have_VBP been_VBN studied_VBN -LRB-_-LRB- =_JJ -_: =_JJ Buja_NNP and_CC Lee_NNP 2001_CD -_: =--RRB-_NN ._.
In_IN this_DT paper_NN ,_, we_PRP assume_VBP that_IN a_DT big_JJ and_CC redundant_JJ tree_NN has_VBZ been_VBN built_VBN ._.
The_DT complexity-penalized_JJ treepruning_NN approach_NN was_VBD described_VBN in_IN Breiman_NNP et_FW al._FW -LRB-_-LRB- 1984_CD -RRB-_-RRB- ._.
The_DT idea_NN is_VBZ originally_RB rooted_VBN 4sin_FW stati_FW
the_DT purpose_NN of_IN the_DT analysis_NN via_IN tree-building_JJ algorithms_NNS is_VBZ to_TO determine_VB a_DT set_NN of_IN if-then_JJ logical_JJ conditions_NNS that_WDT permit_VBP accurate_JJ prediction_NN or_CC classification_NN of_IN cases_NNS ._.
Tree_NN classification_NN techniques_NNS =_JJ -_: =[_NN 3_CD ,_, 25_CD ,_, 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, when_WRB they_PRP ``_`` work_NN ''_'' and_CC produce_VBP accurate_JJ predictions_NNS or_CC predicted_VBN classifications_NNS based_VBN on_IN a_DT few_JJ logical_JJ if-then_JJ conditions_NNS ,_, have_VBP a_DT number_NN of_IN advantages_NNS over_IN many_JJ of_IN those_DT alternative_JJ techniques_NNS ._.
Simpl_NN
l_NN m_NN ;_: m_NN =_JJ 1_CD ;_: 2_CD ;_: :_: :_: :_: ;_: 21_CD Class3_NN :_: xm_NN =_JJ uh_UH 2_CD -LRB-_-LRB- m_NN -RRB-_-RRB- +_CC -LRB-_-LRB- 1_CD \_NN Gamma_NN u_NN -RRB-_-RRB- h_NN 3_CD -LRB-_-LRB- m_NN -RRB-_-RRB- +_CC ffl_NN m_NN ;_: m_NN =_JJ 1_CD ;_: 2_CD ;_: :_: :_: :_: ;_: 21_CD ;_: where_WRB the_DT numbers_NNS u_NN and_CC ffl_NN m_NN are_VBP independently_RB distributed_VBN according_VBG to_TO the_DT uniform_JJ distribution_NN on_IN =_JJ -_: =[_NN 0_CD ;_: 1_LS -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC the_DT Gaussian_NNP with_IN zero_CD mean_NN and_CC unit_NN variance_NN ,_, respectively_RB ._.
The_DT three_CD 21-dimensional_JJ vectors_NNS h_NN i_FW =_JJ -LRB-_-LRB- h_NN i_LS -LRB-_-LRB- m_NN -RRB-_-RRB- -RRB-_-RRB- m_NN =_JJ 1_CD ;_: :_: :_: :_: ;_: 21_CD are_VBP irrelevant_JJ ,_, except_IN for_IN the_DT fact_NN that_IN they_PRP form_VBP an_DT obliquely_RB placed_VBN tri_NN
