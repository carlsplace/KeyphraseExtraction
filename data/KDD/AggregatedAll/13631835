Partial_JJ example_NN acquisition_NN in_IN cost-sensitive_JJ learning_NN
It_PRP is_VBZ often_RB expensive_JJ to_TO acquire_VB data_NNS in_IN real-world_JJ data_NNS mining_NN applications_NNS ._.
Most_JJS previous_JJ data_NNS mining_NN and_CC machine_NN learning_NN research_NN ,_, however_RB ,_, assumes_VBZ that_IN a_DT fixed_JJ set_NN of_IN training_NN examples_NNS is_VBZ given_VBN ._.
In_IN this_DT paper_NN ,_, we_PRP propose_VBP an_DT online_JJ cost-sensitive_JJ framework_NN that_WDT allows_VBZ a_DT learner_NN to_TO dynamically_RB acquire_VB examples_NNS as_IN it_PRP learns_VBZ ,_, and_CC to_TO decide_VB the_DT ideal_JJ number_NN of_IN examples_NNS needed_VBN to_TO minimize_VB the_DT total_JJ cost_NN ._.
We_PRP also_RB propose_VBP a_DT new_JJ strategy_NN for_IN Partial_JJ Example_NN Acquisition_NN -LRB-_-LRB- PAS_NN -RRB-_-RRB- ,_, in_IN which_WDT the_DT learner_NN can_MD acquire_VB examples_NNS with_IN a_DT subset_NN of_IN attribute_NN values_NNS to_TO reduce_VB the_DT data_NNS acquisition_NN cost_NN ._.
Experiments_NNS on_IN UCI_NN datasets_NNS show_VBP that_IN the_DT new_JJ PAS_NN strategy_NN is_VBZ an_DT effective_JJ method_NN in_IN reducing_VBG the_DT total_JJ cost_NN for_IN data_NNS acquisition_NN ._.
ion_NN strategies_NNS -LRB-_-LRB- to_TO be_VB presented_VBN in_IN Sections_NNS 3_CD and_CC 4_CD -RRB-_-RRB- utilize_VBP the_DT costsensitive_JJ decision_NN tree_NN -LRB-_-LRB- CSDT_NN in_IN short_JJ -RRB-_-RRB- as_IN a_DT base_NN learning_NN algorithm_NN ;_: thus_RB we_PRP briefly_RB review_VBP it_PRP here_RB ._.
CSDT_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- is_VBZ similar_JJ to_TO C4_NN .5_NN =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_JJ -_: ,_, but_CC it_PRP uses_VBZ the_DT total_JJ cost_NN of_IN attributes_NNS and_CC misclassifications_NNS ,_, instead_RB of_IN entropy_NN ,_, as_IN the_DT attribute_NN split_NN criterion_NN ._.
At_IN each_DT step_NN ,_, CSDT_NNP always_RB chooses_VBZ an_DT attribute_NN from_IN the_DT available_JJ attribute_NN set_VBN
st._IN That_DT is_VBZ ,_, they_PRP assume_VBP that_IN a_DT fixed_JJ set_NN of_IN training_NN examples_NNS is_VBZ given_VBN ,_, and_CC the_DT leaner_JJR can_MD not_RB acquire_VB additional_JJ information_NN during_IN learning_NN ._.
Some_DT previous_JJ works_NNS study_NN data_NNS acquisition_NN cost_NN ,_, such_JJ as_IN =_JJ -_: =[_NN 10_CD ,_, 9_CD ,_, 23_CD ,_, 13_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Among_IN them_PRP ,_, some_DT -LRB-_-LRB- 10_CD ,_, 9_CD -RRB-_-RRB- study_NN how_WRB to_TO acquire_VB attribute_NN values_NNS to_TO build_VB an_DT optimal_JJ classifier_NN with_IN a_DT certain_JJ budget_NN ._.
The_DT others_NNS -LRB-_-LRB- 23_CD ,_, 13_CD ,_, 14_CD -RRB-_-RRB- study_NN how_WRB to_TO achieve_VB a_DT desired_VBN accuracy_NN of_IN a_DT classifier_NN b_NN
ta_NN acquisition_NN ._.
The_DT most_RBS popular_JJ type_NN of_IN active_JJ learning_NN is_VBZ called_VBN ``_`` pool-based_JJ ''_'' active_JJ learning_NN ._.
Many_JJ works_NNS have_VBP been_VBN published_VBN in_IN recent_JJ years_NNS on_IN pool-based_JJ active_JJ learning_NN ,_, including_VBG ,_, for_IN instance_NN ,_, =_JJ -_: =[_NN 19_CD ,_, 22_CD ,_, 16_CD ,_, 17_CD ,_, 12_CD ,_, 1_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- See_NNP -LRB-_-LRB- 1_LS -RRB-_-RRB- for_IN a_DT good_JJ review_NN of_IN active_JJ learning_NN approaches_NNS -RRB-_-RRB- ._.
All_DT these_DT works_NNS assume_VBP that_IN a_DT pool_NN of_IN unlabeled_JJ examples_NNS is_VBZ given_VBN ,_, and_CC the_DT learner_NN can_MD choose_VB which_WDT ones_NNS to_TO acquire_VB their_PRP$ labels_NNS during_IN lear_NN
st._IN That_DT is_VBZ ,_, they_PRP assume_VBP that_IN a_DT fixed_JJ set_NN of_IN training_NN examples_NNS is_VBZ given_VBN ,_, and_CC the_DT leaner_JJR can_MD not_RB acquire_VB additional_JJ information_NN during_IN learning_NN ._.
Some_DT previous_JJ works_NNS study_NN data_NNS acquisition_NN cost_NN ,_, such_JJ as_IN =_JJ -_: =[_NN 10_CD ,_, 9_CD ,_, 23_CD ,_, 13_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Among_IN them_PRP ,_, some_DT -LRB-_-LRB- 10_CD ,_, 9_CD -RRB-_-RRB- study_NN how_WRB to_TO acquire_VB attribute_NN values_NNS to_TO build_VB an_DT optimal_JJ classifier_NN with_IN a_DT certain_JJ budget_NN ._.
The_DT others_NNS -LRB-_-LRB- 23_CD ,_, 13_CD ,_, 14_CD -RRB-_-RRB- study_NN how_WRB to_TO achieve_VB a_DT desired_VBN accuracy_NN of_IN a_DT classifier_NN b_NN
mber_NN of_IN training_NN examples_NNS in_IN leaves_NNS is_VBZ usually_RB very_RB small_JJ ,_, especially_RB at_IN the_DT beginning_NN of_IN example_NN acquisition_NN ._.
To_TO reduce_VB the_DT effect_NN of_IN extreme_JJ probability_NN estimations_NNS ,_, we_PRP apply_VBP the_DT Laplace_NNP correction_NN =_JJ -_: =[_NN 8_CD ,_, 3_CD -RRB-_-RRB- -_: =_SYM -_: to_TO smooth_VB probability_NN estimates_NNS in_IN leaves_NNS ._.
We_PRP modify_VBP the_DT original_JJ Laplace_NNP based_VBN on_IN accuracy_NN for_IN estimation_NN with_IN misclassification_NN cost_NN ._.
The_DT original_JJ Laplace_NNP correction_NN for_IN accuracy_NN can_MD be_VB expressed_VBN a_DT
st._IN That_DT is_VBZ ,_, they_PRP assume_VBP that_IN a_DT fixed_JJ set_NN of_IN training_NN examples_NNS is_VBZ given_VBN ,_, and_CC the_DT leaner_JJR can_MD not_RB acquire_VB additional_JJ information_NN during_IN learning_NN ._.
Some_DT previous_JJ works_NNS study_NN data_NNS acquisition_NN cost_NN ,_, such_JJ as_IN =_JJ -_: =[_NN 10_CD ,_, 9_CD ,_, 23_CD ,_, 13_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Among_IN them_PRP ,_, some_DT -LRB-_-LRB- 10_CD ,_, 9_CD -RRB-_-RRB- study_NN how_WRB to_TO acquire_VB attribute_NN values_NNS to_TO build_VB an_DT optimal_JJ classifier_NN with_IN a_DT certain_JJ budget_NN ._.
The_DT others_NNS -LRB-_-LRB- 23_CD ,_, 13_CD ,_, 14_CD -RRB-_-RRB- study_NN how_WRB to_TO achieve_VB a_DT desired_VBN accuracy_NN of_IN a_DT classifier_NN b_NN
ta_NN acquisition_NN ._.
The_DT most_RBS popular_JJ type_NN of_IN active_JJ learning_NN is_VBZ called_VBN ``_`` pool-based_JJ ''_'' active_JJ learning_NN ._.
Many_JJ works_NNS have_VBP been_VBN published_VBN in_IN recent_JJ years_NNS on_IN pool-based_JJ active_JJ learning_NN ,_, including_VBG ,_, for_IN instance_NN ,_, =_JJ -_: =[_NN 19_CD ,_, 22_CD ,_, 16_CD ,_, 17_CD ,_, 12_CD ,_, 1_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- See_NNP -LRB-_-LRB- 1_LS -RRB-_-RRB- for_IN a_DT good_JJ review_NN of_IN active_JJ learning_NN approaches_NNS -RRB-_-RRB- ._.
All_DT these_DT works_NNS assume_VBP that_IN a_DT pool_NN of_IN unlabeled_JJ examples_NNS is_VBZ given_VBN ,_, and_CC the_DT learner_NN can_MD choose_VB which_WDT ones_NNS to_TO acquire_VB their_PRP$ labels_NNS during_IN lear_NN
st._IN That_DT is_VBZ ,_, they_PRP assume_VBP that_IN a_DT fixed_JJ set_NN of_IN training_NN examples_NNS is_VBZ given_VBN ,_, and_CC the_DT leaner_JJR can_MD not_RB acquire_VB additional_JJ information_NN during_IN learning_NN ._.
Some_DT previous_JJ works_NNS study_NN data_NNS acquisition_NN cost_NN ,_, such_JJ as_IN =_JJ -_: =[_NN 10_CD ,_, 9_CD ,_, 23_CD ,_, 13_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Among_IN them_PRP ,_, some_DT -LRB-_-LRB- 10_CD ,_, 9_CD -RRB-_-RRB- study_NN how_WRB to_TO acquire_VB attribute_NN values_NNS to_TO build_VB an_DT optimal_JJ classifier_NN with_IN a_DT certain_JJ budget_NN ._.
The_DT others_NNS -LRB-_-LRB- 23_CD ,_, 13_CD ,_, 14_CD -RRB-_-RRB- study_NN how_WRB to_TO achieve_VB a_DT desired_VBN accuracy_NN of_IN a_DT classifier_NN b_NN
ta_NN acquisition_NN ._.
The_DT most_RBS popular_JJ type_NN of_IN active_JJ learning_NN is_VBZ called_VBN ``_`` pool-based_JJ ''_'' active_JJ learning_NN ._.
Many_JJ works_NNS have_VBP been_VBN published_VBN in_IN recent_JJ years_NNS on_IN pool-based_JJ active_JJ learning_NN ,_, including_VBG ,_, for_IN instance_NN ,_, =_JJ -_: =[_NN 19_CD ,_, 22_CD ,_, 16_CD ,_, 17_CD ,_, 12_CD ,_, 1_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- See_NNP -LRB-_-LRB- 1_LS -RRB-_-RRB- for_IN a_DT good_JJ review_NN of_IN active_JJ learning_NN approaches_NNS -RRB-_-RRB- ._.
All_DT these_DT works_NNS assume_VBP that_IN a_DT pool_NN of_IN unlabeled_JJ examples_NNS is_VBZ given_VBN ,_, and_CC the_DT learner_NN can_MD choose_VB which_WDT ones_NNS to_TO acquire_VB their_PRP$ labels_NNS during_IN lear_NN
st._IN That_DT is_VBZ ,_, they_PRP assume_VBP that_IN a_DT fixed_JJ set_NN of_IN training_NN examples_NNS is_VBZ given_VBN ,_, and_CC the_DT leaner_JJR can_MD not_RB acquire_VB additional_JJ information_NN during_IN learning_NN ._.
Some_DT previous_JJ works_NNS study_NN data_NNS acquisition_NN cost_NN ,_, such_JJ as_IN =_JJ -_: =[_NN 10_CD ,_, 9_CD ,_, 23_CD ,_, 13_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Among_IN them_PRP ,_, some_DT -LRB-_-LRB- 10_CD ,_, 9_CD -RRB-_-RRB- study_NN how_WRB to_TO acquire_VB attribute_NN values_NNS to_TO build_VB an_DT optimal_JJ classifier_NN with_IN a_DT certain_JJ budget_NN ._.
The_DT others_NNS -LRB-_-LRB- 23_CD ,_, 13_CD ,_, 14_CD -RRB-_-RRB- study_NN how_WRB to_TO achieve_VB a_DT desired_VBN accuracy_NN of_IN a_DT classifier_NN b_NN
ta_NN acquisition_NN ._.
The_DT most_RBS popular_JJ type_NN of_IN active_JJ learning_NN is_VBZ called_VBN ``_`` pool-based_JJ ''_'' active_JJ learning_NN ._.
Many_JJ works_NNS have_VBP been_VBN published_VBN in_IN recent_JJ years_NNS on_IN pool-based_JJ active_JJ learning_NN ,_, including_VBG ,_, for_IN instance_NN ,_, =_JJ -_: =[_NN 19_CD ,_, 22_CD ,_, 16_CD ,_, 17_CD ,_, 12_CD ,_, 1_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- See_NNP -LRB-_-LRB- 1_LS -RRB-_-RRB- for_IN a_DT good_JJ review_NN of_IN active_JJ learning_NN approaches_NNS -RRB-_-RRB- ._.
All_DT these_DT works_NNS assume_VBP that_IN a_DT pool_NN of_IN unlabeled_JJ examples_NNS is_VBZ given_VBN ,_, and_CC the_DT learner_NN can_MD choose_VB which_WDT ones_NNS to_TO acquire_VB their_PRP$ labels_NNS during_IN lear_NN
ta_NN acquisition_NN ._.
The_DT most_RBS popular_JJ type_NN of_IN active_JJ learning_NN is_VBZ called_VBN ``_`` pool-based_JJ ''_'' active_JJ learning_NN ._.
Many_JJ works_NNS have_VBP been_VBN published_VBN in_IN recent_JJ years_NNS on_IN pool-based_JJ active_JJ learning_NN ,_, including_VBG ,_, for_IN instance_NN ,_, =_JJ -_: =[_NN 19_CD ,_, 22_CD ,_, 16_CD ,_, 17_CD ,_, 12_CD ,_, 1_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- See_NNP -LRB-_-LRB- 1_LS -RRB-_-RRB- for_IN a_DT good_JJ review_NN of_IN active_JJ learning_NN approaches_NNS -RRB-_-RRB- ._.
All_DT these_DT works_NNS assume_VBP that_IN a_DT pool_NN of_IN unlabeled_JJ examples_NNS is_VBZ given_VBN ,_, and_CC the_DT learner_NN can_MD choose_VB which_WDT ones_NNS to_TO acquire_VB their_PRP$ labels_NNS during_IN lear_NN
ts_NNS to_TO compare_VB COM_NN and_CC PAS_NN ,_, and_CC analyze_VB the_DT results_NNS in_IN Section_NNP 5_CD ._.
Finally_RB we_PRP conclude_VBP the_DT work_NN in_IN Section_NN 6_CD ._.
2_CD ._.
RELATED_NNS WORK_VBP Cost-sensitive_JJ learning_NN is_VBZ an_DT active_JJ research_NN topic_NN in_IN recent_JJ years_NNS ._.
Turney_NN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: gives_VBZ an_DT excellent_JJ survey_NN on_IN a_DT variety_NN of_IN costs_NNS that_WDT may_MD be_VB considered_VBN in_IN learning_NN ,_, such_JJ as_IN misclassification_NN costs_NNS ,_, data_NNS acquisition_NN cost_NN -LRB-_-LRB- including_VBG example_NN costs_NNS and_CC attribute_NN costs_NNS -RRB-_-RRB- ,_, active_JJ learni_NNS
ve_IN learning_VBG only_RB consider_VBP minimizing_VBG misclassification_NN costs_NNS -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 5_CD ,_, 20_CD ,_, 6_CD ,_, 18_CD -RRB-_-RRB- -RRB-_-RRB- ._.
A_DT few_JJ works_NNS do_VBP attempt_NN to_TO minimize_VB the_DT sum_NN of_IN 638Research_NNP Track_NNP Paper_NNP misclassification_NN costs_NNS and_CC attribute_NN costs_NNS =_JJ -_: =[_NN 21_CD ,_, 4_CD ,_, 24_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, these_DT works_NNS do_VBP not_RB consider_VB data_NN acquisition_NN cost_NN ._.
That_DT is_VBZ ,_, they_PRP assume_VBP that_IN a_DT fixed_JJ set_NN of_IN training_NN examples_NNS is_VBZ given_VBN ,_, and_CC the_DT leaner_JJR can_MD not_RB acquire_VB additional_JJ information_NN during_IN learning_NN ._.
y_NN have_VBP at_IN least_JJS some_DT discrete_JJ attributes_NNS ,_, binary_JJ class_NN ,_, and_CC a_DT good_JJ number_NN of_IN examples_NNS ._.
641Research_NNP Track_NNP Paper_NNP The_DT numerical_JJ attributes_NNS in_IN datasets_NNS are_VBP discretized_VBN first_RB using_VBG minimal_JJ entropy_NN method_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: as_IN CSDT_NN can_MD currently_RB only_RB deal_VB with_IN discrete_JJ attributes_NNS ._.
We_PRP also_RB try_VBP to_TO choose_VB datasets_NNS with_IN very_RB different_JJ number_NN of_IN attributes_NNS ._.
The_DT number_NN of_IN attributes_NNS and_CC other_JJ features_NNS of_IN these_DT datasets_NNS are_VBP li_FW
ute_NN costs_NNS -RRB-_-RRB- ,_, active_JJ learning_NN costs_NNS ,_, computation_NN cost_NN ,_, human-computer_JJ interaction_NN cost_NN ,_, and_CC so_RB on_RB ._.
Most_JJS previous_JJ works_NNS on_IN cost-sensitive_JJ learning_NN only_RB consider_VBP minimizing_VBG misclassification_NN costs_NNS -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 5_CD ,_, 20_CD ,_, 6_CD ,_, 18_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
A_DT few_JJ works_NNS do_VBP attempt_NN to_TO minimize_VB the_DT sum_NN of_IN 638Research_NNP Track_NNP Paper_NNP misclassification_NN costs_NNS and_CC attribute_NN costs_NNS -LRB-_-LRB- 21_CD ,_, 4_CD ,_, 24_CD ,_, 11_CD -RRB-_-RRB- ._.
However_RB ,_, these_DT works_NNS do_VBP not_RB consider_VB data_NN acquisition_NN cost_NN ._.
That_DT
that_IN of_IN COM_NNP ._.
We_PRP investigate_VBP this_DT in_IN the_DT next_JJ section_NN -LRB-_-LRB- Section_NN 5_CD -RRB-_-RRB- ._.
5_CD ._.
EXPERIMENTS_NNS We_PRP conduct_VBP experiments_NNS with_IN PAS_NN and_CC COM_NN on_IN 10_CD real-world_JJ datasets_NNS downloaded_VBN from_IN the_DT UCI_NNP Machine_NNP Learning_NNP Repository_NNP =_SYM -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
These_DT datasets_NNS are_VBP chosen_VBN because_IN they_PRP have_VBP at_IN least_JJS some_DT discrete_JJ attributes_NNS ,_, binary_JJ class_NN ,_, and_CC a_DT good_JJ number_NN of_IN examples_NNS ._.
641Research_NNP Track_NNP Paper_NNP The_DT numerical_JJ attributes_NNS in_IN datasets_NNS are_VBP discreti_NN
ve_IN learning_VBG only_RB consider_VBP minimizing_VBG misclassification_NN costs_NNS -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 5_CD ,_, 20_CD ,_, 6_CD ,_, 18_CD -RRB-_-RRB- -RRB-_-RRB- ._.
A_DT few_JJ works_NNS do_VBP attempt_NN to_TO minimize_VB the_DT sum_NN of_IN 638Research_NNP Track_NNP Paper_NNP misclassification_NN costs_NNS and_CC attribute_NN costs_NNS =_JJ -_: =[_NN 21_CD ,_, 4_CD ,_, 24_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, these_DT works_NNS do_VBP not_RB consider_VB data_NN acquisition_NN cost_NN ._.
That_DT is_VBZ ,_, they_PRP assume_VBP that_IN a_DT fixed_JJ set_NN of_IN training_NN examples_NNS is_VBZ given_VBN ,_, and_CC the_DT leaner_JJR can_MD not_RB acquire_VB additional_JJ information_NN during_IN learning_NN ._.
ute_NN costs_NNS -RRB-_-RRB- ,_, active_JJ learning_NN costs_NNS ,_, computation_NN cost_NN ,_, human-computer_JJ interaction_NN cost_NN ,_, and_CC so_RB on_RB ._.
Most_JJS previous_JJ works_NNS on_IN cost-sensitive_JJ learning_NN only_RB consider_VBP minimizing_VBG misclassification_NN costs_NNS -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 5_CD ,_, 20_CD ,_, 6_CD ,_, 18_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
A_DT few_JJ works_NNS do_VBP attempt_NN to_TO minimize_VB the_DT sum_NN of_IN 638Research_NNP Track_NNP Paper_NNP misclassification_NN costs_NNS and_CC attribute_NN costs_NNS -LRB-_-LRB- 21_CD ,_, 4_CD ,_, 24_CD ,_, 11_CD -RRB-_-RRB- ._.
However_RB ,_, these_DT works_NNS do_VBP not_RB consider_VB data_NN acquisition_NN cost_NN ._.
That_DT
ve_IN learning_VBG only_RB consider_VBP minimizing_VBG misclassification_NN costs_NNS -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 5_CD ,_, 20_CD ,_, 6_CD ,_, 18_CD -RRB-_-RRB- -RRB-_-RRB- ._.
A_DT few_JJ works_NNS do_VBP attempt_NN to_TO minimize_VB the_DT sum_NN of_IN 638Research_NNP Track_NNP Paper_NNP misclassification_NN costs_NNS and_CC attribute_NN costs_NNS =_JJ -_: =[_NN 21_CD ,_, 4_CD ,_, 24_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, these_DT works_NNS do_VBP not_RB consider_VB data_NN acquisition_NN cost_NN ._.
That_DT is_VBZ ,_, they_PRP assume_VBP that_IN a_DT fixed_JJ set_NN of_IN training_NN examples_NNS is_VBZ given_VBN ,_, and_CC the_DT leaner_JJR can_MD not_RB acquire_VB additional_JJ information_NN during_IN learning_NN ._.
ve_IN learning_VBG only_RB consider_VBP minimizing_VBG misclassification_NN costs_NNS -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 5_CD ,_, 20_CD ,_, 6_CD ,_, 18_CD -RRB-_-RRB- -RRB-_-RRB- ._.
A_DT few_JJ works_NNS do_VBP attempt_NN to_TO minimize_VB the_DT sum_NN of_IN 638Research_NNP Track_NNP Paper_NNP misclassification_NN costs_NNS and_CC attribute_NN costs_NNS =_JJ -_: =[_NN 21_CD ,_, 4_CD ,_, 24_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, these_DT works_NNS do_VBP not_RB consider_VB data_NN acquisition_NN cost_NN ._.
That_DT is_VBZ ,_, they_PRP assume_VBP that_IN a_DT fixed_JJ set_NN of_IN training_NN examples_NNS is_VBZ given_VBN ,_, and_CC the_DT leaner_JJR can_MD not_RB acquire_VB additional_JJ information_NN during_IN learning_NN ._.
ta_NN acquisition_NN ._.
The_DT most_RBS popular_JJ type_NN of_IN active_JJ learning_NN is_VBZ called_VBN ``_`` pool-based_JJ ''_'' active_JJ learning_NN ._.
Many_JJ works_NNS have_VBP been_VBN published_VBN in_IN recent_JJ years_NNS on_IN pool-based_JJ active_JJ learning_NN ,_, including_VBG ,_, for_IN instance_NN ,_, =_JJ -_: =[_NN 19_CD ,_, 22_CD ,_, 16_CD ,_, 17_CD ,_, 12_CD ,_, 1_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- See_NNP -LRB-_-LRB- 1_LS -RRB-_-RRB- for_IN a_DT good_JJ review_NN of_IN active_JJ learning_NN approaches_NNS -RRB-_-RRB- ._.
All_DT these_DT works_NNS assume_VBP that_IN a_DT pool_NN of_IN unlabeled_JJ examples_NNS is_VBZ given_VBN ,_, and_CC the_DT learner_NN can_MD choose_VB which_WDT ones_NNS to_TO acquire_VB their_PRP$ labels_NNS during_IN lear_NN
ute_NN costs_NNS -RRB-_-RRB- ,_, active_JJ learning_NN costs_NNS ,_, computation_NN cost_NN ,_, human-computer_JJ interaction_NN cost_NN ,_, and_CC so_RB on_RB ._.
Most_JJS previous_JJ works_NNS on_IN cost-sensitive_JJ learning_NN only_RB consider_VBP minimizing_VBG misclassification_NN costs_NNS -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 5_CD ,_, 20_CD ,_, 6_CD ,_, 18_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
A_DT few_JJ works_NNS do_VBP attempt_NN to_TO minimize_VB the_DT sum_NN of_IN 638Research_NNP Track_NNP Paper_NNP misclassification_NN costs_NNS and_CC attribute_NN costs_NNS -LRB-_-LRB- 21_CD ,_, 4_CD ,_, 24_CD ,_, 11_CD -RRB-_-RRB- ._.
However_RB ,_, these_DT works_NNS do_VBP not_RB consider_VB data_NN acquisition_NN cost_NN ._.
That_DT
mber_NN of_IN training_NN examples_NNS in_IN leaves_NNS is_VBZ usually_RB very_RB small_JJ ,_, especially_RB at_IN the_DT beginning_NN of_IN example_NN acquisition_NN ._.
To_TO reduce_VB the_DT effect_NN of_IN extreme_JJ probability_NN estimations_NNS ,_, we_PRP apply_VBP the_DT Laplace_NNP correction_NN =_JJ -_: =[_NN 8_CD ,_, 3_CD -RRB-_-RRB- -_: =_SYM -_: to_TO smooth_VB probability_NN estimates_NNS in_IN leaves_NNS ._.
We_PRP modify_VBP the_DT original_JJ Laplace_NNP based_VBN on_IN accuracy_NN for_IN estimation_NN with_IN misclassification_NN cost_NN ._.
The_DT original_JJ Laplace_NNP correction_NN for_IN accuracy_NN can_MD be_VB expressed_VBN a_DT
