A_DT new_JJ multi-view_JJ regression_NN approach_NN with_IN an_DT application_NN to_TO customer_NN wallet_NN estimation_NN
Motivated_VBN by_IN the_DT problem_NN of_IN customer_NN wallet_NN estimation_NN ,_, we_PRP propose_VBP a_DT new_JJ setting_NN for_IN multi-view_JJ regression_NN ,_, where_WRB we_PRP learn_VBP a_DT completely_RB unobserved_JJ target_NN -LRB-_-LRB- in_IN our_PRP$ case_NN ,_, customer_NN wallet_NN -RRB-_-RRB- by_IN modeling_NN it_PRP as_IN a_DT ``_`` central_JJ link_NN ''_'' in_IN a_DT directed_JJ graphical_JJ model_NN ,_, connecting_VBG multiple_JJ sets_NNS of_IN observed_VBN variables_NNS ._.
The_DT resulting_VBG conditional_JJ independence_NN allows_VBZ us_PRP to_TO reduce_VB the_DT maximum_NN discriminative_JJ likelihood_NN estimation_NN problem_NN to_TO a_DT convex_NN optimization_NN problem_NN for_IN exponential_JJ linear_JJ models_NNS ._.
We_PRP show_VBP that_IN under_IN certain_JJ modeling_NN assumptions_NNS ,_, in_IN particular_JJ ,_, when_WRB there_EX exist_VBP two_CD conditionally_RB independent_JJ views_NNS and_CC the_DT noise_NN is_VBZ Gaussian_NNP ,_, this_DT problem_NN can_MD be_VB reduced_VBN to_TO a_DT single_JJ least_JJS squares_NNS regression_NN ._.
Thus_RB ,_, for_IN this_DT specific_JJ ,_, but_CC widely_RB applicable_JJ setting_NN ,_, the_DT ``_`` unsupervised_JJ ''_'' multi-view_JJ problem_NN can_MD be_VB solved_VBN via_IN a_DT simple_JJ supervised_JJ learning_NN approach_NN ._.
This_DT reduction_NN also_RB allows_VBZ us_PRP to_TO test_VB the_DT statistical_JJ independence_NN assumptions_NNS underlying_VBG the_DT graphical_JJ model_NN and_CC perform_VB variable_JJ selection_NN ._.
We_PRP demonstrate_VBP the_DT effectiveness_NN of_IN our_PRP$ approach_NN on_IN our_PRP$ motivating_VBG problem_NN of_IN customer_NN wallet_NN estimation_NN and_CC on_IN simulation_NN data_NNS ._.
monstrate_NN are_VBP closely_RB related_JJ to_TO Bayesian_JJ network_NN learning_NN and_CC least_JJS squares_NNS regression_NN ._.
Statistical_JJ Market_NNP Analysis_NNP ._.
Most_JJS of_IN the_DT classical_JJ market_NN analysis_NN approaches_NNS such_JJ as_IN life_NN time_NN value_NN modeling_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: focus_NN on_IN sales_NNS history_NN ._.
Recent_JJ work_NN -LRB-_-LRB- 7_CD ,_, 9_CD -RRB-_-RRB- shows_VBZ that_IN the_DT share-of-wallet_NN is_VBZ a_DT better_JJR indicator_NN of_IN the_DT customer_NN growth_NN potential_NN ._.
However_RB ,_, there_EX has_VBZ been_VBN relatively_RB little_JJ work_NN on_IN designing_VBG principle_NN
r_NN growth_NN ,_, is_VBZ considered_VBN extremely_RB valuable_JJ for_IN marketing_NN ,_, resource_NN planning_NN and_CC other_JJ tasks_NNS ._.
For_IN a_DT detailed_JJ survey_NN of_IN the_DT motivation_NN ,_, problem_NN definition_NN ,_, and_CC some_DT alternative_JJ solution_NN approaches_NNS ,_, see_VBP =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN our_PRP$ purpose_NN ,_, the_DT important_JJ aspect_NN of_IN this_DT problem_NN is_VBZ that_IN the_DT desired_VBN target_NN ,_, i.e._FW ,_, the_DT customer_NN wallet_NN ,_, is_VBZ completely_RB unobserved_JJ ,_, but_CC we_PRP have_VBP access_NN to_TO two_CD sources_NNS of_IN related_JJ information_NN :_: IBM_NNP 's_POS
in_IN several_JJ different_JJ areas_NNS ._.
It_PRP is_VBZ worth_JJ noting_VBG here_RB briefly_RB the_DT close_JJ relationship_NN and_CC interesting_JJ differences_NNS between_IN our_PRP$ work_NN and_CC two_CD of_IN these_DT areas_NNS ._.
First_RB ,_, the_DT area_NN of_IN co-training_NN and_CC its_PRP$ variants_NNS =_JJ -_: =[_NN 17_CD ,_, 3_CD ,_, 13_CD -RRB-_-RRB- -_: =_JJ -_: deal_NN with_IN a_DT similar_JJ problem_NN of_IN modeling_NN a_DT target_NN that_WDT is_VBZ rarely_RB observed_VBN in_IN the_DT presence_NN of_IN conditionally_RB independent_JJ views_NNS ._.
However_RB ,_, these_DT works_NNS make_VBP a_DT compatibility_NN -LRB-_-LRB- or_CC learnability_NN -RRB-_-RRB- assumption_NN tha_NN
in_IN several_JJ different_JJ areas_NNS ._.
It_PRP is_VBZ worth_JJ noting_VBG here_RB briefly_RB the_DT close_JJ relationship_NN and_CC interesting_JJ differences_NNS between_IN our_PRP$ work_NN and_CC two_CD of_IN these_DT areas_NNS ._.
First_RB ,_, the_DT area_NN of_IN co-training_NN and_CC its_PRP$ variants_NNS =_JJ -_: =[_NN 17_CD ,_, 3_CD ,_, 13_CD -RRB-_-RRB- -_: =_JJ -_: deal_NN with_IN a_DT similar_JJ problem_NN of_IN modeling_NN a_DT target_NN that_WDT is_VBZ rarely_RB observed_VBN in_IN the_DT presence_NN of_IN conditionally_RB independent_JJ views_NNS ._.
However_RB ,_, these_DT works_NNS make_VBP a_DT compatibility_NN -LRB-_-LRB- or_CC learnability_NN -RRB-_-RRB- assumption_NN tha_NN
t_NN via_IN a_DT supervised_JJ learning_NN approach_NN on_IN the_DT surrogate_JJ target_NN ._.
This_DT is_VBZ of_IN course_NN beneficial_JJ from_IN a_DT computational_JJ perspective_NN ,_, as_IN it_PRP allows_VBZ us_PRP to_TO harness_NN the_DT full_JJ power_NN of_IN linear_JJ regression_NN methodology_NN =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Among_IN the_DT things_NNS we_PRP can_MD now_RB do_VB are_VBP variable_JJ selection_NN methodologies_NNS ,_, such_JJ as_IN forward_RB and_CC backward_RB selection_NN ,_, and_CC analysis_NN of_IN variance_NN -LRB-_-LRB- ANOVA_NN -RRB-_-RRB- for_IN testing_NN goodness_NN of_IN fit_NN for_IN nested_JJ models_NNS ._.
The_DT use_NN o_NN
However_RB ,_, these_DT works_NNS make_VBP a_DT compatibility_NN -LRB-_-LRB- or_CC learnability_NN -RRB-_-RRB- assumption_NN that_IN while_IN powerful_JJ ,_, is_VBZ also_RB very_RB limiting_VBG ._.
Our_PRP$ approach_NN makes_VBZ no_DT such_JJ assumptions_NNS ._.
Second_RB ,_, the_DT area_NN of_IN latent_JJ variable_JJ modeling_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: considers_VBZ multiple_JJ views_NNS with_IN conditional_JJ independence_NN much_RB in_IN the_DT same_JJ spirit_NN as_IN this_DT work_NN ,_, although_IN typically_RB with_IN a_DT different_JJ goal_NN in_IN mind_NN ,_, of_IN modeling_NN the_DT observed_VBN data_NNS better_RBR ._.
The_DT main_JJ differenc_NN
f_LS the_DT fact_NN that_IN each_DT parameter_NN θk_NN ,_, -LRB-_-LRB- k_NN -RRB-_-RRB- Nc_NN 0_CD occurs_VBZ in_IN a_DT single_JJ conditional_JJ distribution_NN contributing_VBG to_TO LD_NN -LRB-_-LRB- Θ_NN -RRB-_-RRB- in_IN -LRB-_-LRB- 2.2_CD -RRB-_-RRB- ,_, each_DT of_IN which_WDT corresponds_VBZ to_TO an_DT exponential_JJ distribution_NN known_VBN to_TO be_VB logconcave_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: in_IN the_DT natural_JJ parameters_NNS ,_, in_IN this_DT case_NN θ_NN t_NN 0X_NN and_CC -LRB-_-LRB- W_NN +_CC θ_NN t_NN kYk_NN -RRB-_-RRB- ,_, -LRB-_-LRB- k_NN -RRB-_-RRB- Nc_NN 1_CD ._.
2.3_CD Expectation-Maximization_NNP based_VBN Solution_NN Given_IN the_DT specific_JJ form_NN of_IN the_DT likelihood_NN maximization_NN problem_NN -LRB-_-LRB- 2.3_CD -RRB-_-RRB- ,_, one_CD could_MD
s_NN transformation_NN allows_VBZ us_PRP to_TO employ_VB the_DT standard_JJ Bayesian_JJ network_NN learning_VBG methods_NNS for_IN estimating_VBG the_DT unobserved_JJ or_CC missing_JJ target_NN values_NNS using_VBG a_DT maximum_NN likelihood_NN formulation_NN and_CC EMbased_JJ algorithm_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Further_RB ,_, due_JJ to_TO the_DT special_JJ structure_NN of_IN the_DT Bayesian_JJ networks_NNS we_PRP consider_VBP ,_, the_DT resulting_VBG maximum_NN likelihood_NN estimation_NN problem_NN turns_VBZ out_RP to_TO be_VB convex_VBN for_IN a_DT large_JJ class_NN of_IN parametric_JJ models_NNS so_IN that_IN
ents_NNS of_IN the_DT children_NNS of_IN the_DT target_NN ,_, respectively_RB ._.
2.1_CD Directed_NNP Graphical_NNP Model_NNP We_PRP are_VBP interested_JJ in_IN the_DT case_NN that_IN all_DT relevant_JJ variables_NNS in_IN our_PRP$ graphical_JJ model_NN ,_, i.e._FW ,_, predictors_NNS in_IN the_DT Markov_NNP blanket_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: of_IN the_DT target_NN can_MD be_VB disjointly_RB partitioned_VBN into_IN these_DT three_CD categories_NNS with_IN no_DT dependencies_NNS other_JJ than_IN the_DT ones_NNS specified_VBN above_IN ._.
The_DT reason_NN we_PRP focus_VBP on_IN this_DT class_NN of_IN configurations_NNS is_VBZ because_IN they_PRP r_SYM
in_IN several_JJ different_JJ areas_NNS ._.
It_PRP is_VBZ worth_JJ noting_VBG here_RB briefly_RB the_DT close_JJ relationship_NN and_CC interesting_JJ differences_NNS between_IN our_PRP$ work_NN and_CC two_CD of_IN these_DT areas_NNS ._.
First_RB ,_, the_DT area_NN of_IN co-training_NN and_CC its_PRP$ variants_NNS =_JJ -_: =[_NN 17_CD ,_, 3_CD ,_, 13_CD -RRB-_-RRB- -_: =_JJ -_: deal_NN with_IN a_DT similar_JJ problem_NN of_IN modeling_NN a_DT target_NN that_WDT is_VBZ rarely_RB observed_VBN in_IN the_DT presence_NN of_IN conditionally_RB independent_JJ views_NNS ._.
However_RB ,_, these_DT works_NNS make_VBP a_DT compatibility_NN -LRB-_-LRB- or_CC learnability_NN -RRB-_-RRB- assumption_NN tha_NN
ver_RB ,_, there_EX has_VBZ been_VBN relatively_RB little_JJ work_NN on_IN designing_VBG principled_JJ statistical_JJ methods_NNS for_IN estimating_VBG the_DT share-of-wallet_JJ or_CC equivalently_RB ,_, the_DT wallet_NN itself_PRP ._.
Most_JJS of_IN the_DT existing_VBG wallet_NN modeling_NN work_NN =_JJ -_: =[_NN 6_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: involves_VBZ building_VBG predictive_JJ models_NNS using_VBG self-reported_JJ wallets_NNS of_IN the_DT customers_NNS ,_, which_WDT are_VBP often_RB unreliable_JJ ._.
A_DT recent_JJ work_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- presents_VBZ novel_JJ predictive_JJ techniques_NNS for_IN estimating_VBG the_DT ``_`` realistic_JJ ''_'' wa_NN
network_NN learning_NN and_CC least_JJS squares_NNS regression_NN ._.
Statistical_JJ Market_NNP Analysis_NNP ._.
Most_JJS of_IN the_DT classical_JJ market_NN analysis_NN approaches_NNS such_JJ as_IN life_NN time_NN value_NN modeling_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- focus_NN on_IN sales_NNS history_NN ._.
Recent_JJ work_NN =_JJ -_: =[_NN 7_CD ,_, 9_CD -RRB-_-RRB- -_: =_SYM -_: shows_VBZ that_IN the_DT share-of-wallet_NN is_VBZ a_DT better_JJR indicator_NN of_IN the_DT customer_NN growth_NN potential_NN ._.
However_RB ,_, there_EX has_VBZ been_VBN relatively_RB little_JJ work_NN on_IN designing_VBG principled_JJ statistical_JJ methods_NNS for_IN estimating_VBG the_DT sh_NN
network_NN learning_NN and_CC least_JJS squares_NNS regression_NN ._.
Statistical_JJ Market_NNP Analysis_NNP ._.
Most_JJS of_IN the_DT classical_JJ market_NN analysis_NN approaches_NNS such_JJ as_IN life_NN time_NN value_NN modeling_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- focus_NN on_IN sales_NNS history_NN ._.
Recent_JJ work_NN =_JJ -_: =[_NN 7_CD ,_, 9_CD -RRB-_-RRB- -_: =_SYM -_: shows_VBZ that_IN the_DT share-of-wallet_NN is_VBZ a_DT better_JJR indicator_NN of_IN the_DT customer_NN growth_NN potential_NN ._.
However_RB ,_, there_EX has_VBZ been_VBN relatively_RB little_JJ work_NN on_IN designing_VBG principled_JJ statistical_JJ methods_NNS for_IN estimating_VBG the_DT sh_NN
ion_NN FD_NN -LRB-_-LRB- ˜p_NN ,_, Θ_NN -RRB-_-RRB- corresponding_VBG to_TO the_DT likelihood_NN maximization_NN problem_NN defined_VBN as_IN :_: FD_NN -LRB-_-LRB- ˜p_NN ,_, Θ_NN -RRB-_-RRB- =_JJ E˜p_NN -LRB-_-LRB- log_NN pD_NN ,_, Θ_NN -LRB-_-LRB- W_NN ,_, S1_NN ,_, ·_FW ·_FW ·_NN ,_, SNc_NN -RRB-_-RRB- -RRB-_-RRB- +_CC H_NN -LRB-_-LRB- ˜p_NN -RRB-_-RRB- ,_, -LRB-_-LRB- 2.5_CD -RRB-_-RRB- 1_CD Detailed_JJ proofs_NNS have_VBP been_VBN omitted_VBN for_IN brevity_NN ._.
Please_VB see_VB =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: for_IN details_NNS ._.
where_WRB ˜p_NN is_VBZ the_DT posterior_JJ distribution_NN of_IN the_DT hidden_JJ variable_JJ W_NN given_VBN the_DT observed_VBN ones_NNS ,_, H_NN -LRB-_-LRB- ·_NN -RRB-_-RRB- is_VBZ Shannon_NNP 's_POS entropy_NN and_CC the_DT first_JJ term_NN is_VBZ the_DT expected_VBN complete_JJ likelihood_NN of_IN W_NN and_CC the_DT sur_NN
parametric_JJ model_NN -LRB-_-LRB- 2.1_CD -RRB-_-RRB- identical_JJ to_TO that_DT of_IN the_DT linear_NN least_JJS squares_NNS model_NN -LRB-_-LRB- 3.9_CD -RRB-_-RRB- and_CC that_IN the_DT least_JJS squares_NNS regression_NN estimators_NNS are_VBP unbiased_JJ as_RB well_RB as_IN consistent_JJ estimators_NNS of_IN the_DT true_JJ parameters_NNS =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Since_IN the_DT posterior_JJ distribution_NN ˜pi_NN -LRB-_-LRB- wi_NN -RRB-_-RRB- -LRB-_-LRB- i_LS -RRB-_-RRB- n_NN 1_CD is_VBZ Gaussian_NNP ,_, the_DT ML_NN estimate_NN for_IN the_DT target_NN is_VBZ just_RB the_DT expected_VBN value_NN of_IN the_DT distribution_NN ,_, i.e._FW ,_, ˆ_FW ¯_FW wi_FW ._.
Using_VBG Corollary_NN 1_CD ,_, we_PRP can_MD now_RB prove_VB the_DT the_DT u_NN
roblem_NN with_IN conditional_JJ independence_NN ;_: pose_VB the_DT discriminative_JJ learning_NN problem_NN that_WDT arises_VBZ from_IN it_PRP in_IN terms_NNS of_IN likelihood_NN maximization_NN ;_: and_CC show_VB how_WRB it_PRP can_MD be_VB solved_VBN using_VBG the_DT standard_JJ EM_NN methodology_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Further_RB ,_, we_PRP show_VBP that_IN when_WRB the_DT conditional_JJ distributions_NNS in_IN the_DT graphical_JJ model_NN follow_VBP parametric_JJ forms_NNS arising_VBG from_IN exponential_JJ linear_JJ models_NNS ,_, the_DT likelihood_NN maximization_NN reduces_VBZ to_TO a_DT convex_FW optimi_FW
