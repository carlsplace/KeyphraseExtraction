Effective_JJ label_NN acquisition_NN for_IN collective_JJ classification_NN
Information_NN diffusion_NN ,_, viral_JJ marketing_NN ,_, and_CC collective_JJ classification_NN all_DT attempt_NN to_TO model_VB and_CC exploit_VB the_DT relationships_NNS in_IN a_DT network_NN to_TO make_VB inferences_NNS about_IN the_DT labels_NNS of_IN nodes_NNS ._.
A_DT variety_NN of_IN techniques_NNS have_VBP been_VBN introduced_VBN and_CC methods_NNS that_WDT combine_VBP attribute_NN information_NN and_CC neighboring_JJ label_NN information_NN have_VBP been_VBN shown_VBN to_TO be_VB effective_JJ for_IN collective_JJ labeling_NN of_IN the_DT nodes_NNS in_IN a_DT network_NN ._.
However_RB ,_, in_IN part_NN because_IN of_IN the_DT correlation_NN between_IN node_NN labels_NNS that_IN the_DT techniques_NNS exploit_VBP ,_, it_PRP is_VBZ easy_JJ to_TO find_VB cases_NNS in_IN which_WDT ,_, once_RB a_DT misclassification_NN is_VBZ made_VBN ,_, incorrect_JJ information_NN propagates_VBZ throughout_IN the_DT network_NN ._.
This_DT problem_NN can_MD be_VB mitigated_VBN if_IN the_DT system_NN is_VBZ allowed_VBN to_TO judiciously_RB acquire_VB the_DT labels_NNS for_IN a_DT small_JJ number_NN of_IN nodes_NNS ._.
Unfortunately_RB ,_, under_IN relatively_RB general_JJ assumptions_NNS ,_, determining_VBG the_DT optimal_JJ set_NN of_IN labels_NNS to_TO acquire_VB is_VBZ intractable_JJ ._.
Here_RB we_PRP propose_VBP an_DT acquisition_NN method_NN that_WDT learns_VBZ the_DT cases_NNS when_WRB a_DT given_VBN collective_JJ classification_NN algorithm_NN makes_VBZ mistakes_NNS ,_, and_CC suggests_VBZ acquisitions_NNS to_TO correct_VB those_DT mistakes_NNS ._.
We_PRP empirically_RB show_VBP on_IN both_CC real_JJ and_CC synthetic_JJ datasets_NNS that_IN this_DT method_NN significantly_RB outperforms_VBZ a_DT greedy_JJ approximate_JJ inference_NN approach_NN ,_, a_DT viral_JJ marketing_NN approach_NN ,_, and_CC approaches_NNS based_VBN on_IN network_NN structural_JJ measures_NNS such_JJ as_IN node_NN degree_NN and_CC network_NN clustering_NN ._.
In_IN addition_NN to_TO significantly_RB improving_VBG accuracy_NN with_IN just_RB a_DT small_JJ amount_NN of_IN labeled_JJ data_NNS ,_, our_PRP$ method_NN is_VBZ tractable_JJ on_IN large_JJ networks_NNS ._.
ple_NN nodes_NNS where_WRB ``_`` role_NN ''_'' has_VBZ a_DT high_JJ positive_JJ autocorrelation_NN -LRB-_-LRB- i.e._FW ,_, people_NNS who_WP are_VBP friends_NNS like_IN have_VBP the_DT same_JJ role_NN -RRB-_-RRB- ._.
We_PRP then_RB create_VBP binary_JJ attributes_NNS based_VBN on_IN those_DT labels_NNS using_VBG the_DT method_NN described_VBN in_IN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- 5_CD attributes_NNS per_IN label_NN where_WRB secondary_JJ probability_NN is_VBZ set_VBN to_TO 0.45_CD while_IN the_DT primary_JJ probability_NN is_VBZ varied_VBN to_TO control_VB label_NN ambiguity_NN -RRB-_-RRB- ._.
The_DT second_JJ set_NN of_IN attributes_NNS is_VBZ used_VBN for_IN link_NN prediction_NN and_CC co_NN
e_LS independent_JJ and_CC identically_RB distributed_VBN -LRB-_-LRB- IID_NN -RRB-_-RRB- ,_, where_WRB the_DT objects_NNS either_CC do_VBP not_RB have_VB explicit_JJ relationships_NNS with_IN one_CD another_DT ,_, or_CC the_DT relationships_NNS have_VBP been_VBN ignored_VBN ._.
There_EX are_VBP few_JJ exceptions_NNS to_TO this_DT =_JJ -_: =[_NN 1_CD ,_, 2_CD ,_, 10_CD ,_, 18_CD -RRB-_-RRB- -_: =_JJ -_: ;_: however_RB ,_, none_NN of_IN these_DT work_NN offered_VBD a_DT general_JJ active_JJ learning_NN technique_NN for_IN complex_JJ networks_NNS ._.
With_IN recent_JJ developments_NNS in_IN relational_JJ models_NNS ,_, it_PRP has_VBZ been_VBN shown_VBN that_IN relationships_NNS between_IN objects_NNS carr_VBP
owledge_VB no_DT prior_JJ work_NN has_VBZ weighted_VBN uncertainty_NN sampling_NN by_IN ˆp_NN -LRB-_-LRB- x_NN -RRB-_-RRB- ._.
5_CD ._.
Related_NNP Work_NNP There_EX exists_VBZ a_DT body_NN of_IN work_NN on_IN active_JJ inference_NN in_IN networked_JJ data_NNS ,_, represented_VBN for_IN example_NN by_IN -LRB-_-LRB- Rattigan_NNP et_FW al._FW ,_, 2007_CD ;_: =_JJ -_: =_JJ Bilgic_NNP &_CC Getoor_NNP ,_, 2008_CD -_: =--RRB-_NN ._.
The_DT problem_NN setting_NN of_IN that_DT work_NN is_VBZ different_JJ from_IN that_DT of_IN this_DT paper_NN ._.
Rather_RB than_IN facing_VBG a_DT data_NN stream_NN with_IN possibly_RB repeated_VBN examples_NNS ,_, their_PRP$ examples_NNS are_VBP interconnected_VBN in_IN a_DT network_NN ._.
Via_NNP relation_NN
r_NN from_IN a_DT fully_RB labeled_VBN or_CC partially_RB labeled_VBN network_NN ._.
Recent_JJ work_NN on_IN active_JJ inference_NN has_VBZ demonstrated_VBN that_IN labeling_NN efforts_NNS can_MD be_VB used_VBN to_TO improve_VB collective_JJ inference_NN ,_, based_VBN on_IN the_DT network_NN topology_NN -LRB-_-LRB- =_JJ -_: =_JJ Bilgic_NNP &_CC Getoor_NNP ,_, 2008_CD -_: =_JJ -_: ;_: Macskassy_NNP ,_, 2009_CD -RRB-_-RRB- ._.
However_RB ,_, it_PRP is_VBZ more_RBR difficult_JJ to_TO incorporate_VB network_NN characteristics_NNS into_IN the_DT learning_NN process_NN ._.
Two_CD primary_JJ issues_NNS are_VBP :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- how_WRB to_TO learn_VB an_DT accurate_JJ model_NN from_IN a_DT partially-labeled_JJ
ve_RB because_IN our_PRP$ results_NNS will_MD show_VB they_PRP often_RB have_VBP rather_RB different_JJ performance_NN trends_NNS ._.
2782CAUTIOUS_CD COLLECTIVE_JJ CLASSIFICATION_NN known_VBN to_TO be_VB fraudulent_JJ ._.
Another_DT in-sample_JJ task_NN -LRB-_-LRB- Neville_NNP and_CC Jensen_NNP ,_, 2007_CD ;_: =_JJ -_: =_JJ Bilgic_NNP and_CC Getoor_NNP ,_, 2008_CD -_: =_JJ -_: ;_: Neville_NNP and_CC Jensen_NNP ,_, 2008_CD -RRB-_-RRB- assumes_VBZ a_DT separate_JJ training_NN graph_NN GTr_NN ,_, where_WRB a_DT model_NN is_VBZ learned_VBN from_IN GTr_NN and_CC inference_NN is_VBZ performed_VBN over_IN the_DT test_NN graph_NN G_NN ,_, which_WDT includes_VBZ both_CC labeled_JJ and_CC unlabeled_JJ nodes_NNS ._.
get_VB the_DT best_JJS performance_NN on_IN the_DT remaining_VBG ones_NNS ._.
Rattigan_NNP et_FW al._FW -LRB-_-LRB- 25_CD -RRB-_-RRB- queries_VBZ the_DT instances_NNS that_WDT are_VBP structurally_RB important_JJ ,_, e.g._FW highly_RB connected_VBN instances_NNS ,_, central_JJ instances_NNS ,_, etc._FW ._.
Bilgic_NNP and_CC Getoor_NNP =_SYM -_: =[_NN 26_CD -RRB-_-RRB- -_: =_SYM -_: build_VB a_DT classifier_NN that_WDT can_MD predict_VB which_WDT instances_NNS might_MD be_VB misclassified_VBN and_CC query_VB a_DT central_JJ instance_NN only_RB if_IN it_PRP is_VBZ predicted_VBN as_IN misclassified_VBN ._.
Even_RB though_IN these_DT methods_NNS have_VBP been_VBN quite_RB successful_JJ
ve_FW inference_FW has_VBZ shown_VBN that_IN selectively_RB querying_VBG for_IN node_NN labels_NNS based_VBN on_IN network_NN connectivity_NN and_CC model_NN uncertainty_NN can_MD significantly_RB improve_VB the_DT collective_JJ inference_NN process_NN -LRB-_-LRB- Rattigan_NNP et_FW al._FW ,_, 2007_CD ;_: =_JJ -_: =_JJ Bilgic_NNP &_CC Getoor_NNP ,_, 2008_CD -_: =_JJ -_: ;_: Macskassy_NNP ,_, 2009_CD -RRB-_-RRB- ._.
Second_RB ,_, it_PRP is_VBZ difficult_JJ to_TO learn_VB accurate_JJ joint_JJ models_NNS from_IN partially-labeled_JJ networks_NNS ._.
If_IN learning_VBG methods_NNS ignore_VBP the_DT unlabeled_JJ portion_NN of_IN the_DT network_NN ,_, then_RB there_EX may_MD not_RB be_VB enoug_JJ
hermore_RB ,_, as_IN in_IN other_JJ data_NNS acquisition_NN tasks_NNS -LRB-_-LRB- Section_NN 1.2_CD -RRB-_-RRB- finding_VBG the_DT optimal_JJ set_NN is_VBZ known_VBN to_TO be_VB an_DT NPhard_NN problem_NN as_IN it_PRP necessitates_VBZ the_DT investigation_NN of_IN all_DT possible_JJ candidate_NN active_JJ inference_NN sets_VBZ =_JJ -_: =[_NN 9_CD ,_, 10_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Because_IN of_IN the_DT computational_JJ difficulties_NNS associated_VBN with_IN finding_VBG the_DT optimal_JJ set_NN of_IN instances_NNS to_TO acquire_VB for_IN active_JJ inference_NN ,_, several_JJ approximation_NN techniques_NNS have_VBP been_VBN devised_VBN that_WDT enable_VBP a_DT subst_NN
used_VBN most_RBS effectively_RB for_IN the_DT classification_NN process_NN ._.
The_DT problem_NN of_IN classification_NN is_VBZ widely_RB studied_VBN in_IN the_DT data_NNS mining_NN community_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
The_DT problem_NN has_VBZ been_VBN studied_VBN in_IN the_DT context_NN of_IN both_CC structural_JJ =_JJ -_: =[_NN 3_CD ,_, 4_CD ,_, 10_CD -RRB-_-RRB- -_: =_JJ -_: and_CC content-based_JJ -LRB-_-LRB- 9_CD ,_, 12_CD ,_, 13_CD ,_, 16_CD -RRB-_-RRB- analysis_NN ._.
Two_CD natural_JJ choices_NNS can_MD be_VB used_VBN for_IN classification_NN of_IN content-rich_JJ networks_NNS :_: •_CD The_DT most_RBS straightforward_JJ approach_NN is_VBZ to_TO directly_RB use_VB text_NN classifiers_NNS in_IN ord_NN
erence_NN technique_NN is_VBZ expensive_JJ ,_, this_DT acquisition_NN method_NN can_MD be_VB very_RB slow_JJ ._.
4_LS ._.
VIRAL_NNP MARKETING_NNP ACQUISITION_NNP -LRB-_-LRB- VMA_NNP -RRB-_-RRB- Another_DT ,_, simpler_JJR ,_, approach_NN to_TO label_NN acquisition_NN is_VBZ based_VBN on_IN an_DT analogy_NN to_TO viral_JJ marketing_NN =_JJ -_: =[_NN 9_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN the_DT viral_JJ marketing_NN setting_NN ,_, we_PRP have_VBP customers_NNS that_WDT are_VBP potential_JJ buyers_NNS of_IN a_DT product_NN and_CC the_DT customers_NNS have_VBP relationships_NNS between_IN each_DT other_JJ ,_, such_JJ as_IN family_NN ,_, friendship_NN ,_, co-worker_NN ,_, etc._NN ._.
When_WRB a_DT c_NN
e_LS differences_NNS between_IN the_DT other_JJ methods_NNS were_VBD not_RB statistically_RB significant_JJ ._.
6.2_CD Experiments_NNS on_IN Real_NNP Data_NNP We_PRP experimented_VBD on_IN two_CD real_JJ publication_NN datasets_NNS that_WDT are_VBP publicly_RB available_JJ ,_, the_DT Cora_NNP dataset_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_JJ -_: and_CC the_DT CiteSeer_NNP dataset_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
The_DT Cora_NNP dataset_NN contains_VBZ a_DT 2708_CD machine_NN learning_NN papers_NNS that_WDT are_VBP divided_VBN into_IN 7_CD classes_NNS ,_, while_IN CiteSeer_FW dataset_FW has_VBZ 3312_CD documents_NNS that_WDT are_VBP divided_VBN into_IN 6_CD classes_NNS ._.
Our_PRP$
ady_RB trained_VBN model_NN of_IN the_DT domain_NN ,_, and_CC thus_RB the_DT learning_NN has_VBZ been_VBN done_VBN offline_JJ ,_, but_CC we_PRP have_VBP the_DT option_NN to_TO acquire_VB labels_NNS to_TO seed_NN the_DT classification_NN during_IN inference_NN ._.
This_DT is_VBZ the_DT setting_VBG Rattigan_NNP et_FW al._FW =_SYM -_: =[_NN 22_CD -RRB-_-RRB- -_: =_SYM -_: introduced_VBN and_CC referred_VBN to_TO as_IN ``_`` active_JJ inference_NN ._. ''_''
They_PRP looked_VBD at_IN the_DT relational_JJ network_NN classifier_NN ,_, introduced_VBN by_IN Macskassy_NNP and_CC Provost_NNP -LRB-_-LRB- 14_CD -RRB-_-RRB- in_IN which_WDT there_EX are_VBP no_DT node_NN attributes_VBZ ;_: only_RB labels_NNS are_VBP pro_JJ
it_PRP has_VBZ been_VBN shown_VBN that_IN methods_NNS such_JJ as_IN collective_JJ classification_NN ,_, i.e._FW ,_, classifying_VBG the_DT nodes_NNS of_IN a_DT network_NN simultaneously_RB ,_, can_MD significantly_RB outperform_VB the_DT traditional_JJ independent_JJ labeling_NN approaches_VBZ =_JJ -_: =[_NN 2_CD ,_, 7_CD ,_, 13_CD ,_, 15_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, sometimes_RB ,_, the_DT advantage_NN of_IN exploiting_VBG the_DT relationships_NNS can_MD become_VB a_DT disadvantage_NN ._.
An_DT incorrect_JJ prediction_NN about_IN a_DT particular_JJ node_NN -LRB-_-LRB- due_JJ to_TO an_DT approximate_JJ inference_NN procedure_NN ,_, noise_NN in_IN the_DT
ing_NN model_NN is_VBZ an_DT undirected_JJ graphical_JJ model_NN ,_, such_JJ as_IN Markov_NNP random_JJ field_NN ,_, there_EX are_VBP many_JJ approximate_JJ inference_NN techniques_NNS we_PRP can_MD make_VB use_NN of_IN ,_, such_JJ as_IN loopy_JJ belief_NN propagation_NN -LRB-_-LRB- 28_CD -RRB-_-RRB- ,_, variational_JJ methods_NNS =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Gibbs_NNP sampling_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, etc._NN ._.
If_IN the_DT underlying_JJ model_NN is_VBZ a_DT collection_NN of_IN local_JJ conditional_JJ models_NNS ,_, then_RB one_PRP can_MD use_VB iterative_JJ approaches_NNS to_TO compute_VB the_DT probabilities_NNS -LRB-_-LRB- 19_CD ,_, 13_CD -RRB-_-RRB- ._.
Moreover_RB ,_, instead_RB of_IN consid_NN
instance_NN ,_, when_WRB the_DT underlying_VBG model_NN is_VBZ an_DT undirected_JJ graphical_JJ model_NN ,_, such_JJ as_IN Markov_NNP random_JJ field_NN ,_, there_EX are_VBP many_JJ approximate_JJ inference_NN techniques_NNS we_PRP can_MD make_VB use_NN of_IN ,_, such_JJ as_IN loopy_JJ belief_NN propagation_NN =_JJ -_: =[_NN 28_CD -RRB-_-RRB- -_: =_JJ -_: ,_, variational_JJ methods_NNS -LRB-_-LRB- 8_CD -RRB-_-RRB- ,_, Gibbs_NN sampling_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, etc._NN ._.
If_IN the_DT underlying_JJ model_NN is_VBZ a_DT collection_NN of_IN local_JJ conditional_JJ models_NNS ,_, then_RB one_PRP can_MD use_VB iterative_JJ approaches_NNS to_TO compute_VB the_DT probabilities_NNS -LRB-_-LRB- 19_CD ,_, 13_CD -RRB-_-RRB- ._.
Mo_NN
hod_NN we_PRP propose_VBP significantly_RB outperforms_VBZ all_DT of_IN the_DT other_JJ methods_NNS on_IN both_CC real_JJ and_CC synthetic_JJ datasets_NNS ._.
The_DT label_NN acquisition_NN problem_NN has_VBZ received_VBN ample_JJ attention_NN within_IN the_DT context_NN of_IN active_JJ learning_NN =_JJ -_: =[_NN 3_CD ,_, 16_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
There_EX are_VBP two_CD main_JJ differences_NNS between_IN the_DT scenario_NN we_PRP address_VBP and_CC the_DT active_JJ learning_NN scenario_NN ._.
First_JJ ,_, active_JJ learning_NN has_VBZ traditionally_RB been_VBN concerned_VBN with_IN flat_JJ data_NNS ;_: here_RB ,_, we_PRP are_VBP interested_JJ in_IN ne_NN
butes_NNS of_IN other_JJ nodes_NNS in_IN the_DT graph_NN ._.
There_EX are_VBP many_JJ collective_JJ classification_NN models_NNS proposed_VBN to_TO date_NN that_WDT make_VBP different_JJ modeling_NN assumptions_NNS about_IN these_DT dependencies_NNS ._.
For_IN instance_NN ,_, Neville_NNP and_CC Jensen_NNP =_SYM -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Lu_NNP and_CC Getoor_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, Macskassy_NNP and_CC Provost_NNP -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, and_CC McDowell_NNP et_FW al._FW -LRB-_-LRB- 18_CD -RRB-_-RRB- make_VBP use_NN of_IN local_JJ models_NNS ,_, such_JJ as_IN Naive_JJ Bayes_NNS ,_, Logistic_JJ Regression_NN ,_, etc._NN ,_, as_IN a_DT function_NN of_IN the_DT local_JJ attributes_NNS Xi_NN and_CC aggreg_NN
ition_NN during_IN inference_NN ,_, the_DT aim_NN for_IN active_JJ learning_NN is_VBZ to_TO acquire_VB labels_NNS to_TO learn_VB a_DT good_JJ model_NN ._.
We_PRP are_VBP instead_RB acquiring_VBG labels_NNS during_IN inference_NN ._.
Another_DT related_JJ area_NN is_VBZ viral_JJ -LRB-_-LRB- or_CC targeted_VBN -RRB-_-RRB- marketing_NN =_JJ -_: =[_NN 9_CD ,_, 11_CD ,_, 21_CD ,_, 23_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB a_DT subset_NN of_IN customers_NNS need_VBP to_TO be_VB selected_VBN for_IN targeted_VBN advertisement_NN so_RB as_IN to_TO maximize_VB the_DT product_NN sales_NNS ._.
We_PRP showed_VBD how_WRB viral_JJ marketing_NN is_VBZ related_JJ to_TO label_NN acquisition_NN and_CC used_VBD Richardson_NNP &_CC Do_NNP
ition_NN during_IN inference_NN ,_, the_DT aim_NN for_IN active_JJ learning_NN is_VBZ to_TO acquire_VB labels_NNS to_TO learn_VB a_DT good_JJ model_NN ._.
We_PRP are_VBP instead_RB acquiring_VBG labels_NNS during_IN inference_NN ._.
Another_DT related_JJ area_NN is_VBZ viral_JJ -LRB-_-LRB- or_CC targeted_VBN -RRB-_-RRB- marketing_NN =_JJ -_: =[_NN 9_CD ,_, 11_CD ,_, 21_CD ,_, 23_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB a_DT subset_NN of_IN customers_NNS need_VBP to_TO be_VB selected_VBN for_IN targeted_VBN advertisement_NN so_RB as_IN to_TO maximize_VB the_DT product_NN sales_NNS ._.
We_PRP showed_VBD how_WRB viral_JJ marketing_NN is_VBZ related_JJ to_TO label_NN acquisition_NN and_CC used_VBD Richardson_NNP &_CC Do_NNP
ess_VB very_RB restrictive_JJ assumptions_NNS about_IN the_DT structure_NN of_IN the_DT underlying_VBG collective_JJ model_NN are_VBP made_VBN ,_, such_JJ as_IN linear_JJ dependence_NN on_IN the_DT neighborhood_NN and_CC attributes_NNS ,_, the_DT problem_NN is_VBZ at_IN least_JJS NP_NN PP_NN -_: complete_JJ =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC this_DT is_VBZ the_DT case_NN for_IN our_PRP$ model_NN CM_NN ._.
Since_IN finding_VBG the_DT optimal_JJ solution_NN to_TO the_DT label_NN acquisition_NN problem_NN is_VBZ intractable_JJ in_IN a_DT general_JJ setting_NN ,_, we_PRP must_MD resort_VB to_TO approximate_JJ techniques_NNS ._.
In_IN the_DT next_JJ
eric_JJ and_CC logistic_JJ regression_NN was_VBD able_JJ to_TO handle_VB them_PRP better_RBR than_IN Naive_JJ Bayes_NNPS with_IN Gaussians_NNP ._.
6.1_CD Experiments_NNS on_IN Synthetic_NNP Data_NNP We_PRP generated_VBD synthetic_JJ data_NNS using_VBG the_DT forest-fire_JJ graph_NN generation_NN model_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT forest_NN fire_NN model_NN is_VBZ shown_VBN to_TO exhibit_VB many_JJ real-world_JJ phenomenon_NN such_JJ as_IN power_NN law_NN degree_NN distribution_NN ,_, small_JJ world_NN effect_NN ,_, and_CC shrinking_NN diameters_NNS ._.
However_RB ,_, the_DT forest-fire_JJ method_NN ,_, like_IN most_JJS ra_NN
it_PRP has_VBZ been_VBN shown_VBN that_IN methods_NNS such_JJ as_IN collective_JJ classification_NN ,_, i.e._FW ,_, classifying_VBG the_DT nodes_NNS of_IN a_DT network_NN simultaneously_RB ,_, can_MD significantly_RB outperform_VB the_DT traditional_JJ independent_JJ labeling_NN approaches_VBZ =_JJ -_: =[_NN 2_CD ,_, 7_CD ,_, 13_CD ,_, 15_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, sometimes_RB ,_, the_DT advantage_NN of_IN exploiting_VBG the_DT relationships_NNS can_MD become_VB a_DT disadvantage_NN ._.
An_DT incorrect_JJ prediction_NN about_IN a_DT particular_JJ node_NN -LRB-_-LRB- due_JJ to_TO an_DT approximate_JJ inference_NN procedure_NN ,_, noise_NN in_IN the_DT
r_NN methods_NNS were_VBD not_RB statistically_RB significant_JJ ._.
6.2_CD Experiments_NNS on_IN Real_NNP Data_NNP We_PRP experimented_VBD on_IN two_CD real_JJ publication_NN datasets_NNS that_WDT are_VBP publicly_RB available_JJ ,_, the_DT Cora_NNP dataset_NN -LRB-_-LRB- 17_CD -RRB-_-RRB- and_CC the_DT CiteSeer_NNP dataset_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT Cora_NNP dataset_NN contains_VBZ a_DT 2708_CD machine_NN learning_NN papers_NNS that_WDT are_VBP divided_VBN into_IN 7_CD classes_NNS ,_, while_IN CiteSeer_FW dataset_FW has_VBZ 3312_CD documents_NNS that_WDT are_VBP divided_VBN into_IN 6_CD classes_NNS ._.
Our_PRP$ evaluation_NN methodology_NN is_VBZ sli_NN
st._NNP Other_NNP models_NNS could_MD very_RB well_RB be_VB used_VBN and_CC compared_VBN against_IN ;_: one_CD of_IN the_DT reasons_NNS we_PRP chose_VBD -LRB-_-LRB- 23_CD -RRB-_-RRB- is_VBZ the_DT fact_NN that_IN the_DT exact_JJ solution_NN was_VBD tractable_JJ ._.
The_DT work_NN in_IN feature-value_JJ acquisition_NN during_IN testing_NN =_JJ -_: =[_NN 1_CD ,_, 25_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ very_RB related_JJ to_TO the_DT label_NN acquisition_NN problem_NN ;_: however_RB ,_, the_DT focus_NN has_VBZ been_VBN on_IN acquiring_VBG feature_NN values_NNS ,_, not_RB labels_NNS ,_, and_CC also_RB they_PRP considered_VBD acquisition_NN for_IN non-graph_JJ data_NNS ._.
The_DT most_RBS related_JJ work_NN i_FW
st._NNP Other_NNP models_NNS could_MD very_RB well_RB be_VB used_VBN and_CC compared_VBN against_IN ;_: one_CD of_IN the_DT reasons_NNS we_PRP chose_VBD -LRB-_-LRB- 23_CD -RRB-_-RRB- is_VBZ the_DT fact_NN that_IN the_DT exact_JJ solution_NN was_VBD tractable_JJ ._.
The_DT work_NN in_IN feature-value_JJ acquisition_NN during_IN testing_NN =_JJ -_: =[_NN 1_CD ,_, 25_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ very_RB related_JJ to_TO the_DT label_NN acquisition_NN problem_NN ;_: however_RB ,_, the_DT focus_NN has_VBZ been_VBN on_IN acquiring_VBG feature_NN values_NNS ,_, not_RB labels_NNS ,_, and_CC also_RB they_PRP considered_VBD acquisition_NN for_IN non-graph_JJ data_NNS ._.
The_DT most_RBS related_JJ work_NN i_FW
hod_NN we_PRP propose_VBP significantly_RB outperforms_VBZ all_DT of_IN the_DT other_JJ methods_NNS on_IN both_CC real_JJ and_CC synthetic_JJ datasets_NNS ._.
The_DT label_NN acquisition_NN problem_NN has_VBZ received_VBN ample_JJ attention_NN within_IN the_DT context_NN of_IN active_JJ learning_NN =_JJ -_: =[_NN 3_CD ,_, 16_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
There_EX are_VBP two_CD main_JJ differences_NNS between_IN the_DT scenario_NN we_PRP address_VBP and_CC the_DT active_JJ learning_NN scenario_NN ._.
First_JJ ,_, active_JJ learning_NN has_VBZ traditionally_RB been_VBN concerned_VBN with_IN flat_JJ data_NNS ;_: here_RB ,_, we_PRP are_VBP interested_JJ in_IN ne_NN
it_PRP has_VBZ been_VBN shown_VBN that_IN methods_NNS such_JJ as_IN collective_JJ classification_NN ,_, i.e._FW ,_, classifying_VBG the_DT nodes_NNS of_IN a_DT network_NN simultaneously_RB ,_, can_MD significantly_RB outperform_VB the_DT traditional_JJ independent_JJ labeling_NN approaches_VBZ =_JJ -_: =[_NN 2_CD ,_, 7_CD ,_, 13_CD ,_, 15_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, sometimes_RB ,_, the_DT advantage_NN of_IN exploiting_VBG the_DT relationships_NNS can_MD become_VB a_DT disadvantage_NN ._.
An_DT incorrect_JJ prediction_NN about_IN a_DT particular_JJ node_NN -LRB-_-LRB- due_JJ to_TO an_DT approximate_JJ inference_NN procedure_NN ,_, noise_NN in_IN the_DT
tion_NN during_IN inference_NN ._.
This_DT is_VBZ the_DT setting_VBG Rattigan_NNP et_FW al._FW -LRB-_-LRB- 22_CD -RRB-_-RRB- introduced_VBN and_CC referred_VBN to_TO as_IN ``_`` active_JJ inference_NN ._. ''_''
They_PRP looked_VBD at_IN the_DT relational_JJ network_NN classifier_NN ,_, introduced_VBN by_IN Macskassy_NNP and_CC Provost_NNP =_SYM -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: in_IN which_WDT there_EX are_VBP no_DT node_NN attributes_VBZ ;_: only_RB labels_NNS are_VBP propagated_VBN ._.
Here_RB ,_, we_PRP build_VBP on_IN this_DT ,_, and_CC look_VB at_IN networks_NNS in_IN which_WDT the_DT nodes_NNS have_VBP attribute_NN information_NN and_CC compare_VB to_TO the_DT structural_JJ strategy_NN th_DT
hods_NNS including_VBG AIGA_NN on_IN small_JJ graphs_NNS ,_, graphs_NNS of_IN 100_CD nodes_NNS ,_, and_CC then_RB compare_VB the_DT remaining_VBG methods_NNS on_IN larger_JJR graphs_NNS of_IN 2000_CD nodes_NNS ._.
For_IN each_DT experiment_NN ,_, we_PRP first_RB report_VBP the_DT average_JJ degree_NN ,_, assortativity_NN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: ,_, how_WRB well_RB the_DT local_JJ model_NN LM_NN does_VBZ on_IN average_NN ,_, and_CC the_DT average_JJ perfect_JJ information_NN P_NN I_CD accuracies_NNS ._.
The_DT first_JJ set_NN of_IN graphs_NNS of_IN 100_CD nodes_NNS had_VBD an_DT average_JJ degree_NN of_IN 3.36_CD and_CC an_DT assortativity_NN of_IN 0.62_CD ._.
LM_NN h_NN
hod_NN we_PRP propose_VBP significantly_RB outperforms_VBZ all_DT of_IN the_DT other_JJ methods_NNS on_IN both_CC real_JJ and_CC synthetic_JJ datasets_NNS ._.
The_DT label_NN acquisition_NN problem_NN has_VBZ received_VBN ample_JJ attention_NN within_IN the_DT context_NN of_IN active_JJ learning_NN =_JJ -_: =[_NN 3_CD ,_, 16_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
There_EX are_VBP two_CD main_JJ differences_NNS between_IN the_DT scenario_NN we_PRP address_VBP and_CC the_DT active_JJ learning_NN scenario_NN ._.
First_JJ ,_, active_JJ learning_NN has_VBZ traditionally_RB been_VBN concerned_VBN with_IN flat_JJ data_NNS ;_: here_RB ,_, we_PRP are_VBP interested_JJ in_IN ne_NN
of_IN this_DT method_NN depends_VBZ heavily_RB on_IN theprecision_NN of_IN the_DT estimated_VBN probability_NN values_NNS ._.
If_IN the_DT probability_NN estimates_NNS are_VBP not_RB well-calibrated_JJ ,_, then_RB the_DT expected_VBN misclassification_NN costs_NNS will_MD be_VB incorrect_JJ =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_JJ -_: ,_, making_VBG the_DT valueaiga_NN calculations_NNS meaningless_JJ ._.
Second_RB ,_, the_DT time_NN this_DT acquisition_NN method_NN takes_VBZ to_TO run_VB depends_VBZ on_IN the_DT time_NN complexity_NN of_IN the_DT approximate_JJ inference_NN technique_NN ;_: we_PRP need_VBP to_TO calculate_VB the_DT v_LS
n_NN models_NNS proposed_VBN to_TO date_NN that_WDT make_VBP different_JJ modeling_NN assumptions_NNS about_IN these_DT dependencies_NNS ._.
For_IN instance_NN ,_, Neville_NNP and_CC Jensen_NNP -LRB-_-LRB- 19_CD -RRB-_-RRB- ,_, Lu_NNP and_CC Getoor_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, Macskassy_NNP and_CC Provost_NNP -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, and_CC McDowell_NNP et_FW al._FW =_SYM -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: make_VB use_NN of_IN local_JJ models_NNS ,_, such_JJ as_IN Naive_JJ Bayes_NNS ,_, Logistic_JJ Regression_NN ,_, etc._NN ,_, as_IN a_DT function_NN of_IN the_DT local_JJ attributes_NNS Xi_NN and_CC aggregation_NN of_IN the_DT neighbor_NN labels_NNS ._.
Chakrabarti_NNP et_FW al._FW -LRB-_-LRB- 2_CD -RRB-_-RRB- considered_VBN using_VBG the_DT
ition_NN during_IN inference_NN ,_, the_DT aim_NN for_IN active_JJ learning_NN is_VBZ to_TO acquire_VB labels_NNS to_TO learn_VB a_DT good_JJ model_NN ._.
We_PRP are_VBP instead_RB acquiring_VBG labels_NNS during_IN inference_NN ._.
Another_DT related_JJ area_NN is_VBZ viral_JJ -LRB-_-LRB- or_CC targeted_VBN -RRB-_-RRB- marketing_NN =_JJ -_: =[_NN 9_CD ,_, 11_CD ,_, 21_CD ,_, 23_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB a_DT subset_NN of_IN customers_NNS need_VBP to_TO be_VB selected_VBN for_IN targeted_VBN advertisement_NN so_RB as_IN to_TO maximize_VB the_DT product_NN sales_NNS ._.
We_PRP showed_VBD how_WRB viral_JJ marketing_NN is_VBZ related_JJ to_TO label_NN acquisition_NN and_CC used_VBD Richardson_NNP &_CC Do_NNP
it_PRP has_VBZ been_VBN shown_VBN that_IN methods_NNS such_JJ as_IN collective_JJ classification_NN ,_, i.e._FW ,_, classifying_VBG the_DT nodes_NNS of_IN a_DT network_NN simultaneously_RB ,_, can_MD significantly_RB outperform_VB the_DT traditional_JJ independent_JJ labeling_NN approaches_VBZ =_JJ -_: =[_NN 2_CD ,_, 7_CD ,_, 13_CD ,_, 15_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, sometimes_RB ,_, the_DT advantage_NN of_IN exploiting_VBG the_DT relationships_NNS can_MD become_VB a_DT disadvantage_NN ._.
An_DT incorrect_JJ prediction_NN about_IN a_DT particular_JJ node_NN -LRB-_-LRB- due_JJ to_TO an_DT approximate_JJ inference_NN procedure_NN ,_, noise_NN in_IN the_DT
it_PRP has_VBZ been_VBN shown_VBN that_IN methods_NNS such_JJ as_IN collective_JJ classification_NN ,_, i.e._FW ,_, classifying_VBG the_DT nodes_NNS of_IN a_DT network_NN simultaneously_RB ,_, can_MD significantly_RB outperform_VB the_DT traditional_JJ independent_JJ labeling_NN approaches_VBZ =_JJ -_: =[_NN 2_CD ,_, 7_CD ,_, 13_CD ,_, 15_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, sometimes_RB ,_, the_DT advantage_NN of_IN exploiting_VBG the_DT relationships_NNS can_MD become_VB a_DT disadvantage_NN ._.
An_DT incorrect_JJ prediction_NN about_IN a_DT particular_JJ node_NN -LRB-_-LRB- due_JJ to_TO an_DT approximate_JJ inference_NN procedure_NN ,_, noise_NN in_IN the_DT
it_PRP has_VBZ been_VBN shown_VBN that_IN methods_NNS such_JJ as_IN collective_JJ classification_NN ,_, i.e._FW ,_, classifying_VBG the_DT nodes_NNS of_IN a_DT network_NN simultaneously_RB ,_, can_MD significantly_RB outperform_VB the_DT traditional_JJ independent_JJ labeling_NN approaches_VBZ =_JJ -_: =[_NN 2_CD ,_, 7_CD ,_, 13_CD ,_, 15_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, sometimes_RB ,_, the_DT advantage_NN of_IN exploiting_VBG the_DT relationships_NNS can_MD become_VB a_DT disadvantage_NN ._.
An_DT incorrect_JJ prediction_NN about_IN a_DT particular_JJ node_NN -LRB-_-LRB- due_JJ to_TO an_DT approximate_JJ inference_NN procedure_NN ,_, noise_NN in_IN the_DT
et_CC ,_, acquire_VBP the_DT value_NN for_IN it_PRP ,_, and_CC repeat_VB the_DT process_NN until_IN the_DT budget_NN is_VBZ exhausted_VBN -LRB-_-LRB- Algorithm_NN 1_CD -RRB-_-RRB- ._.
Note_VB that_IN the_DT value_NN calculation_NN at_IN step_NN 7_CD is_VBZ essentially_RB an_DT expected_JJ value_NN of_IN information_NN calculation_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: and_CC it_PRP requires_VBZ running_VBG the_DT inference_NN procedure_NN for_IN each_DT possible_JJ label_NN ._.
Algorithm_NN 1_CD :_: Approximate_JJ inference_NN and_CC greedy_JJ acquisition_NN -LRB-_-LRB- AIGA_NN -RRB-_-RRB- algorithm_NN ._.
Input_NN :_: G_NN --_: the_DT test_NN graph_NN ,_, CM_NN --_: the_DT learned_VBN collec_NN
