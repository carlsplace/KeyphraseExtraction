Collective_JJ annotation_NN of_IN Wikipedia_NNP entities_NNS in_IN web_NN text_NN
To_TO take_VB the_DT first_JJ step_NN beyond_IN keyword-based_JJ search_NN toward_IN entity-based_JJ search_NN ,_, suitable_JJ token_JJ spans_NNS -LRB-_-LRB- ``_`` spots_NNS ''_'' -RRB-_-RRB- on_IN documents_NNS must_MD be_VB identified_VBN as_IN references_NNS to_TO real-world_JJ entities_NNS from_IN an_DT entity_NN catalog_NN ._.
Several_JJ systems_NNS have_VBP been_VBN proposed_VBN to_TO link_VB spots_NNS on_IN Web_NN pages_NNS to_TO entities_NNS in_IN Wikipedia_NNP ._.
They_PRP are_VBP largely_RB based_VBN on_IN local_JJ compatibility_NN between_IN the_DT text_NN around_IN the_DT spot_NN and_CC textual_JJ metadata_NN associated_VBN with_IN the_DT entity_NN ._.
Two_CD recent_JJ systems_NNS exploit_VBP inter-label_JJ dependencies_NNS ,_, but_CC in_IN limited_JJ ways_NNS ._.
We_PRP propose_VBP a_DT general_JJ collective_JJ disambiguation_NN approach_NN ._.
Our_PRP$ premise_NN is_VBZ that_IN coherent_JJ documents_NNS refer_VBP to_TO entities_NNS from_IN one_CD or_CC a_DT few_JJ related_JJ topics_NNS or_CC domains_NNS ._.
We_PRP give_VBP formulations_NNS for_IN the_DT trade-off_NN between_IN local_JJ spot-to-entity_JJ compatibility_NN and_CC measures_NNS of_IN global_JJ coherence_NN between_IN entities_NNS ._.
Optimizing_VBG the_DT overall_JJ entity_NN assignment_NN is_VBZ NP-hard_JJ ._.
We_PRP investigate_VBP practical_JJ solutions_NNS based_VBN on_IN local_JJ hill-climbing_NN ,_, rounding_VBG integer_NN linear_NN programs_NNS ,_, and_CC pre-clustering_JJ entities_NNS followed_VBN by_IN local_JJ optimization_NN within_IN clusters_NNS ._.
In_IN experiments_NNS involving_VBG over_IN a_DT hundred_CD manually-annotated_JJ Web_NN pages_NNS and_CC tens_NNS of_IN thousands_NNS of_IN spots_NNS ,_, our_PRP$ approaches_NNS significantly_RB outperform_VBP recently-proposed_JJ algorithms_NNS ._.
neutral_JJ to_TO the_DT specific_JJ identity_NN of_IN s_NN or_CC γ_NN ,_, as_IN a_DT feature_NN vector_NN fs_NN -LRB-_-LRB- γ_NN -RRB-_-RRB- in_IN some_DT space_NN ._.
Again_RB ,_, we_PRP can_MD learn_VB a_DT model_NN w_NN in_IN the_DT same_JJ space_NN such_JJ that_IN the_DT predicted_VBN entity_NN label_NN is_VBZ arg_FW maxγ_FW ∈_FW Γs_FW ∪_FW N.A._NNP w_FW ⊤_FW fs_FW -LRB-_-LRB- γ_NN -RRB-_-RRB- =_JJ -_: =[_NN 33_CD ,_, 29_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, one_PRP may_MD do_VB better_JJR by_IN exploiting_VBG the_DT fact_NN that_IN entities_NNS mentioned_VBN in_IN a_DT single_JJ discourse_NN tend_VBP to_TO be_VB semantically_RB related_JJ ._.
E.g._RB ,_, Wikipedia_NNP lists_VBZ several_JJ Michael_NNP Jordans_NNP of_IN who_WP only_RB one_CD is_VBZ a_DT Co_NNP
tion_NN of_IN cell_NN entity_NN ,_, column_NN type_NN ,_, and_CC relationship_NN labeling_NN ._.
A._NNP Einstein_NNP mention_NN or_CC reference_NN to_TO said_VBD entity_NN ._.
These_DT annotation_NN tasks_NNS are_VBP challenging_JJ ._.
When_WRB annotating_VBG entity_NN mentions_VBZ in_IN free-form_JJ text_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT textual_JJ context_NN provides_VBZ clues_NNS for_IN disambiguation_NN ._.
In_IN contrast_NN ,_, table_NN cells_NNS referring_VBG to_TO entities_NNS have_VBP negligible_JJ amounts_NNS of_IN additional_JJ text_NN ._.
Given_VBN each_DT table_NN cell_NN can_MD map_VB to_TO several_JJ entities_NNS -LRB-_-LRB- o_NN
es_NNS such_JJ as_IN Wikipedia_NNP -LRB-_-LRB- 18_CD ,_, 21_CD -RRB-_-RRB- ,_, or_CC the_DT general_JJ web_NN -LRB-_-LRB- 4_CD ,_, 6_CD ,_, 19_CD ,_, 2_CD -RRB-_-RRB- ._.
2_CD ._.
The_DT second_JJ approach_NN is_VBZ to_TO annotate_VB web_NN documents_NNS with_IN entity_NN and_CC relationship_NN labels_NNS from_IN a_DT well-known_JJ catalog_NN like_IN Wikipedia_NNP as_IN in_IN =_JJ -_: =[_NN 10_CD ,_, 17_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT allows_VBZ the_DT enrichment_NN of_IN keyword_JJ queries_NNS with_IN structured_JJ primitives_NNS such_JJ as_IN a_DT type_NN specifier_NN for_IN entities_NNS ._.
The_DT first_JJ approach_NN has_VBZ the_DT advantage_NN of_IN providing_VBG high_JJ quality_NN structured_JJ answers_NNS but_CC
IVERSITY_NN 19,717_CD 6,141,840_CD 311_CD TOTAL_NNP 742,862_CD 95,648,273_CD 129_CD entity_NN disambiguation_NN method_NN ._.
Recently_RB we_PRP have_VBP seen_VBN advanced_JJ entity_NN recognition_NN and_CC disambiguation_NN methods_NNS using_VBG Wikipedia_NNP as_IN entity_NN catalog_NN =_JJ -_: =[_NN 20_CD ,_, 21_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: to_TO automatically_RB link_VB entities_NNS mentioned_VBN in_IN plain_JJ text_NN to_TO their_PRP$ corresponding_JJ Wikipedia_NNP articles_NNS ._.
One_CD of_IN our_PRP$ ongoing_JJ efforts_NNS is_VBZ to_TO use_VB Wikify_NNP 6_CD -LRB-_-LRB- the_DT system_NN based_VBN on_IN -LRB-_-LRB- 21_CD -RRB-_-RRB- -RRB-_-RRB- to_TO detect_VB entity_NN occurrences_NNS
ck_IN this_DT corpora_NN ,_, we_PRP instead_RB leverage_NN Wikipedia_NNP as_IN a_DT knowledge_NN base_NN ._.
Other_JJ research_NN has_VBZ proceeded_VBN in_IN this_DT direction_NN ,_, leveraging_VBG Wikipedia_NNP as_IN the_DT knowledge_NN base_NN for_IN entity_NN disambiguation_NN -LRB-_-LRB- and_CC labeling_NN -RRB-_-RRB- =_JJ -_: =[_NN 11_CD ,_, 13_CD ,_, 14_CD ,_, 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP hope_VBP to_TO incorporate_VB such_JJ methods_NNS ,_, though_IN the_DT noisy_JJ ,_, ungrammatical_JJ nature_NN of_IN Tweets_NNS may_MD prove_VB diffi-cult_JJ for_IN them_PRP ._.
We_PRP note_VBP a_DT key_JJ difference_NN is_VBZ that_IN none_NN of_IN these_DT approaches_NNS are_VBP leveraged_JJ to_TO deter_VB
ch_NN as_IN global_JJ -LRB-_-LRB- exact_JJ or_CC approximate_JJ -RRB-_-RRB- agreement_NN ._.
Not_RB all_DT mentioned_VBN quantities_NNS will_MD map_VB to_TO attributes_NNS in_IN the_DT schema_NN ._.
For_IN those_DT ,_, we_PRP create_VBP a_DT special_JJ background\/no_NN attribute_NN na_TO -LRB-_-LRB- similar_JJ to_TO ``_`` no_DT assignment_NN ''_'' =_SYM -_: =[_NN 12_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Our_PRP$ approach_NN is_VBZ to_TO encode_VB assignment_NN decisions_NNS as_IN 0\/1_CD variables_NNS in_IN a_DT suitable_JJ integer_NN linear_NN program_NN -LRB-_-LRB- ILP_NN -RRB-_-RRB- ._.
Constraints_NNS for_IN the_DT ILP_NNP will_MD come_VB from_IN some_DT natural_JJ snippet_NN and_CC value_NN assignment_NN consider_VB
ang_FW et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ,_, measuring_VBG semantic_JJ similarity_NN between_IN texts_NNS -LRB-_-LRB- Gabrilovich_NNP and_CC Markovitch_NNP ,_, 2007a_CD -RRB-_-RRB- ,_, crossdocument_NN co-reference_NN resolution_NN -LRB-_-LRB- Finin_NN et_FW al._FW ,_, 2009_CD ;_: Mayfield_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ,_, and_CC other_JJ tasks_NNS -LRB-_-LRB- =_JJ -_: =_JJ Kulkarni_NNP et_FW al._FW ,_, 2009_CD -_: =--RRB-_NN ._.
1375_CD Previous_JJ studies_NNS on_IN Wikification_NNP differ_VBP with_IN respect_NN to_TO the_DT corpora_NN they_PRP address_VBP and_CC the_DT subset_NN of_IN expressions_NNS they_PRP attempt_VBP to_TO link_VB ._.
For_IN example_NN ,_, some_DT studies_NNS focus_VBP on_IN linking_VBG only_RB named_VBN entit_NN
their_PRP$ dataset_JJ 27.94_CD %_NN of_IN the_DT surface_NN forms_NNS are_VBP unambiguous_JJ and_CC 46.53_CD %_NN of_IN the_DT ambiguous_JJ ones_NNS can_MD be_VB correctly_RB disambiguated_VBN by_IN just_RB choosing_VBG the_DT default_NN sense_NN -LRB-_-LRB- according_VBG to_TO our_PRP$ index_NN -RRB-_-RRB- ._.
Kulkarni_NNP et_FW al._FW =_SYM -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: attempts_VBZ the_DT joint_JJ optimization_NN of_IN all_DT spotted_JJ surface_NN forms_NNS in_IN order_NN to_TO realize_VB the_DT collective_JJ annotation_NN of_IN entities_NNS ._.
The_DT inference_NN problem_NN formulated_VBN by_IN the_DT authors_NNS is_VBZ NP-hard_JJ ,_, leading_VBG to_TO their_PRP$ pr_NN
arowsky_NN 1992_CD -RRB-_-RRB- -RRB-_-RRB- ._.
We_PRP instead_RB leverage_NN Wikipedia_NNP as_IN a_DT knowledge_NN base_NN ._.
Other_JJ research_NN has_VBZ proceeded_VBN in_IN this_DT direction_NN ,_, leveraging_VBG Wikipedia_NNP as_IN the_DT knowledge_NN base_NN for_IN entity_NN disambiguation_NN -LRB-_-LRB- and_CC labeling_NN -RRB-_-RRB- -LRB-_-LRB- =_JJ -_: =_JJ Kulkarni_NNP et_FW al._FW 2009_CD -_: =_JJ -_: ;_: Mihalcea_NNP and_CC Csomai_NNP 2007_CD ;_: Milne_NNP and_CC Witten_NNP 2008_CD ;_: Cucerzan_NNP 2007_CD -RRB-_-RRB- ._.
We_PRP note_VBP a_DT key_JJ difference_NN is_VBZ that_IN none_NN of_IN these_DT approaches_NNS are_VBP leveraged_JJ to_TO determine_VB the_DT topics_NNS that_IN a_DT user_NN writes_VBZ about_IN ,_, but_CC rather_RB
consists_VBZ of_IN modeling_NN the_DT problem_NN as_IN the_DT labeled_JJ clustering_NN of_IN the_DT nodes_NNS of_IN a_DT newly_RB introduced_VBN graph_NN of_IN topics_NNS ._.
The_DT topics_NNS are_VBP Wikipedia-pages_NNS identified_VBN by_IN means_NNS of_IN recently_RB proposed_VBN topic_NN annotators_NNS =_JJ -_: =[_NN 9_CD ,_, 11_CD ,_, 16_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: applied_VBN to_TO the_DT search_NN results_NNS ,_, and_CC the_DT edges_NNS denote_VBP the_DT relatedness_NN among_IN these_DT topics_NNS computed_VBN by_IN taking_VBG into_IN account_NN the_DT linkage_NN of_IN the_DT Wikipedia-graph_NN ._.
We_PRP tackle_VBP this_DT problem_NN by_IN designing_VBG a_DT novel_JJ
1_LS -RRB-_-RRB- ._.
NLP_NN research_NN has_VBZ harnessed_VBN Wikipedia_NNP as_IN a_DT means_NN for_IN linking_VBG words_NNS and_CC phrases_NNS onto_IN canonical_JJ entities_NNS -LRB-_-LRB- 3_CD ,_, 6_CD -RRB-_-RRB- ._.
This_DT theme_NN has_VBZ been_VBN further_RB pursued_VBN in_IN Web_NN mining_NN ,_, most_RBS notably_RB ,_, the_DT work_NN of_IN -LRB-_-LRB- 12_CD -RRB-_-RRB- and_CC =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Recent_JJ methods_NNS leverage_NN knowledge_NN bases_NNS such_JJ as_IN DBpedia_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ,_, freebase.com_NN ,_, or_CC YAGO_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
These_DT contain_VBP millions_NNS of_IN entities_NNS ,_, with_IN fine-grained_JJ assignment_NN to_TO semantic_JJ types_NNS -LRB-_-LRB- e.g._FW ,_, heavy_JJ metal_NN rock_NN gu_NN
ere_NN is_VBZ overlapping_VBG information_NN in_IN the_DT knowledge-bases_NNS which_WDT can_MD be_VB leveraged_JJ -RRB-_-RRB- and_CC subsequently_RB ,_, how_WRB to_TO merge_VB the_DT -LRB-_-LRB- partial_JJ -RRB-_-RRB- results_NNS ._.
Both_DT tasks_NNS are_VBP non-trivial_JJ because_IN on-the-fly_JJ entity_NN disambiguation_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: may_MD be_VB required_VBN due_JJ to_TO different_JJ vocabularies_NNS ._.
With_IN this_DT overview_NN of_IN the_DT IQ_NNP paradigm_NN ,_, we_PRP now_RB illustrate_VBP two_CD case_NN studies_NNS of_IN how_WRB a_DT system_NN built_VBN on_IN these_DT principles_NNS would_MD work_VB ._.
In_IN the_DT first_JJ case_NN study_NN ,_,
nt_NN Obama_NNP ,_, the_DT entity_NN name_NN ``_`` Obama_NNP ''_'' might_MD refer_VB to_TO PresidentBarack_Obama_NN or_CC to_TO his_PRP$ father_NN Barack_Obama_Sr_NN ._.
The_DT problem_NN of_IN identifying_VBG the_DT right_JJ entity_NN for_IN a_DT given_VBN name_NN is_VBZ known_VBN as_IN entity_NN disambiguation_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, at_IN this_DT point_NN we_PRP assume_VBP :_: 1_CD ._.
Each_DT entity_NN name_NN is_VBZ uniquely_RB addressing_VBG exactly_RB one_CD entity_NN within_IN a_DT given_VBN document_NN ._.
2_CD ._.
The_DT disambiguation_NN is_VBZ solved_VBN externally_RB and_CC a_DT mapping_NN from_IN entity_NN names_NNS t_NN
ovides_VBZ a_DT stunning_JJ contextualization_NN of_IN the_DT input_NN text_NN so_IN that_IN each_DT subsequent_JJ IR-task_NN could_MD be_VB improved_VBN by_IN leveraging_VBG the_DT huge_JJ semantic_JJ network_NN provided_VBN by_IN Wikipedia_NNP ._.
Recently_RB several_JJ works_NNS -LRB-_-LRB- see_VB e.g._FW =_SYM -_: =[_NN 4_CD ,_, 6_CD -RRB-_-RRB- -_: =_JJ -_: and_CC refs_NNS therein_RB -RRB-_-RRB- addressed_VBD the_DT problem_NN of_IN annotating_VBG texts_NNS with_IN hyper-links_NNS to_TO Wikipedia_NNP pages_NNS ._.
We_PRP add_VBP to_TO this_DT flow_NN of_IN work_NN the_DT specialty_NN that_IN the_DT input_NN texts_NNS to_TO be_VB annotated_JJ are_VBP short_JJ ,_, namely_RB ,_, they_PRP
ssigned_VBN entities_NNS =_JJ -_: =[_NN 15_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Coherence_NN between_IN a_DT pair_NN of_IN entities_NNS is_VBZ computed_VBN using_VBG the_DT knowledge_NN base_NN ,_, e.g._FW ,_, based_VBN on_IN the_DT number_NN of_IN common_JJ Wikipedia_NNP pages_NNS that_WDT link_VBP to_TO Wiki_NNP pages_NNS of_IN these_DT two_CD entities_NNS -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
While_IN some_DT approaches_NNS model_VBP the_DT interdependence_NN as_IN sum_NN of_IN their_PRP$ pair-wise_JJ dependencies_NNS -LRB-_-LRB- 18_CD ,_, 15_CD -RRB-_-RRB- ,_, more_RBR recent_JJ techniques_NNS model_VBP the_DT global_JJ interdependence_NN -LRB-_-LRB- 14_CD ,_, 12_CD -RRB-_-RRB- ._.
These_DT studiesconsideronlyentitiespr_NN
c_NN similarity_NN of_IN entity_NN e_SYM with_IN Γd_NNP Global_NNP coherence_NN of_IN entity_NN e_SYM in_FW d_FW disambiguation_NN ._.
Given_VBN an_DT input_NN document_NN ,_, these_DT systems_NNS are_VBP able_JJ to_TO automatically_RB enrich_VB the_DT input_NN text_NN with_IN links_NNS to_TO Wikipedia_NNP pages_NNS =_JJ -_: =[_NN 19_CD ,_, 21_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, this_DT task_NN is_VBZ different_JJ from_IN our_PRP$ entity_NN linking_VBG task_NN in_IN several_JJ respects_NNS :_: firstly_RB ,_, these_DT systems_NNS have_VBP to_TO decide_VB whether_IN the_DT detected_VBN terms_NNS or_CC phrases_NNS are_VBP important_JJ enough_RB in_IN the_DT document_NN to_TO
ed_VBN worse_JJR than_IN each_DT of_IN our_PRP$ algorithms_NNS ,_, which_WDT used_VBD the_DT relatedness_NN definition_NN described_VBN next_RB ._.
2.4.2_CD M&W_NNP 's_POS inlink-based_JJ g_NN -LRB-_-LRB- γ_NN -RRB-_-RRB- and_CC r_NN -LRB-_-LRB- γ_NN ,_, γ_FW ′_FW -RRB-_-RRB- Cocitation_NNP has_VBZ been_VBN used_VBN to_TO detect_VB relatedness_NN for_IN a_DT long_JJ time_NN =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Milne_NNP and_CC Witten_NNP -LRB-_-LRB- 15_CD -RRB-_-RRB- represented_VBD g_NN -LRB-_-LRB- γ_NN -RRB-_-RRB- as_IN the_DT set_NN of_IN Wikipedia_NNP pages_NNS that_WDT link_VBP to_TO γ_NN ,_, with_IN size_NN |_CD g_NN -LRB-_-LRB- γ_NN -RRB-_-RRB- |_CD ._.
Let_VB c_NN be_VB the_DT total_JJ number_NN of_IN Wikipedia_NNP pages_NNS ._.
M&W_NNP defined_VBD a_DT relatedness_NN measure_NN -LRB-_-LRB- larger_JJR value_NN i_FW
of_IN the_DT entity_NN catalog_NN ._.
For_IN common_JJ English_NNP words_NNS ,_, WordNet_NNP -LRB-_-LRB- 14_CD -RRB-_-RRB- provides_VBZ an_DT authoritative_JJ lexical_JJ network_NN designed_VBN by_IN linguists_NNS ,_, and_CC widely_RB used_VBN for_IN disambiguation_NN of_IN common_JJ words_NNS -LRB-_-LRB- 1_LS -RRB-_-RRB- ._.
CYC_NN and_CC OpenCYC_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_JJ -_: Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN all_DT or_CC part_NN of_IN this_DT work_NN for_IN personal_JJ or_CC classroom_NN use_NN is_VBZ granted_VBN without_IN fee_NN provided_VBN that_IN copies_NNS are_VBP not_RB made_VBN or_CC distributed_VBN for_IN profit_NN or_CC commercial_JJ ad_NN
cantly_RB better_JJR than_IN two_CD recently-proposed_JJ annotation_NN algorithms_NNS ._.
In_IN continuing_VBG work_NN ,_, we_PRP are_VBP trying_VBG to_TO cast_VB the_DT annotation_NN problem_NN as_IN special_JJ cases_NNS of_IN quadratic_JJ assignment_NN that_WDT can_MD be_VB approximated_VBN well_RB =_JJ -_: =[_NN 6_CD ,_, 16_CD -RRB-_-RRB- -_: =_JJ -_: or_CC show_VBP that_IN even_RB approximation_NN is_VBZ difficult_JJ -LRB-_-LRB- 10_CD ,_, 16_CD -RRB-_-RRB- ._.
We_PRP are_VBP trying_VBG to_TO combine_VB the_DT generally_RB low-recall_JJ ,_, high-precision_JJ nature_NN of_IN M&W_NNP 's_POS r_NN -LRB-_-LRB- γ_NN ,_, γ_FW ′_FW -RRB-_-RRB- based_VBN on_IN inlinks_NNS with_IN the_DT converse_NN properties_NNS of_IN Cu_NN
y_NN widespread_JJ adoption_NN of_IN the_DT entity_NN catalog_NN ._.
For_IN common_JJ English_NNP words_NNS ,_, WordNet_NNP -LRB-_-LRB- 14_CD -RRB-_-RRB- provides_VBZ an_DT authoritative_JJ lexical_JJ network_NN designed_VBN by_IN linguists_NNS ,_, and_CC widely_RB used_VBN for_IN disambiguation_NN of_IN common_JJ words_NNS =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
CYC_NN and_CC OpenCYC_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN all_DT or_CC part_NN of_IN this_DT work_NN for_IN personal_JJ or_CC classroom_NN use_NN is_VBZ granted_VBN without_IN fee_NN provided_VBN that_IN copies_NNS are_VBP not_RB made_VBN or_CC distributed_VBN for_IN p_NN
st_IN to_TO understand_VB the_DT complexity_NN of_IN inference_NN ._.
Proposition_NN 1_CD ._.
Inference_NN problem_NN maxy_NN -LRB-_-LRB- NP_NN -RRB-_-RRB- +_CC -LRB-_-LRB- CP1_NN -RRB-_-RRB- is_VBZ NP-hard_JJ ,_, even_RB when_WRB ρna_NN =_JJ −_FW ∞_FW and_CC therefore_RB A0_NN =_JJ S0_NN ._.
The_DT reduction_NN is_VBZ from_IN the_DT maximal_JJ clique_NN problem_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP also_RB note_VBP that_IN other_JJ natural_JJ definitions_NNS of_IN CP_NN do_VBP not_RB make_VB the_DT problem_NN easier_JJR ._.
Proposition_NN 2_CD ._.
The_DT inference_NN problem_NN remains_VBZ NP-hard_JJ with_IN the_DT following_JJ alternative_JJ definitions_NNS of_IN CP_NNP :_: 0_CD CP_NN -LRB-_-LRB- y_NN -RRB-_-RRB- =_JJ exp_NN
like_IN unsupervised_JJ coreference_NN resolution_NN ._. -RRB-_-RRB-
1.1_CD Entity_NN catalogs_NNS The_DT success_NN of_IN semantic_JJ annotation_NN is_VBZ greatly_RB determined_VBN by_IN widespread_JJ adoption_NN of_IN the_DT entity_NN catalog_NN ._.
For_IN common_JJ English_NNP words_NNS ,_, WordNet_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: provides_VBZ an_DT authoritative_JJ lexical_JJ network_NN designed_VBN by_IN linguists_NNS ,_, and_CC widely_RB used_VBN for_IN disambiguation_NN of_IN common_JJ words_NNS -LRB-_-LRB- 1_LS -RRB-_-RRB- ._.
CYC_NN and_CC OpenCYC_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN all_DT or_CC part_NN
iated_VBN with_IN candidate_NN entity_NN γ_NN in_IN TAP_NN ._.
SemTag_NNP preferred_VBD high_JJ precision_NN over_IN recall_NN ,_, proposing_VBG only_RB about_RB 450_CD million_CD annotations_NNS ,_, i.e._FW ,_, fewer_JJR than_IN two_CD annotations_NNS per_IN page_NN on_IN average_NN ._.
Wikify_NNP !_. ._.
Wikify_NNP !_.
=_SYM -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: has_VBZ two_CD components_NNS ._.
The_DT first_JJ ,_, keyword_JJ extraction_NN ,_, decides_VBZ if_IN a_DT phrase_NN should_MD be_VB linked_VBN to_TO Wikipedia_NNP ._.
This_DT is_VBZ based_VBN on_IN how_WRB often_RB a_DT word_NN or_CC phrase_NN is_VBZ found_VBN to_TO be_VB in_IN the_DT anchor_NN text_NN of_IN some_DT link_NN intern_NN
ly_RB 1_CD ,_, 2009_CD ,_, Paris_NNP ,_, France_NNP ._.
Copyright_NN 2009_CD ACM_NNP 978-1-60558-495-9_CD \/_: 09\/06_CD ..._: $_$ 10.00_CD ._.
are_VBP partly_RB commercial_JJ efforts_NNS to_TO maintain_VB entity_NN catalogs_NNS ,_, rules_NNS and_CC reasoning_NN engines_NNS ._.
To_TO understand_VB and_CC maintain_VB TAP_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, WordNet_NNP ,_, or_CC OpenCYC_NN ,_, substantial_JJ training_NN is_VBZ needed_VBN in_IN knowledge_NN representation_NN and_CC linguistics_NNS ._.
In_IN contrast_NN ,_, the_DT ``_`` Web_NN 2.0_CD ''_'' trend_NN is_VBZ to_TO throw_VB open_JJ tagging_VBG and_CC cataloging_VBG of_IN knowledge_NN to_TO the_DT masses_NNS ._.
nd_NN locations_NNS -RRB-_-RRB- are_VBP disambiguated_VBN ._.
The_DT goal_NN is_VBZ to_TO emulate_VB Wikipedia_NNP 's_POS restrained_JJ ,_, informative_JJ ,_, editorial_JJ links_NNS on_IN ordinary_JJ Web_NN pages_NNS ._.
SemTag_NNP ._.
The_DT first_JJ Web-scale_JJ entity_NN disambiguation_NN system_NN was_VBD SemTag_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
SemTag_NNP annotated_JJ about_IN 250_CD million_CD Web_NN pages_NNS with_IN IDs_NNS from_IN the_DT Stanford_NNP TAP_NN entity_NN catalog_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
The_DT basic_JJ technique_NN was_VBD to_TO compare_VB the_DT surrounding_JJ context_NN of_IN a_DT spot_NN s_NN with_IN text_NN metadata_NN associated_JJ w_NN
fs_NN -LRB-_-LRB- γ_NN -RRB-_-RRB- -RRB-_-RRB- \/_: Zs_NNS where_WRB Zs_NN =_JJ P_NN γ_FW ′_FW ∈_FW Γs_FW exp_FW -LRB-_-LRB- w_FW ⊤_FW fs_FW -LRB-_-LRB- γ_FW ′_FW -RRB-_-RRB- -RRB-_-RRB- ,_, is_VBZ the_DT partition_NN function_NN -LRB-_-LRB- hence_RB the_DT log_NN in_IN the_DT sense_NN probability_NN feature_NN above_IN -RRB-_-RRB- ._.
We_PRP call_VBP exp_NN -LRB-_-LRB- w_FW ⊤_FW fs_FW -LRB-_-LRB- ·_NN -RRB-_-RRB- -RRB-_-RRB- the_DT node_NN potential_NN of_IN s_NN ,_, using_VBG graphical_JJ model_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_JJ -_: terminology_NN ._.
We_PRP train_VBP w_NN using_VBG a_DT max-margin_JJ technique_NN ._.
Given_VBN ground_NN truth_NN assignment_NN γ_NN ∗_NN s_VBZ ∈_FW Γs_FW ,_, we_PRP want_VBP w_FW ⊤_FW fs_FW -LRB-_-LRB- γ_FW ∗_FW s_NNS -RRB-_-RRB- to_TO be_VB larger_JJR than_IN any_DT other_JJ w_NN ⊤_FW fs_FW -LRB-_-LRB- γ_NN -RRB-_-RRB- ,_, with_IN a_DT margin_NN ;_: this_DT gives_VBZ us_PRP the_DT usual_JJ SV_NN
lgorithms_NNS ._.
In_IN continuing_VBG work_NN ,_, we_PRP are_VBP trying_VBG to_TO cast_VB the_DT annotation_NN problem_NN as_IN special_JJ cases_NNS of_IN quadratic_JJ assignment_NN that_WDT can_MD be_VB approximated_VBN well_RB -LRB-_-LRB- 6_CD ,_, 16_CD -RRB-_-RRB- or_CC show_VBP that_IN even_RB approximation_NN is_VBZ difficult_JJ =_JJ -_: =[_NN 10_CD ,_, 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP are_VBP trying_VBG to_TO combine_VB the_DT generally_RB low-recall_JJ ,_, high-precision_JJ nature_NN of_IN M&W_NNP 's_POS r_NN -LRB-_-LRB- γ_NN ,_, γ_FW ′_FW -RRB-_-RRB- based_VBN on_IN inlinks_NNS with_IN the_DT converse_NN properties_NNS of_IN Cucerzan_NNP 's_POS r_NN -LRB-_-LRB- γ_NN ,_, γ_FW ′_FW -RRB-_-RRB- based_VBN on_IN categories_NNS ._.
This_DT involves_VBZ
ations_NNS is_VBZ compared_VBN with_IN the_DT context_NN of_IN s_NN to_TO decide_VB on_IN a_DT compatibility_NN score_NN ._.
This_DT may_MD be_VB regarded_VBN as_IN generalizing_VBG SemTag_NNP ,_, where_WRB known_JJ references_NNS to_TO γ_JJ form_NN part_NN of_IN the_DT metadata_NN of_IN γ_NN ._.
Bunescu_NN and_CC Pasca_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: further_RB improved_VBD the_DT compatibility_NN function_NN using_VBG SVMs_NNS with_IN tree_NN kernels_NNS ._.
However_RB ,_, none_NN of_IN these_DT systems_NNS attempt_VBP collective_JJ disambiguation_NN across_IN spots_NNS ._.
M&W_NNP ._.
A_DT limited_JJ form_NN of_IN collective_JJ disambiguati_NNS
and_CC Wikify_NNP !_.
,_, sacrifices_NNS recall_VBP for_IN high_JJ precision_NN ._.
For_IN the_DT spots_NNS picked_VBN by_IN M&W_NN for_IN labeling_NN ,_, even_RB random_JJ disambiguation_NN achieves_VBZ an_DT F1_NN score_NN of_IN 0.53_CD ._.
Cucerzan_NNP 's_POS algorithm_NN ._.
To_TO our_PRP$ knowledge_NN ,_, Cucerzan_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_JJ -_: was_VBD the_DT first_JJ to_TO recognize_VB general_JJ interdependence_NN between_IN entity_NN labels_NNS in_IN the_DT context_NN of_IN Wikipedia_NNP annotations_NNS ._.
He_PRP represents_VBZ each_DT entity_NN γ_NN as_IN a_DT high-dimensional_JJ feature_NN vector_NN g_NN -LRB-_-LRB- γ_NN -RRB-_-RRB- ,_, and_CC expressed_VBD
t_NN cover_NN by_IN 3-sets_NNS -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
Hardness_NN using_VBG -LRB-_-LRB- 4_CD -RRB-_-RRB- is_VBZ shown_VBN using_VBG a_DT reduction_NN from_IN 3SAT_NN ._.
Proofs_NNS are_VBP omitted_VBN to_TO save_VB space_NN ._.
3.4_CD LP_NN rounding_VBG approach_NN Guided_VBN by_IN approaches_NNS to_TO Quadratic_JJ Assignment_NN Problems_NNS -LRB-_-LRB- QAPs_NNS -RRB-_-RRB- =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_JJ -_: we_PRP can_MD turn_VB our_PRP$ optimization_NN into_IN a_DT 0\/1_CD integer_NN linear_NN program_NN ,_, and_CC then_RB relax_VB it_PRP to_TO an_DT LP_NN ._.
First_JJ disallow_NN ys_VBZ =_JJ na_TO ._.
The_DT ILP_NNP is_VBZ designed_VBN with_IN up_RB to_TO |_NN Γ0_NN |_CD +_CC |_CD Γ0_NN |_NN 2_CD variables_NNS zsγ_NN =_JJ -LRB-_-LRB- -LRB-_-LRB- spot_NN s_NN is_VBZ assigned_JJ lab_NN
ity_NN function_NN using_VBG SVMs_NNS with_IN tree_NN kernels_NNS ._.
However_RB ,_, none_NN of_IN these_DT systems_NNS attempt_VBP collective_JJ disambiguation_NN across_IN spots_NNS ._.
M&W_NNP ._.
A_DT limited_JJ form_NN of_IN collective_JJ disambiguation_NN proposed_VBN by_IN Milne_NNP and_CC Witten_NNP =_SYM -_: =[_NN 15_CD -RRB-_-RRB- -_: =_SYM -_: yields_VBZ considerable_JJ improvement_NN beyond_IN Wikify_NNP !_. ._.
M&W_NNP propose_VBP a_DT relatedness_NN score_NN r_NN -LRB-_-LRB- γ_NN ,_, γ_FW ′_FW -RRB-_-RRB- between_IN two_CD entities_NNS ._.
From_IN the_DT set_NN of_IN all_DT spots_NNS S0_NN ,_, they_PRP identify_VBP the_DT subset_NN S_NN !_.
of_IN so-called_JJ context_NN spots_NNS t_NN
abels_NNS ,_, which_WDT is_VBZ precisely_RB what_WP we_PRP undertake_VBP ._.
The_DT above_JJ line_NN of_IN work_NN has_VBZ some_DT similarity_NN to_TO identifying_VBG mentions_VBZ of_IN entities_NNS in_IN databases_NNS -LRB-_-LRB- e.g._FW product_NN catalogs_NNS -RRB-_-RRB- amidst_IN unstructured_JJ text_NN -LRB-_-LRB- e.g._FW ,_, blogs_NNS -RRB-_-RRB- =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: ,_, but_CC ,_, in_IN such_JJ applications_NNS ,_, the_DT ``_`` entity_NN catalog_NN ''_'' is_VBZ a_DT clean_JJ relational_JJ database_NN ,_, and_CC ,_, to_TO our_PRP$ knowledge_NN ,_, no_DT collective_JJ labeling_NN is_VBZ employed_VBN ._.
1.3_CD Our_PRP$ goals_NNS and_CC contributions_NNS Our_PRP$ goal_NN in_IN this_DT paper_NN is_VBZ a_DT
ls_NNS ''_'' -RRB-_-RRB- from_IN a_DT catalog_NN ._.
These_DT entity_NN ID_NN annotations_NNS enable_VBP powerful_JJ join_VB operations_NNS that_WDT can_MD combine_VB information_NN across_IN pages_NNS and_CC sites_NNS ._.
Named_VBN entity_NN recognition_NN and_CC tagging_NN have_VBP seen_VBN widespread_JJ success_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Here_RB we_PRP are_VBP concerned_VBN with_IN the_DT second_JJ step_NN :_: entity_NN disambiguation_NN from_IN a_DT given_VBN catalog_NN ,_, such_JJ as_IN Wikipedia_NNP ._.
-LRB-_-LRB- The_DT availability_NN of_IN a_DT catalog_NN makes_VBZ this_DT a_DT supervised_JJ setting_NN ,_, unlike_IN unsupervised_JJ corefer_NN
