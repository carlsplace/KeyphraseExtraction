A_DT general_JJ framework_NN for_IN accurate_JJ and_CC fast_JJ regression_NN by_IN data_NNS summarization_NN in_IN random_JJ decision_NN trees_NNS
Predicting_VBG the_DT values_NNS of_IN continuous_JJ variable_NN as_IN a_DT function_NN of_IN several_JJ independent_JJ variables_NNS is_VBZ one_CD of_IN the_DT most_RBS important_JJ problems_NNS for_IN data_NN mining_NN ._.
A_DT very_RB large_JJ number_NN of_IN regression_NN methods_NNS ,_, both_DT parametric_JJ and_CC nonparametric_JJ ,_, have_VBP been_VBN proposed_VBN in_IN the_DT past_NN ._.
However_RB ,_, since_IN the_DT list_NN is_VBZ quite_RB extensive_JJ and_CC many_JJ of_IN these_DT models_NNS make_VBP rather_RB explicit_JJ ,_, strong_JJ yet_RB different_JJ assumptions_NNS about_IN the_DT type_NN of_IN applicable_JJ problems_NNS and_CC involve_VB a_DT lot_NN of_IN parameters_NNS and_CC options_NNS ,_, choosing_VBG the_DT appropriate_JJ regression_NN methodology_NN and_CC then_RB specifying_VBG the_DT parameter_NN values_NNS is_VBZ a_DT none-trivial_JJ ,_, sometimes_RB frustrating_JJ ,_, task_NN for_IN data_NN mining_NN practitioners_NNS ._.
Choosing_VBG the_DT inappropriate_JJ methodology_NN can_MD have_VB rather_RB disappointing_JJ results_NNS ._.
This_DT issue_NN is_VBZ against_IN the_DT general_JJ utility_NN of_IN data_NNS mining_NN software_NN ._.
For_IN example_NN ,_, linear_JJ regression_NN methods_NNS are_VBP straightforward_JJ and_CC well-understood_JJ ._.
However_RB ,_, since_IN the_DT linear_JJ assumption_NN is_VBZ very_RB strong_JJ ,_, its_PRP$ performance_NN is_VBZ compromised_VBN for_IN complicated_JJ non-linear_JJ problems_NNS ._.
Kernel-based_JJ methods_NNS perform_VBP quite_RB well_RB if_IN the_DT kernel_NN functions_NNS are_VBP selected_VBN correctly_RB ._.
In_IN this_DT paper_NN ,_, we_PRP propose_VBP a_DT straightforward_JJ approach_NN based_VBN on_IN summarizing_VBG the_DT training_NN data_NNS using_VBG an_DT ensemble_NN of_IN random_JJ decisions_NNS trees_NNS ._.
It_PRP requires_VBZ very_RB little_JJ knowledge_NN from_IN the_DT user_NN ,_, yet_RB is_VBZ applicable_JJ to_TO every_DT type_NN of_IN regression_NN problem_NN that_IN we_PRP are_VBP currently_RB aware_JJ of_IN ._.
We_PRP have_VBP experimented_VBN on_IN a_DT wide_JJ range_NN of_IN problems_NNS including_VBG those_DT that_IN parametric_JJ methods_NNS performwell_NN ,_, a_DT large_JJ selection_NN of_IN benchmark_JJ datasets_NNS for_IN nonparametric_JJ regression_NN ,_, as_RB well_RB as_IN highly_RB non-linear_JJ stochastic_JJ problems_NNS ._.
Our_PRP$ results_NNS are_VBP either_RB significantly_RB better_JJR than_IN or_CC identical_JJ to_TO many_JJ approaches_NNS that_WDT are_VBP known_VBN to_TO perform_VB well_RB on_IN these_DT problems_NNS ._.
ees_NNS ._.
That_DT means_VBZ with_IN the_DT increasing_VBG of_IN tree_NN number_NN ,_, RDT_NN reduces_VBZ the_DT training_NN and_CC test_NN errors_NNS on_IN the_DT same_JJ time_NN ._.
The_DT result_NN fits_VBZ the_DT analysis_NN above_RB well_RB ._.
4_CD Computation_NNP Complexity_NNP Analysis_NNP Previous_JJ work_NN =_JJ -_: =[_NN 27_CD ,_, 25_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: reported_VBD the_DT low_JJ training_NN cost_NN of_IN RDT_NN for_IN binary_JJ classification_NN and_CC regression_NN by_IN experimental_JJ results_NNS ._.
We_PRP formally_RB analyze_VBP the_DT computation_NN complexity_NN of_IN Multi-label_JJ RDT_NN in_IN this_DT section_NN ._.
According_VBG to_TO
ombines_NNS parametric_JJ and_CC nonparametric_JJ regression_NN ._.
Combining_VBG the_DT notions_NNS of_IN both_CC GLM_NN and_CC additive_JJ models_NNS ,_, generalized_JJ additive_JJ model_NN or_CC GAM_NN relaxes_VBZ the_DT linear_JJ combination_NN of_IN xi_NN in_IN GLM_NN to_TO be_VB functional_JJ -LRB-_-LRB- =_JJ -_: =_JJ Hastie_NNP and_CC Tibshirani_NNP ,_, 1986_CD -_: =-]_CD ._.
In_IN biFi_NN -LRB-_-LRB- xi_NN -RRB-_-RRB- ._.
Generalized_NNP additive_JJ models_NNS maximize_VBP the_DT quality_NN of_IN prediction_NN of_IN a_DT dependent_JJ variable_JJ y_NN from_IN various_JJ distributions_NNS ,_, by_IN estimating_VBG nonparametric_JJ functions_NNS of_IN the_DT independent_JJ variables_NNS
tance_NN of_IN regression_NN trees_NNS in_IN the_DT data_NNS mining_NN community_NN and_CC the_DT recent_JJ results_NNS of_IN randomized_VBN decision_NN trees_NNS or_CC RDT_NN for_IN classification_NN and_CC conditional_JJ probability_NN estimation_NN problems_NNS -LRB-_-LRB- Fan_NN et_FW al._FW ,_, 2003_CD ,_, =_JJ -_: =_JJ Fan_NN et_FW al._FW ,_, 2005_CD -_: =_JJ -_: ,_, Zhang_NNP et_FW al._FW ,_, 2005_CD ,_, Liu_NNP ,_, 2005_CD -RRB-_-RRB- ,_, we_PRP propose_VBP an_DT extension_NN to_TO use_VB random_JJ decision_NN trees_NNS for_IN general-purpose_JJ regression_NN problems_NNS ._.
The_DT procedure_NN to_TO generate_VB random_JJ trees_NNS for_IN regressions_NNS is_VBZ exactly_RB the_DT sa_NN
search_NN has_VBZ been_VBN summarized_VBN in_IN Section_NN 1.1_CD ._.
There_EX are_VBP a_DT number_NN of_IN significant_JJ works_NNS on_IN regression_NN ensembles_NNS ._.
For_IN example_NN ,_, multiple_JJ SVM-based_JJ regression_NN has_VBZ been_VBN applied_VBN successfully_RB to_TO recognize_VB face_NN -LRB-_-LRB- =_JJ -_: =_JJ Yan_NNP et_FW al._FW ,_, 2001_CD -_: =-]_CD ._.
A_DT genetic_JJ algorithm-based_JJ approach_NN to_TO combine_VB multiple_JJ neural_JJ network_NN regression_NN has_VBZ been_VBN examined_VBN in_IN -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2001_CD -RRB-_-RRB- ._.
Previously_RB ,_, a_DT rule-based_JJ approach_NN to_TO combine_VB multiple_JJ regression_NN model_NN has_VBZ
parametric_JJ models_NNS ._.
We_PRP consider_VBP a_DT time_NN series_NN of_IN monthly_JJ evapotranspiration_NN rates_NNS Xt_NN ,_, t_NN =_JJ 1_CD ,_, ..._: ,_, 96_CD ,_, obtained_VBN during_IN the_DT period_NN of_IN 1960_CD to_TO 1970_CD at_IN Yotvata_NNP ,_, Souther_NNP Israel_NNP ._.
The_DT problem_NN appears_VBZ in_IN -LRB-_-LRB- =_JJ -_: =_JJ Kedem_NNP and_CC Fokianos_NNP ,_, 2002_CD -_: =-]_CD ._.
The_DT data_NN is_VBZ analyzed_VBN by_IN clipping_JJ the_DT seasonal_JJ difference_NN Wt_NN =_JJ Xt_FW −_FW Xt_FW −_FW 12_CD ,_, thus_RB Yt_FW −_FW 12_CD =_JJ 1_CD if_IN Wt_NNP ≥_NNP ¯_NNP W_NNP or_CC else_RB Yt_FW −_FW 12_CD =_JJ 0_CD for_IN t_NN =_JJ 13_CD ,_, ..._: ,_, 96_CD ._.
The_DT clipped_VBN time_NN series_NN Yt_NN ,_, t_NN =_JJ 1_CD ,_, ..._: ,_, 84_CD ,_, can_MD be_VB
nonparametric_JJ methods_NNS differing_VBG in_IN the_DT choice_NN of_IN function_NN familities_NNS and_CC combination_NN of_IN function_NN families_NNS ._.
One_CD of_IN the_DT simplest_JJS nonparametric_JJ regression_NN methods_NNS is_VBZ regression_NN trees_NNS ,_, pioneered_VBN by_IN CART_NN -LRB-_-LRB- =_JJ -_: =_JJ Breiman_NNP et_FW al._FW ,_, 1984_CD -_: =-]_CD ._.
When_WRB constructing_VBG the_DT regression_NN tree_NN ,_, it_PRP chooses_VBZ one_CD independent_JJ variable_NN as_IN the_DT splitting_NN feature_NN that_WDT can_MD minimize_VB the_DT variance_NN of_IN predictions_NNS after_IN the_DT split_NN ._.
CART_NN always_RB predicts_VBZ with_IN the_DT aver_NN
mining_NN community_NN and_CC the_DT recent_JJ results_NNS of_IN randomized_VBN decision_NN trees_NNS or_CC RDT_NN for_IN classification_NN and_CC conditional_JJ probability_NN estimation_NN problems_NNS -LRB-_-LRB- Fan_NN et_FW al._FW ,_, 2003_CD ,_, Fan_NN et_FW al._FW ,_, 2005_CD ,_, Zhang_NNP et_FW al._FW ,_, 2005_CD ,_, =_JJ -_: =_JJ Liu_NNP ,_, 2005_CD -_: =-]_CD ,_, we_PRP propose_VBP an_DT extension_NN to_TO use_VB random_JJ decision_NN trees_NNS for_IN general-purpose_JJ regression_NN problems_NNS ._.
The_DT procedure_NN to_TO generate_VB random_JJ trees_NNS for_IN regressions_NNS is_VBZ exactly_RB the_DT same_JJ as_IN for_IN classification_NN and_CC po_NN
oaches_NNS for_IN randomization_NN independently_RB proposed_VBN by_IN various_JJ researchers_NNS are_VBP reviewed_VBN and_CC studied_VBN in_IN -LRB-_-LRB- Fan_NN et_FW al._FW ,_, 2005_CD ,_, Liu_NNP ,_, 2005_CD -RRB-_-RRB- ._.
In_IN particular_JJ ,_, it_PRP is_VBZ worthwhile_JJ to_TO mention_VB bagging_NN and_CC random_JJ forest_NN -LRB-_-LRB- =_JJ -_: =_JJ Breiman_NNP ,_, 2001_CD -_: =-]_NN ,_, feature_NN subset_NN randomization_NN -LRB-_-LRB- Amit_NNP and_CC Geman_NNP ,_, 1997_CD -RRB-_-RRB- among_IN others_NNS ._.
For_IN regression_NN problem_NN ,_, random_JJ forest_NN -LRB-_-LRB- RF_NN -RRB-_-RRB- for_IN regression_NN is_VBZ the_DT closest_JJS work_NN to_TO random_JJ decision_NN trees_NNS -LRB-_-LRB- Breiman_NNP ,_, 2001_CD ,_, Segal_NNP ,_, 2004_CD -RRB-_-RRB-
implify_VB the_DT construction_NN of_IN sophisticated_JJ functions_NNS by_IN combining_VBG these_DT basic_JJ functions_NNS in_IN some_DT ways_NNS and_CC under_IN some_DT assumptions_NNS ._.
In_IN generalized_JJ linear_JJ model_NN -LRB-_-LRB- GLM_NN or_CC GLIM_NN -RRB-_-RRB- -LRB-_-LRB- Nelder_NNP and_CC Wedderburn_NNP ,_, 1972_CD ,_, =_JJ -_: =_JJ McCullagh_NNP and_CC Nelder_NNP ,_, 1989_CD -_: =-]_CD ,_, a_DT dependent_JJ variable_JJ y_NN is_VBZ linearly_RB associated_VBN with_IN values_NNS on_IN the_DT x_NN variables_NNS whilethe_VBP functional_JJ relationship_NN is_VBZ assumed_VBN to_TO be_VB nonlinear_JJ or_CC formally_RB ,_, E_NN -LRB-_-LRB- y_NN |_CD x_NN -RRB-_-RRB- =_JJ G_NN -LRB-_-LRB- b0_NN +_CC Pp_NN 1_CD bixi_NN -RRB-_-RRB- ._.
The_DT inverse_JJ functi_NNS
nerality_NN on_IN the_DT same_JJ family_NN of_IN functions_NNS ._.
They_PRP balance_VBP model_NN complexity_NN with_IN generalization_NN error_NN ._.
There_EX is_VBZ still_RB much_RB active_JJ work_NN being_VBG done_VBN on_IN this_DT topic_NN ,_, for_IN example_NN ,_, Neyman_NNP test_NN based_VBN approaches_NNS -LRB-_-LRB- =_JJ -_: =_JJ Fan_NN and_CC Huang_NNP ,_, 2001_CD -_: =-]_CD ._.
Another_DT practical_JJ restriction_NN is_VBZ that_IN most_JJS parametric_JJ models_NNS do_VBP not_RB handle_VB categorical_JJ features_NNS directly_RB ._.
The_DT simple_JJ approach_NN is_VBZ to_TO assign_VB an_DT integer_NN value_NN to_TO each_DT unique_JJ category_NN ,_, but_CC this_DT imposes_VBZ
ts_NNS of_IN basic_JJ functions_NNS ,_, then_RB simplify_VB the_DT construction_NN of_IN sophisticated_JJ functions_NNS by_IN combining_VBG these_DT basic_JJ functions_NNS in_IN some_DT ways_NNS and_CC under_IN some_DT assumptions_NNS ._.
In_IN generalized_JJ linear_JJ model_NN -LRB-_-LRB- GLM_NN or_CC GLIM_NN -RRB-_-RRB- -LRB-_-LRB- =_JJ -_: =_JJ Nelder_NNP and_CC Wedderburn_NNP ,_, 1972_CD -_: =_JJ -_: ,_, McCullagh_NNP and_CC Nelder_NNP ,_, 1989_CD -RRB-_-RRB- ,_, a_DT dependent_JJ variable_JJ y_NN is_VBZ linearly_RB associated_VBN with_IN values_NNS on_IN the_DT x_NN variables_NNS whilethe_VBP functional_JJ relationship_NN is_VBZ assumed_VBN to_TO be_VB nonlinear_JJ or_CC formally_RB ,_, E_NN -LRB-_-LRB- y_NN |_CD x_NN -RRB-_-RRB- =_JJ G_NN -LRB-_-LRB- b0_NN +_CC Pp_NN
n_NN trees_NNS in_IN the_DT data_NNS mining_NN community_NN and_CC the_DT recent_JJ results_NNS of_IN randomized_VBN decision_NN trees_NNS or_CC RDT_NN for_IN classification_NN and_CC conditional_JJ probability_NN estimation_NN problems_NNS -LRB-_-LRB- Fan_NN et_FW al._FW ,_, 2003_CD ,_, Fan_NN et_FW al._FW ,_, 2005_CD ,_, =_JJ -_: =_JJ Zhang_NNP et_FW al._FW ,_, 2005_CD -_: =_JJ -_: ,_, Liu_NNP ,_, 2005_CD -RRB-_-RRB- ,_, we_PRP propose_VBP an_DT extension_NN to_TO use_VB random_JJ decision_NN trees_NNS for_IN general-purpose_JJ regression_NN problems_NNS ._.
The_DT procedure_NN to_TO generate_VB random_JJ trees_NNS for_IN regressions_NNS is_VBZ exactly_RB the_DT same_JJ as_IN for_IN classifica_NN
d_NN by_IN various_JJ researchers_NNS are_VBP reviewed_VBN and_CC studied_VBN in_IN -LRB-_-LRB- Fan_NN et_FW al._FW ,_, 2005_CD ,_, Liu_NNP ,_, 2005_CD -RRB-_-RRB- ._.
In_IN particular_JJ ,_, it_PRP is_VBZ worthwhile_JJ to_TO mention_VB bagging_NN and_CC random_JJ forest_NN -LRB-_-LRB- Breiman_NNP ,_, 2001_CD -RRB-_-RRB- ,_, feature_NN subset_NN randomization_NN -LRB-_-LRB- =_JJ -_: =_JJ Amit_NNP and_CC Geman_NNP ,_, 1997_CD -_: =-]_CD among_IN others_NNS ._.
For_IN regression_NN problem_NN ,_, random_JJ forest_NN -LRB-_-LRB- RF_NN -RRB-_-RRB- for_IN regression_NN is_VBZ the_DT closest_JJS work_NN to_TO random_JJ decision_NN trees_NNS -LRB-_-LRB- Breiman_NNP ,_, 2001_CD ,_, Segal_NNP ,_, 2004_CD -RRB-_-RRB- ._.
However_RB ,_, there_EX are_VBP a_DT few_JJ important_JJ distinctions_NNS ._.
Fi_NN
reiman_NN ,_, 2001_CD -RRB-_-RRB- ,_, feature_NN subset_NN randomization_NN -LRB-_-LRB- Amit_NNP and_CC Geman_NNP ,_, 1997_CD -RRB-_-RRB- among_IN others_NNS ._.
For_IN regression_NN problem_NN ,_, random_JJ forest_NN -LRB-_-LRB- RF_NN -RRB-_-RRB- for_IN regression_NN is_VBZ the_DT closest_JJS work_NN to_TO random_JJ decision_NN trees_NNS -LRB-_-LRB- Breiman_NNP ,_, 2001_CD ,_, =_JJ -_: =_JJ Segal_NNP ,_, 2004_CD -_: =-]_CD ._.
However_RB ,_, there_EX are_VBP a_DT few_JJ important_JJ distinctions_NNS ._.
First_RB ,_, each_DT tree_NN in_IN random_JJ forest_NN is_VBZ trained_VBN from_IN one_CD bootstrap_NN sample_NN of_IN the_DT training_NN set_NN ._.
But_CC each_DT tree_NN in_IN RDT_NN is_VBZ trained_VBN from_IN the_DT same_JJ original_JJ t_NN
IDE_NN as_IN discussed_VBN below_IN ._.
Using_VBG decision_NN trees_NNS to_TO group_NN examples_NNS with_IN similar_JJ independent_JJ feature_NN values_NNS ,_, GUIDE_NNP replaces_VBZ the_DT average_JJ value_NN prediction_NN in_IN the_DT leaf_NN node_NN of_IN CART_NN by_IN some_DT parametric_JJ models_NNS -LRB-_-LRB- =_JJ -_: =_JJ Loh_NN ,_, 2002_CD -_: =-]_CD ._.
The_DT current_JJ release_NN of_IN GUIDE_NNP includes_VBZ linear_JJ ,_, piece-wise_JJ linear_NN ,_, quantile_NN ,_, Poisson_NNP ,_, and_CC proportional_JJ hazard_NN regressions_NNS ._.
Each_DT leaf_NN node_NN has_VBZ its_PRP$ own_JJ parametric_JJ model_NN -LRB-_-LRB- same_JJ kind_NN for_IN every_DT leaf_NN node_NN b_NN
ls_NNS include_VBP ,_, but_CC is_VBZ not_RB limited_VBN to_TO ,_, Kernel-smoothing_NN ,_, RBF_NN ,_, neural_JJ network_NN ,_, nearest_JJS neighbor_NN ,_, orthogonal_JJ series_NN estimator_NN ,_, spline_NN smoothing_NN ._.
For_IN an_DT extensive_JJ treatment_NN of_IN this_DT subject_NN ,_, please_VBP refer_VB to_TO -LRB-_-LRB- =_JJ -_: =_JJ Hardle_NNP ,_, 1990_CD -_: =-]_CD ._.
Several_JJ work_NN combines_VBZ parametric_JJ and_CC nonparametric_JJ regression_NN ._.
Combining_VBG the_DT notions_NNS of_IN both_CC GLM_NN and_CC additive_JJ models_NNS ,_, generalized_JJ additive_JJ model_NN or_CC GAM_NN relaxes_VBZ the_DT linear_JJ combination_NN of_IN xi_NN in_IN GLM_NN t_NN
thm-based_JJ approach_NN to_TO combine_VB multiple_JJ neural_JJ network_NN regression_NN has_VBZ been_VBN examined_VBN in_IN -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2001_CD -RRB-_-RRB- ._.
Previously_RB ,_, a_DT rule-based_JJ approach_NN to_TO combine_VB multiple_JJ regression_NN model_NN has_VBZ been_VBN explored_VBN in_IN -LRB-_-LRB- =_JJ -_: =_JJ Indurkhya_NNP and_CC Weiss_NNP ,_, 2001_CD -_: =-]_CD ._.
The_DT term_NN ``_`` random_JJ regression_NN ''_'' has_VBZ been_VBN used_VBN to_TO train_VB multiple_JJ random_JJ parametric_JJ models_NNS ._.
The_DT idea_NN of_IN random_JJ decision_NN tree_NN was_VBD originally_RB proposed_VBN in_IN -LRB-_-LRB- Fan_NN et_FW al._FW ,_, 2003_CD -RRB-_-RRB- ._.
Some_DT notable_JJ previous_JJ works_NNS of_IN
Based_VBN on_IN the_DT acceptance_NN of_IN regression_NN trees_NNS in_IN the_DT data_NNS mining_NN community_NN and_CC the_DT recent_JJ results_NNS of_IN randomized_VBN decision_NN trees_NNS or_CC RDT_NN for_IN classification_NN and_CC conditional_JJ probability_NN estimation_NN problems_NNS -LRB-_-LRB- =_JJ -_: =_JJ Fan_NN et_FW al._FW ,_, 2003_CD -_: =_JJ -_: ,_, Fan_NN et_FW al._FW ,_, 2005_CD ,_, Zhang_NNP et_FW al._FW ,_, 2005_CD ,_, Liu_NNP ,_, 2005_CD -RRB-_-RRB- ,_, we_PRP propose_VBP an_DT extension_NN to_TO use_VB random_JJ decision_NN trees_NNS for_IN general-purpose_JJ regression_NN problems_NNS ._.
The_DT procedure_NN to_TO generate_VB random_JJ trees_NNS for_IN regressions_NNS
