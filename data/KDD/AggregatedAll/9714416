The_DT cost_NN of_IN privacy_NN :_: destruction_NN of_IN data-mining_JJ utility_NN in_IN anonymized_JJ data_NNS publishing_NN
Re-identification_NN is_VBZ a_DT major_JJ privacy_NN threat_NN to_TO public_JJ datasets_NNS containing_VBG individual_JJ records_NNS ._.
Many_JJ privacy_NN protection_NN algorithms_NNS rely_VBP on_IN generalization_NN and_CC suppression_NN of_IN ``_`` quasi-identifier_JJ ''_'' attributes_NNS such_JJ as_IN ZIP_NN code_NN and_CC birthdate_NN ._.
Their_PRP$ objective_NN is_VBZ usually_RB syntactic_JJ sanitization_NN :_: for_IN example_NN ,_, k-anonymity_NN requires_VBZ that_IN each_DT ``_`` quasi-identifier_JJ ''_'' tuple_NN appear_VBP in_IN at_IN least_JJS k_NN records_NNS ,_, while_IN l-diversity_NN requires_VBZ that_IN the_DT distribution_NN of_IN sensitive_JJ attributes_NNS for_IN each_DT quasi-identifier_NN have_VBP high_JJ entropy_NN ._.
The_DT utility_NN of_IN sanitized_VBN data_NNS is_VBZ also_RB measured_VBN syntactically_RB ,_, by_IN the_DT number_NN of_IN generalization_NN steps_NNS applied_VBD or_CC the_DT number_NN of_IN records_NNS with_IN the_DT same_JJ quasi-identifier_NN ._.
In_IN this_DT paper_NN ,_, we_PRP ask_VBP whether_IN generalization_NN and_CC suppression_NN of_IN quasi-identifiers_NNS offer_VBP any_DT benefits_NNS over_IN trivial_JJ sanitization_NN which_WDT simply_RB separates_VBZ quasi-identifiers_NNS from_IN sensitive_JJ attributes_NNS ._.
Previous_JJ work_NN showed_VBD that_IN k-anonymous_NN databases_NNS can_MD be_VB useful_JJ for_IN data_NNS mining_NN ,_, but_CC k-anonymization_NN does_VBZ not_RB guarantee_VB any_DT privacy_NN ._.
By_IN contrast_NN ,_, we_PRP measure_VBP the_DT tradeoff_NN between_IN privacy_NN -LRB-_-LRB- how_WRB much_RB can_MD the_DT adversary_NN learn_VB from_IN the_DT sanitized_VBN records_NNS ?_. -RRB-_-RRB-
and_CC utility_NN ,_, measured_VBN as_IN accuracy_NN of_IN data-mining_JJ algorithms_NNS executed_VBN on_IN the_DT same_JJ sanitized_VBN records_NNS ._.
For_IN our_PRP$ experimental_JJ evaluation_NN ,_, we_PRP use_VBP the_DT same_JJ datasets_NNS from_IN the_DT UCI_NNP machine_NN learning_NN repository_NN as_IN were_VBD used_VBN in_IN previous_JJ research_NN on_IN generalization_NN and_CC suppression_NN ._.
Our_PRP$ results_NNS demonstrate_VBP that_IN even_RB modest_JJ privacy_NN gains_NNS require_VBP almost_RB complete_JJ destruction_NN of_IN the_DT data-mining_JJ utility_NN ._.
In_IN most_JJS cases_NNS ,_, trivial_JJ sanitization_NN provides_VBZ equivalent_JJ utility_NN and_CC better_JJR privacy_NN than_IN k-anonymity_NN ,_, l-diversity_NN ,_, and_CC similar_JJ methods_NNS based_VBN on_IN generalization_NN and_CC suppression_NN ._.
o_NN get_VB a_DT large_JJ gain_NN in_IN utility_NN ._.
In_IN short_JJ ,_, we_PRP currently_RB lack_VBP a_DT framework_NN for_IN thinking_VBG about_IN the_DT privacy-utility_NN tradeoff_NN in_IN data_NN publishing_NN ._.
In_IN a_DT paper_NN that_WDT appeared_VBD in_IN KDD_NNP 2008_CD ,_, Brickell_NNP and_CC Shmatikov_NNP =_SYM -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: applied_VBD a_DT fresh_JJ angle_NN to_TO the_DT tradeoff_NN between_IN privacy_NN and_CC utility_NN ._.
They_PRP directly_RB compared_VBD the_DT privacy_NN gain_NN with_IN the_DT utility_NN gain_NN caused_VBN by_IN data_NNS anonymization_NN ,_, and_CC reached_VBD an_DT intrigu-ing_JJ conclusion_NN ``_``
ok_VB for_IN a_DT convex_NN optimization_NN problem_NN to_TO be_VB solved_VBN numerically_RB as_IN the_DT next_JJ most_RBS attractive_JJ option_NN ._.
â€¢_NNP Investigate_NNP the_DT connection_NN of_IN mutual_JJ information_NN with_IN information_NN loss_NN metrics_NNS other_JJ than_IN MSE_NNP ,_, like_IN =_JJ -_: =[_NN 5_CD ,_, 15_CD ,_, 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Acknowledgments_NNS and_CC disclaimer_VB This_DT work_NN was_VBD partly_RB funded_VBN by_IN the_DT Spanish_NNP Government_NNP through_IN projects_NNS CONSOLIDER_NNP INGENIO_NNP 2010_CD CSD200700004_NN ``_`` ARES_NNP ''_'' and_CC TSI2007-65406-C03-01_NN ``_`` E-AEGIS_NN ''_'' ._.
The_DT first_JJ author_NN
rt_FW et_FW al._FW -LRB-_-LRB- 8_CD -RRB-_-RRB- and_CC applies_VBZ anomaly_RB detection_NN methodologies_NNS to_TO the_DT anonymized_VBN data_NNS to_TO quantify_VB the_DT way_NN in_IN which_WDT it_PRP affects_VBZ its_PRP$ performance_NN ._.
Both_DT methods_NNS closely_RB resemble_VBP those_DT of_IN Brickell_NNP and_CC Shmatikov_NNP =_SYM -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: that_WDT apply_VBP machine_NN learning_VBG tasks_NNS to_TO microdata_VB to_TO determine_VB the_DT degradation_NN in_IN accuracy_NN ._.
In_IN addition_NN ,_, the_DT global_JJ utility_NN measure_NN of_IN Woo_NNP et_FW al._FW -LRB-_-LRB- 44_CD -RRB-_-RRB- can_MD also_RB be_VB adapted_VBN to_TO network_NN data_NNS due_JJ to_TO its_PRP$ use_NN
xample_RB ,_, an_DT individual_NN might_MD mark_VB bubbles_NNS differently_RB near_IN the_DT end_NN of_IN forms_NNS -LRB-_-LRB- this_DT is_VBZ also_RB a_DT problem_NN for_IN averaging_VBG the_DT bubble_NN colors_NNS -RRB-_-RRB- ._.
Finally_RB ,_, concerns_NNS exist_VBP over_IN the_DT guarantees_NNS provided_VBN by_IN kanonymity_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, but_CC the_DT work_NN may_MD be_VB extensible_JJ to_TO achieve_VB other_JJ notions_NNS of_IN privacy_NN ,_, such_JJ as_IN differential_JJ privacy_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
We_PRP caution_VBP that_IN the_DT value_NN of_IN these_DT images_NNS for_IN proving_VBG the_DT true_JJ contents_NNS of_IN physical_JJ bubble_NN forms_NNS
the_DT sufficient_JJ statistics_NNS of_IN applications_NNS that_WDT will_MD use_VB the_DT sanitized_VBN search_NN log_NN ,_, and_CC for_IN some_DT applications_NNS the_DT sufficient_JJ statistics_NNS are_VBP hard_JJ to_TO characterize_VB ._.
To_TO avoid_VB this_DT drawback_NN ,_, Brickell_NNP et_FW al._FW =_SYM -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: measure_VB the_DT utility_NN with_IN respect_NN to_TO data_NN mining_NN tasks_NNS and_CC they_PRP take_VBP the_DT actual_JJ classification_NN error_NN of_IN an_DT induced_VBN classifier_NN as_IN their_PRP$ utility_NN metric_NN ._.
In_IN this_DT chapter_NN we_PRP take_VBP a_DT similar_JJ approach_NN ._.
We_PRP us_PRP
S._NNP Census_NNP show_VBP that_IN applying_VBG data_NNS privacy_NN leads_VBZ to_TO incorrect_JJ results_NNS -LRB-_-LRB- 5_CD ,_, 8_CD -RRB-_-RRB- ._.
Multiple_JJ studies_NNS demonstrate_VBP that_IN even_RB modest_JJ privacy_NN gains_NNS require_VBP almost_RB complete_JJ destruction_NN of_IN the_DT data-mining_JJ utility_NN =_JJ -_: =[_NN 1_CD ,_, 9_CD ,_, 18_CD ,_, 19_CD ,_, 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Data_NNS swapping_VBG is_VBZ an_DT anonymization_NN technique_NN that_WDT is_VBZ based_VBN on_IN exchanging_VBG values_NNS of_IN attributes_NNS among_IN individual_JJ records_NNS while_IN maintaining_VBG certain_JJ distribution_NN properties_NNS -LRB-_-LRB- 33_CD ,_, 32_CD -RRB-_-RRB- ._.
Data_NNS swapping_VBG is_VBZ mor_NN
ect_NN value_NN ._.
Clearly_RB ,_, this_DT fraction_NN will_MD vary_VB as_IN a_DT function_NN of_IN the_DT data_NNS ,_, and_CC of_IN parameters_NNS of_IN the_DT anonymization_NN ._.
2.2_CD Accurate_NNP Differentially_NNP Private_NNP Classifiers_NNPS In_IN line_NN with_IN previous_JJ attacks_NNS on_IN privacy_NN =_JJ -_: =[_NN 14_CD ,_, 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, we_PRP describe_VBP a_DT method_NN to_TO build_VB an_DT accurate_JJ classifier_NN which_WDT ,_, given_VBN the_DT quasi-identifier_NN of_IN an_DT individual_NN ,_, predicts_VBZ their_PRP$ sensitive_JJ attribute_NN ._.
For_IN simplicity_NN ,_, we_PRP initially_RB assume_VBP that_IN all_DT attributes_NNS i_LS
al._FW develop_VB a_DT language_NN to_TO describe_VB public_JJ background_NN knowledge_NN and_CC design_NN an_DT algorithm_NN to_TO measure_VB the_DT worst-case_JJ information_NN disclosure_NN for_IN different_JJ anonymization_NN techniques_NNS ._.
Brickell_NNP and_CC Shmatikov_NNP =_SYM -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: analyze_VB the_DT privacy\/utility_NN tradeoff_NN in_FW microdata_FW anonymization_NN ,_, and_CC showed_VBD that_IN quasi-identifier_JJ generalization_NN often_RB incurs_VBZ significant_JJ negative_JJ impact_NN on_IN data_NNS utility_NN ._.
All_PDT the_DT above_RB works_VBZ focus_NN on_IN
full_JJ list_NN approach_NN are_VBP set_VBN to_TO k_NN =_JJ m_NN =_JJ 10_CD and_CC those_DT for_IN the_DT prefix_NN list_NN approach_NN are_VBP set_VBN as_IN k_NN =_JJ 10_CD ,_, m_NN =_JJ 20_CD ,_, which_WDT guarantees_VBZ individual_NN 's_POS privacy_NN with_IN probability_NN at_IN least_JJS 90_CD %_NN ,_, similar_JJ to_TO previous_JJ work_NN =_JJ -_: =[_NN 4_CD ,_, 8_CD ,_, 15_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
On_IN the_DT smaller_JJR speed_NN dating_VBG dataset_NN ,_, the_DT parameters_NNS chosen_VBN are_VBP correspondingly_RB smaller_JJR :_: k_NN =_JJ m_NN =_JJ 5_CD for_IN full_JJ lists_NNS ,_, and_CC k_NN =_JJ 5_CD ,_, m_NN =_JJ 10_CD for_IN the_DT prefix_NN list_NN approach_NN ._.
Both_CC anonymization_NN and_CC query_NN answerin_NN
