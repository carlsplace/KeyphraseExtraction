An_DT objective_JJ evaluation_NN criterion_NN for_IN clustering_NN
We_PRP propose_VBP and_CC test_VBP an_DT objective_JJ criterion_NN for_IN evaluation_NN of_IN clustering_NN performance_NN :_: How_WRB well_RB does_VBZ a_DT clustering_NN algorithm_NN run_NN on_IN unlabeled_JJ data_NNS aid_VBP a_DT classification_NN algorithm_NN ?_.
The_DT accuracy_NN is_VBZ quantified_VBN using_VBG the_DT PAC-MDL_NN bound_VBD -LRB-_-LRB- 3_CD -RRB-_-RRB- in_IN a_DT semisupervised_JJ setting_NN ._.
Clustering_NN algorithms_NNS which_WDT naturally_RB separate_VBP the_DT data_NNS according_VBG to_TO -LRB-_-LRB- hidden_JJ -RRB-_-RRB- labels_NNS with_IN a_DT small_JJ number_NN of_IN clusters_NNS perform_VBP well_RB ._.
A_DT simple_JJ extension_NN of_IN the_DT argument_NN leads_VBZ to_TO an_DT objective_JJ model_NN selection_NN method_NN ._.
Experimental_JJ results_NNS on_IN text_NN analysis_NN datasets_NNS demonstrate_VBP that_IN this_DT approach_NN empirically_RB results_VBZ in_IN very_RB competitive_JJ bounds_NNS on_IN test_NN set_NN performance_NN on_IN natural_JJ datasets_NNS ._.
s_VBZ an_DT input_NN ,_, produces_VBZ the_DT labels_NNS ^_CD Y_NN m_NN +_CC n_NN as_IN output_NN and_CC halts_NNS ._.
Therefore_RB ,_, the_DT description_NN language_NN L_NN =_JJ -LCB-_-LRB- oe_NN -RCB-_-RRB- must_MD be_VB a_DT prefix-free_JJ code_NN -LRB-_-LRB- by_IN the_DT halting_VBG property_NN -RRB-_-RRB- and_CC hence_RB satisfy_VB Kraft_NNP 's_POS inequality_NN -LRB-_-LRB- see_VB =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Theorem_NNP 5.2.1_NNP ,_, Lemma_NNP 7.3.1_NNP ,_, for_IN details_NNS -RRB-_-RRB- ,_, i.e._FW ,_, Poe2L_NN 2_CD -_: |_CD oe_FW |_FW -LRB-_-LRB- =_JJ 1_CD ._.
This_DT is_VBZ the_DT only_JJ condition_NN a_DT label_NN description_NN language_NN L_NN =_JJ -LCB-_-LRB- oe_NN -RCB-_-RRB- must_MD satisfy_VB for_IN the_DT proposed_VBN bound_VBD to_TO hold_VB ._.
3.1_CD PAC-MDL_NN Bound_VBN for_IN
the_DT PAC-MDL_NN bound_VBD -LRB-_-LRB- 3_CD -RRB-_-RRB- on_IN the_DT accuracy_NN of_IN a_DT test_NN set_NN ._.
Our_PRP$ proposed_VBN criterion_NN has_VBZ several_JJ natural_JJ properties_NNS :_: 1_CD ._.
It_PRP applies_VBZ to_TO every_DT clustering_NN algorithm_NN ._.
2_CD ._.
It_PRP is_VBZ inherently_RB normalized_VBN to_TO the_DT interval_NN =_JJ -_: =[_NN 0_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
3_LS ._.
All_DT possible_JJ values_NNS are_VBP exercised_VBN on_IN natural_JJ datasets_NNS ._.
4_LS ._.
The_DT metric_NN can_MD flexibly_RB incorporate_VB prior_JJ information_NN by_IN proper_JJ design_NN of_IN a_DT description_NN language_NN ._.
5_CD ._.
It_PRP can_MD be_VB used_VBN for_IN model_NN selection_NN ._.
on_IN ,_, which_WDT is_VBZ often_RB a_DT big_JJ issue_NN for_IN these_DT supervised_JJ measures_NNS ._.
An_DT information_NN theoretic_JJ external_JJ validity_NN measure_NN motivated_VBN by_IN the_DT minimum_JJ description_NN length_NN -LRB-_-LRB- MDL_NN -RRB-_-RRB- principle_NN has_VBZ been_VBN recently_RB proposed_VBN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN spite_NN of_IN having_VBG several_JJ desirable_JJ properties_NNS ,_, this_DT measure_NN has_VBZ a_DT few_JJ drawbacks_NNS with_IN respect_NN to_TO the_DT measure_NN proposed_VBN here_RB :_: -LRB-_-LRB- i_LS -RRB-_-RRB- the_DT measure_NN is_VBZ not_RB normalized_VBN to_TO the_DT interval_NN -LRB-_-LRB- 0,1_NN -RRB-_-RRB- -LRB-_-LRB- and_CC not_RB easily_RB n_NN
tionrelated_VBN quality_NN measures_NNS are_VBP often_RB appropriate_JJ ._.
Several_JJ supervised_JJ measures_NNS such_JJ as_IN purity_NN ,_, entropy_NN ,_, normalized_VBD mutual_JJ information_NN ,_, supervised_VBN F-measure_FW etc._FW have_VBP been_VBN used_VBN in_IN the_DT literature_NN -LRB-_-LRB- see_VB =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: for_IN details_NNS -RRB-_-RRB- ._.
However_RB ,_, it_PRP is_VBZ not_RB clear_JJ how_WRB these_DT measures_NNS are_VBP related_JJ to_TO the_DT error-rate_NN of_IN the_DT clustering_NN algorithm_NN when_WRB used_VBN for_IN prediction_NN ._.
Furthermore_RB ,_, none_NN of_IN these_DT supervised_JJ measures_NNS help_VBP with_IN
es-Fisher_JJ distributions_NNS to_TO model_VB the_DT data_NNS with_IN soft-assignments_NNS that_WDT are_VBP finally_RB converted_VBN to_TO hard_JJ assignments_NNS by_IN the_DT standard_JJ method_NN assigning_VBG a_DT data_NN point_NN to_TO the_DT highest_JJS probability_NN cluster_NN ;_: KMeans_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT standard_NN kmeans_VBZ clustering_NN algorithm_NN ;_: and_CC KLKMeans_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, better_RB known_VBN as_IN information_NN theoretic_JJ clustering_NN ,_, that_WDT uses_VBZ KLdivergence_NN between_IN L1_NN normalized_VBD document_NN vectors_NNS instead_RB of_IN squared_VBN Euclide_NN
several_JJ unsupervised_JJ methods_NNS for_IN comparing_VBG clusterings_NNS ,_, e.g._FW ,_, Jaccard_NNP index_NN ,_, Rand_NNP index_NN ,_, Fowlkes-Mallows_NNP index_NN ,_, Mirkin_NNP metric_NN ,_, variation_NN of_IN information_NN etc._NN ,_, exist_VBP in_IN the_DT literature_NN -LRB-_-LRB- for_IN details_NNS ,_, see_VBP =_JJ -_: =[_NN 9_CD ,_, 10_CD -RRB-_-RRB- -_: =_JJ -_: and_CC references_NNS therein_RB -RRB-_-RRB- ._.
These_DT completely_RB unsupervised_JJ methods_NNS are_VBP incapable_JJ of_IN measuring_VBG performance_NN in_IN supervised_JJ tasks_NNS ,_, such_JJ as_IN prediction_NN ._.
Since_IN the_DT predictive_JJ ability_NN of_IN clustering_NN algorithms_NNS is_VBZ
rt_NN and_CC have_VBP been_VBN applied_VBN to_TO text_NN clustering_NN in_IN the_DT literature_NN ._.
The_DT algorithms_NNS we_PRP consider_VBP are_VBP :_: SPKMeans_NNS -LRB-_-LRB- 6_CD -RRB-_-RRB- ,_, better_RB known_VBN as_IN spherical_JJ kmeans_NNS ,_, that_WDT employs_VBZ the_DT widely_RB used_VBN cosine_NN similarity_NN ;_: FSKMeans_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT frequency_NN sensitive_JJ version_NN of_IN spherical_JJ kmeans_NNS ;_: Hard-moVMF_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ,_, a_DT generative_JJ model_NN based_JJ clustering_NN that_WDT uses_VBZ a_DT mixture_NN of_IN von_NN Mises-Fisher_NN -LRB-_-LRB- vMF_NN -RRB-_-RRB- distributions_NNS to_TO model_VB the_DT data_NNS ;_: Soft-moVMF_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ,_,
ctive_JJ criterion_NN for_IN evaluation_NN of_IN clustering_NN performance_NN :_: How_WRB well_RB does_VBZ a_DT clustering_NN algorithm_NN run_NN on_IN unlabeled_JJ data_NNS aid_VBP a_DT classification_NN algorithm_NN ?_.
The_DT accuracy_NN is_VBZ quantified_VBN using_VBG the_DT PAC-MDL_NN bound_VBD =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: in_IN a_DT semisupervised_JJ setting_NN ._.
Clustering_NN algorithms_NNS which_WDT naturally_RB separate_VBP the_DT data_NNS according_VBG to_TO -LRB-_-LRB- hidden_JJ -RRB-_-RRB- labels_NNS with_IN a_DT small_JJ number_NN of_IN clusters_NNS perform_VBP well_RB ._.
A_DT simple_JJ extension_NN of_IN the_DT argument_NN lead_NN
orithms_NNS that_WDT have_VBP been_VBN used_VBN ._.
However_RB ,_, we_PRP have_VBP chosen_VBN algorithms_NNS that_WDT represent_VBP the_DT state-ofthe-art_JJ and_CC have_VBP been_VBN applied_VBN to_TO text_NN clustering_NN in_IN the_DT literature_NN ._.
The_DT algorithms_NNS we_PRP consider_VBP are_VBP :_: SPKMeans_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: ,_, better_RB known_VBN as_IN spherical_JJ kmeans_NNS ,_, that_WDT employs_VBZ the_DT widely_RB used_VBN cosine_NN similarity_NN ;_: FSKMeans_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, a_DT frequency_NN sensitive_JJ version_NN of_IN spherical_JJ kmeans_NNS ;_: Hard-moVMF_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ,_, a_DT generative_JJ model_NN based_JJ clustering_NN
