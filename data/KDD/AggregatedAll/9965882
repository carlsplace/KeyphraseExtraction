Issues_NNS in_IN evaluation_NN of_IN stream_NN learning_NN algorithms_NNS
Learning_VBG from_IN data_NNS streams_NNS is_VBZ a_DT research_NN area_NN of_IN increasing_VBG importance_NN ._.
Nowadays_RB ,_, several_JJ stream_NN learning_NN algorithms_NNS have_VBP been_VBN developed_VBN ._.
Most_JJS of_IN them_PRP learn_VBP decision_NN models_NNS that_WDT continuously_RB evolve_VBP over_IN time_NN ,_, run_VBN in_IN resource-aware_JJ environments_NNS ,_, detect_VB and_CC react_VB to_TO changes_NNS in_IN the_DT environment_NN generating_NN data_NNS ._.
One_CD important_JJ issue_NN ,_, not_RB yet_RB conveniently_RB addressed_VBN ,_, is_VBZ the_DT design_NN of_IN experimental_JJ work_NN to_TO evaluate_VB and_CC compare_VB decision_NN models_NNS that_WDT evolve_VBP over_IN time_NN ._.
There_EX are_VBP no_DT golden_JJ standards_NNS for_IN assessing_VBG performance_NN in_IN non-stationary_JJ environments_NNS ._.
This_DT paper_NN proposes_VBZ a_DT general_JJ framework_NN for_IN assessing_VBG predictive_JJ stream_NN learning_NN algorithms_NNS ._.
We_PRP defend_VBP the_DT use_NN of_IN Predictive_JJ Sequential_JJ methods_NNS for_IN error_NN estimate_NN -_: the_DT prequential_JJ error_NN ._.
The_DT prequential_JJ error_NN allows_VBZ us_PRP to_TO monitor_VB the_DT evolution_NN of_IN the_DT performance_NN of_IN models_NNS that_WDT evolve_VBP over_IN time_NN ._.
Nevertheless_RB ,_, it_PRP is_VBZ known_VBN to_TO be_VB a_DT pessimistic_JJ estimator_NN in_IN comparison_NN to_TO holdout_NN estimates_NNS ._.
To_TO obtain_VB more_RBR reliable_JJ estimators_NNS we_PRP need_VBP some_DT forgetting_VBG mechanism_NN ._.
Two_CD viable_JJ alternatives_NNS are_VBP :_: sliding_VBG windows_NNS and_CC fading_JJ factors_NNS ._.
We_PRP observe_VBP that_IN the_DT prequential_JJ error_NN converges_VBZ to_TO an_DT holdout_NN estimator_NN when_WRB estimated_VBN over_IN a_DT sliding_VBG window_NN or_CC using_VBG fading_JJ factors_NNS ._.
We_PRP present_VBP illustrative_JJ examples_NNS of_IN the_DT use_NN of_IN prequential_JJ error_NN estimators_NNS ,_, using_VBG fading_JJ factors_NNS ,_, for_IN the_DT tasks_NNS of_IN :_: i_LS -RRB-_-RRB- assessing_VBG performance_NN of_IN a_DT learning_NN algorithm_NN ;_: ii_LS -RRB-_-RRB- comparing_VBG learning_NN algorithms_NNS ;_: iii_LS -RRB-_-RRB- hypothesis_NN testing_NN using_VBG McNemar_NNP test_NN ;_: and_CC iv_LS -RRB-_-RRB- change_NN detection_NN using_VBG Page-Hinkley_NNP test_NN ._.
In_IN these_DT tasks_NNS ,_, the_DT prequential_JJ error_NN estimated_VBN using_VBG fading_JJ factors_NNS provide_VBP reliable_JJ estimators_NNS ._.
In_IN comparison_NN to_TO sliding_VBG windows_NNS ,_, fading_JJ factors_NNS are_VBP faster_JJR and_CC memory-less_JJ ,_, a_DT requirement_NN for_IN streaming_NN applications_NNS ._.
This_DT paper_NN is_VBZ a_DT contribution_NN to_TO a_DT discussion_NN in_IN the_DT good-practices_NNS on_IN performance_NN assessment_NN when_WRB learning_VBG dynamic_JJ models_NNS that_WDT evolve_VBP over_IN time_NN ._.
ment_NN classifier_NN ._.
4_CD Streaming_NNP Data_NNP Evaluation_NN with_IN Unbalanced_JJ Classes_NNS In_IN data_NN stream_NN mining_NN ,_, the_DT most_RBS frequently_RB used_VBN measure_NN for_IN evaluating_VBG predictive_JJ accuracy_NN of_IN a_DT classifier_NN is_VBZ prequential_JJ accuracy_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP argue_VBP that_IN this_DT measure_NN is_VBZ only_RB appropriate_JJ when_WRB all_DT classes_NNS are_VBP balanced_JJ ,_, and_CC have_VBP -LRB-_-LRB- approximately_RB -RRB-_-RRB- the_DT same_JJ number_NN of_IN examples_NNS ._.
In_IN this_DT section_NN ,_, we_PRP propose_VBP the_DT Kappa_NNP statistic_NN as_IN a_DT more_JJR sensitiv_NN
ing_NN of_IN the_DT learning_NN and_CC the_DT evaluation_NN ._.
The_DT most_RBS efficient_JJ way_NN to_TO get_VB a_DT precise_JJ measure_NN of_IN the_DT recent_JJ accuracy_NN of_IN the_DT sub-trees_NNS is_VBZ by_IN using_VBG fading_JJ factors_NNS in_IN the_DT computation_NN of_IN the_DT sum_NN as_IN proposed_VBN in_IN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB it_PRP has_VBZ been_VBN shown_VBN that_IN the_DT fading_JJ factor_NN mimics_VBZ the_DT sliding_VBG window_NN computation_NN of_IN any_DT statistic_NN ._.
The_DT procedure_NN is_VBZ the_DT following_NN :_: when_WRB the_DT maximum_NN number_NN of_IN options_NNS k_NN is_VBZ reached_VBN ,_, every_DT time_NN a_DT n_NN
valuation_NN methodology_NN used_VBN was_VBD Interleaved_NNP Test-Then-Train_NNP or_CC Prequential_JJ evaluation_NN -LRB-_-LRB- based_VBN on_IN 10_CD runs_NNS for_IN the_DT artificial_JJ data_NNS -RRB-_-RRB- :_: every_DT example_NN was_VBD used_VBN for_IN testing_VBG the_DT model_NN before_IN using_VBG it_PRP to_TO train_VB -LRB-_-LRB- =_JJ -_: =_JJ Gama_NNP et_FW al._FW ,_, 2009_CD -_: =--RRB-_NN ._.
This_DT interleaved_JJ test_NN followed_VBN by_IN train_NN procedure_NN was_VBD carried_VBN out_RP on_IN the_DT full_JJ training_NN set_VBN in_IN each_DT case_NN ._.
The_DT parameters_NNS of_IN the_DT artificial_JJ streams_NNS are_VBP as_IN follows_VBZ :_: •_CD RBF_NN -LRB-_-LRB- x_NN ,_, v_LS -RRB-_-RRB- :_: RandomRBF_NN data_NNS stream_NN o_NN
or_CC testing_NN ,_, making_VBG maximum_JJ use_NN of_IN the_DT available_JJ data_NNS ._.
It_PRP also_RB ensures_VBZ a_DT smooth_JJ plot_NN of_IN accuracy_NN over_IN time_NN ,_, as_IN each_DT individual_JJ example_NN will_MD become_VB increasingly_RB less_RBR significant_JJ to_TO the_DT overall_JJ average_NN -LRB-_-LRB- =_JJ -_: =_JJ Gama_NNP et_FW al._FW ,_, 2009_CD -_: =--RRB-_NN ._.
1602MOA_NN :_: MASSIVE_NNP ONLINE_NNP ANALYSIS_NNP Figure_NNP 2_CD :_: MOA_NNP Graphical_NNP User_NN Interface_NNP As_IN data_NNS stream_NN classification_NN is_VBZ a_DT relatively_RB new_JJ field_NN ,_, such_JJ evaluation_NN practices_NNS are_VBP not_RB nearly_RB as_RB well_RB researched_VBD and_CC est_VBD
ues_NNS per_IN class_NN ,_, P_NN -LRB-_-LRB- xi_FW |_FW c_NN -RRB-_-RRB- ._.
Tohaverobust_JJ estimators_NNS of_IN these_DT probabilities_NNS ,_, we_PRP require_VBP a_DT minimum_JJ number_NN of_IN training_NN examples_NNS covered_VBN by_IN the_DT rule_NN 3_CD ._.
Figure_NN 1_CD plots_NNS the_DT evolution_NN of_IN the_DT prequential_JJ error_NN -LRB-_-LRB- =_JJ -_: =_JJ Gama_NNP et_FW al._FW ,_, 2009_CD -_: =--RRB-_NN for_IN the_DT LED_NNP and_CC Waveform_NNP datasets_NNS ._.
The_DT VFDRNB_NNP exhibit_VBP much_RB more_RBR powerful_JJ predicting_VBG capabilities_NNS than_IN VFDR_NNP ,_, especially_RB in_IN case_NN of_IN noisy_JJ data_NNS ,_, as_IN in_FW LED_FW dataset_NN ._.
Another_DT observation_NN is_VBZ that_IN VFDRNB_FW ex_FW
n_NN be_VB stored_VBN permanently_RB -_: they_PRP are_VBP observed_VBN and_CC then_RB forgotten_VBN ._.
Many_JJ incremental_JJ learners_NNS and_CC stream_NN mining_NN algorithms_NNS have_VBP been_VBN proposed_VBN in_IN the_DT last_JJ years_NNS ,_, accompanied_VBN by_IN methods_NNS for_IN evaluating_VBG them_PRP =_JJ -_: =[_NN 3_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, modern_JJ applications_NNS ask_VB for_IN more_RBR sophisticated_JJ stream_NN learners_NNS than_IN can_MD currently_RB be_VB evaluated_VBN on_IN synthetically_RB generated_VBN data_NNS ._.
In_IN this_DT work_NN ,_, we_PRP propose_VBP a_DT generator_NN for_IN complex_JJ stream_NN data_NNS
obability_NN of_IN error_NN ,_, M_NN ±_FW ε_FW ,_, using_VBG Chernoff_NNP bound_VBD -LRB-_-LRB- 5_CD -RRB-_-RRB- :_: √_NN 3_CD ×_FW ¯_FW µ_FW εc_FW =_JJ n_NN ln_NN -LRB-_-LRB- 2_CD \/_: δ_NN -RRB-_-RRB- ,_, where_WRB δ_NN is_VBZ a_DT user_NN defined_VBN confidence_NN level_NN ._.
In_IN the_DT case_NN of_IN bounded_JJ loss_NN functions_NNS ,_, like_IN the_DT 0-1_CD loss_NN ,_, the_DT Hoeffding_NNP bound_VBD =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: can_MD be_VB used_VBN :_: √_CD R_NN εh_NN =_JJ 2n_FW ln_FW -LRB-_-LRB- -RRB-_-RRB- 2_CD ,_, δ_NN where_WRB R_NN is_VBZ the_DT range_NN of_IN the_DT random_JJ variable_NN ._.
Both_DT bounds_NNS use_VBP the_DT sum_NN of_IN independent_JJ random_JJ variables_NNS and_CC give_VB a_DT relative_JJ or_CC absolute_JJ approximation_NN of_IN the_DT deviati_NNS
e_LS over_IN time_NN ,_, taking_VBG into_IN account_NN that_IN the_DT environment_NN is_VBZ non-stationary_JJ and_CC computational_JJ resources_NNS are_VBP limited_JJ ._.
Examples_NNS of_IN public_JJ available_JJ software_NN for_IN learning_VBG from_IN data_NNS streams_NNS include_VBP :_: the_DT VFML_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: toolkit_NN for_IN mining_NN high-speed_JJ time-changing_JJ data_NNS streams_NNS ,_, the_DT MOA_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- system_NN for_IN learning_VBG from_IN massive_JJ data_NNS sets_NNS ,_, Rapid-Miner_NN -LRB-_-LRB- 24_CD -RRB-_-RRB- a_DT data_NN mining_NN system_NN with_IN plug-in_JJ for_IN stream_NN processing_NN ,_, etc._NN ._.
For_IN i_LS
ude_NN :_: i_LS -RRB-_-RRB- probability_NN of_IN false_JJ alarms_NNS ;_: ii_LS -RRB-_-RRB- probability_NN of_IN true_JJ alarms_NNS ;_: ii_LS -RRB-_-RRB- delay_NN in_IN detection_NN ._.
3.4.1_CD The_DT Page-Hinkley_NNP Algorithm_NNP ._.
Several_JJ tests_NNS for_IN change_NN detection_NN have_VBP been_VBN presented_VBN in_IN the_DT literature_NN =_JJ -_: =[_NN 2_CD ,_, 28_CD ,_, 22_CD ,_, 23_CD ,_, 13_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT most_RBS referred_VBN is_VBZ the_DT Page-Hinkley_JJ test_NN -LRB-_-LRB- PHT_NN -RRB-_-RRB- ,_, a_DT sequential_JJ analysis_NN technique_NN typically_RB used_VBN for_IN monitoring_VBG change_NN detection_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- in_IN signal_NN processing_NN ._.
It_PRP allows_VBZ efficient_JJ detection_NN of_IN ch_NN
ion_NN and_CC Si_NNP for_IN points_NNS where_WRB yi_NN is_VBZ known_VBN ._.
The_DT mean_JJ loss_NN is_VBZ given_VBN by_IN :_: M_NN =_JJ 1_CD ×_FW S._FW For_IN any_DT loss_NN n_NN function_NN ,_, we_PRP can_MD estimate_VB a_DT confidence_NN interval_NN for_IN the_DT probability_NN of_IN error_NN ,_, M_NN ±_FW ε_FW ,_, using_VBG Chernoff_NNP bound_VBD =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: :_: √_NN 3_CD ×_FW ¯_FW µ_FW εc_FW =_JJ n_NN ln_NN -LRB-_-LRB- 2_CD \/_: δ_NN -RRB-_-RRB- ,_, where_WRB δ_NN is_VBZ a_DT user_NN defined_VBN confidence_NN level_NN ._.
In_IN the_DT case_NN of_IN bounded_JJ loss_NN functions_NNS ,_, like_IN the_DT 0-1_CD loss_NN ,_, the_DT Hoeffding_NNP bound_VBD -LRB-_-LRB- 17_CD -RRB-_-RRB- can_MD be_VB used_VBN :_: √_CD R_NN εh_NN =_JJ 2n_FW ln_FW -LRB-_-LRB- -RRB-_-RRB- 2_CD ,_, δ_NN where_WRB R_NN
are_VBP faced_VBN with_IN this_DT scenario_NN include_VBP sensor_NN networks_NNS ,_, social_JJ networks_NNS ,_, user_NN modeling_NN ,_, radio_NN frequency_NN identification_NN ,_, web_NN mining_NN ,_, scientific_JJ data_NNS ,_, financial_JJ data_NNS ,_, etc._FW ._.
Most_RBS recent_JJ learning_NN algorithms_NNS =_JJ -_: =[_NN 6_CD ,_, 1_CD ,_, 10_CD ,_, 20_CD ,_, 15_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: maintain_VB a_DT decision_NN model_NN that_WDT continuously_RB evolve_VBP over_IN time_NN ,_, taking_VBG into_IN account_NN that_IN the_DT environment_NN is_VBZ non-stationary_JJ and_CC computational_JJ resources_NNS are_VBP limited_JJ ._.
Examples_NNS of_IN public_JJ available_JJ software_NN
are_VBP faced_VBN with_IN this_DT scenario_NN include_VBP sensor_NN networks_NNS ,_, social_JJ networks_NNS ,_, user_NN modeling_NN ,_, radio_NN frequency_NN identification_NN ,_, web_NN mining_NN ,_, scientific_JJ data_NNS ,_, financial_JJ data_NNS ,_, etc._FW ._.
Most_RBS recent_JJ learning_NN algorithms_NNS =_JJ -_: =[_NN 6_CD ,_, 1_CD ,_, 10_CD ,_, 20_CD ,_, 15_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: maintain_VB a_DT decision_NN model_NN that_WDT continuously_RB evolve_VBP over_IN time_NN ,_, taking_VBG into_IN account_NN that_IN the_DT environment_NN is_VBZ non-stationary_JJ and_CC computational_JJ resources_NNS are_VBP limited_JJ ._.
Examples_NNS of_IN public_JJ available_JJ software_NN
available_JJ software_NN for_IN learning_VBG from_IN data_NNS streams_NNS include_VBP :_: the_DT VFML_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- toolkit_NN for_IN mining_NN high-speed_JJ time-changing_JJ data_NNS streams_NNS ,_, the_DT MOA_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- system_NN for_IN learning_VBG from_IN massive_JJ data_NNS sets_NNS ,_, Rapid-Miner_NN =_JJ -_: =[_NN 24_CD -RRB-_-RRB- -_: =_SYM -_: a_DT data_NN mining_NN system_NN with_IN plug-in_JJ for_IN stream_NN processing_NN ,_, etc._NN ._.
For_IN illustrative_JJ purposes_NNS ,_, consider_VB a_DT sensor_NN network_NN ._.
Sensors_NNS are_VBP geographically_RB distributed_VBN and_CC produce_VBP high-speed_JJ distributed_VBN data_NNS stre_VBP
ude_NN :_: i_LS -RRB-_-RRB- probability_NN of_IN false_JJ alarms_NNS ;_: ii_LS -RRB-_-RRB- probability_NN of_IN true_JJ alarms_NNS ;_: ii_LS -RRB-_-RRB- delay_NN in_IN detection_NN ._.
3.4.1_CD The_DT Page-Hinkley_NNP Algorithm_NNP ._.
Several_JJ tests_NNS for_IN change_NN detection_NN have_VBP been_VBN presented_VBN in_IN the_DT literature_NN =_JJ -_: =[_NN 2_CD ,_, 28_CD ,_, 22_CD ,_, 23_CD ,_, 13_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT most_RBS referred_VBN is_VBZ the_DT Page-Hinkley_JJ test_NN -LRB-_-LRB- PHT_NN -RRB-_-RRB- ,_, a_DT sequential_JJ analysis_NN technique_NN typically_RB used_VBN for_IN monitoring_VBG change_NN detection_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- in_IN signal_NN processing_NN ._.
It_PRP allows_VBZ efficient_JJ detection_NN of_IN ch_NN
tion_NN have_VBP been_VBN presented_VBN in_IN the_DT literature_NN -LRB-_-LRB- 2_CD ,_, 28_CD ,_, 22_CD ,_, 23_CD ,_, 13_CD -RRB-_-RRB- ._.
One_CD of_IN the_DT most_RBS referred_VBN is_VBZ the_DT Page-Hinkley_JJ test_NN -LRB-_-LRB- PHT_NN -RRB-_-RRB- ,_, a_DT sequential_JJ analysis_NN technique_NN typically_RB used_VBN for_IN monitoring_VBG change_NN detection_NN =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_SYM -_: in_IN signal_NN processing_NN ._.
It_PRP allows_VBZ efficient_JJ detection_NN of_IN changes_NNS in_IN the_DT normal_JJ behavior_NN of_IN a_DT process_NN which_WDT is_VBZ established_VBN by_IN a_DT model_NN ._.
The_DT PHT_NNP is_VBZ designed_VBN to_TO detect_VB a_DT change_NN in_IN the_DT average_NN of_IN a_DT Gaussian_NN
ature_NN shows_VBZ the_DT diversity_NN of_IN evaluation_NN methods_NNS ._.
Table_NNP 1_CD resumes_VBZ the_DT evaluation_NN methods_NNS found_VBN in_IN a_DT diverse_JJ set_NN of_IN well-known_JJ stream_NN learning_NN algorithms_NNS ._.
The_DT algorithms_NNS under_IN analysis_NN are_VBP described_VBN in_IN =_JJ -_: =[_NN 10_CD ,_, 20_CD ,_, 15_CD ,_, 14_CD ,_, 11_CD ,_, 21_CD ,_, 4_CD -RRB-_-RRB- -_: =_JJ -_: and_CC are_VBP presented_VBN in_IN that_DT order_NN .3_NN ._.
EVALUATION_NN ISSUES_NNS A_DT key_JJ point_NN in_IN any_DT intelligent_JJ system_NN is_VBZ the_DT evaluation_NN methodology_NN ._.
Learning_NNP systems_NNS generate_VBP compact_JJ representations_NNS of_IN what_WP is_VBZ being_VBG observed_VBN ._.
ategy_NN ._.
Section_NN 4_CD presents_VBZ the_DT main_JJ contributions_NNS of_IN the_DT paper_NN ,_, while_IN the_DT last_JJ section_NN concludes_VBZ the_DT exposition_NN ,_, presenting_VBG the_DT lessons_NNS learned_VBD ._.
2_CD ._.
LEARNING_NNP FROM_NNP DATA_NNP STREAMS_NNP G._NNP Hulten_NNP and_CC P._NNP Domingos_NNP =_SYM -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: identify_VB desirable_JJ properties_NNS of_IN learning_VBG systems_NNS for_IN efficient_JJ mining_NN continuous_JJ ,_, high-volume_JJ ,_, open-ended_JJ data_NNS streams_NNS :_: •_CD require_VBP small_JJ constant_JJ time_NN per_IN data_NN example_NN ;_: •_CD use_NN fix_NN amount_NN of_IN main_JJ memor_NN
set_VBN ._.
Apply_RB the_DT current_JJ decision_NN model_NN to_TO the_DT test_NN set_NN ,_, at_IN regular_JJ time_NN intervals_NNS -LRB-_-LRB- or_CC set_NN of_IN examples_NNS -RRB-_-RRB- ._.
The_DT loss_NN estimated_VBN in_IN the_DT holdout_NN is_VBZ an_DT unbiased_JJ estimator_NN ._.
•_NNP Predictive_NNP Sequential_NNP :_: Prequential_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB the_DT error_NN of_IN a_DT model_NN is_VBZ computed_VBN from_IN the_DT sequence_NN of_IN examples_NNS ._.
For_IN each_DT example_NN in_IN the_DT stream_NN ,_, the_DT actual_JJ model_NN makes_VBZ a_DT prediction_NN based_VBN only_RB on_IN the_DT example_NN attribute-values_NNS ._.
The_DT prequential_JJ -_:
ul_IN evaluation_NN metrics_NNS 1_CD We_PRP do_VBP not_RB argue_VB that_IN this_DT is_VBZ the_DT most_RBS appropriate_JJ test_NN for_IN comparing_VBG classifiers_NNS ._.
An_DT in_IN depth_NN analysis_NN on_IN statistical_JJ tests_NNS to_TO compare_VB classifiers_NNS in_IN batch_NN scenario_NN appears_VBZ in_IN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
include_VBP :_: i_LS -RRB-_-RRB- probability_NN of_IN false_JJ alarms_NNS ;_: ii_LS -RRB-_-RRB- probability_NN of_IN true_JJ alarms_NNS ;_: ii_LS -RRB-_-RRB- delay_NN in_IN detection_NN ._.
3.4.1_CD The_DT Page-Hinkley_NNP Algorithm_NNP ._.
Several_JJ tests_NNS for_IN change_NN detection_NN have_VBP been_VBN presented_VBN in_IN the_DT liter_NN
are_VBP faced_VBN with_IN this_DT scenario_NN include_VBP sensor_NN networks_NNS ,_, social_JJ networks_NNS ,_, user_NN modeling_NN ,_, radio_NN frequency_NN identification_NN ,_, web_NN mining_NN ,_, scientific_JJ data_NNS ,_, financial_JJ data_NNS ,_, etc._FW ._.
Most_RBS recent_JJ learning_NN algorithms_NNS =_JJ -_: =[_NN 6_CD ,_, 1_CD ,_, 10_CD ,_, 20_CD ,_, 15_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: maintain_VB a_DT decision_NN model_NN that_WDT continuously_RB evolve_VBP over_IN time_NN ,_, taking_VBG into_IN account_NN that_IN the_DT environment_NN is_VBZ non-stationary_JJ and_CC computational_JJ resources_NNS are_VBP limited_JJ ._.
Examples_NNS of_IN public_JJ available_JJ software_NN
ature_NN shows_VBZ the_DT diversity_NN of_IN evaluation_NN methods_NNS ._.
Table_NNP 1_CD resumes_VBZ the_DT evaluation_NN methods_NNS found_VBN in_IN a_DT diverse_JJ set_NN of_IN well-known_JJ stream_NN learning_NN algorithms_NNS ._.
The_DT algorithms_NNS under_IN analysis_NN are_VBP described_VBN in_IN =_JJ -_: =[_NN 10_CD ,_, 20_CD ,_, 15_CD ,_, 14_CD ,_, 11_CD ,_, 21_CD ,_, 4_CD -RRB-_-RRB- -_: =_JJ -_: and_CC are_VBP presented_VBN in_IN that_DT order_NN .3_NN ._.
EVALUATION_NN ISSUES_NNS A_DT key_JJ point_NN in_IN any_DT intelligent_JJ system_NN is_VBZ the_DT evaluation_NN methodology_NN ._.
Learning_NNP systems_NNS generate_VBP compact_JJ representations_NNS of_IN what_WP is_VBZ being_VBG observed_VBN ._.
le_DT of_IN iid_JJ examples_NNS ;_: •_CD decision_NN models_NNS evolve_VBP over_IN time_NN instead_RB of_IN being_VBG static_JJ ;_: •_CD data_NNS is_VBZ generated_VBN by_IN non-stationary_JJ distributions_NNS instead_RB of_IN a_DT stationary_JJ sample_NN ._.
In_IN a_DT referenced_VBN paper_NN ,_, T._NNP Diettrich_NNP =_SYM -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: proposes_VBZ a_DT straightforward_JJ technique_NN to_TO evaluate_VB learning_NN algorithms_NNS when_WRB data_NNS is_VBZ abundant_JJ :_: ``_`` learn_VB a_DT classifier_NN from_IN a_DT large_JJ enough_JJ training_NN set_NN and_CC apply_VB the_DT classifier_NN to_TO a_DT large_JJ enough_JJ test_NN set_NN ._. ''_''
are_VBP faced_VBN with_IN this_DT scenario_NN include_VBP sensor_NN networks_NNS ,_, social_JJ networks_NNS ,_, user_NN modeling_NN ,_, radio_NN frequency_NN identification_NN ,_, web_NN mining_NN ,_, scientific_JJ data_NNS ,_, financial_JJ data_NNS ,_, etc._FW ._.
Most_RBS recent_JJ learning_NN algorithms_NNS =_JJ -_: =[_NN 6_CD ,_, 1_CD ,_, 10_CD ,_, 20_CD ,_, 15_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: maintain_VB a_DT decision_NN model_NN that_WDT continuously_RB evolve_VBP over_IN time_NN ,_, taking_VBG into_IN account_NN that_IN the_DT environment_NN is_VBZ non-stationary_JJ and_CC computational_JJ resources_NNS are_VBP limited_JJ ._.
Examples_NNS of_IN public_JJ available_JJ software_NN
ature_NN shows_VBZ the_DT diversity_NN of_IN evaluation_NN methods_NNS ._.
Table_NNP 1_CD resumes_VBZ the_DT evaluation_NN methods_NNS found_VBN in_IN a_DT diverse_JJ set_NN of_IN well-known_JJ stream_NN learning_NN algorithms_NNS ._.
The_DT algorithms_NNS under_IN analysis_NN are_VBP described_VBN in_IN =_JJ -_: =[_NN 10_CD ,_, 20_CD ,_, 15_CD ,_, 14_CD ,_, 11_CD ,_, 21_CD ,_, 4_CD -RRB-_-RRB- -_: =_JJ -_: and_CC are_VBP presented_VBN in_IN that_DT order_NN .3_NN ._.
EVALUATION_NN ISSUES_NNS A_DT key_JJ point_NN in_IN any_DT intelligent_JJ system_NN is_VBZ the_DT evaluation_NN methodology_NN ._.
Learning_NNP systems_NNS generate_VBP compact_JJ representations_NNS of_IN what_WP is_VBZ being_VBG observed_VBN ._.
are_VBP faced_VBN with_IN this_DT scenario_NN include_VBP sensor_NN networks_NNS ,_, social_JJ networks_NNS ,_, user_NN modeling_NN ,_, radio_NN frequency_NN identification_NN ,_, web_NN mining_NN ,_, scientific_JJ data_NNS ,_, financial_JJ data_NNS ,_, etc._FW ._.
Most_RBS recent_JJ learning_NN algorithms_NNS =_JJ -_: =[_NN 6_CD ,_, 1_CD ,_, 10_CD ,_, 20_CD ,_, 15_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: maintain_VB a_DT decision_NN model_NN that_WDT continuously_RB evolve_VBP over_IN time_NN ,_, taking_VBG into_IN account_NN that_IN the_DT environment_NN is_VBZ non-stationary_JJ and_CC computational_JJ resources_NNS are_VBP limited_JJ ._.
Examples_NNS of_IN public_JJ available_JJ software_NN
ith_VB the_DT known_JJ problems_NNS of_IN deciding_VBG the_DT window-size_NN ,_, and_CC fading-factors_NNS ._.
Both_DT methods_NNS have_VBP been_VBN used_VBN for_IN blind_JJ adaptation_NN ,_, e.g._FW without_IN explicit_JJ change_NN detection_NN ,_, of_IN decision_NN models_NNS in_IN drift_NN scenarios_NNS =_JJ -_: =[_NN 22_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT formula_NN for_IN using_VBG fading_JJ factors_NNS with_IN the_DT Qi_NN statistic_NN is_VBZ :_: Q_NNP α_FW i_FW -LRB-_-LRB- A_NN ,_, B_NN -RRB-_-RRB- =_JJ log_NN -LRB-_-LRB- Li_NNP -LRB-_-LRB- A_NNP -RRB-_-RRB- +_CC α_FW ×_FW SA_NNP i_FW −_FW 1_CD Li_NNP -LRB-_-LRB- B_NN -RRB-_-RRB- +_CC α_FW ×_FW SB_NN -RRB-_-RRB- ._.
i_FW −_FW 1_CD It_PRP is_VBZ interesting_JJ to_TO observe_VB that_IN these_DT two_CD alternatives_NNS exhibit_VBP similar_JJ p_NN
ith_VB the_DT known_JJ problems_NNS of_IN deciding_VBG the_DT window-size_NN ,_, and_CC fading-factors_NNS ._.
Both_DT methods_NNS have_VBP been_VBN used_VBN for_IN blind_JJ adaptation_NN ,_, e.g._FW without_IN explicit_JJ change_NN detection_NN ,_, of_IN decision_NN models_NNS in_IN drift_NN scenarios_NNS =_JJ -_: =[_NN 22_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT formula_NN for_IN using_VBG fading_JJ factors_NNS with_IN the_DT Qi_NN statistic_NN is_VBZ :_: Q_NNP α_FW i_FW -LRB-_-LRB- A_NN ,_, B_NN -RRB-_-RRB- =_JJ log_NN -LRB-_-LRB- Li_NNP -LRB-_-LRB- A_NNP -RRB-_-RRB- +_CC α_FW ×_FW SA_NNP i_FW −_FW 1_CD Li_NNP -LRB-_-LRB- B_NN -RRB-_-RRB- +_CC α_FW ×_FW SB_NN -RRB-_-RRB- ._.
i_FW −_FW 1_CD It_PRP is_VBZ interesting_JJ to_TO observe_VB that_IN these_DT two_CD alternatives_NNS exhibit_VBP similar_JJ p_NN
ude_NN :_: i_LS -RRB-_-RRB- probability_NN of_IN false_JJ alarms_NNS ;_: ii_LS -RRB-_-RRB- probability_NN of_IN true_JJ alarms_NNS ;_: ii_LS -RRB-_-RRB- delay_NN in_IN detection_NN ._.
3.4.1_CD The_DT Page-Hinkley_NNP Algorithm_NNP ._.
Several_JJ tests_NNS for_IN change_NN detection_NN have_VBP been_VBN presented_VBN in_IN the_DT literature_NN =_JJ -_: =[_NN 2_CD ,_, 28_CD ,_, 22_CD ,_, 23_CD ,_, 13_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT most_RBS referred_VBN is_VBZ the_DT Page-Hinkley_JJ test_NN -LRB-_-LRB- PHT_NN -RRB-_-RRB- ,_, a_DT sequential_JJ analysis_NN technique_NN typically_RB used_VBN for_IN monitoring_VBG change_NN detection_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- in_IN signal_NN processing_NN ._.
It_PRP allows_VBZ efficient_JJ detection_NN of_IN ch_NN
are_VBP faced_VBN with_IN this_DT scenario_NN include_VBP sensor_NN networks_NNS ,_, social_JJ networks_NNS ,_, user_NN modeling_NN ,_, radio_NN frequency_NN identification_NN ,_, web_NN mining_NN ,_, scientific_JJ data_NNS ,_, financial_JJ data_NNS ,_, etc._FW ._.
Most_RBS recent_JJ learning_NN algorithms_NNS =_JJ -_: =[_NN 6_CD ,_, 1_CD ,_, 10_CD ,_, 20_CD ,_, 15_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: maintain_VB a_DT decision_NN model_NN that_WDT continuously_RB evolve_VBP over_IN time_NN ,_, taking_VBG into_IN account_NN that_IN the_DT environment_NN is_VBZ non-stationary_JJ and_CC computational_JJ resources_NNS are_VBP limited_JJ ._.
Examples_NNS of_IN public_JJ available_JJ software_NN
th_DT 1_CD degree_NN of_IN freedom_NN ._.
For_IN a_DT confidence_NN level_NN of_IN 0.99_CD ,_, the_DT null_JJ hypothesis_NN is_VBZ rejected_VBN if_IN the_DT statistic_NN is_VBZ greater_JJR than_IN 6.635_CD -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
3.3.1.1_CD Illustrative_JJ Example_NN ._.
We_PRP have_VBP used_VBN the_DT dataset_JJ SEA_NN concepts_NNS =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT benchmark_JJ problem_NN for_IN concept_NN drift_NN ._.
Figure_NN 6_CD -LRB-_-LRB- top_JJ panel_NN -RRB-_-RRB- shows_VBZ the_DT evolution_NN of_IN the_DT error_NN rate_NN of_IN two_CD naive-Bayes_JJ variants_NNS :_: a_DT standard_JJ one_CD and_CC a_DT variant_NN that_WDT detects_VBZ and_CC relearn_VB a_DT new_JJ decision_NN mo_NN
and_CC computational_JJ resources_NNS are_VBP limited_JJ ._.
Examples_NNS of_IN public_JJ available_JJ software_NN for_IN learning_VBG from_IN data_NNS streams_NNS include_VBP :_: the_DT VFML_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- toolkit_NN for_IN mining_NN high-speed_JJ time-changing_JJ data_NNS streams_NNS ,_, the_DT MOA_NN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_JJ -_: system_NN for_IN learning_VBG from_IN massive_JJ data_NNS sets_NNS ,_, Rapid-Miner_NN -LRB-_-LRB- 24_CD -RRB-_-RRB- a_DT data_NN mining_NN system_NN with_IN plug-in_JJ for_IN stream_NN processing_NN ,_, etc._NN ._.
For_IN illustrative_JJ purposes_NNS ,_, consider_VB a_DT sensor_NN network_NN ._.
Sensors_NNS are_VBP geographic_JJ
al_FW processing_NN ._.
It_PRP allows_VBZ efficient_JJ detection_NN of_IN changes_NNS in_IN the_DT normal_JJ behavior_NN of_IN a_DT process_NN which_WDT is_VBZ established_VBN by_IN a_DT model_NN ._.
The_DT PHT_NNP is_VBZ designed_VBN to_TO detect_VB a_DT change_NN in_IN the_DT average_NN of_IN a_DT Gaussian_JJ signal_NN =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT test_NN considers_VBZ a_DT cumulative_JJ variable_JJ mT_NN ,_, defined_VBN as_IN the_DT cumulated_JJ difference_NN between_IN the_DT observed_VBN values_NNS and_CC their_PRP$ mean_NN till_IN the_DT current_JJ moment_NN :_: T_NN ∑_CD mT_NN =_JJ -LRB-_-LRB- xt_FW −_FW ¯_FW xT_FW −_FW δ_FW -RRB-_-RRB- t_NN =_JJ 1_CD where_WRB xT_NN ¯_NN =_JJ 1\/T_FW ∑_FW t_NN
