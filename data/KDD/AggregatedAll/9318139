A_DT study_NN of_IN support_NN vectors_NNS on_IN model_NN independent_JJ example_NN selection_NN
ractable_JJ ._.
This_DT issue_NN is_VBZ becoming_VBG more_RBR evident_JJ today_NN ,_, because_IN there_EX are_VBP complex_JJ classification_NN problems_NNS waiting_VBG to_TO be_VB solved_VBN in_IN many_JJ domains_NNS ,_, where_WRB large_JJ amounts_NNS of_IN training_NN data_NNS are_VBP already_RB available_JJ =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Researchers_NNS in_IN the_DT machine_NN learning_NN and_CC data_NN mining_NN community_NN -LRB-_-LRB- 6_CD ,_, 5_CD ,_, 11_CD -RRB-_-RRB- have_VBP therefore_RB been_VBN trying_VBG to_TO scale_VB up_RP classical_JJ inductive_JJ learning_NN algorithms_NNS to_TO handle_VB extremely_RB large_JJ data_NNS sets_NNS ._.
One_CD popul_NN
an_DT omit_VB important_JJ information_NN captured_VBN in_IN the_DT original_JJ large_JJ data_NNS set_NN ,_, and_CC hence_RB lead_VB to_TO significantly_RB poorer_JJR prediction_NN results_NNS ._.
Various_JJ data_NNS sampling_NN methods_NNS have_VBP been_VBN studied_VBN -LRB-_-LRB- 3_LS -RRB-_-RRB- such_JJ as_IN windowing_NN =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, random_JJ sampling_NN ,_, stratified_JJ sampling_NN ,_, peepholing_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, and_CC information-theoretic_JJ peepholing_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
Catlett_NNP 's_POS study_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- showed_VBD that_IN certain_JJ sampling_NN strategies_NNS helped_VBD in_IN speed-ups_NNS ,_, and_CC improving_VBG the_DT ac_NN
nd_RB permanently_RB discard_VB from_IN the_DT database_NN ._.
Support_NN Vector_NNP Machines_NNP -LRB-_-LRB- SVMs_NNS -RRB-_-RRB- are_VBP a_DT recently_RB developed_VBN class_NN of_IN statistical_JJ learning_NN architectures_NNS de1srived_VBN from_IN the_DT structural_JJ risk_NN minimization_NN principle_NN =_JJ -_: =[_NN 16_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Over_IN the_DT past_JJ few_JJ years_NNS ,_, researchers_NNS have_VBP reported_VBN experimental_JJ results_NNS suggesting_VBG that_IN the_DT SVM_NN training_NN procedure_NN exhibits_VBZ certain_JJ promising_JJ model_NN independent_JJ example_NN selection_NN characteristics_NNS for_IN
with_IN the_DT selected_VBN examples_NNS ,_, and_CC the_DT average_JJ predictive_JJ accuracy_NN on_IN the_DT test_NN set_NN P_NN Asel_NN is_VBZ recorded_VBN ._.
We_PRP chose_VBD to_TO use_VB the_DT following_JJ classifiers_NNS as_IN a_DT representative_JJ set_NN -LRB-_-LRB- a_DT -RRB-_-RRB- Multi-Layer_NNP Perceptron_NNP -LRB-_-LRB- MLP_NNP -RRB-_-RRB- =_JJ -_: =[_NN 14_CD ,_, 2_CD -RRB-_-RRB- -_: =_SYM -_: -_: connectionist_JJ learning_NN architecture_NN ._.
Simple_JJ backpropagation_NN algorithm_NN was_VBD used_VBN to_TO train_VB the_DT Neural_NNP Network_NNP ._.
-LRB-_-LRB- b_LS -RRB-_-RRB- Nearest_JJ Neighbor_NN -LRB-_-LRB- 1-NN_NN -RRB-_-RRB- -LRB-_-LRB- 8_CD -RRB-_-RRB- -_: instancebased_JJ learning_NN architecture_NN ._.
-LRB-_-LRB- c_LS -RRB-_-RRB- C4_NN .5_CD -LRB-_-LRB- 12_CD -RRB-_-RRB- -_: tre_NN
are_VBP complex_JJ classification_NN problems_NNS waiting_VBG to_TO be_VB solved_VBN in_IN many_JJ domains_NNS ,_, where_WRB large_JJ amounts_NNS of_IN training_NN data_NNS are_VBP already_RB available_JJ -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Researchers_NNS in_IN the_DT machine_NN learning_NN and_CC data_NN mining_NN community_NN =_JJ -_: =[_NN 6_CD ,_, 5_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP therefore_RB been_VBN trying_VBG to_TO scale_VB up_RP classical_JJ inductive_JJ learning_NN algorithms_NNS to_TO handle_VB extremely_RB large_JJ data_NNS sets_NNS ._.
One_CD popular_JJ approach_NN for_IN dealing_VBG with_IN the_DT intractability_NN problem_NN of_IN learning_VBG from_IN h_NN
naive_JJ sampling_NN methods_NNS are_VBP often_RB not_RB suitable_JJ for_IN real_JJ world_NN domains_NNS with_IN noisy_JJ training_NN data_NNS ,_, where_WRB prediction_NN results_NNS can_MD degrade_VB unpredictably_RB and_CC significantly_RB ._.
Boundary_NN hunting_NN methods_NNS like_IN IB2_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: seek_VB out_RP training_NN examples_NNS near_IN class_NN boundaries_NNS because_IN these_DT examples_NNS tend_VBP to_TO be_VB useful_JJ for_IN locating_VBG class_NN boundaries_NNS precisely_RB ._.
Assuming_VBG only_RB a_DT small_JJ fraction_NN of_IN training_NN examples_NNS in_IN a_DT large_JJ datab_NN
nd_RB permanently_RB discard_VB from_IN the_DT database_NN ._.
Support_NN Vector_NNP Machines_NNP -LRB-_-LRB- SVMs_NNS -RRB-_-RRB- are_VBP a_DT recently_RB developed_VBN class_NN of_IN statistical_JJ learning_NN architectures_NNS de1srived_VBN from_IN the_DT structural_JJ risk_NN minimization_NN principle_NN =_JJ -_: =[_NN 16_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Over_IN the_DT past_JJ few_JJ years_NNS ,_, researchers_NNS have_VBP reported_VBN experimental_JJ results_NNS suggesting_VBG that_IN the_DT SVM_NN training_NN procedure_NN exhibits_VBZ certain_JJ promising_JJ model_NN independent_JJ example_NN selection_NN characteristics_NNS for_IN
a_DT small_JJ training_NN set_NN can_MD omit_VB important_JJ information_NN captured_VBN in_IN the_DT original_JJ large_JJ data_NNS set_NN ,_, and_CC hence_RB lead_VB to_TO significantly_RB poorer_JJR prediction_NN results_NNS ._.
Various_JJ data_NNS sampling_NN methods_NNS have_VBP been_VBN studied_VBN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: such_JJ as_IN windowing_NN -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, random_JJ sampling_NN ,_, stratified_JJ sampling_NN ,_, peepholing_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, and_CC information-theoretic_JJ peepholing_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
Catlett_NNP 's_POS study_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- showed_VBD that_IN certain_JJ sampling_NN strategies_NNS helped_VBD in_IN speed-up_NN
antly_RB poorer_JJR prediction_NN results_NNS ._.
Various_JJ data_NNS sampling_NN methods_NNS have_VBP been_VBN studied_VBN -LRB-_-LRB- 3_LS -RRB-_-RRB- such_JJ as_IN windowing_NN -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, random_JJ sampling_NN ,_, stratified_JJ sampling_NN ,_, peepholing_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, and_CC information-theoretic_JJ peepholing_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Catlett_NNP 's_POS study_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- showed_VBD that_IN certain_JJ sampling_NN strategies_NNS helped_VBD in_IN speed-ups_NNS ,_, and_CC improving_VBG the_DT accuracy_NN of_IN classifiers_NNS in_IN noise_NN free_JJ domains_NNS ._.
However_RB ,_, he_PRP also_RB acknowledged_VBD that_IN naive_JJ sampling_NN me_PRP
are_VBP complex_JJ classification_NN problems_NNS waiting_VBG to_TO be_VB solved_VBN in_IN many_JJ domains_NNS ,_, where_WRB large_JJ amounts_NNS of_IN training_NN data_NNS are_VBP already_RB available_JJ -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Researchers_NNS in_IN the_DT machine_NN learning_NN and_CC data_NN mining_NN community_NN =_JJ -_: =[_NN 6_CD ,_, 5_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP therefore_RB been_VBN trying_VBG to_TO scale_VB up_RP classical_JJ inductive_JJ learning_NN algorithms_NNS to_TO handle_VB extremely_RB large_JJ data_NNS sets_NNS ._.
One_CD popular_JJ approach_NN for_IN dealing_VBG with_IN the_DT intractability_NN problem_NN of_IN learning_VBG from_IN h_NN
ed_VBN to_TO select_VB almost_RB identical_JJ data_NN subsets_NNS as_IN support_NN vectors_NNS -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
3_LS -RRB-_-RRB- SVMs_NNS trained_VBN with_IN different_JJ kernel_NN functions_NNS on_IN the_DT same_JJ database_NN have_VBP given_VBN rise_NN to_TO similar_JJ high_JJ prediction_NN rates_NNS on_IN novel_JJ data_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
It_PRP is_VBZ thus_RB tempting_JJ to_TO treat_VB SVM_NN training_NN as_IN a_DT form_NN of_IN model_NN independent_JJ example_NN selection_NN procedure_NN ._.
This_DT paper_NN attempts_VBZ to_TO verify_VB the_DT model_NN independent_JJ characteristics_NNS of_IN support_NN vectors_NNS ,_, obtained_VBN
are_VBP complex_JJ classification_NN problems_NNS waiting_VBG to_TO be_VB solved_VBN in_IN many_JJ domains_NNS ,_, where_WRB large_JJ amounts_NNS of_IN training_NN data_NNS are_VBP already_RB available_JJ -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Researchers_NNS in_IN the_DT machine_NN learning_NN and_CC data_NN mining_NN community_NN =_JJ -_: =[_NN 6_CD ,_, 5_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP therefore_RB been_VBN trying_VBG to_TO scale_VB up_RP classical_JJ inductive_JJ learning_NN algorithms_NNS to_TO handle_VB extremely_RB large_JJ data_NNS sets_NNS ._.
One_CD popular_JJ approach_NN for_IN dealing_VBG with_IN the_DT intractability_NN problem_NN of_IN learning_VBG from_IN h_NN
with_IN the_DT selected_VBN examples_NNS ,_, and_CC the_DT average_JJ predictive_JJ accuracy_NN on_IN the_DT test_NN set_NN P_NN Asel_NN is_VBZ recorded_VBN ._.
We_PRP chose_VBD to_TO use_VB the_DT following_JJ classifiers_NNS as_IN a_DT representative_JJ set_NN -LRB-_-LRB- a_DT -RRB-_-RRB- Multi-Layer_NNP Perceptron_NNP -LRB-_-LRB- MLP_NNP -RRB-_-RRB- =_JJ -_: =[_NN 14_CD ,_, 2_CD -RRB-_-RRB- -_: =_SYM -_: -_: connectionist_JJ learning_NN architecture_NN ._.
Simple_JJ backpropagation_NN algorithm_NN was_VBD used_VBN to_TO train_VB the_DT Neural_NNP Network_NNP ._.
-LRB-_-LRB- b_LS -RRB-_-RRB- Nearest_JJ Neighbor_NN -LRB-_-LRB- 1-NN_NN -RRB-_-RRB- -LRB-_-LRB- 8_CD -RRB-_-RRB- -_: instancebased_JJ learning_NN architecture_NN ._.
-LRB-_-LRB- c_LS -RRB-_-RRB- C4_NN .5_CD -LRB-_-LRB- 12_CD -RRB-_-RRB- -_: tre_NN
P_NN -RRB-_-RRB- -LRB-_-LRB- 14_CD ,_, 2_CD -RRB-_-RRB- -_: connectionist_JJ learning_NN architecture_NN ._.
Simple_JJ backpropagation_NN algorithm_NN was_VBD used_VBN to_TO train_VB the_DT Neural_NNP Network_NNP ._.
-LRB-_-LRB- b_LS -RRB-_-RRB- Nearest_JJ Neighbor_NN -LRB-_-LRB- 1-NN_NN -RRB-_-RRB- -LRB-_-LRB- 8_CD -RRB-_-RRB- -_: instancebased_JJ learning_NN architecture_NN ._.
-LRB-_-LRB- c_LS -RRB-_-RRB- C4_NN .5_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: -_: tree_NN based_JJ classifier_NN ._.
-LRB-_-LRB- d_LS -RRB-_-RRB- SVM_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- -_: optimal_JJ margin_NN classifier_NN ._.
The_DT datasets_NNS used_VBN for_IN carrying_VBG out_RP the_DT empirical_JJ Dataset_NNP #_# of_IN Examples_NNS No._NN of_IN Attr_NNP ._.
Australian_JJ 670_CD 14_CD Diabetes_NNP 768_CD 8_CD German_JJ 1000_CD 24_CD
a_DT representative_JJ set_NN -LRB-_-LRB- a_DT -RRB-_-RRB- Multi-Layer_NNP Perceptron_NNP -LRB-_-LRB- MLP_NNP -RRB-_-RRB- -LRB-_-LRB- 14_CD ,_, 2_CD -RRB-_-RRB- -_: connectionist_JJ learning_NN architecture_NN ._.
Simple_JJ backpropagation_NN algorithm_NN was_VBD used_VBN to_TO train_VB the_DT Neural_NNP Network_NNP ._.
-LRB-_-LRB- b_LS -RRB-_-RRB- Nearest_JJ Neighbor_NN -LRB-_-LRB- 1-NN_NN -RRB-_-RRB- =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: -_: instancebased_JJ learning_NN architecture_NN ._.
-LRB-_-LRB- c_LS -RRB-_-RRB- C4_NN .5_CD -LRB-_-LRB- 12_CD -RRB-_-RRB- -_: tree_NN based_JJ classifier_NN ._.
-LRB-_-LRB- d_LS -RRB-_-RRB- SVM_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- -_: optimal_JJ margin_NN classifier_NN ._.
The_DT datasets_NNS used_VBN for_IN carrying_VBG out_RP the_DT empirical_JJ Dataset_NNP #_# of_IN Examples_NNS No._NN of_IN A_NN
lynomial_JJ ,_, Gaussian_JJ RBF_NNP and_CC Neural_NNP Network_NNP classifiers_NNS -RRB-_-RRB- ._.
SVMs_NNS trained_VBN with_IN different_JJ kernel_NN functions_NNS on_IN the_DT same_JJ database_NN have_VBP been_VBN observed_VBN to_TO select_VB almost_RB identical_JJ data_NN subsets_NNS as_IN support_NN vectors_NNS =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
3_LS -RRB-_-RRB- SVMs_NNS trained_VBN with_IN different_JJ kernel_NN functions_NNS on_IN the_DT same_JJ database_NN have_VBP given_VBN rise_NN to_TO similar_JJ high_JJ prediction_NN rates_NNS on_IN novel_JJ data_NNS -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
It_PRP is_VBZ thus_RB tempting_JJ to_TO treat_VB SVM_NN training_NN as_IN a_DT form_NN of_IN model_NN
