Generative_JJ model-based_JJ clustering_NN of_IN directional_JJ data_NNS
High_JJ dimensional_JJ directional_JJ data_NNS is_VBZ becoming_VBG increasingly_RB important_JJ in_IN contemporary_JJ applications_NNS such_JJ as_IN analysis_NN of_IN text_NN and_CC gene-expression_NN data_NNS ._.
A_DT natural_JJ model_NN for_IN multi-variate_JJ directional_JJ data_NNS is_VBZ provided_VBN by_IN the_DT von_NN Mises-Fisher_NN -LRB-_-LRB- vMF_NN -RRB-_-RRB- distribution_NN on_IN the_DT unit_NN hypersphere_NN that_WDT is_VBZ analogous_JJ to_TO the_DT multi-variate_JJ Gaussian_JJ distribution_NN in_IN Rd._NNP ._.
In_IN this_DT paper_NN ,_, we_PRP propose_VBP modeling_NN complex_NN directional_JJ data_NNS as_IN a_DT mixture_NN of_IN vMF_NN distributions_NNS ._.
We_PRP derive_VBP and_CC analyze_VBP two_CD variants_NNS of_IN the_DT Expectation_NN Maximization_NN -LRB-_-LRB- EM_NN -RRB-_-RRB- framework_NN for_IN estimating_VBG the_DT parameters_NNS of_IN this_DT mixture_NN ._.
We_PRP also_RB propose_VBP two_CD clustering_NN algorithms_NNS corresponding_VBG to_TO these_DT variants_NNS ._.
An_DT interesting_JJ aspect_NN of_IN our_PRP$ methodology_NN is_VBZ that_IN the_DT spherical_JJ kmeans_NNS algorithm_NN -LRB-_-LRB- kmeans_NNS with_IN cosine_NN similarity_NN -RRB-_-RRB- can_MD be_VB shown_VBN to_TO be_VB a_DT special_JJ case_NN of_IN both_CC our_PRP$ algorithms_NNS ._.
Thus_RB ,_, modeling_NN text_NN data_NNS by_IN vMF_NN distributions_NNS lends_VBZ theoretical_JJ validity_NN to_TO the_DT use_NN of_IN cosine_NN similarity_NN which_WDT has_VBZ been_VBN widely_RB used_VBN by_IN the_DT information_NN retrieval_NN community_NN ._.
As_IN part_NN of_IN experimental_JJ validation_NN ,_, we_PRP present_VBP results_NNS on_IN modeling_NN high-dimensional_JJ text_NN and_CC gene-expression_NN data_NNS as_IN a_DT mixture_NN of_IN vMF_NN distributions_NNS ._.
The_DT results_NNS indicate_VBP that_IN our_PRP$ approach_NN yields_VBZ superior_JJ clusterings_NNS especially_RB for_IN difficult_JJ clustering_NN tasks_NNS in_IN high-dimensional_JJ spaces_NNS ._.
component_NN vectors_NNS in_IN Section_NNP 5_CD ._.
The_DT von_NNP Mises-Fisher_NNP distribution_NN -LRB-_-LRB- vMF_NN distribution_NN -RRB-_-RRB- is_VBZ the_DT most_RBS natural_JJ distribution_NN for_IN directional_JJ data_NNS in_IN that_IN it_PRP can_MD be_VB derived_VBN using_VBG the_DT maximum_NN entropy_NN principle_NN =_JJ -_: =[_NN 1_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
3.3_CD Problem_NNP Description_NN Here_RB ,_, we_PRP clearly_RB describe_VBP the_DT problem_NN once_RB more_JJR ._.
Let_VB us_PRP assume_VB that_IN we_PRP have_VBP telemetry_NN data_NNS in_IN normal_JJ operation_NN ._.
The_DT telemetry_NN data_NNS have_VBP thousands_NNS of_IN time_NN series_NN and_CC each_DT elem_NN
based_VBN approaches_NNS are_VBP not_RB appropriate_JJ in_IN this_DT case_NN since_IN the_DT signs_NNS of_IN faults_NNS are_VBP hidden_VBN deep_RB inside_IN the_DT systems_NNS -RRB-_-RRB- ._.
However_RB ,_, the_DT normal_JJ mixtures_NNS are_VBP not_RB appropriate_JJ to_TO handle_VB directional_JJ data_NNS ._.
Reference_NNP =_SYM -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: employs_VBZ a_DT mixture_NN of_IN the_DT von_NNP Mises-Fisher_NNP distribution_NN ,_, and_CC discusses_VBZ the_DT connection_NN to_TO the_DT cosine_NN measure_NN ._.
We_PRP also_RB consider_VBP the_DT von_NNP Mises-Fisher_NNP distribution_NN ._.
Our_PRP$ contribution_NN is_VBZ to_TO derive_VB a_DT probabi_NN
n_NN the_DT data_NNS ._.
If_IN is_VBZ the_DT random_JJ variable_NN denoting_VBG the_DT cluster_NN assignments_NNS of_IN the_DT points_NNS ,_, and_CC is_VBZ the_DT random_JJ variable_NN denoting_VBG the_DT underlying_VBG class_NN labels_NNS on_IN the_DT points_NNS ,_, then_RB the_DT NMI_NNP measure_NN is_VBZ defined_VBN as_IN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: :_: q_NN 0_CD -RRB-_-RRB- -LRB-_-LRB- 0_CD P_NN o_NN 0_CD Y_NN 0_CD q_NN where_WRB is_VBZ the_DT mutual_JJ information_NN between_IN the_DT random_JJ variables_NNS and_CC 0_CD ,_, is_VBZ the_DT Shannon_NNP entropy_NN of_IN ,_, 0_CD q_NN and_CC is_VBZ the_DT conditional_JJ entropy_NN of_IN given_VBN ._.
Pairwise_JJ F-measure_NN is_VBZ defined_VBN as_IN
the_DT PAC-MDL_NN bound_VBD -LRB-_-LRB- 3_CD -RRB-_-RRB- on_IN the_DT accuracy_NN of_IN a_DT test_NN set_NN ._.
Our_PRP$ proposed_VBN criterion_NN has_VBZ several_JJ natural_JJ properties_NNS :_: 1_CD ._.
It_PRP applies_VBZ to_TO every_DT clustering_NN algorithm_NN ._.
2_CD ._.
It_PRP is_VBZ inherently_RB normalized_VBN to_TO the_DT interval_NN =_JJ -_: =[_NN 0_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
3_LS ._.
All_DT possible_JJ values_NNS are_VBP exercised_VBN on_IN natural_JJ datasets_NNS ._.
4_LS ._.
The_DT metric_NN can_MD flexibly_RB incorporate_VB prior_JJ information_NN by_IN proper_JJ design_NN of_IN a_DT description_NN language_NN ._.
5_CD ._.
It_PRP can_MD be_VB used_VBN for_IN model_NN selection_NN ._.
d_NN on_IN a_DT discriminative_JJ model_NN ._.
A_DT generative_JJ model_NN can_MD create_VB other_JJ examples_NNS of_IN the_DT data_NNS ,_, usually_RB provides_VBZ good_JJ insight_NN into_IN the_DT nature_NN of_IN the_DT data_NNS and_CC facilitates_VBZ easy_JJ incorporation_NN of_IN domain_NN knowledge_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP observe_VBP that_IN an_DT author_NN 's_POS citations_NNS usually_RB contain_VBP the_DT information_NN of_IN the_DT author_NN 's_POS research_NN area_NN and_CC his_PRP$ or_CC her_PRP$ individual_JJ patterns_NNS of_IN coauthoring_VBG ._.
Therefore_RB ,_, we_PRP propose_VBP a_DT naive_JJ Bayes_NNP model_NN ,_, a_DT ge_NN
s_VBZ a_DT wide_JJ variety_NN of_IN distribution_NN types_NNS ,_, including_VBG Gaussian_NNP ,_, Bernoulli_NNP ,_, and_CC Poisson_NNP ._.
As_IN well_RB ,_, it_PRP uses_VBZ learning_VBG techniques_NNS to_TO estimate_VB the_DT number_NN of_IN distributions_NNS ._.
A_DT more_RBR recent_JJ work_NN by_IN Banerjee_NNP et_FW al._FW =_SYM -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: uses_VBZ Von_NNP Mises-Fisher_NNP distributions_NNS in_IN EM_NN clustering_NN ._.
Von_NNP Mises-Fisher_NNP distributions_NNS are_VBP designed_VBN to_TO deal_VB with_IN directional_JJ data_NNS -LRB-_-LRB- e.g._FW ,_, numeric_JJ vector_NN ,_, where_WRB Di_NNP =_JJ 1_CD -RRB-_-RRB- ._.
Such_JJ data_NNS representations_NNS produ_VBP
as_IN described_VBN above_IN ._.
To_TO estimate_VB the_DT parameters_NNS of_IN a_DT Gaussian_JJ mixture_NN ,_, the_DT Expectation_NN Maximization_NN -LRB-_-LRB- EM_NN -RRB-_-RRB- algorithm_NN is_VBZ widely_RB used_VBN for_IN its_PRP$ numerical_JJ stability_NN and_CC simplicity_NN ._.
Recently_RB ,_, Banerjee_NNP et_FW al._FW =_SYM -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: proposed_VBD two_CD variants_NNS -LRB-_-LRB- called_VBN the_DT hard-assignment_NN scheme_NN ,_, soft-assignment_JJ scheme_NN -RRB-_-RRB- of_IN the_DT EM_NNP algorithm_NN for_IN estimating_VBG the_DT parameters_NNS of_IN a_DT mixture_NN of_IN vMF_NN distributions_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP adopt_VBP Banerjee_NNP
n_NN that_IN the_DT Cosine_NNP similarity_NN measure_NN is_VBZ the_DT natural_JJ distortion_NN measure_NN for_IN prototype-based_JJ clustering_NN under_IN the_DT assumption_NN that_IN the_DT data_NNS were_VBD generated_VBN by_IN a_DT mixture_NN of_IN von-Mises_NNP Fisher_NNP distributions_NNS -LRB-_-LRB- =_JJ -_: =_JJ Banerjee_NNP et_FW al._FW ,_, 2003_CD -_: =--RRB-_NN ._.
This_DT similarity_NN measure_NN has_VBZ been_VBN widely_RB used_VBN in_IN information_NN retrieval_NN applications_NNS including_VBG text_NN analysis_NN -LRB-_-LRB- Aggarwal_NNP ,_, 2003_CD -RRB-_-RRB- ,_, bioinformatics_NNS and_CC collaborative_JJ filtering_VBG -LRB-_-LRB- Banerjee_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- ._.
It_PRP h_NN
orm_VB a_DT preprocessing_VBG step_NN to_TO identify_VB a_DT small_JJ number_NN of_IN representative_JJ states_NNS ._.
This_DT step_NN is_VBZ as_RB much_JJ art_NN as_IN science_NN ,_, and_CC is_VBZ usually_RB performed_VBN through_IN the_DT use_NN of_IN a_DT clustering_NN algorithm_NN ._.
Banerjee_FW et_FW ._.
al._FW =_SYM -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP given_VBN an_DT excellent_JJ formulation_NN to_TO the_DT problem_NN of_IN clustering_VBG high_JJ dimensional_JJ data_NNS based_VBN on_IN the_DT von_NN Mises_NNP Fischer_NNP distribution_NN ._.
We_PRP use_VBP their_PRP$ algorithm_NN along_IN with_IN standard_JJ clustering_NN methods_NNS such_JJ
d_NN on_IN a_DT discriminative_JJ model_NN ._.
A_DT generative_JJ model_NN can_MD create_VB other_JJ examples_NNS of_IN the_DT data_NNS ,_, usually_RB provides_VBZ good_JJ insight_NN into_IN the_DT nature_NN of_IN the_DT data_NNS and_CC facilitates_VBZ easy_JJ incorporation_NN of_IN domain_NN knowledge_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP observe_VBP that_IN an_DT author_NN 's_POS citations_NNS usually_RB contain_VBP the_DT information_NN of_IN the_DT author_NN 's_POS research_NN area_NN and_CC his_PRP$ or_CC her_PRP$ individual_JJ patterns_NNS of_IN coauthoring_VBG ._.
Therefore_RB ,_, we_PRP propose_VBP a_DT naive_JJ Bayes_NNP model_NN ,_, a_DT ge_NN
t_NN among_IN the_DT non-RSN_JJ algorithms_NNS ._.
Note_VB that_IN since_IN the_DT document_NN vector_NN is_VBZ L2-normalized_JJ ,_, the_DT KM-ED_NN is_VBZ actually_RB based_VBN on_IN von_NNP Mises-Fisher_NNP distribution_NN -LRB-_-LRB- 24_CD -RRB-_-RRB- ,_, which_WDT proved_VBD efficient_JJ for_IN document_NN clustering_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP also_RB observe_VBP that_IN for_IN these_DT graphs_NNS ,_, in_IN general_JJ the_DT algorithms_NNS based_VBN on_IN logistic_JJ loss_NN provide_VB better_JJR performance_NN ._.
The_DT possible_JJ reason_NN is_VBZ that_IN logistic_JJ loss_NN corresponds_VBZ to_TO Bernoulli_NNP distribution_NN wh_NN
cribed_VBN above_IN ._.
For_IN estimating_VBG the_DT parameters_NNS of_IN a_DT Gaussian_JJ mixture_NN ,_, the_DT Expectation_NN Maximization_NN -LRB-_-LRB- EM_NN -RRB-_-RRB- algorithm_NN is_VBZ widely_RB used_VBN for_IN its_PRP$ numerical_JJ stability_NN and_CC simplicity_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
Recently_RB ,_, Banerjee_NNP et_FW al._FW =_SYM -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: proposed_VBD two_CD variants_NNS -LRB-_-LRB- called_VBN the_DT hard-assignment_NN scheme_NN ,_, softassignment_NN scheme_NN -RRB-_-RRB- of_IN the_DT EM_NNP algorithm_NN for_IN estimating_VBG the_DT parameters_NNS of_IN a_DT mixture_NN of_IN vMF_NN distributions_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP adopt_VBP Banerjee_NNP
Normalized_VBN mutual_JJ information_NN ._.
For_IN the_DT datasets_NNS that_WDT have_VBP more_JJR than_IN five_CD classes_NNS ,_, due_JJ to_TO the_DT expensive_JJ computation_NN involved_VBN in_IN finding_VBG the_DT optimal_JJ alignment_NN ,_, we_PRP use_VBP the_DT normalized_VBN mutual_JJ information_NN -LRB-_-LRB- =_JJ -_: =_JJ Banerjee_NNP et_FW al._FW ,_, 2003_CD -_: =--RRB-_NN as_IN the_DT alternative_JJ evaluation_NN metric_NN ._.
If_IN Tu_NN and_CC Tl_NN denote_VBP the_DT cluster_NN labels_NNS and_CC true_JJ class_NN labels_NNS assigned_VBN to_TO data_NNS points_NNS ,_, the_DT normalized_VBN mutual_JJ information_NN ``_`` nmi_NN ''_'' is_VBZ defined_VBN as_IN nmi_NN =_JJ 2I_NN -LRB-_-LRB- Tu_NN ,_, Tl_NN -RRB-_-RRB- -LRB-_-LRB- H_NN -LRB-_-LRB- T_NN
µ_NN h_NN +_CC λh_NN -LRB-_-LRB- µ_NN T_NN h_NN µ_NN h_NN −_NN 1_CD -RRB-_-RRB- k_NN h_NN =_JJ 1_CD λh_NN -LRB-_-LRB- µ_NN T_NN h_NN µ_NN h_NN −_NN 1_CD -RRB-_-RRB- ,_, 1_CD One_NN can_MD also_RB formulate_VB a_DT soft_JJ assignment_NN based_VBN algorithm_NN based_VBN on_IN vMF_NN distributions_NNS ,_, but_CC soft_JJ clustering_NN is_VBZ outside_IN the_DT scope_NN of_IN this_DT chapter_NN ._.
See_VB =_JJ -_: =_JJ -LRB-_-LRB- BDGS03_NN -RRB-_-RRB- -_: =_SYM -_: for_IN details_NNS ._.
2_CD There_EX is_VBZ a_DT subtle_JJ difference_NN between_IN the_DT constraints_NNS µh_VBP =_JJ 1_CD and_CC µ_NN T_NN h_NN µ_NN h_NN =_JJ 1_CD ._.
Since_IN this_DT difference_NN is_VBZ not_RB important_JJ in_IN the_DT present_JJ analysis_NN ,_, we_PRP choose_VBP to_TO ignore_VB it_PRP for_IN simplicity_NN ._.
measure_NN based_VBN on_IN the_DT angle_NN between_IN vectors_NNS is_VBZ more_RBR appropriate_JJ -LRB-_-LRB- 1_LS -RRB-_-RRB- ._.
Consequently_RB ,_, clustering_NN algorithms_NNS that_WDT utilize_VBP distortion_NN measures_NNS appropriate_JJ for_IN directional_JJ data_NNS have_VBP recently_RB been_VBN developed_VBN =_JJ -_: =[_NN 18_CD ,_, 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Our_PRP$ unified_JJ semi-supervised_JJ clustering_NN framework_NN based_VBN on_IN HMRFs_NNS is_VBZ also_RB applicable_JJ to_TO such_JJ directional_JJ similarity_NN measures_NNS ._.
To_TO summarize_VB ,_, the_DT proposed_VBN approach_NN aids_VBZ unsupervised_JJ clustering_NN by_IN incorp_NN
comparison_NN with_IN SGC_NN ,_, METIS_NN and_CC a_DT state-of-the-art_JJ document_NN clustering_NN algorithm_NN ,_, VMF_NNP ,_, which_WDT is_VBZ based_VBN on_IN von_NNP Mises-Fisher_NNP distribution_NN and_CC was_VBD reported_VBN as_IN one_CD of_IN the_DT best_JJS document_NN clustering_NN algorithm_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP observe_VBP that_IN although_IN there_EX is_VBZ no_DT single_JJ winner_NN on_IN all_PDT the_DT graphs_NNS ,_, for_IN most_JJS graphs_NNS CLGA_NNP algorithms_NNS perform_VBP better_RBR than_IN or_CC close_JJ to_TO SGC_NNP ,_, METIS_NNP and_CC VMF_NNP ._.
The_DT CLGA_NNP algorithms_NNS provide_VBP the_DT best_JJS perform_VB
f_FW vMF_FW distributions_NNS ,_, as_IN described_VBN above_IN ._.
For_IN estimating_VBG the_DT parameters_NNS of_IN a_DT Gaussian_JJ mixture_NN ,_, the_DT EM_NNP algorithm_NN is_VBZ widely_RB used_VBN for_IN its_PRP$ numerical_JJ stability_NN and_CC simplicity_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
Recently_RB ,_, Banerjee_NNP et_FW al._FW =_SYM -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: proposed_VBD two_CD variants_NNS -LRB-_-LRB- called_VBN the_DT hard-assignment_NN scheme_NN and_CC the_DT soft-assignment_JJ scheme_NN -RRB-_-RRB- of_IN the_DT EM_NNP algorithm_NN for_IN estimating_VBG the_DT parameters_NNS of_IN a_DT mixture_NN of_IN vMF_NN distributions_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP adopt_VBP B_NN
the_DT PAC-MDL_NN bound_VBD -LRB-_-LRB- 3_CD -RRB-_-RRB- on_IN the_DT accuracy_NN of_IN a_DT test_NN set_NN ._.
Our_PRP$ proposed_VBN criterion_NN has_VBZ several_JJ natural_JJ properties_NNS :_: 1_CD ._.
It_PRP applies_VBZ to_TO every_DT clustering_NN algorithm_NN ._.
2_CD ._.
It_PRP is_VBZ inherently_RB normalized_VBN to_TO the_DT interval_NN =_JJ -_: =[_NN 0_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
3_LS ._.
All_DT possible_JJ values_NNS are_VBP exercised_VBN on_IN natural_JJ datasets_NNS ._.
4_LS ._.
The_DT metric_NN can_MD flexibly_RB incorporate_VB prior_JJ information_NN by_IN proper_JJ design_NN of_IN a_DT description_NN language_NN ._.
5_CD ._.
It_PRP can_MD be_VB used_VBN for_IN model_NN selection_NN ._.
ion_NN of_IN deterministic_JJ annealing_NN ,_, however_RB ,_, multinomial_JJ models_NNS perform_VBP comparably_RB with_IN vMF_NN models_NNS ._.
Here_RB is_VBZ why_WRB we_PRP use_VBP multinomial_JJ models_NNS instead_RB of_IN vMF_NN models_NNS underlying_VBG the_DT spherical_JJ k-means_NN algorithm_NN -LRB-_-LRB- =_JJ -_: =_JJ Banerjee_NNP et_FW al._FW ,_, 2003_CD -_: =--RRB-_NN :_: Even_RB though_IN the_DT spherical_JJ kmeans_NNS algorithm_NN is_VBZ simple_JJ and_CC efficient_JJ ,_, the_DT mixture-of-vMFs_NN ,_, a_DT soft_JJ version_NN of_IN spherical_JJ k-means_NN ,_, involves_VBZ Bessel_NNP function_NN in_IN its_PRP$ parameterization_NN and_CC requires_VBZ intensive_JJ
the_DT data_NNS ._.
Ifsis_NNP the_DT random_JJ variable_NN denoting_VBG the_DT cluster_NN assignments_NNS of_IN the_DT points_NNS ,_, and_CC ¡_NN is_VBZ the_DT random_JJ variable_NN denoting_VBG the_DT underlying_VBG class_NN labels_NNS on_IN the_DT points_NNS ,_, then_RB the_DT NMI_NNP measure_NN is_VBZ defined_VBN as_IN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: :_: #_# cents_NNS ¥_VBP $_$ ¡_CD $_$ ¦_CD ¨_CD §_FW ©_FW ¡_FW ¦_FW ¡_FW ¦_FW ¦_FW where_WRB $_$ §_CD ©_CD ¡_NN is_VBZ the_DT mutual_JJ information_NN between_IN the_DT random_JJ variables_NNS and_CC ,_, is_VBZ the_DT Shannon_NNP entropy_NN of_IN ,_, and_CC
ghted_VBN by_IN the_DT association_NN probabilities_NNS ,_, which_WDT is_VBZ to_TO be_VB maximized_VBN ._.
Indeed_RB ,_, maximizing_VBG this_DT objective_JJ function_NN leads_VBZ to_TO a_DT well-known_JJ hard_JJ clustering_NN algorithm_NN -LRB-_-LRB- Kearns_NNP et_FW al._FW ,_, 1997_CD ;_: Li_NNP and_CC Biswas_NNP ,_, 2002_CD ;_: =_JJ -_: =_JJ Banerjee_NNP et_FW al._FW ,_, 2003_CD -_: =_SYM -_: b_LS -RRB-_-RRB- ._.
We_PRP will_MD show_VB in_IN the_DT next_JJ section_NN that_IN soft_JJ modelbased_JJ clustering_NN can_MD be_VB obtained_VBN by_IN adding_VBG entropy_NN constraints_NNS to_TO the_DT objective_JJ function_NN ._.
Similar_JJ to_TO deterministic_JJ annealing_NN ,_, a_DT temperature_NN paramete_NN
t_NN al_NNP proposed_VBD two_CD variants_NNS of_IN the_DT EM_NNP algorithm_NN for_IN soft_JJ clustering_NN ,_, where_WRB each_DT object_NN is_VBZ allowed_VBN to_TO belong_VB to_TO more_JJR than_IN one_CD cluster_NN ,_, and_CC applied_VBD them_PRP to_TO text_NN clustering_NN and_CC gene_NN expression_NN clustering_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN 2002_CD ,_, Lodhi_NNP et_NNP al_NNP attempted_VBD to_TO solve_VB the_DT two_CD main_JJ problems_NNS from_IN representing_VBG documents_NNS into_IN numerical_JJ vectors_NNS by_IN proposing_VBG the_DT string_NN kernel_NN for_IN SVM_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
The_DT string_NN kernel_NN proposed_VBN by_IN them_PRP is_VBZ th_DT
hat_NN performs_VBZ kmeans_NNS using_VBG cosine_NN similarity_NN instead_RB of_IN Euclidean_JJ distortion_NN ,_, has_VBZ been_VBN found_VBN to_TO empirically_RB outperform_VB several_JJ other_JJ schemes_NNS ._.
sThere_NN are_VBP quite_RB a_DT few_JJ other_JJ domains_NNS such_JJ as_IN bioinformatics_NNS =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, collaborative_JJ filtering_VBG -LRB-_-LRB- 26_CD -RRB-_-RRB- etc._NN ,_, in_IN which_WDT directional_JJ data_NNS is_VBZ encountered_VBN ._.
A_DT similarity_NN measure_NN that_WDT has_VBZ been_VBN found_VBN to_TO be_VB useful_JJ in_IN these_DT domains_NNS is_VBZ the_DT Pearson_NNP correlation_NN coefficient_NN ._.
Given_VBN x_NN ,_, y_NN
xi_RB ,_, Θ_NN -RRB-_-RRB- ,_, -LRB-_-LRB- 12_CD -RRB-_-RRB- 0_CD ,_, otherwise_RB ._.
Though_IN soft-assignments_NNS are_VBP theoretically_RB very_RB well_RB motivated_VBN -LRB-_-LRB- 5_CD ,_, 23_CD -RRB-_-RRB- ,_, hard-assignments_NNS have_VBP not_RB received_VBN much_JJ theoretical_JJ attention_NN -LRB-_-LRB- though_IN some_DT discussion_NN can_MD be_VB found_VBN in_IN =_JJ -_: =_JJ -LRB-_-LRB- 20_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
In_IN the_DT rest_NN of_IN this_DT section_NN ,_, we_PRP formally_RB study_VBD the_DT connection_NN between_IN soft_JJ and_CC hard-assignments_NNS in_IN the_DT EM_NN framework_NN ._.
Note_VB that_IN this_DT analysis_NN is_VBZ applicable_JJ to_TO general_JJ mixture_NN model_NN learning_VBG in_IN the_DT E_NN
g_NN vMF_NN distributions_NNS and_CC the_DT spkmeans_NNS algorithm_NN was_VBD first_RB observed_VBN in_IN -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
An_DT online_JJ competitive_JJ learning_NN scheme_NN using_VBG vMF_NN distributions_NNS for_IN minimizing_VBG a_DT KL-divergence_NN based_VBN distortion_NN was_VBD proposed_VBN in_IN =_JJ -_: =[_NN 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, these_DT approaches_NNS do_VBP not_RB cluster_VB directional_JJ data_NNS using_VBG explicit_JJ probabilistic_JJ generative_JJ models_NNS ._.
In_IN this_DT work_NN ,_, the_DT directional_JJ nature_NN of_IN the_DT data_NN is_VBZ used_VBN explicitly_RB resulting_VBG in_IN significant_JJ
ype_NN distances_NNS from_IN the_DT discriminative_JJ perspective_NN ._.
1.1_CD Motivation_NN and_CC Related_NNP Work_NNP There_EX are_VBP several_JJ application_NN domains_NNS where_WRB clustering_NN based_VBN on_IN minimizing_VBG Euclidean_JJ distortions_NNS yields_VBZ poor_JJ results_NNS =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, empirical_JJ studies_NNS in_IN information_NN retrieval_NN applications_NNS show_VBP that_IN cosine_NN similarity_NN is_VBZ a_DT far_RB more_RBR effective_JJ measure_NN of_IN similarity_NN for_IN analyzing_NN and_CC clustering_NN text_NN documents_NNS ._.
Such_JJ domai_NNS
uristic_JJ or_CC a_DT discriminatory_JJ approach_NN -LRB-_-LRB- 15_CD ,_, 1_CD ,_, 16_CD -RRB-_-RRB- ._.
Perhaps_RB the_DT most_RBS noteworthy_JJ generative_JJ approach_NN for_IN clustering_VBG high-dimensional_JJ data_NNS is_VBZ to_TO use_VB mixtures_NNS of_IN Gaussians_NNP -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
Certain_JJ other_JJ works_NNS such_JJ as_IN =_JJ -_: =[_NN 24_CD -RRB-_-RRB- -_: =_SYM -_: use_VB a_DT generative_JJ model_NN from_IN the_DT exponential_JJ family_NN and_CC have_VBP been_VBN explicitly_RB developed_VBN for_IN modeling_NN text_NN ._.
The_DT spkmeans_NNS algorithm_NN for_IN clustering_NN normalized_VBD data_NNS was_VBD proposed_VBN in_IN -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, while_IN the_DT connecti_NN
ts_NNS chosen_VBN at_IN random_JJ have_VBP a_DT high_JJ probability_NN of_IN being_VBG orthogonal_JJ to_TO each_DT other_JJ ,_, so_IN that_IN a_DT kmeans-based_JJ iterative_JJ update_VBP scheme_NN may_MD get_VB stuck_VBN at_IN a_DT local_JJ minimum_NN at_IN the_DT very_JJ point_NN it_PRP is_VBZ initialized_VBN -LRB-_-LRB- see_VB =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
As_IN a_DT result_NN ,_, kmeansbased_JJ algorithms_NNS suffer_VBP in_IN high-dimensions_NNS ,_, especially_RB when_WRB the_DT number_NN of_IN data_NNS points_NNS available_JJ is_VBZ small_JJ ._.
This_DT explains_VBZ the_DT performance_NN of_IN fskmeans_NNS and_CC spkmeans_NNS ._.
Among_IN the_DT vMF-ba_NN
n._VB The_DT underlying_VBG clusters_NNS in_IN this_DT dataset_NN are_VBP highly_RB skewed_VBN in_IN terms_NNS of_IN the_DT number_NN of_IN documents_NNS per_IN clusters_NNS ,_, with_IN sizes_NNS ranging_VBG from_IN 9_CD to_TO 494_CD ._.
The_DT Rosetta_NNP Inpharmatics_NNPS Yeast_NN gene-expression_NN dataset_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ a_DT collection_NN of_IN gene-expression_NN vectors_NNS constructed_VBN using_VBG 2_CD http:\/\/www.ai.mit.edu\/people\/jrennie\/20_NN newsgroups_NNS 3_CD ftp_NN :_: \/_: \/_: ftp.cs.umn.edu\/users\/boley\/PDDPdata\/sDNA_NN microarray_NN experiments_NNS on_IN the_DT Yeast_NN
al_FW data_NNS that_WDT is_VBZ becoming_VBG increasingly_RB common_JJ in_IN several_JJ application_NN domains_NNS ._.
One_CD can_MD broadly_RB categorize_VB clustering_NN approaches_NNS into_IN generative_JJ -LRB-_-LRB- parametric_JJ -RRB-_-RRB- -LRB-_-LRB- 29_CD ,_, 18_CD -RRB-_-RRB- and_CC discriminative_JJ -LRB-_-LRB- non-parametric_JJ -RRB-_-RRB- =_JJ -_: =[_NN 17_CD ,_, 27_CD -RRB-_-RRB- -_: =_JJ -_: ones_NNS ._.
The_DT performance_NN of_IN an_DT approach_NN -LRB-_-LRB- and_CC of_IN a_DT specific_JJ method_NN within_IN that_DT approach_NN -RRB-_-RRB- is_VBZ quite_RB data_NN dependent_JJ ;_: there_EX is_VBZ no_DT clustering_NN method_NN that_WDT works_VBZ the_DT best_JJS across_IN all_DT types_NNS of_IN data_NNS ._.
Generative_JJ mo_NN
ustin_NN ,_, TX_NNP ,_, USA_NNP suvrit@cs.utexas.edu_NNP directional_JJ data_NNS that_WDT is_VBZ becoming_VBG increasingly_RB common_JJ in_IN several_JJ application_NN domains_NNS ._.
One_CD can_MD broadly_RB categorize_VB clustering_NN approaches_NNS into_IN generative_JJ -LRB-_-LRB- parametric_JJ -RRB-_-RRB- =_JJ -_: =[_NN 29_CD ,_, 18_CD -RRB-_-RRB- -_: =_JJ -_: and_CC discriminative_JJ -LRB-_-LRB- non-parametric_JJ -RRB-_-RRB- -LRB-_-LRB- 17_CD ,_, 27_CD -RRB-_-RRB- ones_NNS ._.
The_DT performance_NN of_IN an_DT approach_NN -LRB-_-LRB- and_CC of_IN a_DT specific_JJ method_NN within_IN that_DT approach_NN -RRB-_-RRB- is_VBZ quite_RB data_NN dependent_JJ ;_: there_EX is_VBZ no_DT clustering_NN method_NN that_WDT works_VBZ the_DT
tering_JJ ,_, directional_JJ data_NNS ,_, mixtures_NNS ,_, von_NNP Mises-Fisher_NNP ,_, EM_NNP 1_CD ._.
INTRODUCTION_NN Clustering_NN or_CC segmentation_NN of_IN data_NNS is_VBZ a_DT fundamental_JJ data_NN analysis_NN step_NN that_WDT has_VBZ been_VBN widely_RB studied_VBN across_IN various_JJ disciplines_NNS =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, several_JJ large_JJ datasets_NNS that_WDT are_VBP being_VBG acquired_VBN from_IN scientific_JJ domains_NNS ,_, as_RB well_RB as_IN the_DT world_NN wide_JJ web_NN ,_, have_VBP a_DT variety_NN of_IN complex_JJ characteristics_NNS that_WDT severely_RB challenge_VBP traditional_JJ methods_NNS
hods_NNS following_VBG a_DT density-based_JJ heuristic_NN or_CC a_DT discriminatory_JJ approach_NN -LRB-_-LRB- 15_CD ,_, 1_CD ,_, 16_CD -RRB-_-RRB- ._.
Perhaps_RB the_DT most_RBS noteworthy_JJ generative_JJ approach_NN for_IN clustering_VBG high-dimensional_JJ data_NNS is_VBZ to_TO use_VB mixtures_NNS of_IN Gaussians_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Certain_JJ other_JJ works_NNS such_JJ as_IN -LRB-_-LRB- 24_CD -RRB-_-RRB- use_VBP a_DT generative_JJ model_NN from_IN the_DT exponential_JJ family_NN and_CC have_VBP been_VBN explicitly_RB developed_VBN for_IN modeling_NN text_NN ._.
The_DT spkmeans_NNS algorithm_NN for_IN clustering_NN normalized_VBD data_NNS was_VBD pr_NN
al_FW data_NNS that_WDT is_VBZ becoming_VBG increasingly_RB common_JJ in_IN several_JJ application_NN domains_NNS ._.
One_CD can_MD broadly_RB categorize_VB clustering_NN approaches_NNS into_IN generative_JJ -LRB-_-LRB- parametric_JJ -RRB-_-RRB- -LRB-_-LRB- 29_CD ,_, 18_CD -RRB-_-RRB- and_CC discriminative_JJ -LRB-_-LRB- non-parametric_JJ -RRB-_-RRB- =_JJ -_: =[_NN 17_CD ,_, 27_CD -RRB-_-RRB- -_: =_JJ -_: ones_NNS ._.
The_DT performance_NN of_IN an_DT approach_NN -LRB-_-LRB- and_CC of_IN a_DT specific_JJ method_NN within_IN that_DT approach_NN -RRB-_-RRB- is_VBZ quite_RB data_NN dependent_JJ ;_: there_EX is_VBZ no_DT clustering_NN method_NN that_WDT works_VBZ the_DT best_JJS across_IN all_DT types_NNS of_IN data_NNS ._.
Generative_JJ mo_NN
ormation_NN retrieval_NN applications_NNS show_VBP that_IN cosine_NN similarity_NN is_VBZ a_DT far_RB more_RBR effective_JJ measure_NN of_IN similarity_NN for_IN analyzing_NN and_CC clustering_NN text_NN documents_NNS ._.
Such_JJ domains_NNS require_VBP the_DT use_NN of_IN directional_JJ data_NN =_JJ -_: =[_NN 22_CD -RRB-_-RRB- -_: =_JJ -_: data_NNS that_IN deals_NNS only_RB with_IN the_DT directions_NNS of_IN unit_NN vectors_NNS ._.
Thus_RB ,_, there_EX is_VBZ a_DT need_NN for_IN generative_JJ models_NNS that_WDT are_VBP more_RBR appropriate_JJ for_IN the_DT analysis_NN and_CC clustering_NN of_IN directional_JJ data_NNS ._.
In_IN this_DT article_NN ,_,
pecific_JJ desirable_JJ patterns_NNS that_IN one_CD is_VBZ looking_VBG for_IN ._.
Clustering_NN algorithms_NNS using_VBG the_DT generative_JJ model_NN framework_NN ,_, often_RB involve_VBP an_DT appropriate_JJ application_NN of_IN the_DT Expectation_NN Maximization_NN -LRB-_-LRB- EM_NN -RRB-_-RRB- algorithm_NN =_JJ -_: =[_NN 8_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: on_IN a_DT properly_RB chosen_VBN statistical_JJ generative_JJ model_NN for_IN the_DT data_NNS under_IN consideration_NN ._.
For_IN vector_NN data_NNS ,_, there_EX are_VBP well_RB studied_VBN clustering_NN algorithms_NNS for_IN popular_JJ generative_JJ models_NNS such_JJ as_IN a_DT mixture_NN of_IN Ga_NNP
i_LS =_JJ 1_CD xip_NN -LRB-_-LRB- h_NN |_FW xi_FW ,_, Θ_NN -RRB-_-RRB- Pn_NN ._.
-LRB-_-LRB- 9_CD -RRB-_-RRB- p_NN -LRB-_-LRB- h_NN |_FW xi_FW ,_, Θ_NN -RRB-_-RRB- 1_CD analysis_NN using_VBG the_DT KKT_NN conditions_NNS is_VBZ skipped_VBN for_IN brevity_NN ._.
κh_FW ≥_FW 0_CD is_VBZ accounted_VBN for_IN by_IN taking_VBG positive_JJ square_NN roots_NNS ._.
The_DT final_JJ estimates_NNS come_VBP out_RP to_TO be_VB th_DT =_JJ -_: =_JJ e_LS same_JJ -LRB-_-LRB- 2_CD -RRB-_-RRB- ._.
i_LS =_JJ 1_CD w_NN -_: =_JJ -_: here_RB Ad_NN -LRB-_-LRB- κ_NN -RRB-_-RRB- =_JJ Id\/2_NN -LRB-_-LRB- κ_NN -RRB-_-RRB- ._.
A_DT closed_JJ form_NN solution_NN of_IN -LRB-_-LRB- 9_CD -RRB-_-RRB- is_VBZ Id\/2_FW −_FW 1_CD -LRB-_-LRB- κ_NN -RRB-_-RRB- not_RB possible_JJ and_CC one_PRP can_MD use_VB numerical_JJ techniques_NNS to_TO solve_VB for_IN ˆκh_NN ._.
A_DT reasonable_JJ approximation_NN to_TO the_DT solution_NN is_VBZ obtained_VBN by_IN
of_IN the_DT multivariate_JJ Gaussian_JJ distribution_NN for_IN multi-variate_JJ data_NNS in_IN R_NN d_NN ._.
For_IN example_NN ,_, the_DT maximum_NN entropy_NN density_NN on_IN S_NN d_FW −_FW 1_CD subject_JJ to_TO the_DT constraint_NN that_IN E_NN -LRB-_-LRB- x_NN -RRB-_-RRB- is_VBZ fixed_VBN is_VBZ a_DT vMF_NN density_NN -LRB-_-LRB- see_VB -LRB-_-LRB- 25_CD -RRB-_-RRB- an_DT =_JJ -_: =d_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- -_: =_SYM -_: for_IN details_NNS -RRB-_-RRB- ._.
3_LS ._.
EM_NNP ON_NNP MIXTURE_NNP OF_IN VMFS_FW In_FW this_DT section_NN ,_, we_PRP introduce_VBP a_DT mixture_NN of_IN k_NN vMF_NN -LRB-_-LRB- movMF_NN -RRB-_-RRB- distributions_NNS as_IN a_DT generative_JJ model_NN for_IN directional_JJ data_NNS ,_, and_CC then_RB derive_VB the_DT mixture-density_JJ parameter_NN
ep_NN of_IN EM_NNP -RCB-_-RRB- for_IN h_NN =_JJ 1_CD to_TO k_NN do_VBP µ_NN h_NN ←_CD P_NN x_NN ∈_CD X_NN h_NN x_NN P_NN x_NN ∈_CD X_NN h_NN x_NN end_NN for_IN until_IN convergence_NN competitive_JJ learning_NN that_WDT implicitly_RB prevents_VBZ the_DT formation_NN of_IN null_JJ clusters_NNS ,_, a_DT well-known_JJ problem_NN in_IN regu_NN =_JJ -_: =_JJ lar_JJ kmeans_NNS -LRB-_-LRB- 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
5_CD ._.
EXPERIMENTAL_JJ RESULTS_NNS In_IN this_DT section_NN we_PRP briefly_RB describe_VBP the_DT datasets_NNS and_CC experimental_JJ methodology_NN used_VBN ._.
Then_RB ,_, we_PRP discuss_VBP the_DT performance_NN of_IN the_DT four_CD algorithms_NNS under_IN consideration_NN on_IN the_DT various_JJ
e_LS thousands_NNS or_CC more_JJR ._.
Clustering_NN of_IN such_JJ high-dimensional_JJ data_NNS has_VBZ been_VBN of_IN great_JJ interest_NN lately_RB -LRB-_-LRB- 9_CD -RRB-_-RRB- ,_, with_IN most_JJS of_IN the_DT proposed_VBN methods_NNS following_VBG a_DT density-based_JJ heuristic_NN or_CC a_DT discriminatory_JJ approach_NN =_JJ -_: =[_NN 15_CD ,_, 1_CD ,_, 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Perhaps_RB the_DT most_RBS noteworthy_JJ generative_JJ approach_NN for_IN clustering_VBG high-dimensional_JJ data_NNS is_VBZ to_TO use_VB mixtures_NNS of_IN Gaussians_NNP -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
Certain_JJ other_JJ works_NNS such_JJ as_IN -LRB-_-LRB- 24_CD -RRB-_-RRB- use_VBP a_DT generative_JJ model_NN from_IN the_DT exponential_NN
hus_NN ,_, x_NN ,_, µ_FW ∈_FW S_NN d_NN −_NN 1_CD ._.
The_DT normalizing_VBG constant_JJ cd_NN -LRB-_-LRB- κ_NN -RRB-_-RRB- is_VBZ given_VBN by_IN :_: cd_NN -LRB-_-LRB- κ_NN -RRB-_-RRB- =_JJ κ_FW d\/2_FW −_NN 1_CD -LRB-_-LRB- 2π_NN -RRB-_-RRB- d\/2_NN ,_, -LRB-_-LRB- 2_LS -RRB-_-RRB- Id\/2_NN −_NN 1_CD -LRB-_-LRB- κ_NN -RRB-_-RRB- where_WRB Ir_NN -LRB-_-LRB- ·_NN -RRB-_-RRB- represents_VBZ the_DT modified_VBN Bessel_NNP function_NN of_IN the_DT first_JJ kind_NN of_IN order_NN r_NN =_JJ -_: =_JJ ,_, see_VB -LRB-_-LRB- 22_CD -RRB-_-RRB- and_CC -LRB-_-LRB- 12_CD -RRB-_-RRB- for_IN -_: =_JJ -_: more_JJR details_NNS on_IN vMF_NN distributions_NNS ._.
The_DT density_NN f_SYM -LRB-_-LRB- x_NN |_CD µ_NN ,_, κ_NN -RRB-_-RRB- is_VBZ parameterized_VBN by_IN the_DT mean_NN direction_NN ,_, µ_NN ,_, and_CC the_DT concentration_NN parameter_NN ,_, κ_NN ,_, so-called_JJ because_IN it_PRP characterizes_VBZ how_WRB strongly_RB the_DT unit_NN ve_FW
ral_JJ large_JJ datasets_NNS that_WDT are_VBP being_VBG acquired_VBN from_IN scientific_JJ domains_NNS ,_, as_RB well_RB as_IN the_DT world_NN wide_JJ web_NN ,_, have_VBP a_DT variety_NN of_IN complex_JJ characteristics_NNS that_WDT severely_RB challenge_VBP traditional_JJ methods_NNS for_IN clustering_NN =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT article_NN is_VBZ concerned_VBN with_IN the_DT clustering_NN of_IN high-dimensional_JJ Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN all_DT or_CC part_NN of_IN this_DT work_NN for_IN personal_JJ or_CC classroom_NN use_NN is_VBZ granted_VBN without_IN fee_NN provided_VBD
he_PRP spkmeans_VBZ algorithm_NN for_IN clustering_NN normalized_VBD data_NNS was_VBD proposed_VBN in_IN -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, while_IN the_DT connection_NN between_IN a_DT generative_JJ model_NN involving_VBG vMF_NN distributions_NNS and_CC the_DT spkmeans_NNS algorithm_NN was_VBD first_RB observed_VBN in_IN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
An_DT online_JJ competitive_JJ learning_NN scheme_NN using_VBG vMF_NN distributions_NNS for_IN minimizing_VBG a_DT KL-divergence_NN based_VBN distortion_NN was_VBD proposed_VBN in_IN -LRB-_-LRB- 28_CD -RRB-_-RRB- ._.
However_RB ,_, these_DT approaches_NNS do_VBP not_RB cluster_VB directional_JJ data_NNS using_VBG ex_FW
e_LS thousands_NNS or_CC more_JJR ._.
Clustering_NN of_IN such_JJ high-dimensional_JJ data_NNS has_VBZ been_VBN of_IN great_JJ interest_NN lately_RB -LRB-_-LRB- 9_CD -RRB-_-RRB- ,_, with_IN most_JJS of_IN the_DT proposed_VBN methods_NNS following_VBG a_DT density-based_JJ heuristic_NN or_CC a_DT discriminatory_JJ approach_NN =_JJ -_: =[_NN 15_CD ,_, 1_CD ,_, 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Perhaps_RB the_DT most_RBS noteworthy_JJ generative_JJ approach_NN for_IN clustering_VBG high-dimensional_JJ data_NNS is_VBZ to_TO use_VB mixtures_NNS of_IN Gaussians_NNP -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
Certain_JJ other_JJ works_NNS such_JJ as_IN -LRB-_-LRB- 24_CD -RRB-_-RRB- use_VBP a_DT generative_JJ model_NN from_IN the_DT exponential_NN
he_PRP data_NNS is_VBZ maximized_VBN ._.
The_DT first_JJ update_VBP scheme_NN exactly_RB follows_VBZ the_DT soft-assignment_JJ scheme_NN for_IN learning_VBG mixture_NN models_NNS using_VBG EM_NN ._.
From_IN the_DT standard_JJ EM_NN framework_NN ,_, the_DT distribution_NN of_IN the_DT hidden_JJ variables_NNS =_JJ -_: =[_NN 23_CD -RRB-_-RRB- is_VBZ g_NN -_: =_JJ -_: iven_VBN by_IN :_: p_NN -LRB-_-LRB- h_NN |_FW xi_FW ,_, Θ_NN -RRB-_-RRB- =_JJ αh_FW fh_FW -LRB-_-LRB- xi_FW |_FW Θ_NN -RRB-_-RRB- Pk_NN l_NN =_JJ 1_CD αl_NN ._.
-LRB-_-LRB- 11_CD -RRB-_-RRB- fl_NN -LRB-_-LRB- xi_FW |_FW Θ_NN -RRB-_-RRB- Our_PRP$ second_JJ update_VBP scheme_NN is_VBZ based_VBN on_IN the_DT widely_RB used_VBN hardassignment_NN heuristic_NN for_IN unsupervised_JJ learning_NN ._.
In_IN this_DT case_NN ,_, the_DT distribution_NN
to_TO those_DT of_IN the_DT multivariate_JJ Gaussian_JJ distribution_NN for_IN multi-variate_JJ data_NNS in_IN R_NN d_NN ._.
For_IN example_NN ,_, the_DT maximum_NN entropy_NN density_NN on_IN S_NN d_FW −_FW 1_CD subject_JJ to_TO the_DT constraint_NN that_IN E_NN -LRB-_-LRB- x_NN -RRB-_-RRB- is_VBZ fixed_VBN is_VBZ a_DT vMF_NN density_NN -LRB-_-LRB- se_FW =_JJ -_: =_JJ e_LS -LRB-_-LRB- 25_CD -RRB-_-RRB- -_: =_JJ -_: and_CC -LRB-_-LRB- 21_CD -RRB-_-RRB- for_IN details_NNS -RRB-_-RRB- ._.
3_LS ._.
EM_NNP ON_NNP MIXTURE_NNP OF_IN VMFS_FW In_FW this_DT section_NN ,_, we_PRP introduce_VBP a_DT mixture_NN of_IN k_NN vMF_NN -LRB-_-LRB- movMF_NN -RRB-_-RRB- distributions_NNS as_IN a_DT generative_JJ model_NN for_IN directional_JJ data_NNS ,_, and_CC then_RB derive_VB the_DT mixture-density_NN
ustin_NN ,_, TX_NNP ,_, USA_NNP suvrit@cs.utexas.edu_NNP directional_JJ data_NNS that_WDT is_VBZ becoming_VBG increasingly_RB common_JJ in_IN several_JJ application_NN domains_NNS ._.
One_CD can_MD broadly_RB categorize_VB clustering_NN approaches_NNS into_IN generative_JJ -LRB-_-LRB- parametric_JJ -RRB-_-RRB- =_JJ -_: =[_NN 29_CD ,_, 18_CD -RRB-_-RRB- -_: =_JJ -_: and_CC discriminative_JJ -LRB-_-LRB- non-parametric_JJ -RRB-_-RRB- -LRB-_-LRB- 17_CD ,_, 27_CD -RRB-_-RRB- ones_NNS ._.
The_DT performance_NN of_IN an_DT approach_NN -LRB-_-LRB- and_CC of_IN a_DT specific_JJ method_NN within_IN that_DT approach_NN -RRB-_-RRB- is_VBZ quite_RB data_NN dependent_JJ ;_: there_EX is_VBZ no_DT clustering_NN method_NN that_WDT works_VBZ the_DT
pecific_JJ desirable_JJ patterns_NNS that_IN one_CD is_VBZ looking_VBG for_IN ._.
Clustering_NN algorithms_NNS using_VBG the_DT generative_JJ model_NN framework_NN ,_, often_RB involve_VBP an_DT appropriate_JJ application_NN of_IN the_DT Expectation_NN Maximization_NN -LRB-_-LRB- EM_NN -RRB-_-RRB- algorithm_NN =_JJ -_: =[_NN 8_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: on_IN a_DT properly_RB chosen_VBN statistical_JJ generative_JJ model_NN for_IN the_DT data_NNS under_IN consideration_NN ._.
For_IN vector_NN data_NNS ,_, there_EX are_VBP well_RB studied_VBN clustering_NN algorithms_NNS for_IN popular_JJ generative_JJ models_NNS such_JJ as_IN a_DT mixture_NN of_IN Ga_NNP
ne_NN similarity_NN instead_RB of_IN Euclidean_JJ distortion_NN ,_, has_VBZ been_VBN found_VBN to_TO empirically_RB outperform_VB several_JJ other_JJ schemes_NNS ._.
sThere_NN are_VBP quite_RB a_DT few_JJ other_JJ domains_NNS such_JJ as_IN bioinformatics_NNS -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, collaborative_JJ filtering_VBG =_JJ -_: =[_NN 26_CD -RRB-_-RRB- e_SYM -_: =_JJ -_: tc._NN ,_, in_IN which_WDT directional_JJ data_NNS is_VBZ encountered_VBN ._.
A_DT similarity_NN measure_NN that_WDT has_VBZ been_VBN found_VBN to_TO be_VB useful_JJ in_IN these_DT domains_NNS is_VBZ the_DT Pearson_NNP correlation_NN coefficient_NN ._.
Given_VBN x_NN ,_, y_FW ∈_FW R_NN d_NN ,_, the_DT Pearson_NNP product_NN m_NN
xt_NN analysis_NN ,_, and_CC text_NN clustering_NN in_IN particular_JJ ._.
It_PRP has_VBZ been_VBN experimentally_RB shown_VBN that_IN in_IN order_NN to_TO remove_VB the_DT bias_NN arising_VBG due_JJ to_TO the_DT length_NN of_IN a_DT document_NN ,_, it_PRP often_RB helps_VBZ to_TO normalize_VB the_DT data_NN vectors_NNS =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Further_RB ,_, the_DT spkmeans_NNS algorithm_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, that_WDT performs_VBZ kmeans_NNS using_VBG cosine_NN similarity_NN instead_RB of_IN Euclidean_JJ distortion_NN ,_, has_VBZ been_VBN found_VBN to_TO empirically_RB outperform_VB several_JJ other_JJ schemes_NNS ._.
sThere_NN are_VBP quite_RB a_DT
