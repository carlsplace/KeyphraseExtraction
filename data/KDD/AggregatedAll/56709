IDR\/QR_NN :_: an_DT incremental_JJ dimension_NN reduction_NN algorithm_NN via_IN QR_NN decomposition_NN
Dimension_NN reduction_NN is_VBZ critical_JJ for_IN many_JJ database_NN and_CC data_NN mining_NN applications_NNS ,_, such_JJ as_IN efficient_JJ storage_NN and_CC retrieval_NN of_IN high-dimensional_JJ data_NNS ._.
In_IN the_DT literature_NN ,_, a_DT well-known_JJ dimension_NN reduction_NN scheme_NN is_VBZ Linear_NNP Discriminant_NNP Analysis_NNP -LRB-_-LRB- LDA_NNP -RRB-_-RRB- ._.
The_DT common_JJ aspect_NN of_IN previously_RB proposed_VBN LDA_NNP based_VBN algorithms_NNS is_VBZ the_DT use_NN of_IN Singular_JJ Value_NN Decomposition_NN -LRB-_-LRB- SVD_NN -RRB-_-RRB- ._.
Due_JJ to_TO the_DT difficulty_NN of_IN designing_VBG an_DT incremental_JJ solution_NN for_IN the_DT eigenvalue_NN problem_NN on_IN the_DT product_NN of_IN scatter_NN matrices_NNS in_IN LDA_NNP ,_, there_EX is_VBZ little_JJ work_NN on_IN designing_VBG incremental_JJ LDA_NNP algorithms_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP propose_VBP an_DT LDA_NN based_VBN incremental_JJ dimension_NN reduction_NN algorithm_NN ,_, called_VBN IDR\/QR_NN ,_, which_WDT applies_VBZ QR_NN Decomposition_NN rather_RB than_IN SVD_NNP ._.
Unlike_IN other_JJ LDA_NNP based_VBN algorithms_NNS ,_, this_DT algorithm_NN does_VBZ not_RB require_VB the_DT whole_JJ data_NNS matrix_NN in_IN main_JJ memory_NN ._.
This_DT is_VBZ desirable_JJ for_IN large_JJ data_NNS sets_NNS ._.
More_RBR importantly_RB ,_, with_IN the_DT insertion_NN of_IN new_JJ data_NNS items_NNS ,_, the_DT IDR\/QR_NN algorithm_NN can_MD constrain_VB the_DT computational_JJ cost_NN by_IN applying_VBG efficient_JJ QR-updating_JJ techniques_NNS ._.
Finally_RB ,_, we_PRP evaluate_VBP the_DT effectiveness_NN of_IN the_DT IDR\/QR_NN algorithm_NN in_IN terms_NNS of_IN classification_NN accuracy_NN on_IN the_DT reduced_VBN dimensional_JJ space_NN ._.
Our_PRP$ experiments_NNS on_IN several_JJ real-world_JJ data_NNS sets_NNS reveal_VBP that_IN the_DT accuracy_NN achieved_VBN by_IN the_DT IDR\/QR_NN algorithm_NN is_VBZ very_RB close_JJ to_TO the_DT best_JJS possible_JJ accuracy_NN achieved_VBN by_IN other_JJ LDA_NNP based_VBN algorithms_NNS ._.
However_RB ,_, the_DT IDR\/QR_NN algorithm_NN has_VBZ much_RB less_RBR computational_JJ cost_NN ,_, especially_RB when_WRB new_JJ data_NNS items_NNS are_VBP dynamically_RB inserted_VBN ._.
criminative_JJ subspaces_NNS have_VBP also_RB been_VBN proposed_VBN ._.
Gradient-based_JJ incremental_JJ learning_NN of_IN a_DT modified_VBN LDA_NN was_VBD proposed_VBN by_IN Hiraoka_NNP et_FW al._FW -LRB-_-LRB- 25_CD -RRB-_-RRB- ._.
This_DT ,_, however_RB ,_, requires_VBZ setting_NN of_IN a_DT learning_NN rate_NN ._.
Ye_FW et_FW al._FW =_SYM -_: =[_NN 24_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP proposed_VBN an_DT incremental_JJ version_NN of_IN LDA_NNP ,_, which_WDT can_MD include_VB a_DT single_JJ new_JJ data_NNS point_NN in_IN each_DT time_NN step_NN ._.
An_DT important_JJ limitation_NN is_VBZ the_DT computational_JJ complexity_NN of_IN the_DT method_NN when_WRB the_DT number_NN of_IN clas_NNS
esented_VBN as_IN compartments_NNS -RRB-_-RRB- ,_, make_VB up_RP the_DT entire_JJ neuron_NN shapes_NNS ._.
These_DT varieties_NNS of_IN neuron_NN shapes_NNS attain_VBP through_IN a_DT development_NN process_NN called_VBN of_IN elongation_NN and_CC branching_VBG of_IN axonal_JJ and_CC dendrites_JJ extensions_NNS =_JJ -_: =[_NN 1,2,3,4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Such_JJ digital_JJ reconstruction_NN files_NNS are_VBP efficient_JJ and_CC allow_VB extensive_JJ morphometric_JJ analysis_NN to_TO be_VB produced_VBN from_IN implementation_NN of_IN biophysical_JJ virtual_JJ neuron_NN models_NNS as_IN allowing_VBG `_`` pseudo-3D_NN '_'' rendering_VBG an_DT
es_NNS for_IN incrementally_RB updating_VBG the_DT discriminant_JJ components_NNS when_WRB more_JJR data_NNS becomes_VBZ available_JJ ._.
A_DT number_NN of_IN incremental_JJ versions_NNS of_IN LDA_NNP have_VBP been_VBN suggested_VBN ,_, which_WDT can_MD be_VB applied_VBN to_TO on-line_JJ learning_NN tasks_NNS =_JJ -_: =[_NN 4_CD ,_, 7_CD ,_, 9_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Ye_FW et_FW al._FW -LRB-_-LRB- 14_CD -RRB-_-RRB- proposed_VBD an_DT incremental_JJ version_NN of_IN LDA_NNP ,_, which_WDT can_MD include_VB only_RB a_DT single_JJ new_JJ data_NNS point_NN in_IN each_DT time_NN step_NN ._.
A_DT further_JJ limitation_NN is_VBZ the_DT computational_JJ complexity_NN of_IN the_DT method_NN when_WRB the_DT n_NN
ot_RB be_VB applied_VBN ._.
Second_JJ ,_, incremental_JJ learning_NN requires_VBZ less_JJR memory_NN and_CC has_VBZ lower_JJR computational_JJ costs_NNS ._.
In_IN the_DT following_NN we_PRP will_MD focus_VB on_IN incremental_JJ LDA_NN learning_NN ._.
Existing_VBG incremental_JJ LDA_NN methods_NNS ,_, e.g._FW ,_, =_JJ -_: =[_NN 6_CD ,_, 15_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: are_VBP based_VBN on_IN directly_RB updating_VBG the_DT between_IN class_NN scatter_NN matrix_NN and_CC the_DT within_IN class_NN scatter_NN matrix_NN ._.
That_DT is_VBZ ,_, they_PRP consider_VBP mostly_RB discriminative_JJ information_NN focusing_VBG on_IN specific_JJ features_NNS that_IN best_JJS d_NN
tant_JJ values_NNS to_TO the_DT diagonal_JJ elements_NNS of_IN Sw_NN ,_, as_IN Sw_NN +_CC αI_NN ,_, for_IN some_DT α_NN -RRB-_-RRB- 0_CD and_CC I_PRP is_VBZ an_DT identity_NN matrix_NN ._.
3_LS -RRB-_-RRB- Spectral_JJ Regression_NN Discriminant_JJ Analysis_NN -LRB-_-LRB- SRDA_NN -RRB-_-RRB- ,_, our_PRP$ approach_NN proposed_VBN in_IN this_DT paper_NN ._.
4_LS -RRB-_-RRB- IDR\/QR_NN =_JJ -_: =[_NN 22_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT LDA_NNP variation_NN in_IN which_WDT QR_NN decomposition_NN is_VBZ applied_VBN rather_RB than_IN SVD_NNP ._.
Thus_RB ,_, IDR\/QR_NN is_VBZ very_RB efficient_JJ ._.
We_PRP compute_VBP the_DT closed_JJ form_NN solution_NN of_IN SRDA_NN -LRB-_-LRB- by_IN solving_VBG normal_JJ equations_NNS -RRB-_-RRB- for_IN the_DT first_JJ three_CD da_NN
Many_JJ dimensionality_NN reduction_NN methods_NNS have_VBP been_VBN proposed_VBN to_TO transform_VB high_JJ dimensional_JJ data_NNS to_TO low_JJ dimensional_JJ data_NNS such_JJ that_IN the_DT information_NN of_IN high_JJ dimensional_JJ data_NNS is_VBZ kept_VBN as_RB much_JJ as_IN possible_JJ -LRB-_-LRB- see_VB =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: for_IN a_DT review_NN -RRB-_-RRB- ._.
The_DT approach_NN of_IN dimensionality_NN reduction_NN can_MD be_VB supervised_VBN or_CC unsupervised_JJ ._.
Supervised_VBN approach_NN means_VBZ we_PRP know_VBP the_DT class_NN label_NN of_IN data_NNS beforehand_RB ._.
Linear_JJ discriminant_JJ analysis_NN -LRB-_-LRB- LDA_NN -RRB-_-RRB- is_VBZ
account_VB the_DT prior_JJ information_NN about_IN object_NN labels_NNS ,_, thus_RB they_PRP do_VBP not_RB exploit_VB all_DT information_NN ,_, which_WDT is_VBZ available_JJ for_IN classification_NN ._.
Several_JJ methods_NNS for_IN incremental_JJ LDA_NN have_VBP also_RB been_VBN already_RB proposed_VBN =_JJ -_: =[_NN 9_CD ,_, 15_CD ,_, 20_CD ,_, 21_CD ,_, 24_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_JJS of_IN these_DT methods_NNS focus_VBP on_IN the_DT updating_VBG of_IN the_DT between_IN class_NN scatter_NN matrix_NN and_CC the_DT within_IN class_NN scatter_NN matrix_NN ,_, thus_RB keeping_VBG the_DT discriminative_JJ information_NN only_RB ._.
In_IN contrast_NN ,_, our_PRP$ method_NN keeps_VBZ u_NN
ues_NNS to_TO the_DT diagonal_JJ elements_NNS of_IN Sw_NNP ,_, asSwþ_NNP I_NNP ,_, for_IN some_DT -RRB-_-RRB- 0_CD ._.
In_IN -LRB-_-LRB- 27_CD -RRB-_-RRB- ,_, Ye_NNP and_CC Wang_NNP proposed_VBD an_DT efficient_JJ algorithm_NN to_TO compute_VB the_DT solution_NN of_IN RLDA_NN ._.
3_LS ._.
SRDA_NNP ,_, our_PRP$ approach_NN proposed_VBN in_IN this_DT paper_NN ._.
4_LS ._.
IDR\/QR_NN =_SYM -_: =[_NN 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, an_DT LDA_NN variation_NN in_IN which_WDT QR_NN decomposition_NN is_VBZ applied_VBN rather_RB than_IN SVD_NNP ._.
Thus_RB ,_, IDR\/QR_NN is_VBZ very_RB efficient_JJ ._.
TABLE_NN 5_CD Computational_JJ Time_NN on_IN PIE_NN -LRB-_-LRB- Seconds_NNS -RRB-_-RRB- We_PRP compute_VBP the_DT closed-form_JJ solution_NN of_IN SRDA_NN -LRB-_-LRB- by_IN sol_NN
tilizing_VBG special_JJ representations_NNS of_IN the_DT pooled_JJ scatter_NN matrix_NN and_CC between-class_JJ scatter_NN matrix_NN ._.
A_DT similar_JJ general_JJ approach_NN has_VBZ been_VBN used_VBN in_IN the_DT development_NN of_IN efficient_JJ approximate_JJ algorithms_NNS for_IN LDA_NN =_JJ -_: =[_NN 2_CD ,_, 21_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, the_DT challenge_NN of_IN developing_VBG an_DT efficient_JJ general_JJ implementation_NN methodology_NN for_IN LDA_NNP still_RB remains_VBZ ._.
It_PRP is_VBZ well_RB known_VBN that_IN LDA_NN is_VBZ equivalent_JJ to_TO a_DT least_JJS mean_NN squared_VBD error_NN procedure_NN in_IN the_DT bin_NN
es_NNS for_IN incrementally_RB updating_VBG the_DT discriminant_JJ components_NNS when_WRB more_JJR data_NNS becomes_VBZ available_JJ ._.
A_DT number_NN of_IN incremental_JJ versions_NNS of_IN LDA_NNP have_VBP been_VBN suggested_VBN ,_, which_WDT can_MD be_VB applied_VBN to_TO on-line_JJ learning_NN tasks_NNS =_JJ -_: =[_NN 4_CD ,_, 7_CD ,_, 9_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Ye_FW et_FW al._FW -LRB-_-LRB- 14_CD -RRB-_-RRB- proposed_VBD an_DT incremental_JJ version_NN of_IN LDA_NNP ,_, which_WDT can_MD include_VB only_RB a_DT single_JJ new_JJ data_NNS point_NN in_IN each_DT time_NN step_NN ._.
A_DT further_JJ limitation_NN is_VBZ the_DT computational_JJ complexity_NN of_IN the_DT method_NN when_WRB the_DT n_NN
