Efficient_JJ handling_NN of_IN high-dimensional_JJ feature_NN spaces_NNS by_IN randomized_VBN classifier_NN ensembles_NNS
Handling_VBG massive_JJ datasets_NNS is_VBZ a_DT difficult_JJ problem_NN not_RB only_RB due_JJ to_TO prohibitively_RB large_JJ numbers_NNS of_IN entries_NNS but_CC in_IN some_DT cases_NNS also_RB due_JJ to_TO the_DT very_RB high_JJ dimensionality_NN of_IN the_DT data_NNS ._.
Often_RB ,_, severe_JJ feature_NN selection_NN is_VBZ performed_VBN to_TO limit_VB the_DT number_NN of_IN attributes_NNS to_TO a_DT manageable_JJ size_NN ,_, which_WDT unfortunately_RB can_MD lead_VB to_TO a_DT loss_NN of_IN useful_JJ information_NN ._.
Feature_NN space_NN reduction_NN may_MD well_RB be_VB necessary_JJ for_IN many_JJ stand-alone_JJ classifiers_NNS ,_, but_CC recent_JJ advances_NNS in_IN the_DT area_NN of_IN ensemble_NN classifier_NN techniques_NNS indicate_VBP that_IN overall_JJ accurate_JJ classifier_NN aggregates_NNS can_MD be_VB learned_VBN even_RB if_IN each_DT individual_JJ classifier_NN operates_VBZ on_IN incomplete_JJ ``_`` feature_NN view_NN ''_'' training_NN data_NNS ,_, i.e._FW ,_, such_JJ where_WRB certain_JJ input_NN attributes_NNS are_VBP excluded_VBN ._.
In_IN fact_NN ,_, by_IN using_VBG only_RB small_JJ random_JJ subsets_NNS of_IN features_NNS to_TO build_VB individual_JJ component_NN classifiers_NNS ,_, surprisingly_RB accurate_JJ and_CC robust_JJ models_NNS can_MD be_VB created_VBN ._.
In_IN this_DT work_NN we_PRP demonstrate_VBP how_WRB these_DT types_NNS of_IN architectures_NNS effectively_RB reduce_VB the_DT feature_NN space_NN for_IN submodels_NNS and_CC groups_NNS of_IN sub-models_NNS ,_, which_WDT lends_VBZ itself_PRP to_TO efficient_JJ sequential_JJ and\/or_CC parallel_JJ implementations_NNS ._.
Experiments_NNS with_IN a_DT randomized_VBN version_NN of_IN Adaboost_NNP are_VBP used_VBN to_TO support_VB our_PRP$ arguments_NNS ,_, using_VBG the_DT text_NN classification_NN task_NN as_IN an_DT example_NN ._.
