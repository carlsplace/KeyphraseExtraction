Interpretable_JJ nonnegative_JJ matrix_NN decompositions_NNS
A_DT matrix_NN decomposition_NN expresses_VBZ a_DT matrix_NN as_IN a_DT product_NN of_IN at_IN least_JJS two_CD factor_NN matrices_NNS ._.
Equivalently_RB ,_, it_PRP expresses_VBZ each_DT column_NN of_IN the_DT input_NN matrix_NN as_IN a_DT linear_JJ combination_NN of_IN the_DT columns_NNS in_IN the_DT first_JJ factor_NN matrix_NN ._.
The_DT interpretability_NN of_IN the_DT decompositions_NNS is_VBZ a_DT key_JJ issue_NN in_IN many_JJ data-analysis_JJ tasks_NNS ._.
We_PRP propose_VBP two_CD new_JJ matrix-decomposition_JJ problems_NNS :_: the_DT nonnegative_JJ CX_NN and_CC nonnegative_JJ CUR_NN problems_NNS ,_, that_WDT give_VBP naturally_RB interpretable_JJ factors_NNS ._.
They_PRP extend_VBP the_DT recently-proposed_JJ column_NN and_CC column-row_JJ based_JJ decompositions_NNS ,_, and_CC are_VBP aimed_VBN to_TO be_VB used_VBN with_IN nonnegative_JJ matrices_NNS ._.
Our_PRP$ decompositions_NNS represent_VBP the_DT input_NN matrix_NN as_IN a_DT nonnegative_JJ linear_JJ combination_NN of_IN a_DT subset_NN of_IN its_PRP$ columns_NNS -LRB-_-LRB- or_CC columns_NNS and_CC rows_NNS -RRB-_-RRB- ._.
We_PRP present_VBP two_CD algorithms_NNS to_TO solve_VB these_DT problems_NNS and_CC provide_VB an_DT extensive_JJ experimental_JJ evaluation_NN where_WRB we_PRP assess_VBP the_DT quality_NN of_IN our_PRP$ algorithms_NNS '_POS results_NNS as_RB well_RB as_IN the_DT intuitiveness_NN of_IN nonnegative_JJ CX_NN and_CC CUR_NN decompositions_NNS ._.
We_PRP show_VBP that_IN our_PRP$ algorithms_NNS return_VBP intuitive_JJ answers_NNS with_IN smaller_JJR reconstruction_NN errors_NNS than_IN the_DT previously-proposed_JJ methods_NNS for_IN column_NN and_CC column-row_NN decompositions_NNS ._.
work_NN in_IN this_DT thread_NN can_MD be_VB traced_VBN back_RB to_TO -LRB-_-LRB- 31_CD -RRB-_-RRB- and_CC there_EX are_VBP a_DT lot_NN of_IN follow-up_JJ work_NN in_IN this_DT direction_NN -LRB-_-LRB- 13_CD ,_, 29_CD ,_, 28_CD ,_, 12_CD -RRB-_-RRB- ._.
There_EX are_VBP also_RB efforts_NNS to_TO address_VB both_CC the_DT sparseness_NN and_CC nonnegativity_NN issues_NNS =_JJ -_: =[_NN 23_CD ,_, 24_CD -RRB-_-RRB- -_: =_SYM -_: ._.
It_PRP is_VBZ worth_JJ pointing_VBG out_RP that_IN most_JJS ,_, if_IN not_RB all_DT ,_, of_IN these_DT modifications_NNS -LRB-_-LRB- i.e._FW ,_, sparseness_NN and_CC nonnegativity_NN constrains_VBZ -RRB-_-RRB- are_VBP imposed_VBN on_IN the_DT factorized_JJ matrices_NNS ._.
As_IN a_DT result_NN ,_, they_PRP mainly_RB improve_VBP the_DT in_IN
aces_VBZ whose_WP$ basis_NN vectors_NNS correspond_VBP to_TO actual_JJ data_NNS points_NNS ._.
They_PRP are_VBP guaranteed_VBN to_TO preserve_VB properties_NNS such_JJ as_IN sparseness_NN or_CC non-negativity_NN and_CC enjoy_VB increasing_VBG popularity_NN in_IN the_DT data_NNS mining_NN community_NN =_JJ -_: =[_NN 12_CD ,_, 13_CD ,_, 17_CD ,_, 20_CD ,_, 31_CD ,_, 35_CD -RRB-_-RRB- -_: =_SYM -_: with_IN important_JJ applications_NNS to_TO fraud_NN detection_NN ,_, fMRI_NN segmentation_NN ,_, collaborative_JJ filtering_VBG ,_, and_CC co-clustering_NN ._.
But_CC how_WRB do_VBP we_PRP select_VB columns_NNS in_IN Line_NNP 1_CD ?_.
A_DT prominent_JJ approach_NN is_VBZ based_VBN on_IN the_DT statistical_JJ
paces_NNS whose_WP$ basis_NN vectors_NNS correspond_VBP to_TO actual_JJ data_NNS points_NNS ._.
They_PRP are_VBP guaranteed_VBN to_TO preserve_VB properties_NNS such_JJ as_IN sparseness_NN or_CC nonnegativity_NN and_CC enjoy_VB increasing_VBG popularity_NN in_IN the_DT data_NNS mining_NN community_NN =_JJ -_: =[_NN 3_CD ,_, 11_CD ,_, 12_CD ,_, 17_CD ,_, 21_CD ,_, 22_CD ,_, 26_CD ,_, 28_CD -RRB-_-RRB- -_: =_SYM -_: where_WRB they_PRP have_VBP been_VBN applied_VBN to_TO fraud_NN detection_NN ,_, fMRI_NN segmentation_NN ,_, collaborative_JJ filtering_VBG ,_, and_CC co-clustering_NN ._.
The_DT idea_NN of_IN selecting_VBG suitable_JJ rows_NNS and_CC columns_NNS for_IN low-rank_JJ matrix_NN approximations_NNS has_VBZ
