Unsupervised_JJ feature_NN selection_NN for_IN principal_JJ components_NNS analysis_NN
Principal_NN Components_NNP Analysis_NNP -LRB-_-LRB- PCA_NNP -RRB-_-RRB- is_VBZ the_DT predominant_JJ linear_JJ dimensionality_NN reduction_NN technique_NN ,_, and_CC has_VBZ been_VBN widely_RB applied_VBN on_IN datasets_NNS in_IN all_DT scientific_JJ domains_NNS ._.
We_PRP consider_VBP ,_, both_DT theoretically_RB and_CC empirically_RB ,_, the_DT topic_NN of_IN unsupervised_JJ feature_NN selection_NN for_IN PCA_NNP ,_, by_IN leveraging_VBG algorithms_NNS for_IN the_DT so-called_JJ Column_NNP Subset_NNP Selection_NN Problem_NNP -LRB-_-LRB- CSSP_NNP -RRB-_-RRB- ._.
In_IN words_NNS ,_, the_DT CSSP_NNP seeks_VBZ the_DT ``_`` best_JJS ''_'' subset_NN of_IN exactly_RB k_NN columns_NNS from_IN an_DT m_NN x_NN n_NN data_NNS matrix_NN A_NN ,_, and_CC has_VBZ been_VBN extensively_RB studied_VBN in_IN the_DT Numerical_NNP Linear_NNP Algebra_NNP community_NN ._.
We_PRP present_VBP a_DT novel_JJ two-stage_JJ algorithm_NN for_IN the_DT CSSP_NN ._.
From_IN a_DT theoretical_JJ perspective_NN ,_, for_IN small_JJ to_TO moderate_JJ values_NNS of_IN k_NN ,_, this_DT algorithm_NN significantly_RB improves_VBZ upon_IN the_DT best_JJS previously-existing_JJ results_NNS -LRB-_-LRB- 24_CD ,_, 12_CD -RRB-_-RRB- for_IN the_DT CSSP_NN ._.
From_IN an_DT empirical_JJ perspective_NN ,_, we_PRP evaluate_VBP this_DT algorithm_NN as_IN an_DT unsupervised_JJ feature_NN selection_NN strategy_NN in_IN three_CD application_NN domains_NNS of_IN modern_JJ statistical_JJ data_NNS analysis_NN :_: finance_NN ,_, document-term_JJ data_NNS ,_, and_CC genetics_NNS ._.
We_PRP pay_VBP particular_JJ attention_NN to_TO how_WRB this_DT algorithm_NN may_MD be_VB used_VBN to_TO select_VB representative_JJ or_CC landmark_JJ features_NNS from_IN an_DT object-feature_JJ matrix_NN in_IN an_DT unsupervised_JJ manner_NN ._.
In_IN all_DT three_CD application_NN domains_NNS ,_, we_PRP are_VBP able_JJ to_TO identify_VB k_NN landmark_NN features_NNS ,_, i.e._FW ,_, columns_NNS of_IN the_DT data_NNS matrix_NN ,_, that_WDT capture_VBP nearly_RB the_DT same_JJ amount_NN of_IN information_NN as_IN does_VBZ the_DT subspace_NN that_WDT is_VBZ spanned_VBN by_IN the_DT top_JJ k_NN ``_`` eigenfeatures_NNS ._. ''_''
xample_RB ,_, -LRB-_-LRB- 23_CD ,_, 5_CD ,_, 25_CD ,_, 26_CD -RRB-_-RRB- ._.
Finally_RB ,_, note_VBP that_IN employing_VBG the_DT leverage_NN scores_NNS in_IN a_DT randomized_VBN manner_NN similar_JJ to_TO Algorithm_NN 1_CD has_VBZ already_RB been_VBN proven_VBN to_TO be_VB accurate_JJ for_IN least-squares_JJ regression_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- and_CC PCA_NN =_JJ -_: =[_NN 7_CD ,_, 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
3.1_CD Connections_NNP with_IN the_DT SVD_NN A_NN well-known_JJ property_NN connects_VBZ the_DT SVD_NN of_IN a_DT matrix_NN and_CC k-means_NN clustering_NN ._.
Recall_VB Definition_NN 1_CD ,_, and_CC notice_NN that_IN XoptX_NN T_NN optA_NN is_VBZ a_DT matrix_NN of_IN rank_NN at_IN most_JJS k._NN From_IN the_DT SVD_NN
ring_VB an_DT internship_NN ._.
Financially_RB supported_VBN by_IN ANR-07-BLAN-0328-01_NN GAIA_NN -LRB-_-LRB- Computational_JJ Information_NN Geometry_NN and_CC Applications_NNS -RRB-_-RRB- and_CC DIGITEO_NN GAS_NN 2008-16D_NN -LRB-_-LRB- Geometric_JJ Algorithms_NNPS &_CC Statistics_NNPS -RRB-_-RRB- 10_CD ._.
REFERENCES_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: A._NNP Bar-Hillel_NNP ,_, T._NNP Hertz_NNP ,_, N._NNP Shental_NNP ,_, and_CC D._NNP Weinshall_NNP ._.
Learning_VBG a_DT mahalanobis_NN metric_NN from_IN equivalence_JJ constraints_NNS ._.
J._NNP Mach_NNP ._.
Learn_VB ._.
Res._NNP ,_, 6:937_NNP --_: 965_CD ,_, 2005_CD ._.
-LRB-_-LRB- 2_LS -RRB-_-RRB- L._NNP Bregman_NNP ._.
The_DT relaxation_NN method_NN of_IN find_VB
form_NN -LRB-_-LRB- 2.1_CD -RRB-_-RRB- ._.
Via_NNP the_DT methods_NNS of_IN Rudelson_NNP and_CC Vershynin_NNP -LRB-_-LRB- 116_CD -RRB-_-RRB- ,_, they_PRP showed_VBD that_IN sampling_NN columns_NNS according_VBG to_TO their_PRP$ leverage_NN scores_NNS is_VBZ likely_JJ to_TO produce_VB the_DT required_JJ submatrix_NN -LRB-_-LRB- 50,51_CD -RRB-_-RRB- ._.
Subsequent_JJ work_NN =_JJ -_: =[_NN 17,18_CD -RRB-_-RRB- -_: =_JJ -_: showed_VBD that_IN postprocessing_VBG the_DT sampled_VBN columns_NNS with_IN a_DT rank-revealing_JJ QR_NN algorithm_NN can_MD reduce_VB the_DT number_NN of_IN output_NN columns_NNS required_VBN -LRB-_-LRB- 2.1_CD -RRB-_-RRB- ._.
The_DT argument_NN in_IN -LRB-_-LRB- 17_CD -RRB-_-RRB- explicitly_RB decouples_VBZ the_DT linear_JJ algebrai_NNS
or_CC computationally_RB manageable_JJ in_IN low_JJ dimensional_JJ spaces_NNS may_MD become_VB completely_RB intractable_JJ in_IN spaces_NNS of_IN several_JJ hundred_CD or_CC thousand_CD dimensions_NNS -LRB-_-LRB- 12_CD -RRB-_-RRB- ._.
To_TO overcome_VB this_DT problem_NN ,_, featureselectiontechniques_VBZ =_JJ -_: =[_NN 3_CD ,_, 4_CD ,_, 17_CD ,_, 21_CD ,_, 29_CD ,_, 30_CD -RRB-_-RRB- -_: =_SYM -_: are_VBP designed_VBN to_TO reduce_VB the_DT dimensionality_NN by_IN finding_VBG a_DT relevant_JJ feature_NN subset_NN ._.
Once_RB a_DT small_JJ number_NN of_IN relevant_JJ features_NNS are_VBP selected_VBN ,_, conventional_JJ data_NN analysis_NN techniques_NNS can_MD then_RB be_VB applied_VBN ._.
Based_VBN
s_NN much_RB harder_RBR ._.
Existing_VBG unsupervised_JJ feature_NN selection_NN techniques_NNS can_MD be_VB classified_VBN into_IN two_CD categories_NNS ._.
The_DT first_JJ category_NN exploits_VBZ the_DT geometrical_JJ structure_NN of_IN the_DT data_NNS space_NN to_TO guide_VB the_DT selection_NN =_JJ -_: =[_NN 3,14,25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT typical_JJ algorithms_NNS in_IN this_DT category_NN include_VBP maximum_NN variance_NN ,_, unsupervised_JJ feature_NN selection_NN for_IN PCA_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- and_CC Laplacian_JJ score_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
Maximum_NNP variance_NN selects_VBZ features_NNS with_IN the_DT largest_JJS variances_NNS an_DT
paces_NNS whose_WP$ basis_NN vectors_NNS correspond_VBP to_TO actual_JJ data_NNS points_NNS ._.
They_PRP are_VBP guaranteed_VBN to_TO preserve_VB properties_NNS such_JJ as_IN sparseness_NN or_CC nonnegativity_NN and_CC enjoy_VB increasing_VBG popularity_NN in_IN the_DT data_NNS mining_NN community_NN =_JJ -_: =[_NN 3_CD ,_, 11_CD ,_, 12_CD ,_, 17_CD ,_, 21_CD ,_, 22_CD ,_, 26_CD ,_, 28_CD -RRB-_-RRB- -_: =_SYM -_: where_WRB they_PRP have_VBP been_VBN applied_VBN to_TO fraud_NN detection_NN ,_, fMRI_NN segmentation_NN ,_, collaborative_JJ filtering_VBG ,_, and_CC co-clustering_NN ._.
The_DT idea_NN of_IN selecting_VBG suitable_JJ rows_NNS and_CC columns_NNS for_IN low-rank_JJ matrix_NN approximations_NNS has_VBZ
