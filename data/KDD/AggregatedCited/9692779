Collective_JJ annotation_NN of_IN Wikipedia_NNP entities_NNS in_IN web_NN text_NN
To_TO take_VB the_DT first_JJ step_NN beyond_IN keyword-based_JJ search_NN toward_IN entity-based_JJ search_NN ,_, suitable_JJ token_JJ spans_NNS -LRB-_-LRB- ``_`` spots_NNS ''_'' -RRB-_-RRB- on_IN documents_NNS must_MD be_VB identified_VBN as_IN references_NNS to_TO real-world_JJ entities_NNS from_IN an_DT entity_NN catalog_NN ._.
Several_JJ systems_NNS have_VBP been_VBN proposed_VBN to_TO link_VB spots_NNS on_IN Web_NN pages_NNS to_TO entities_NNS in_IN Wikipedia_NNP ._.
They_PRP are_VBP largely_RB based_VBN on_IN local_JJ compatibility_NN between_IN the_DT text_NN around_IN the_DT spot_NN and_CC textual_JJ metadata_NN associated_VBN with_IN the_DT entity_NN ._.
Two_CD recent_JJ systems_NNS exploit_VBP inter-label_JJ dependencies_NNS ,_, but_CC in_IN limited_JJ ways_NNS ._.
We_PRP propose_VBP a_DT general_JJ collective_JJ disambiguation_NN approach_NN ._.
Our_PRP$ premise_NN is_VBZ that_IN coherent_JJ documents_NNS refer_VBP to_TO entities_NNS from_IN one_CD or_CC a_DT few_JJ related_JJ topics_NNS or_CC domains_NNS ._.
We_PRP give_VBP formulations_NNS for_IN the_DT trade-off_NN between_IN local_JJ spot-to-entity_JJ compatibility_NN and_CC measures_NNS of_IN global_JJ coherence_NN between_IN entities_NNS ._.
Optimizing_VBG the_DT overall_JJ entity_NN assignment_NN is_VBZ NP-hard_JJ ._.
We_PRP investigate_VBP practical_JJ solutions_NNS based_VBN on_IN local_JJ hill-climbing_NN ,_, rounding_VBG integer_NN linear_NN programs_NNS ,_, and_CC pre-clustering_JJ entities_NNS followed_VBN by_IN local_JJ optimization_NN within_IN clusters_NNS ._.
In_IN experiments_NNS involving_VBG over_IN a_DT hundred_CD manually-annotated_JJ Web_NN pages_NNS and_CC tens_NNS of_IN thousands_NNS of_IN spots_NNS ,_, our_PRP$ approaches_NNS significantly_RB outperform_VBP recently-proposed_JJ algorithms_NNS ._.
neutral_JJ to_TO the_DT specific_JJ identity_NN of_IN s_NN or_CC γ_NN ,_, as_IN a_DT feature_NN vector_NN fs_NN -LRB-_-LRB- γ_NN -RRB-_-RRB- in_IN some_DT space_NN ._.
Again_RB ,_, we_PRP can_MD learn_VB a_DT model_NN w_NN in_IN the_DT same_JJ space_NN such_JJ that_IN the_DT predicted_VBN entity_NN label_NN is_VBZ arg_FW maxγ_FW ∈_FW Γs_FW ∪_FW N.A._NNP w_FW ⊤_FW fs_FW -LRB-_-LRB- γ_NN -RRB-_-RRB- =_JJ -_: =[_NN 33_CD ,_, 29_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, one_PRP may_MD do_VB better_JJR by_IN exploiting_VBG the_DT fact_NN that_IN entities_NNS mentioned_VBN in_IN a_DT single_JJ discourse_NN tend_VBP to_TO be_VB semantically_RB related_JJ ._.
E.g._RB ,_, Wikipedia_NNP lists_VBZ several_JJ Michael_NNP Jordans_NNP of_IN who_WP only_RB one_CD is_VBZ a_DT Co_NNP
tion_NN of_IN cell_NN entity_NN ,_, column_NN type_NN ,_, and_CC relationship_NN labeling_NN ._.
A._NNP Einstein_NNP mention_NN or_CC reference_NN to_TO said_VBD entity_NN ._.
These_DT annotation_NN tasks_NNS are_VBP challenging_JJ ._.
When_WRB annotating_VBG entity_NN mentions_VBZ in_IN free-form_JJ text_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT textual_JJ context_NN provides_VBZ clues_NNS for_IN disambiguation_NN ._.
In_IN contrast_NN ,_, table_NN cells_NNS referring_VBG to_TO entities_NNS have_VBP negligible_JJ amounts_NNS of_IN additional_JJ text_NN ._.
Given_VBN each_DT table_NN cell_NN can_MD map_VB to_TO several_JJ entities_NNS -LRB-_-LRB- o_NN
es_NNS such_JJ as_IN Wikipedia_NNP -LRB-_-LRB- 18_CD ,_, 21_CD -RRB-_-RRB- ,_, or_CC the_DT general_JJ web_NN -LRB-_-LRB- 4_CD ,_, 6_CD ,_, 19_CD ,_, 2_CD -RRB-_-RRB- ._.
2_CD ._.
The_DT second_JJ approach_NN is_VBZ to_TO annotate_VB web_NN documents_NNS with_IN entity_NN and_CC relationship_NN labels_NNS from_IN a_DT well-known_JJ catalog_NN like_IN Wikipedia_NNP as_IN in_IN =_JJ -_: =[_NN 10_CD ,_, 17_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT allows_VBZ the_DT enrichment_NN of_IN keyword_JJ queries_NNS with_IN structured_JJ primitives_NNS such_JJ as_IN a_DT type_NN specifier_NN for_IN entities_NNS ._.
The_DT first_JJ approach_NN has_VBZ the_DT advantage_NN of_IN providing_VBG high_JJ quality_NN structured_JJ answers_NNS but_CC
IVERSITY_NN 19,717_CD 6,141,840_CD 311_CD TOTAL_NNP 742,862_CD 95,648,273_CD 129_CD entity_NN disambiguation_NN method_NN ._.
Recently_RB we_PRP have_VBP seen_VBN advanced_JJ entity_NN recognition_NN and_CC disambiguation_NN methods_NNS using_VBG Wikipedia_NNP as_IN entity_NN catalog_NN =_JJ -_: =[_NN 20_CD ,_, 21_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: to_TO automatically_RB link_VB entities_NNS mentioned_VBN in_IN plain_JJ text_NN to_TO their_PRP$ corresponding_JJ Wikipedia_NNP articles_NNS ._.
One_CD of_IN our_PRP$ ongoing_JJ efforts_NNS is_VBZ to_TO use_VB Wikify_NNP 6_CD -LRB-_-LRB- the_DT system_NN based_VBN on_IN -LRB-_-LRB- 21_CD -RRB-_-RRB- -RRB-_-RRB- to_TO detect_VB entity_NN occurrences_NNS
ck_IN this_DT corpora_NN ,_, we_PRP instead_RB leverage_NN Wikipedia_NNP as_IN a_DT knowledge_NN base_NN ._.
Other_JJ research_NN has_VBZ proceeded_VBN in_IN this_DT direction_NN ,_, leveraging_VBG Wikipedia_NNP as_IN the_DT knowledge_NN base_NN for_IN entity_NN disambiguation_NN -LRB-_-LRB- and_CC labeling_NN -RRB-_-RRB- =_JJ -_: =[_NN 11_CD ,_, 13_CD ,_, 14_CD ,_, 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP hope_VBP to_TO incorporate_VB such_JJ methods_NNS ,_, though_IN the_DT noisy_JJ ,_, ungrammatical_JJ nature_NN of_IN Tweets_NNS may_MD prove_VB diffi-cult_JJ for_IN them_PRP ._.
We_PRP note_VBP a_DT key_JJ difference_NN is_VBZ that_IN none_NN of_IN these_DT approaches_NNS are_VBP leveraged_JJ to_TO deter_VB
ch_NN as_IN global_JJ -LRB-_-LRB- exact_JJ or_CC approximate_JJ -RRB-_-RRB- agreement_NN ._.
Not_RB all_DT mentioned_VBN quantities_NNS will_MD map_VB to_TO attributes_NNS in_IN the_DT schema_NN ._.
For_IN those_DT ,_, we_PRP create_VBP a_DT special_JJ background\/no_NN attribute_NN na_TO -LRB-_-LRB- similar_JJ to_TO ``_`` no_DT assignment_NN ''_'' =_SYM -_: =[_NN 12_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Our_PRP$ approach_NN is_VBZ to_TO encode_VB assignment_NN decisions_NNS as_IN 0\/1_CD variables_NNS in_IN a_DT suitable_JJ integer_NN linear_NN program_NN -LRB-_-LRB- ILP_NN -RRB-_-RRB- ._.
Constraints_NNS for_IN the_DT ILP_NNP will_MD come_VB from_IN some_DT natural_JJ snippet_NN and_CC value_NN assignment_NN consider_VB
ang_FW et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ,_, measuring_VBG semantic_JJ similarity_NN between_IN texts_NNS -LRB-_-LRB- Gabrilovich_NNP and_CC Markovitch_NNP ,_, 2007a_CD -RRB-_-RRB- ,_, crossdocument_NN co-reference_NN resolution_NN -LRB-_-LRB- Finin_NN et_FW al._FW ,_, 2009_CD ;_: Mayfield_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ,_, and_CC other_JJ tasks_NNS -LRB-_-LRB- =_JJ -_: =_JJ Kulkarni_NNP et_FW al._FW ,_, 2009_CD -_: =--RRB-_NN ._.
1375_CD Previous_JJ studies_NNS on_IN Wikification_NNP differ_VBP with_IN respect_NN to_TO the_DT corpora_NN they_PRP address_VBP and_CC the_DT subset_NN of_IN expressions_NNS they_PRP attempt_VBP to_TO link_VB ._.
For_IN example_NN ,_, some_DT studies_NNS focus_VBP on_IN linking_VBG only_RB named_VBN entit_NN
their_PRP$ dataset_JJ 27.94_CD %_NN of_IN the_DT surface_NN forms_NNS are_VBP unambiguous_JJ and_CC 46.53_CD %_NN of_IN the_DT ambiguous_JJ ones_NNS can_MD be_VB correctly_RB disambiguated_VBN by_IN just_RB choosing_VBG the_DT default_NN sense_NN -LRB-_-LRB- according_VBG to_TO our_PRP$ index_NN -RRB-_-RRB- ._.
Kulkarni_NNP et_FW al._FW =_SYM -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: attempts_VBZ the_DT joint_JJ optimization_NN of_IN all_DT spotted_JJ surface_NN forms_NNS in_IN order_NN to_TO realize_VB the_DT collective_JJ annotation_NN of_IN entities_NNS ._.
The_DT inference_NN problem_NN formulated_VBN by_IN the_DT authors_NNS is_VBZ NP-hard_JJ ,_, leading_VBG to_TO their_PRP$ pr_NN
arowsky_NN 1992_CD -RRB-_-RRB- -RRB-_-RRB- ._.
We_PRP instead_RB leverage_NN Wikipedia_NNP as_IN a_DT knowledge_NN base_NN ._.
Other_JJ research_NN has_VBZ proceeded_VBN in_IN this_DT direction_NN ,_, leveraging_VBG Wikipedia_NNP as_IN the_DT knowledge_NN base_NN for_IN entity_NN disambiguation_NN -LRB-_-LRB- and_CC labeling_NN -RRB-_-RRB- -LRB-_-LRB- =_JJ -_: =_JJ Kulkarni_NNP et_FW al._FW 2009_CD -_: =_JJ -_: ;_: Mihalcea_NNP and_CC Csomai_NNP 2007_CD ;_: Milne_NNP and_CC Witten_NNP 2008_CD ;_: Cucerzan_NNP 2007_CD -RRB-_-RRB- ._.
We_PRP note_VBP a_DT key_JJ difference_NN is_VBZ that_IN none_NN of_IN these_DT approaches_NNS are_VBP leveraged_JJ to_TO determine_VB the_DT topics_NNS that_IN a_DT user_NN writes_VBZ about_IN ,_, but_CC rather_RB
consists_VBZ of_IN modeling_NN the_DT problem_NN as_IN the_DT labeled_JJ clustering_NN of_IN the_DT nodes_NNS of_IN a_DT newly_RB introduced_VBN graph_NN of_IN topics_NNS ._.
The_DT topics_NNS are_VBP Wikipedia-pages_NNS identified_VBN by_IN means_NNS of_IN recently_RB proposed_VBN topic_NN annotators_NNS =_JJ -_: =[_NN 9_CD ,_, 11_CD ,_, 16_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: applied_VBN to_TO the_DT search_NN results_NNS ,_, and_CC the_DT edges_NNS denote_VBP the_DT relatedness_NN among_IN these_DT topics_NNS computed_VBN by_IN taking_VBG into_IN account_NN the_DT linkage_NN of_IN the_DT Wikipedia-graph_NN ._.
We_PRP tackle_VBP this_DT problem_NN by_IN designing_VBG a_DT novel_JJ
1_LS -RRB-_-RRB- ._.
NLP_NN research_NN has_VBZ harnessed_VBN Wikipedia_NNP as_IN a_DT means_NN for_IN linking_VBG words_NNS and_CC phrases_NNS onto_IN canonical_JJ entities_NNS -LRB-_-LRB- 3_CD ,_, 6_CD -RRB-_-RRB- ._.
This_DT theme_NN has_VBZ been_VBN further_RB pursued_VBN in_IN Web_NN mining_NN ,_, most_RBS notably_RB ,_, the_DT work_NN of_IN -LRB-_-LRB- 12_CD -RRB-_-RRB- and_CC =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Recent_JJ methods_NNS leverage_NN knowledge_NN bases_NNS such_JJ as_IN DBpedia_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ,_, freebase.com_NN ,_, or_CC YAGO_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
These_DT contain_VBP millions_NNS of_IN entities_NNS ,_, with_IN fine-grained_JJ assignment_NN to_TO semantic_JJ types_NNS -LRB-_-LRB- e.g._FW ,_, heavy_JJ metal_NN rock_NN gu_NN
ere_NN is_VBZ overlapping_VBG information_NN in_IN the_DT knowledge-bases_NNS which_WDT can_MD be_VB leveraged_JJ -RRB-_-RRB- and_CC subsequently_RB ,_, how_WRB to_TO merge_VB the_DT -LRB-_-LRB- partial_JJ -RRB-_-RRB- results_NNS ._.
Both_DT tasks_NNS are_VBP non-trivial_JJ because_IN on-the-fly_JJ entity_NN disambiguation_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: may_MD be_VB required_VBN due_JJ to_TO different_JJ vocabularies_NNS ._.
With_IN this_DT overview_NN of_IN the_DT IQ_NNP paradigm_NN ,_, we_PRP now_RB illustrate_VBP two_CD case_NN studies_NNS of_IN how_WRB a_DT system_NN built_VBN on_IN these_DT principles_NNS would_MD work_VB ._.
In_IN the_DT first_JJ case_NN study_NN ,_,
nt_NN Obama_NNP ,_, the_DT entity_NN name_NN ``_`` Obama_NNP ''_'' might_MD refer_VB to_TO PresidentBarack_Obama_NN or_CC to_TO his_PRP$ father_NN Barack_Obama_Sr_NN ._.
The_DT problem_NN of_IN identifying_VBG the_DT right_JJ entity_NN for_IN a_DT given_VBN name_NN is_VBZ known_VBN as_IN entity_NN disambiguation_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, at_IN this_DT point_NN we_PRP assume_VBP :_: 1_CD ._.
Each_DT entity_NN name_NN is_VBZ uniquely_RB addressing_VBG exactly_RB one_CD entity_NN within_IN a_DT given_VBN document_NN ._.
2_CD ._.
The_DT disambiguation_NN is_VBZ solved_VBN externally_RB and_CC a_DT mapping_NN from_IN entity_NN names_NNS t_NN
ovides_VBZ a_DT stunning_JJ contextualization_NN of_IN the_DT input_NN text_NN so_IN that_IN each_DT subsequent_JJ IR-task_NN could_MD be_VB improved_VBN by_IN leveraging_VBG the_DT huge_JJ semantic_JJ network_NN provided_VBN by_IN Wikipedia_NNP ._.
Recently_RB several_JJ works_NNS -LRB-_-LRB- see_VB e.g._FW =_SYM -_: =[_NN 4_CD ,_, 6_CD -RRB-_-RRB- -_: =_JJ -_: and_CC refs_NNS therein_RB -RRB-_-RRB- addressed_VBD the_DT problem_NN of_IN annotating_VBG texts_NNS with_IN hyper-links_NNS to_TO Wikipedia_NNP pages_NNS ._.
We_PRP add_VBP to_TO this_DT flow_NN of_IN work_NN the_DT specialty_NN that_IN the_DT input_NN texts_NNS to_TO be_VB annotated_JJ are_VBP short_JJ ,_, namely_RB ,_, they_PRP
ssigned_VBN entities_NNS =_JJ -_: =[_NN 15_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Coherence_NN between_IN a_DT pair_NN of_IN entities_NNS is_VBZ computed_VBN using_VBG the_DT knowledge_NN base_NN ,_, e.g._FW ,_, based_VBN on_IN the_DT number_NN of_IN common_JJ Wikipedia_NNP pages_NNS that_WDT link_VBP to_TO Wiki_NNP pages_NNS of_IN these_DT two_CD entities_NNS -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
While_IN some_DT approaches_NNS model_VBP the_DT interdependence_NN as_IN sum_NN of_IN their_PRP$ pair-wise_JJ dependencies_NNS -LRB-_-LRB- 18_CD ,_, 15_CD -RRB-_-RRB- ,_, more_RBR recent_JJ techniques_NNS model_VBP the_DT global_JJ interdependence_NN -LRB-_-LRB- 14_CD ,_, 12_CD -RRB-_-RRB- ._.
These_DT studiesconsideronlyentitiespr_NN
c_NN similarity_NN of_IN entity_NN e_SYM with_IN Γd_NNP Global_NNP coherence_NN of_IN entity_NN e_SYM in_FW d_FW disambiguation_NN ._.
Given_VBN an_DT input_NN document_NN ,_, these_DT systems_NNS are_VBP able_JJ to_TO automatically_RB enrich_VB the_DT input_NN text_NN with_IN links_NNS to_TO Wikipedia_NNP pages_NNS =_JJ -_: =[_NN 19_CD ,_, 21_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, this_DT task_NN is_VBZ different_JJ from_IN our_PRP$ entity_NN linking_VBG task_NN in_IN several_JJ respects_NNS :_: firstly_RB ,_, these_DT systems_NNS have_VBP to_TO decide_VB whether_IN the_DT detected_VBN terms_NNS or_CC phrases_NNS are_VBP important_JJ enough_RB in_IN the_DT document_NN to_TO
