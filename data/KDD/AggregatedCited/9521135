Fast_JJ approximate_JJ spectral_JJ clustering_NN
Spectral_JJ clustering_NN refers_VBZ to_TO a_DT flexible_JJ class_NN of_IN clustering_NN procedures_NNS that_WDT can_MD produce_VB high-quality_JJ clusterings_NNS on_IN small_JJ data_NNS sets_NNS but_CC which_WDT has_VBZ limited_VBN applicability_NN to_TO large-scale_JJ problems_NNS due_JJ to_TO its_PRP$ computational_JJ complexity_NN of_IN O_NN -LRB-_-LRB- n3_NN -RRB-_-RRB- in_IN general_JJ ,_, with_IN n_NN the_DT number_NN of_IN data_NNS points_NNS ._.
We_PRP extend_VBP the_DT range_NN of_IN spectral_JJ clustering_NN by_IN developing_VBG a_DT general_JJ framework_NN for_IN fast_JJ approximate_JJ spectral_JJ clustering_NN in_IN which_WDT a_DT distortion-minimizing_JJ local_JJ transformation_NN is_VBZ first_RB applied_VBN to_TO the_DT data_NNS ._.
This_DT framework_NN is_VBZ based_VBN on_IN a_DT theoretical_JJ analysis_NN that_WDT provides_VBZ a_DT statistical_JJ characterization_NN of_IN the_DT effect_NN of_IN local_JJ distortion_NN on_IN the_DT mis-clustering_JJ rate_NN ._.
We_PRP develop_VBP two_CD concrete_JJ instances_NNS of_IN our_PRP$ general_JJ framework_NN ,_, one_CD based_VBN on_IN local_JJ k-means_NN clustering_NN -LRB-_-LRB- KASP_NN -RRB-_-RRB- and_CC one_CD based_VBN on_IN random_JJ projection_NN trees_NNS -LRB-_-LRB- RASP_NN -RRB-_-RRB- ._.
Extensive_JJ experiments_NNS show_VBP that_IN these_DT algorithms_NNS can_MD achieve_VB significant_JJ speedups_NNS with_IN little_JJ degradation_NN in_IN clustering_NN accuracy_NN ._.
Specifically_RB ,_, our_PRP$ algorithms_NNS outperform_VBP k-means_NN by_IN a_DT large_JJ margin_NN in_IN terms_NNS of_IN accuracy_NN ,_, and_CC run_VB several_JJ times_NNS faster_RBR than_IN approximate_JJ spectral_JJ clustering_NN based_VBN on_IN the_DT Nystrom_NNP method_NN ,_, with_IN comparable_JJ accuracy_NN and_CC significantly_RB smaller_JJR memory_NN footprint_NN ._.
Remarkably_RB ,_, our_PRP$ algorithms_NNS make_VBP it_PRP possible_JJ for_IN a_DT single_JJ machine_NN to_TO spectral_JJ cluster_NN data_NNS sets_VBZ with_IN a_DT million_CD observations_NNS within_IN several_JJ minutes_NNS ._.
site_NN direction_NN to_TO our_PRP$ work_NN ,_, clustering_NN can_MD be_VB approximated_VBN by_IN finding_VBG representative_JJ objects_NNS ,_, clustering_VBG them_PRP ,_, and_CC assigning_VBG the_DT remaining_VBG objects_NNS to_TO the_DT clusters_NNS of_IN their_PRP$ representatives_NNS ._.
Yan_NNP et_FW al._FW =_SYM -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: use_VB k-means_NN or_CC RP_NN trees_NNS to_TO find_VB representative_JJ points_NNS ,_, Kaufman_NNP and_CC Rousseeuw_NNP -LRB-_-LRB- 3_CD -RRB-_-RRB- k-medoids_NNS ,_, and_CC Ester_NNP et_FW al._FW -LRB-_-LRB- 4_LS -RRB-_-RRB- the_DT most_RBS central_JJ object_NN of_IN a_DT data_NN page_NN ._.
Representatives_NNS are_VBP also_RB used_VBN to_TO reduce_VB the_DT nu_NN
que-like_JJ structures_NNS also_RB exist_VBP -LRB-_-LRB- 23_CD ,_, 30_CD ,_, 29_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN we_PRP propose_VBP an_DT algorithm_NN that_WDT can_MD handle_VB large_JJ datasets_NNS ,_, particularly_RB those_DT with_IN a_DT high_JJ number_NN of_IN objects_NNS ;_: we_PRP also_RB allow_VBP overlap_VB ._.
The_DT work_NN in_IN =_JJ -_: =[_NN 22_CD ,_, 28_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ similar_JJ to_TO ours_PRP in_IN that_IN the_DT first_JJ step_NN in_IN our_PRP$ algorithm_NN is_VBZ spectral_JJ ,_, similar_JJ to_TO multi-dimensional_JJ scaling_NN -LRB-_-LRB- MDS_NN -RRB-_-RRB- ;_: their_PRP$ algorithm_NN is_VBZ based_VBN on_IN spectral_JJ properties_NNS of_IN the_DT Laplacian_NN of_IN a_DT graph_NN which_WDT t_NN
ely_RB expensive_JJ in_IN both_CC storage_NN space_NN and_CC algorithm_NN runtime_NN ._.
Prior_JJ work_NN have_VBP tried_VBN to_TO address_VB these_DT issues_NNS along_IN three_CD directions_NNS :_: -LRB-_-LRB- a_LS -RRB-_-RRB- sample_NN the_DT data_NN points_NNS and_CC do_VBP computation_NN on_IN a_DT much_RB smaller_JJR matrix_NN =_JJ -_: =[_NN 6,20_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- b_NN -RRB-_-RRB- sparsify_VBP the_DT matrix_NN by_IN a_DT k-nearest_NN neighbor_NN technique_NN and_CC do_VBP computation_NN on_IN a_DT much_RB sparser_JJR matrix_NN -LRB-_-LRB- 1_CD ,_, 4_CD ,_, 19_CD -RRB-_-RRB- ,_, and_CC -LRB-_-LRB- c_LS -RRB-_-RRB- do_VBP computation_NN on_IN lots_NNS of_IN machines_NNS at_IN the_DT same_JJ time_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ._.
Sampling_NN and_CC sparsi_NNS
e_LS clustering_NN problem_NN as_IN a_DT normalized_VBN mincut_NN problem_NN ._.
Unfortunately_RB the_DT spectral_JJ approach_NN is_VBZ not_RB really_RB scalable_JJ ,_, requiring_VBG O_NN -LRB-_-LRB- N3_NN -RRB-_-RRB- time_NN ._.
Recently_RB ,_, a_DT scalable_JJ approximate_JJ spectral_JJ method_NN was_VBD introduced_VBN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT first_RB selects_VBZ representative_JJ points_NNS on_IN which_WDT the_DT full_JJ spectral_JJ clustering_NN is_VBZ performed_VBN ._.
Many_JJ efforts_NNS have_VBP focused_VBN on_IN scaling_VBG spatial_JJ cluster-ing_NN ._.
For_IN scaling_VBG hierarchical_JJ clustering_NN further_RBR ,_,
e_LS ,_, the_DT change_NN in_IN the_DT resulting_VBG coefficient_NN matrix_NN is_VBZ bounded_VBN by_IN a_DT constant_JJ multiple_NN of_IN the_DT small_JJ noise_NN variance_NN ._.
Approximations_NNS to_TO the_DT moments_NNS of_IN the_DT perturbation_NN dW_NN =_JJ ˜_CD W_NN −_NN W_NN are_VBP also_RB given_VBN in_IN -LRB-_-LRB- 28_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 47_CD -RRB-_-RRB- -_: =_JJ -_: :_: E_NN -LRB-_-LRB- dW_NN -RRB-_-RRB- ≈_NN E_NN -LRB-_-LRB- dD_NN -RRB-_-RRB- D_NN −_NN 2_CD K_NN −_NN D_NN −_NN 1_CD E_NN -LRB-_-LRB- dK_NN -RRB-_-RRB- ,_, E_NN -LRB-_-LRB- dW_NN 2_CD -RRB-_-RRB- ≈_NN E_NN -LRB-_-LRB- dD_NN 2_CD -RRB-_-RRB- D_NN −_NN 4_CD K_NN 2_CD +_CC D_NN −_NN 2_CD E_NN -LRB-_-LRB- dK_NN 2_CD -RRB-_-RRB- −_NN E_NN -LRB-_-LRB- dDdK_NN -RRB-_-RRB- D_NN −_NN 3_CD ◦_NNP K._NNP where_WRB dD_NN =_JJ ˜_NN D_NN −_NN D_NN ,_, and_CC dK_NN =_JJ ˜_CD K_NNP −_NNP K_NNP ,_, and_CC ◦_NN denotes_VBZ element-wise_JJ product_NN ._.
A_DT thorough_JJ descript_NN
s_NNS not_RB provide_VBP any_DT performance_NN guarantees_NNS ._.
More_RBR importantly_RB ,_, the_DT choice_NN of_IN the_DT subset_NN is_VBZ often_RB based_VBN on_IN knowledge_NN of_IN the_DT entire_JJ data_NNS matrix_NN ,_, an_DT unrealistic_JJ assumption_NN in_IN our_PRP$ setting_NN ._.
A_DT good_JJ example_NN is_VBZ =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB the_DT subset_NN is_VBZ chosen_VBN by_IN partitioning_VBG the_DT data_NNS space_NN using_VBG k-means_NN or_CC random_JJ projection_NN trees_NNS ._.
Note_VB that_IN this_DT algorithm_NN is_VBZ not_RB relevant_JJ when_WRB we_PRP do_VBP not_RB have_VB a-priori_NN access_NN to_TO the_DT entire_JJ dataset_NN
o_NN a_DT different_JJ notion_NN ∗_NNP Work_NNP done_VBN as_IN an_DT undergraduate_JJ student_NN at_IN IIT_NNP Kanpur_NNP 1of_JJ intrinsic_JJ dimensionality_NN ._.
Both_DT variants_NNS have_VBP already_RB found_VBN numerous_JJ applications_NNS in_IN regression_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- ,_, spectral_JJ clustering_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, face_NN recognition_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- and_CC image_NN super-resolution_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
1.1_CD Contributions_NNS The_DT RPTREE_NN structures_NNS are_VBP new_JJ entrants_NNS in_IN a_DT large_JJ family_NN of_IN space_NN partitioning_VBG data_NNS structures_NNS such_JJ as_IN k-d_NN trees_NNS -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, BBD_NN tre_NN
Limited_JJ apriori_NN knowledge_NN is_VBZ needed_VBN ._.
SSDE-Cluster_NN discovers_VBZ the_DT community_NN structure_NN given_VBN only_RB the_DT number_NN of_IN communities_NNS in_IN the_DT network_NN ._.
We_PRP also_RB discuss_VBP how_WRB to_TO estimate_VB this_DT number_NN ._.
The_DT work_NN in_IN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ similar_JJ to_TO ours_PRP in_IN that_IN it_PRP starts_VBZ with_IN spectral_JJ properties_NNS ,_, similar_JJ to_TO multi-dimensional_JJ scaling_NN -LRB-_-LRB- MDS_NN -RRB-_-RRB- ._.
However_RB ,_, they_PRP construct_VBP the_DT Laplacian_NNP ,_, which_WDT has_VBZ Ω_NN -LRB-_-LRB- n_NN 2_CD -RRB-_-RRB- runtime_NN ._.
A_DT comprehensive_JJ review_NN of_IN
tcomings_NNS ._.
First_RB ,_, finding_VBG eigenvectors_NNS of_IN a_DT matrix_NN takes_VBZ O_NN -LRB-_-LRB- n3_NN -RRB-_-RRB- in_IN general_JJ where_WRB n_NN is_VBZ the_DT number_NN of_IN data_NNS points_NNS ._.
Which_WDT recent_JJ work_NN has_VBZ tried_VBN to_TO address_VB this_DT with_IN multilevel_JJ -LRB-_-LRB- 17_CD -RRB-_-RRB- and_CC data_NNS preprocessing_VBG =_JJ -_: =[_NN 6_CD ,_, 20_CD -RRB-_-RRB- -_: =_JJ -_: techniques_NNS ._.
Second_JJ ,_, simply_RB using_VBG the_DT first_JJ k_NN eigenvectors_NNS seems_VBZ to_TO fail_VB on_IN many_JJ real_JJ datasets_NNS because_IN they_PRP often_RB turns_VBZ out_RP to_TO be_VB uninformative_JJ ,_, especially_RB in_IN the_DT presence_NN of_IN noise_NN ._.
This_DT prompted_VBD work_NN
