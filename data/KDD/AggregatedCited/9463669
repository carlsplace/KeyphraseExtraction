Composition_NN attacks_NNS and_CC auxiliary_JJ information_NN in_IN data_NNS privacy_NN
Privacy_NN is_VBZ an_DT increasingly_RB important_JJ aspect_NN of_IN data_NN publishing_NN ._.
Reasoning_NN about_IN privacy_NN ,_, however_RB ,_, is_VBZ fraught_JJ with_IN pitfalls_NNS ._.
One_CD of_IN the_DT most_RBS significant_JJ is_VBZ the_DT auxiliary_JJ information_NN -LRB-_-LRB- also_RB called_VBN external_JJ knowledge_NN ,_, background_NN knowledge_NN ,_, or_CC side_NN information_NN -RRB-_-RRB- that_IN an_DT adversary_NN gleans_VBZ from_IN other_JJ channels_NNS such_JJ as_IN the_DT web_NN ,_, public_JJ records_NNS ,_, or_CC domain_NN knowledge_NN ._.
This_DT paper_NN explores_VBZ how_WRB one_CD can_NN reason_NN about_IN privacy_NN in_IN the_DT face_NN of_IN rich_JJ ,_, realistic_JJ sources_NNS of_IN auxiliary_JJ information_NN ._.
Specifically_RB ,_, we_PRP investigate_VBP the_DT effectiveness_NN of_IN current_JJ anonymization_NN schemes_NNS in_IN preserving_NN privacy_NN when_WRB multiple_JJ organizations_NNS independently_RB release_VBP anonymized_JJ data_NNS about_IN overlapping_VBG populations_NNS ._.
1_CD ._.
We_PRP investigate_VBP composition_NN attacks_NNS ,_, in_IN which_WDT an_DT adversary_NN uses_VBZ independent_JJ anonymized_JJ releases_NNS to_TO breach_VB privacy_NN ._.
We_PRP explain_VBP why_WRB recently_RB proposed_VBN models_NNS of_IN limited_JJ auxiliary_JJ information_NN fail_VBP to_TO capture_VB composition_NN attacks_NNS ._.
Our_PRP$ experiments_NNS demonstrate_VBP that_IN even_RB a_DT simple_JJ instance_NN of_IN a_DT composition_NN attack_NN can_MD breach_VB privacy_NN in_IN practice_NN ,_, for_IN a_DT large_JJ class_NN of_IN currently_RB proposed_VBN techniques_NNS ._.
The_DT class_NN includes_VBZ k-anonymity_NN and_CC several_JJ recent_JJ variants_NNS ._.
2_CD ._.
On_IN a_DT more_RBR positive_JJ note_NN ,_, certain_JJ randomization-based_JJ notions_NNS of_IN privacy_NN -LRB-_-LRB- such_JJ as_IN differential_JJ privacy_NN -RRB-_-RRB- provably_RB resist_VBP composition_NN attacks_NNS and_CC ,_, in_IN fact_NN ,_, the_DT use_NN of_IN arbitrary_JJ side_NN information_NN ._.
This_DT resistance_NN enables_VBZ ``_`` stand-alone_JJ ''_'' design_NN of_IN anonymization_NN schemes_NNS ,_, without_IN the_DT need_NN for_IN explicitly_RB keeping_VBG track_NN of_IN other_JJ releases_NNS ._.
We_PRP provide_VBP a_DT precise_JJ formulation_NN of_IN this_DT property_NN ,_, and_CC prove_VBP that_IN an_DT important_JJ class_NN of_IN relaxations_NNS of_IN differential_JJ privacy_NN also_RB satisfy_VBP the_DT property_NN ._.
This_DT significantly_RB enlarges_VBZ the_DT class_NN of_IN protocols_NNS known_VBN to_TO enable_VB modular_JJ design_NN ._.
zed_VBN data_NNS ,_, there_EX is_VBZ no_DT loss_NN of_IN data_NN accuracy_NN in_IN the_DT aggregation_NN results_NNS ._.
A_DT new_JJ approach_NN to_TO providing_VBG anonymity_NN when_WRB sharing_VBG data_NNS has_VBZ appeared_VBN with_IN the_DT recent_JJ stream_NN of_IN research_NN on_IN differential_JJ privacy_NN =_JJ -_: =[_NN 7_CD ,_, 10_CD ,_, 12_CD ,_, 9_CD -RRB-_-RRB- -_: =_JJ -_: ,_, in_IN which_WDT noise_NN is_VBZ added_VBN to_TO query_VB results_NNS to_TO prevent_VB the_DT querier_NN from_IN inferring_VBG information_NN about_IN individuals_NNS ._.
Our_PRP$ work_NN ,_, on_IN the_DT other_JJ hand_NN ,_, is_VBZ concerned_VBN with_IN adding_VBG proofs_NNS of_IN integrity_NN to_TO exact_JJ respo_NN
hierarchies_NNS associated_VBN with_IN the_DT nominal_JJ attributes_NNS ._.
For_IN each_DT dataset_NN ,_, we_PRP create_VBP a_DT set_NN of_IN 40000_CD random_JJ rangecount_NN queries_NNS ,_, such_JJ that_IN the_DT number_NN of_IN predicates_NNS in_IN each_DT query_NN is_VBZ uniformly_RB distributed_VBN in_IN =_JJ -_: =[_NN 1_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Each_DT query_NN predicate_VB ``_`` Ai_FW ∈_FW 4_CD Both_DT datasets_NNS are_VBP public_JJ available_JJ as_IN part_NN of_IN the_DT Integrated_NNP Public_NNP Use_NNP Microdata_NNP Series_NNP -LRB-_-LRB- 12_CD -RRB-_-RRB- ._.
Si_NNP ''_'' is_VBZ generated_VBN as_IN follows_VBZ ._.
First_RB ,_, we_PRP choose_VBP Ai_NNP randomly_RB from_IN the_DT attribu_NN
er_IN we_PRP present_VBP a_DT new_JJ privacy_NN framework_NN ,_, called_VBN Pufferfish_NNP ._.
This_DT framework_NN can_MD be_VB used_VBN to_TO study_VB existing_VBG privacy_NN definitions_NNS like_IN differential_JJ privacy_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, to_TO study_VB important_JJ concepts_NNS like_IN composition_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC to_TO generate_VB privacy_NN definitions_NNS that_WDT are_VBP customized_VBN for_IN different_JJ application_NN domains_NNS ._.
The_DT Pufferfish_NNP framework_NN follows_VBZ modern_JJ design_NN guidelines_NNS such_JJ as_IN adherence_NN to_TO privacy_NN axioms_NNS -LRB-_-LRB- 21_CD ,_, 20_CD -RRB-_-RRB- and_CC
42_CD -RRB-_-RRB- ,_, nor_CC the_DT sensitive_JJ attributes_NNS associated_VBN with_IN any_DT individual_JJ -LRB-_-LRB- 32_CD ,_, 34_CD -RRB-_-RRB- ._.
Multiple_JJ releases_NNS of_IN the_DT same_JJ dataset_NN or_CC mere_JJ knowledge_NN of_IN the_DT k-anonymization_NN algorithm_NN may_MD completely_RB break_VB the_DT protection_NN =_JJ -_: =[_NN 19_CD ,_, 52_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Variants_NNS ,_, such_JJ as_IN l-diversity_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- and_CC m-invariance_NN -LRB-_-LRB- 50_CD -RRB-_-RRB- ,_, suffer_VBP from_IN many_JJ of_IN the_DT same_JJ flaws_NNS ._.
Program_NN analysis_NN techniques_NNS can_MD be_VB used_VBN to_TO estimate_VB how_WRB much_JJ information_NN is_VBZ leaked_VBN by_IN a_DT program_NN -LRB-_-LRB- 36_CD -RRB-_-RRB- ._.
Pr_NN
flix_NN -LRB-_-LRB- 35_CD ,_, 36_CD -RRB-_-RRB- data_NNS -RRB-_-RRB- have_VBP occurred_VBN when_WRB such_JJ intuition_NN was_VBD not_RB followed_VBN by_IN a_DT thorough_JJ analysis_NN ._.
In_IN other_JJ cases_NNS ,_, subtle_JJ implicit_JJ assumptions_NNS created_VBD weaknesses_NNS that_WDT could_MD be_VB exploited_VBN to_TO breach_VB privacy_NN =_JJ -_: =[_NN 27_CD ,_, 46_CD ,_, 23_CD ,_, 30_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Similarly_RB ,_, the_DT choice_NN of_IN a_DT privacy_NN mechanism_NN based_VBN on_IN some_DT intuitively_RB plausible_JJ measures_NNS of_IN utility_NN can_MD result_VB in_IN a_DT dataset_NN that_WDT is_VBZ not_RB as_RB useful_JJ as_IN it_PRP could_MD be_VB -LRB-_-LRB- 37_CD ,_, 24_CD ,_, 25_CD -RRB-_-RRB- ._.
For_IN example_NN ,_, Ghosh_FW et_FW
an_DT attacker_NN ._.
However_RB ,_, many_JJ reasonable_JJ types_NNS of_IN background_NN knowledge_NN can_MD cause_VB privacy_NN breaches_NNS when_WRB combined_VBN with_IN differential_JJ privacy_NN -LRB-_-LRB- in_IN other_JJ words_NNS ,_, differential_JJ privacy_NN composes_VBZ well_RB with_IN itself_PRP =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: but_CC not_RB necessarily_RB with_IN other_JJ privacy_NN definitions_NNS or_CC data_NNS release_NN mechanisms_NNS -RRB-_-RRB- ._.
Such_JJ background_NN knowledge_NN includes_VBZ previously_RB released_VBN exact_JJ query_NN answers_NNS ._.
We_PRP demonstrate_VBP a_DT privacy_NN breach_NN using_VBG this_DT
and_CC should_MD still_RB provide_VB privacy_NN guarantees_NNS even_RB when_WRB subjected_VBN to_TO joint_JJ analysis_NN ._.
The_DT issue_NN of_IN composition_NN underlies_VBZ many_JJ of_IN the_DT shortcomings_NNS of_IN current_JJ privacy_NN guarantees_NNS ._.
For_IN example_NN ,_, Ganta_NNP et_FW al._FW =_SYM -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: show_VBP that_IN independent_JJ k-anonymizations_NNS of_IN intersecting_VBG data_NNS sets_NNS can_MD leak_NN volumes_NNS of_IN sensitive_JJ data_NNS ._.
Here_RB we_PRP review_VBP two_CD prior_JJ results_NNS on_IN the_DT composition_NN properties_NNS of_IN differential_JJ privacy_NN ,_, one_CD with_IN a_DT
as_IN the_DT removal_NN of_IN Personally_RB Identifiable_JJ Information_NN -RRB-_-RRB- to_TO more_RBR sophisticated_JJ anonymization_NN mechanisms_NNS satisfying_VBG privacy_NN definitions_NNS like_IN k-anonymity_NN -LRB-_-LRB- 25_CD -RRB-_-RRB- and_CC ℓ-diversity_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
However_RB ,_, Ganta_NNP et_FW al._FW =_SYM -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Kifer_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- showed_VBD that_IN practical_JJ attacks_NNS can_MD be_VB mounted_VBN against_IN all_PDT these_DT techniques_NNS ._.
A_DT recent_JJ definition_NN called_VBN differential_JJ privacy_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- formalizes_VBZ the_DT notion_NN of_IN privacy_NN of_IN an_DT individual_NN in_IN a_DT da_NN
anonymization_NN ,_, i.e._FW using_VBG k-Anonymity_NN -LRB-_-LRB- 32_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 34_CD -RRB-_-RRB- ,_, on_IN the_DT other_JJ hand_NN ,_, is_VBZ a_DT low_JJ cost_NN solution_NN but_CC does_VBZ not_RB provide_VB strong_JJ privacy_NN ,_, as_IN k-Anonymity_NN and_CC its_PRP$ variants_NNS are_VBP vulnerable_JJ to_TO a_DT number_NN of_IN attacks_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Such_JJ attacks_NNS also_RB apply_VBP to_TO hybrid_JJ solutions_NNS that_WDT run_VBP PIR_NNP on_IN k-anonymous_JJ data_NNS subset_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 35_CD -RRB-_-RRB- ._.
The_DT aim_NN of_IN this_DT paper_NN is_VBZ to_TO design_VB techniques_NNS towards_IN a_DT practical_JJ private_JJ database_NN query_NN process_NN
ch_NN allows_VBZ an_DT observer_NN to_TO guess_VB the_DT value_NN of_IN a_DT particular_JJ attribute_NN of_IN a_DT tuple_NN ._.
The_DT attack_NN is_VBZ considered_VBN successful_JJ when_WRB the_DT guess_NN is_VBZ correct_JJ with_IN probability_NN larger_JJR than_IN is_VBZ intended_VBN by_IN the_DT anonymizer_NN =_JJ -_: =[_NN 21_CD ,_, 9_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN parallel_NN ,_, a_DT more_RBR principled_JJ approach_NN to_TO privacy_NN has_VBZ arisen_VBN ,_, in_IN the_DT form_NN of_IN differential_JJ privacy_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- ._.
In_IN its_PRP$ simplest_JJS form_NN ,_, differential_JJ privacy_NN releases_VBZ statistics_NNS ,_, by_IN computing_VBG the_DT exact_JJ value_NN o_NN
which_WDT the_DT analyst_NN can_MD study_VB in_IN place_NN of_IN the_DT original_NN ._.
While_IN publishing_VBG a_DT graph_NN allows_VBZ a_DT broader_JJR range_NN of_IN analysis_NN ,_, anonymization_NN is_VBZ a_DT much_RB weaker_JJR notion_NN of_IN privacy_NN and_CC is_VBZ vulnerable_JJ to_TO attack_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 21_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Furthermore_RB ,_, for_IN the_DT analyst_NN interested_JJ in_IN studying_VBG the_DT degree_NN distribution_NN ,_, these_DT techniques_NNS may_MD not_RB scale_VB to_TO largegraphs_NNS and_CC can_MD introduce_VB considerable_JJ distortion_NN ._.
For_IN example_NN ,_, the_DT techniq_NN
guarantee_NN made_VBN on_IN all_DT possible_JJ inputs_NNS I_NN and_CC algorithm_NN 's_POS outputs_NNS ,_, so_RB is_VBZ this_DT relaxation_NN ._.
Thus_RB it_PRP is_VBZ different_JJ from_IN the_DT average-case_JJ relaxations_NNS considered_VBN in_IN the_DT past_JJ -LRB-_-LRB- such_JJ as_IN -LRB-_-LRB- ǫ_NN ,_, δ_NN -RRB-_-RRB- -_: semantic_JJ privacy_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
4.2_CD Some_DT Properties_NNPS of_IN Adversarial_JJ Privacy_NN We_PRP mention_VBP here_RB some_DT properties_NNS of_IN adversarial_JJ privacy_NN that_WDT follow_VBP from_IN its_PRP$ relationship_NN with_IN ǫ-indistinguishability_NN ._.
4.2.1_CD Protecting_VBG Boolean_NNP Properties_NNPS
42_CD -RRB-_-RRB- ,_, nor_CC the_DT sensitive_JJ attributes_NNS associated_VBN with_IN any_DT individual_JJ -LRB-_-LRB- 32_CD ,_, 34_CD -RRB-_-RRB- ._.
Multiple_JJ releases_NNS of_IN the_DT same_JJ dataset_NN or_CC mere_JJ knowledge_NN of_IN the_DT k-anonymization_NN algorithm_NN may_MD completely_RB break_VB the_DT protection_NN =_JJ -_: =[_NN 19_CD ,_, 52_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Variants_NNS ,_, such_JJ as_IN l-diversity_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- and_CC m-invariance_NN -LRB-_-LRB- 50_CD -RRB-_-RRB- ,_, suffer_VBP from_IN many_JJ of_IN the_DT same_JJ flaws_NNS ._.
Program_NN analysis_NN techniques_NNS can_MD be_VB used_VBN to_TO estimate_VB how_WRB much_JJ information_NN is_VBZ leaked_VBN by_IN a_DT program_NN -LRB-_-LRB- 36_CD -RRB-_-RRB- ._.
Pr_NN
a_DT lottery_NN always_RB has_VBZ a_DT victim_NN whose_WP$ data_NNS is_VBZ revealed_VBN completely_RB ._.
Differential_JJ privacy_NN precludes_VBZ such_JJ victimization_NN by_IN guaranteeing_VBG that_IN no_DT output_NN reveals_VBZ any_DT single_JJ person_NN 's_POS data_NNS with_IN certainty_NN ._.
See_VB =_SYM -_: =[_NN 19_CD ,_, 31_CD -RRB-_-RRB- -_: =_SYM -_: for_IN discussion_NN ._.
3_LS ._.
In_IN a_DT differentially_RB private_JJ mechanism_NN ,_, every_DT possible_JJ output_NN has_VBZ either_CC non-zero_JJ probability_NN on_IN every_DT input_NN or_CC zero_NN probability_NN on_IN every_DT input_NN ._.
This_DT should_MD be_VB compared_VBN with_IN the_DT lit_VBN
nst_NN collusion_NN ._.
However_RB ,_, to_TO the_DT best_JJS of_IN our_PRP$ knowledge_NN ,_, none_NN of_IN them_PRP can_MD achieve_VB the_DT same_JJ strength_NN of_IN protection_NN as_IN described_VBN in_IN Section_NNP 1.2_CD ._.
The_DT works_VBZ closest_JJS to_TO ours_PRP are_VBP those_DT on_IN differential_JJ privacy_NN =_JJ -_: =[_NN 9,10,13,24_CD -RRB-_-RRB- -_: =_SYM -_: ._.
They_PRP can_MD be_VB employed_VBN to_TO publish_VB several_JJ anonymized_JJ versions_NNS which_WDT ,_, even_RB put_VBD all_DT together_RB by_IN an_DT adversary_NN ,_, still_RB ensure_VB privacy_NN to_TO some_DT extent_NN ._.
Nevertheless_RB ,_, as_IN shown_VBN in_IN -LRB-_-LRB- 24_CD -RRB-_-RRB- ,_, the_DT combination_NN of_IN any_DT
lely_RB on_IN the_DT perceived_VBN complexity_NN of_IN their_PRP$ data_NNS transformations_NNS ,_, there_EX has_VBZ been_VBN a_DT growing_VBG body_NN of_IN work_NN that_WDT investigates_VBZ strategies_NNS an_DT attacker_NN may_MD use_VB to_TO breach_VB privacy_NN ._.
These_DT include_VBP linking_VBG attacks_NN =_JJ -_: =[_NN 46_CD ,_, 21_CD -RRB-_-RRB- -_: =_JJ -_: ,_, exploitation_NN of_IN properties_NNS of_IN the_DT sanitization_NN algorithm_NN -LRB-_-LRB- 48_CD ,_, 20_CD -RRB-_-RRB- ,_, use_NN of_IN background_NN knowledge_NN -LRB-_-LRB- 35_CD ,_, 36_CD ,_, 10_CD ,_, 23_CD ,_, 5_CD -RRB-_-RRB- and_CC reasoning_NN about_IN how_WRB an_DT attacker_NN 's_POS prior_JJ belief_NN changes_NNS into_IN a_DT posterior_JJ belief_NN
