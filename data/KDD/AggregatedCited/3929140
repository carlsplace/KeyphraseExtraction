Formulating_VBG distance_NN functions_NNS via_IN the_DT kernel_NN trick_NN
Tasks_NNS of_IN data_NNS mining_NN and_CC information_NN retrieval_NN depend_VBP on_IN a_DT good_JJ distance_NN function_NN for_IN measuring_VBG similarity_NN between_IN data_NNS instances_NNS ._.
The_DT most_RBS effective_JJ distance_NN function_NN must_MD be_VB formulated_VBN in_IN a_DT context-dependent_JJ -LRB-_-LRB- also_RB application_NN -_: ,_, data_NNS -_: ,_, and_CC user-dependent_JJ -RRB-_-RRB- way_NN ._.
In_IN this_DT paper_NN ,_, we_PRP propose_VBP to_TO learn_VB a_DT distance_NN function_NN by_IN capturing_VBG the_DT nonlinear_JJ relationships_NNS among_IN contextual_JJ information_NN provided_VBN by_IN the_DT application_NN ,_, data_NNS ,_, or_CC user_NN ._.
We_PRP show_VBP that_IN through_IN a_DT process_NN called_VBN the_DT ``_`` kernel_NN trick_NN ,_, ''_'' such_JJ nonlinear_JJ relationships_NNS can_MD be_VB learned_VBN efficiently_RB in_IN a_DT projected_JJ space_NN ._.
Theoretically_RB ,_, we_PRP substantiate_VBP that_IN our_PRP$ method_NN is_VBZ both_CC sound_JJ and_CC optimal_JJ ._.
Empirically_RB ,_, using_VBG several_JJ datasets_NNS and_CC applications_NNS ,_, we_PRP demonstrate_VBP that_IN our_PRP$ method_NN is_VBZ effective_JJ and_CC useful_JJ ._.
,_, ULP_NNP returns_VBZ to_TO the_DT second_JJ step_NN using_VBG the_DT newly_RB aligned_VBN kernel_NN matrix_NN to_TO conduct_VB an_DT unsupervised_JJ ,_, membership_NN stability_NN test_NN ._.
When_WRB the_DT algorithm_NN converges_VBZ ,_, ULP_NNP outputs_VBZ a_DT kernel_NN matrix_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- or_CC function_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
ULP_NNP is_VBZ essential_JJ for_IN large-scale_JJ information_NN management_NN ._.
First_RB ,_, for_IN a_DT large-scale_JJ task_NN ,_, a_DT supervised_JJ approach_NN for_IN pattern_NN analysis_NN or_CC knowledge_NN discovery_NN is_VBZ not_RB scalable_JJ ._.
ULP_NNP uses_VBZ the_DT unlabeled_JJ data_NNS
126_CD -RRB-_-RRB- ._.
This_DT algorithm_NN is_VBZ shown_VBN to_TO enable_VB significant_JJ knowledge_NN transfer_NN between_IN related_JJ classification_NN tasks_NNS with_IN small_JJ samples_NNS ._.
Another_DT algorithm_NN which_WDT may_MD be_VB used_VBN for_IN kernel_NN learning_NN is_VBZ presented_VBN in_IN =_JJ -_: =[_NN 157_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB an_DT existing_VBG kernel_NN matrix_NN is_VBZ modified_VBN ,_, and_CC then_RB approximated_VBN by_IN a_DT learned_VBN Mahalanobis_NNP metric_NN in_IN the_DT induced_VBN feature_NN space_NN ._.
1.2.3_CD Learning_NNP from_IN equivalence_JJ constraints_NNS In_IN recent_JJ years_NNS there_RB has_VBZ
between_IN the_DT alignment_NN score_NN and_CC the_DT generalization_NN performance_NN of_IN the_DT resulting_VBG classifier_NN ._.
This_DT has_VBZ motivated_VBN various_JJ computational_JJ methods_NNS of_IN optimizing_VBG kernelsalignment_NN ,_, including_VBG metric_JJ learning_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, eigendecomposition_NN of_IN the_DT Gram_NN matrix_NN -LRB-_-LRB- 11_CD ,_, 15_CD -RRB-_-RRB- and_CC linear_JJ combination_NN of_IN kernels_NNS -LRB-_-LRB- 16_CD ,_, 17_CD -RRB-_-RRB- ._.
We_PRP will_MD focus_VB on_IN the_DT latter_NN of_IN these_DT issues_NNS ,_, which_WDT consider_VBP the_DT kernel_NN expansion_NN κα_NN -LRB-_-LRB- xi_NN ,_, xj_NN -RRB-_-RRB- =_JJ m_NN αkκk_NN -LRB-_-LRB- xi_NN ,_, xj_NN -RRB-_-RRB-
126_CD -RRB-_-RRB- ._.
This_DT algorithm_NN is_VBZ shown_VBN to_TO enable_VB significant_JJ knowledge_NN transfer_NN between_IN related_JJ classification_NN tasks_NNS with_IN small_JJ samples_NNS ._.
Another_DT algorithm_NN which_WDT may_MD be_VB used_VBN for_IN kernel_NN learning_NN is_VBZ presented_VBN in_IN =_JJ -_: =[_NN 157_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB an_DT existing_VBG kernel_NN matrix_NN is_VBZ modified_VBN ,_, and_CC then_RB approximated_VBN by_IN a_DT learned_VBN Mahalanobis_NNP metric_NN in_IN the_DT induced_VBN feature_NN space_NN ._.
1.2.3_CD Learning_NNP from_IN equivalence_JJ constraints_NNS In_IN recent_JJ years_NNS there_RB has_VBZ
rieval_JJ domain_NN that_IN a_DT query_NN concept_NN is_VBZ typically_RB a_DT nonlinear_JJ combination_NN of_IN perceptual_JJ features_NNS -LRB-_-LRB- color_NN ,_, texture_NN ,_, and_CC shape_NN -RRB-_-RRB- -LRB-_-LRB- 21_CD ,_, 24_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN we_PRP first_JJ review_NN a_DT nonlinear-transformation_JJ framework_NN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_SYM -_: on_IN the_DT feature_NN space_NN to_TO gain_VB greater_JJR flexibility_NN for_IN mapping_NN features_NNS to_TO semantics_NNS ;_: we_PRP then_RB detail_NN two_CD companion_NN algorithms_NNS ,_, one_CD for_IN collecting_VBG contextual_JJ information_NN and_CC one_CD for_IN speeding_VBG up_RP function_NN
