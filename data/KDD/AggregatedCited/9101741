Learning_NNP classifiers_NNS from_IN only_RB positive_JJ and_CC unlabeled_JJ data_NNS
The_DT input_NN to_TO an_DT algorithm_NN that_WDT learns_VBZ a_DT binary_JJ classifier_NN normally_RB consists_VBZ of_IN two_CD sets_NNS of_IN examples_NNS ,_, where_WRB one_CD set_NN consists_VBZ of_IN positive_JJ examples_NNS of_IN the_DT concept_NN to_TO be_VB learned_VBN ,_, and_CC the_DT other_JJ set_NN consists_VBZ of_IN negative_JJ examples_NNS ._.
However_RB ,_, it_PRP is_VBZ often_RB the_DT case_NN that_IN the_DT available_JJ training_NN data_NNS are_VBP an_DT incomplete_JJ set_NN of_IN positive_JJ examples_NNS ,_, and_CC a_DT set_NN of_IN unlabeled_JJ examples_NNS ,_, some_DT of_IN which_WDT are_VBP positive_JJ and_CC some_DT of_IN which_WDT are_VBP negative_JJ ._.
The_DT problem_NN solved_VBD in_IN this_DT paper_NN is_VBZ how_WRB to_TO learn_VB a_DT standard_JJ binary_JJ classifier_NN given_VBN a_DT nontraditional_JJ training_NN set_NN of_IN this_DT nature_NN ._.
Under_IN the_DT assumption_NN that_IN the_DT labeled_JJ examples_NNS are_VBP selected_VBN randomly_RB from_IN the_DT positive_JJ examples_NNS ,_, we_PRP show_VBP that_IN a_DT classifier_NN trained_VBN on_IN positive_JJ and_CC unlabeled_JJ examples_NNS predicts_VBZ probabilities_NNS that_WDT differ_VBP by_IN only_RB a_DT constant_JJ factor_NN from_IN the_DT true_JJ conditional_JJ probabilities_NNS of_IN being_VBG positive_JJ ._.
We_PRP show_VBP how_WRB to_TO use_VB this_DT result_NN in_IN two_CD different_JJ ways_NNS to_TO learn_VB a_DT classifier_NN from_IN a_DT nontraditional_JJ training_NN set_NN ._.
We_PRP then_RB apply_VBP these_DT two_CD new_JJ methods_NNS to_TO solve_VB a_DT real-world_JJ problem_NN :_: identifying_VBG protein_NN records_NNS that_WDT should_MD be_VB included_VBN in_IN an_DT incomplete_JJ specialized_JJ molecular_JJ biology_NN database_NN ._.
Our_PRP$ experiments_NNS in_IN this_DT domain_NN show_VBP that_IN models_NNS trained_VBN using_VBG the_DT new_JJ methods_NNS perform_VBP better_RBR than_IN the_DT current_JJ state-of-the-art_JJ biased_VBN SVM_NN method_NN for_IN learning_VBG from_IN positive_JJ and_CC unlabeled_JJ examples_NNS ._.
sparser_JJR query_NN vectors_NNS ;_: both_DT and_CC work_NN much_RB better_JJR than_IN the_DT Rocchio_NNP algorithm_NN ,_, with_IN being_VBG much_RB faster_RBR than_IN ._.
4_LS ._.
Related_NNP Work_NNP PU_NN Learning_NNP has_VBZ been_VBN studied_VBN recently_RB in_IN the_DT context_NN of_IN text_NN classification_NN =_JJ -_: =[_NN 3_CD ,_, 2_CD ,_, 5_CD ,_, 12_CD ,_, 18_CD ,_, 17_CD ,_, 15_CD ,_, 7_CD ,_, 35_CD ,_, 34_CD ,_, 37_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Actually_RB •_FW •_FW •_FW it_PRP should_MD be_VB more_RBR effective_JJ because_IN it_PRP directly_RB optimises_VBZ meaningful_JJ multivariate_JJ performance_NN measures_NNS ;_: it_PRP is_VBZ hundreds_NNS of_IN times_NNS more_RBR efficient_JJ because_IN it_PRP only_RB needs_VBZ to_TO train_VB one_CD SVM_NN c_NN
tive_JJ training_NN data_NNS ,_, we_PRP use_VBP PU_NN learning_VBG to_TO solve_VB the_DT problem_NN -LRB-_-LRB- Liu_NNP et_FW al._FW 2002_CD ;_: Yu_NNP et_FW al._FW 2002_CD ;_: Denis_NNP et_FW al._FW 2002_CD ;_: Li_NNP et_FW al._FW 2003_CD ;_: Lee_NNP and_CC Liu_NNP ,_, 2003_CD ;_: Liu_NNP et_FW al._FW 2003_CD ;_: Denis_NNP et_FW al._FW 2003_CD ;_: Li_NNP et_FW al._FW 2007_CD ;_: =_JJ -_: =_JJ Elkan_NNP and_CC Noto_NNP ,_, 2008_CD -_: =_JJ -_: ;_: Li_NNP et_FW al._FW 2009_CD ;_: Li_NNP et_FW al._FW 2010_CD -RRB-_-RRB- ._.
We_PRP will_MD discuss_VB this_DT learning_NN model_NN further_RBR in_IN Section_NNP 3_CD ._.
Another_DT related_JJ work_NN to_TO ours_PRP is_VBZ transfer_NN learning_NN or_CC domain_NN adaptation_NN ._.
Unlike_IN our_PRP$ problem_NN setting_NN ,_, transfe_NN
articles_NNS ._.
The_DT system_NN then_RB adjusts_VBZ the_DT trained_JJ model_NN mathematically_RB to_TO account_VB for_IN the_DT fact_NN that_IN a_DT small_JJ fraction_NN of_IN unlabeled_JJ articles_NNS are_VBP actually_RB positive_JJ ;_: for_IN details_NNS see_VBP Elkan_NNP and_CC Noto_NNP ,_, KDD_NNP 2008_CD =_SYM -_: =[_NN 68_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT features_NNS that_IN PMAC_NN extracts_NNS from_IN PubMed_NNP are_VBP •_JJ Words_NNS in_IN an_DT article_NN 's_POS abstract_JJ ,_, •_JJ Words_NNS in_IN its_PRP$ title_NN ,_, •_CD Author_NN names_NNS and_CC affiliations_NNS ,_, •_NNP Journal_NNP name_NN and_CC publication_NN type_NN ,_, •_NNP Chemical_NNP substances_NNS me_PRP
ied_VBD unbalanced_JJ weights_NNS to_TO positive_JJ and_CC unlabeled_JJ observations_NNS under_IN a_DT maximum_JJ margin_NN framework_NN ._.
This_DT approach_NN doubly_RB penalized_VBD a_DT SVM_NN and_CC demonstrated_VBD good_JJ empirical_JJ performance_NN ._.
A_DT more_RBR recently_RB paper_NN =_JJ -_: =[_NN 61_CD -RRB-_-RRB- -_: =_SYM -_: discussed_VBD an_DT alternative_JJ Bayesian_JJ approach_NN to_TO learning_VBG a_DT classifier_NN from_IN only_RB positive_JJ and_CC unlabeled_JJ observations_NNS ._.
Unfortunately_RB ,_, all_PDT these_DT methods_NNS concentrated_VBD on_IN the_DT very_RB limited_JJ positive_JJ labels_NNS an_DT
ust_NN preferences_NNS of_IN individual_JJ researchers_NNS ._.
Previous_JJ work_NN has_VBZ also_RB considered_VBN the_DT more_RBR general_JJ ,_, yet_RB related_JJ ,_, problem_NN of_IN taking_VBG positive_JJ examples_NNS of_IN membership_NN in_IN a_DT set_NN and_CC using_VBG them_PRP to_TO expand_VB the_DT set_NN =_JJ -_: =[_NN 17_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
While_IN such_JJ approacheshave_NN been_VBN applied_VBN to_TO the_DT domain_NN of_IN research_NN literature_NN ,_, they_PRP do_VBP not_RB explicitly_RB model_VB the_DT particular_JJ characteristics_NNS of_IN our_PRP$ problem_NN ,_, e.g._FW ,_, the_DT effect_NN of_IN citations_NNS ,_, publication_NN ve_NN
ignificance_JJ standard_JJ supervised_JJ classification_NN methods_NNS assuming_VBG that_IN all_DT unlabeled_JJ examples_NNS are_VBP negative_JJ and_CC using_VBG cross-validation_NN to_TO obtain_VB non-trivial_JJ predictions_NNS for_IN the_DT unlabeled_JJ examples_NNS -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 15_CD ,_, 9_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
It_PRP is_VBZ shown_VBN in_IN -LRB-_-LRB- 9_CD -RRB-_-RRB- that_IN ,_, under_IN the_DT assumption_NN that_IN the_DT labeled_JJ examples_NNS are_VBP selected_VBN randomly_RB from_IN the_DT positive_JJ examples_NNS ,_, this_DT approach_NN predicts_VBZ class_NN conditional_JJ probabilities_NNS that_WDT differ_VBP by_IN only_RB
ever_RB ,_, the_DT issue_NN has_VBZ not_RB yet_RB been_VBN investigated_VBN in_IN the_DT context_NN of_IN the_DT task_NN of_IN identifying_VBG articles_NNS that_WDT are_VBP relevant_JJ to_TO a_DT biomedical_JJ database_NN ._.
We_PRP provide_VBP a_DT comparison_NN with_IN the_DT aforementioned_JJ methods_NNS in_IN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC we_PRP believe_VBP that_IN our_PRP$ recent_JJ formalization_NN -LRB-_-LRB- explained_VBN in_IN detail_NN Section_NN 3.2_CD -RRB-_-RRB- demonstrates_VBZ that_IN our_PRP$ approaches_NNS are_VBP well-suited_JJ to_TO this_DT task_NN ._.
s6_NNP Noto_NNP et_FW al._FW 3.1_CD Iterative_JJ relabeling_VBG Our_PRP$ first_JJ approac_NN
eled_VBN negative_JJ set_NN which_WDT is_VBZ typically_RB also_RB provided_VBN as_IN part_NN of_IN the_DT input_NN to_TO a_DT learning_NN algorithm_NN ._.
However_RB ,_, we_PRP recently_RB showed_VBD why_WRB we_PRP were_VBD able_JJ to_TO do_VB almost_RB as_RB well_RB by_IN using_VBG unlabeled_JJ Medline_NNP documents_NNS =_JJ -_: =-LRB-_NN 24_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT features_NNS that_IN we_PRP use_VBP are_VBP words_NNS that_WDT are_VBP associated_VBN with_IN each_DT document_NN ,_, either_CC by_IN appearing_VBG in_IN the_DT document_NN itself_PRP ,_, or_CC by_IN being_VBG part_NN of_IN a_DT set_NN of_IN keywords_NNS associated_VBN with_IN the_DT document_NN ._.
That_DT is_VBZ ,_, ea_FW
mpletion_NN ''_'' -RRB-_-RRB- ,_, our_PRP$ task_NN more_RBR closely_RB resembles_VBZ traditional_JJ predictive_JJ modeling_NN of_IN a_DT specific_JJ target_NN variable_NN ,_, but_CC with_IN a_DT massive_JJ number_NN of_IN variables_NNS ,_, and_CC technically_RB only_RB positive_JJ and_CC unlabeled_JJ examples_NNS =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Nonetheless_RB ,_, it_PRP may_MD be_VB that_IN CF-style_JJ dimensionality_NN reduction_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- can_MD further_RB improve_VB audience_NN selection_NN ._.
Although_IN we_PRP have_VBP tried_VBN to_TO design_VB the_DT experiments_NNS carefully_RB ,_, there_EX may_MD be_VB some_DT residual_JJ bias_NN
