Using_VBG ghost_NN edges_NNS for_IN classification_NN in_IN sparsely_RB labeled_VBN networks_NNS
We_PRP address_VBP the_DT problem_NN of_IN classification_NN in_IN partially_RB labeled_VBN networks_NNS -LRB-_-LRB- a.k.a._FW within-network_JJ classification_NN -RRB-_-RRB- where_WRB observed_VBN class_NN labels_NNS are_VBP sparse_JJ ._.
Techniques_NNS for_IN statistical_JJ relational_JJ learning_NN have_VBP been_VBN shown_VBN to_TO perform_VB well_RB on_IN network_NN classification_NN tasks_NNS by_IN exploiting_VBG dependencies_NNS between_IN class_NN labels_NNS of_IN neighboring_JJ nodes_NNS ._.
However_RB ,_, relational_JJ classifiers_NNS can_MD fail_VB when_WRB unlabeled_JJ nodes_NNS have_VBP too_RB few_JJ labeled_JJ neighbors_NNS to_TO support_VB learning_NN -LRB-_-LRB- during_IN training_NN phase_NN -RRB-_-RRB- and\/or_CC inference_NN -LRB-_-LRB- during_IN testing_NN phase_NN -RRB-_-RRB- ._.
This_DT situation_NN arises_VBZ in_IN real-world_JJ problems_NNS when_WRB observed_VBN labels_NNS are_VBP sparse_JJ ._.
In_IN this_DT paper_NN ,_, we_PRP propose_VBP a_DT novel_JJ approach_NN to_TO within-network_JJ classification_NN that_WDT combines_VBZ aspects_NNS of_IN statistical_JJ relational_JJ learning_NN and_CC semi-supervised_JJ learning_NN to_TO improve_VB classification_NN performance_NN in_IN sparse_JJ networks_NNS ._.
Our_PRP$ approach_NN works_VBZ by_IN adding_VBG ``_`` ghost_NN edges_NNS ''_'' to_TO a_DT network_NN ,_, which_WDT enable_VBP the_DT flow_NN of_IN information_NN from_IN labeled_VBN to_TO unlabeled_JJ nodes_NNS ._.
Through_IN experiments_NNS on_IN real-world_JJ data_NNS sets_NNS ,_, we_PRP demonstrate_VBP that_IN our_PRP$ approach_NN performs_VBZ well_RB across_IN a_DT range_NN of_IN conditions_NNS where_WRB existing_VBG approaches_NNS ,_, such_JJ as_IN collective_JJ classification_NN and_CC semi-supervised_JJ learning_NN ,_, fail_VBP ._.
On_IN all_DT tasks_NNS ,_, our_PRP$ approach_NN improves_VBZ area_NN under_IN the_DT ROC_NN curve_NN -LRB-_-LRB- AUC_NN -RRB-_-RRB- by_IN up_IN to_TO 15_CD points_NNS over_IN existing_VBG approaches_NNS ._.
Furthermore_RB ,_, we_PRP demonstrate_VBP that_IN our_PRP$ approach_NN runs_VBZ in_IN time_NN proportional_JJ to_TO L_NNP •_NNP E_NNP ,_, where_WRB L_NN is_VBZ the_DT number_NN of_IN labeled_JJ nodes_NNS and_CC E_NN is_VBZ the_DT number_NN of_IN edges_NNS ._.
._.
In_IN addition_NN ,_, the_DT link_NN prediction_NN algorithms_NNS can_MD also_RB be_VB used_VBN to_TO generate_VB some_DT artificial_JJ links_NNS to_TO help_VB the_DT further_JJ network_NN analysis_NN ,_, such_JJ as_IN the_DT classification_NN problem_NN in_IN partially_RB labeled_VBN networks_NNS =_JJ -_: =[_NN 11_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Some_DT algorithms_NNS based_VBN on_IN Markov_NNP chains_NNS -LRB-_-LRB- 19_CD ,_, 23_CD ,_, 2_CD -RRB-_-RRB- and_CC machine_NN learning_NN -LRB-_-LRB- 16_CD ,_, 20_CD -RRB-_-RRB- have_VBP been_VBN proposed_VBN recently_RB ,_, and_CC another_DT group_NN of_IN algorithms_NNS are_VBP based_VBN on_IN the_DT definition_NN of_IN node_NN similarity_NN ._.
In_IN this_DT
network_NN −_CD trainSet_NN F_NN =_JJ F_NN ∪_NN -LRB-_-LRB- trainSet_NN ,_, testSet_NN ,_, inferenceSet_NN -RRB-_-RRB- end_NN for_IN output_NN :_: F_NN Table_NNP 4_CD ._.
Network_NNP cross-validation_NN procedure_NN ._.
the_DT methodological_JJ design_NN of_IN 23_CD research_NN papers_NNS most_RBS relevant_JJ to_TO our_PRP$ work_NN =_JJ -_: =[_NN 1_CD ,_, 4_CD ,_, 5_CD ,_, 6_CD ,_, 7_CD ,_, 8_CD ,_, 9_CD ,_, 11_CD ,_, 12_CD ,_, 13_CD ,_, 14_CD ,_, 15_CD ,_, 16_CD ,_, 17_CD ,_, 18_CD ,_, 19_CD ,_, 20_CD ,_, 21_CD ,_, 22_CD ,_, 23_CD ,_, 24_CD ,_, 25_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Relevant_JJ papers_NNS compare_VBP the_DT performance_NN of_IN two_CD or_CC more_JJR classifiers_NNS on_IN a_DT relational_JJ classification_NN task_NN ._.
Based_VBN on_IN our_PRP$ survey_NN ,_, there_EX are_VBP two_CD common_JJ evaluation_NN methodologies_NNS which_WDT emerge_VBP :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- Independe_NN
l_NN in_IN terms_NNS of_IN accuracy_NN ,_, although_IN GRF_NN produces_VBZ slightly_RB better_JJR probability_NN rankings_NNS ._.
Our_PRP$ results_NNS with_IN wvRN_NN +_CC RL_NN and_CC GRF_NN are_VBP consistent_JJ with_IN this_DT conclusion_NN ._.
The_DT ``_`` ghost_NN edge_NN ''_'' approach_NN of_IN Gallagher_NNP et_FW al._FW =_SYM -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: combines_VBZ aspects_NNS of_IN both_CC SRL_NN and_CC SSL_NN ,_, and_CC compares_VBZ favorably_RB with_IN both_CC wvRN_NN +_CC RL_NN and_CC GRF_NN ._.
3_CD Label-Dependent_JJ vs._FW Label-Independent_FW Features_VBZ Relational_JJ classifiers_NNS leverage_NN link_NN structure_NN to_TO improve_VB perf_NN
nd_IN many_JJ other_JJ areas_NNS ._.
Many_JJ existing_VBG methods_NNS for_IN label_NN prediction_NN are_VBP proximity-based_JJ :_: missing_VBG labels_NNS are_VBP inferred_VBN based_VBN on_IN the_DT hypothesis_NN that_WDT linked_VBD or_CC nearby_JJ nodes_NNS are_VBP likely_JJ to_TO have_VB the_DT same_JJ labels_NNS =_JJ -_: =[_NN 7_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT hypothesis_NN is_VBZ also_RB known_VBN as_IN homophily_NN -LRB-_-LRB- i.e._FW ,_, love_NN of_IN the_DT same_JJ -RRB-_-RRB- and_CC describes_VBZ the_DT tendency_NN of_IN individuals_NNS to_TO associate_NN and_CC bond_NN with_IN similar_JJ others_NNS ._.
Thus_RB it_PRP is_VBZ not_RB surprising_JJ that_IN these_DT approach_NN
synthetic_JJ data_NNS ._.
Collective_JJ F_NN usion_NN continues_VBZ to_TO outperform_VB Decision_NN F_NN usion_NN across_IN all_DT levels_NNS of_IN labeling_NN -LRB-_-LRB- p_NN -LRB-_-LRB- 0.01_CD for_IN 10-70_CD %_NN ,_, p_NN -LRB-_-LRB- 0.05_CD for_IN 90_CD %_NN -RRB-_-RRB- ._.
4_LS ._.
RELATED_NNS WORK_VBP Much_JJ of_IN the_DT past_JJ work_NN on_IN data_NNS fusion_NN =_JJ -_: =[_NN 1_CD ,_, 4_CD ,_, 7_CD ,_, 8_CD ,_, 17_CD -RRB-_-RRB- -_: =_SYM -_: can_MD be_VB categorized_VBN as_IN F_NN eature_NN F_NN usion_NN ,_, where_WRB the_DT main_JJ focus_NN is_VBZ to_TO combine_VB features_NNS ._.
We_PRP discuss_VBP how_WRB these_DT methods_NNS differ_VBP from_IN our_PRP$ proposed_VBN F_NN eature_NN F_NN usion_NN approach_NN below_IN ._.
Methods_NNS developed_VBD for_IN appli_NNS
rmance_NN ._.
Our_PRP$ focus_NN is_VBZ on_IN the_DT case_NN where_WRB relatively_RB few_JJ attributes_NNS are_VBP available_JJ -LRB-_-LRB- or_CC the_DT attributes_NNS are_VBP not_RB very_RB predictive_JJ -RRB-_-RRB- as_IN may_MD occur_VB in_IN large_JJ real-world_JJ networks_NNS -LRB-_-LRB- c.f._FW ,_, Macskassy_NNP and_CC Provost_NNP 2007_CD ,_, =_JJ -_: =_JJ Gallagher_NNP et_FW al._FW 2008_CD -_: =--RRB-_NN ._.
Thus_RB ,_, for_IN most_JJS of_IN our_PRP$ experiments_NNS we_PRP randomly_RB select_VBP 10_CD of_IN the_DT 100_CD available_JJ words_NNS to_TO use_VB as_IN attributes_NNS ._.
We_PRP also_RB briefly_RB discuss_VB results_NNS when_WRB using_VBG 100_CD attributes_NNS ._.
For_IN the_DT synthetic_JJ data_NNS ,_, ten_CD binar_NN
ted_VBN on_IN the_DT web-graph_NN of_IN another_DT ._.
For_IN in-sample_JJ tasks_NNS ,_, where_WRB some_DT labels_NNS in_IN G_NN are_VBP known_VBN ,_, CC_NN can_MD be_VB applied_VBN to_TO the_DT single_JJ graph_NN G_NN -LRB-_-LRB- Macskassy_NNP and_CC Provost_NNP ,_, 2007_CD ;_: McDowell_NNP et_FW al._FW ,_, 2007a_CD ;_: Sen_NNP et_FW al._FW ,_, 2008_CD ;_: =_JJ -_: =_JJ Gallagher_NNP et_FW al._FW ,_, 2008_CD -_: =--RRB-_NN ;_: within-network_JJ classification_NN -LRB-_-LRB- Macskassy_NNP and_CC Provost_NNP ,_, 2006_CD -RRB-_-RRB- involves_VBZ training_NN on_IN the_DT subset_NN G_NN K_NN ⊂_NN G_NN with_IN known_JJ labels_NNS ,_, and_CC testing_NN by_IN running_VBG inference_NN over_IN the_DT entire_JJ graph_NN ._.
This_DT task_NN simulates_VBZ ,_, f_SYM
re_IN 1_CD ._.
We_PRP will_MD refer_VB to_TO this_DT algorithm_NN as_IN MultiRankWalk_NNP ,_, as_IN it_PRP creates_VBZ multiple_JJ rankings_NNS using_VBG random_JJ walks_VBZ from_IN seed_NN instances_NNS ._.
This_DT method_NN is_VBZ similar_JJ to_TO some_DT previously_RB described_VBN methods_NNS -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_JJ -_: ;_: though_IN the_DT lack_NN of_IN experimental_JJ results_NNS and_CC comparison_NN to_TO other_JJ methods_NNS in_IN prior_JJ work_NN makes_VBZ it_PRP difficult_JJ to_TO assess_VB its_PRP$ effectiveness_NN on_IN real_JJ network_NN datasets_NNS ._.
Given_VBN :_: A_DT graph_NN G_NN =_JJ -LRB-_-LRB- V_NN ,_, E_NN -RRB-_-RRB- ,_, correspondin_NN
among_IN their_PRP$ neighboring_JJ links_NNS ._.
For_IN these_DT classes_NNS ,_, we_PRP may_MD benefit_VB from_IN more_RBR sophisticated_JJ algorithms_NNS ,_, which_WDT learn_VBP statistical_JJ dependencies_NNS between_IN neighbors_NNS instead_RB of_IN simply_RB relying_VBG on_IN link-homophily_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN both_DT traces_NNS ,_, NLC+RL_NN gives_VBZ very_RB good_JJ results_NNS for_IN challenging_JJ application_NN such_JJ as_IN P2P_NN and_CC games_NNS ._.
With_IN only_RB 5_CD %_NN seed_NN size_NN ,_, NLC+RL_NN achieves_VBZ above_IN 95_CD %_NN Precision_NN and_CC Recall_VB in_IN identifying_VBG the_DT 3,500_CD flow_NN
ass_NN classification_NN problem_NN ._.
Table_NNP 1_CD summarizes_VBZ the_DT data_NNS that_IN we_PRP extracted_VBD ._.
3.2_CD Classifiers_NNS To_TO test_VB the_DT predictive_JJ ability_NN of_IN ReFeX_NN 's_POS features_NNS ,_, we_PRP use_VBP the_DT logForest_NN model_NN described_VBN by_IN Gallagher_NNP et_FW al._FW =_SYM -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT logForest_NN is_VBZ a_DT bagged_JJ model_NN ,_, composed_VBN of_IN a_DT set_NN of_IN logistic_JJ regression_NN -LRB-_-LRB- LR_NN -RRB-_-RRB- clas-IP-A1_NN IP-A2_NN IP-A3_NN IP-A4_NN IP-B_NN Nodes_VBZ 81450_CD 57415_CD 154103_CD 206704_CD 181267_CD -LRB-_-LRB- labeled_VBN -RRB-_-RRB- 29868_CD 16112_CD 30955_CD 67944_CD 27649_CD Links_NNP
inference_NN ._.
Collective_JJ inference_NN allows_VBZ to_TO infer_VB various_JJ interrelated_JJ values_NNS simultaneously_RB ._.
It_PRP is_VBZ used_VBN in_IN network_NN learning_VBG since_IN it_PRP permits_VBZ to_TO estimate_VB neighboring_JJ labels_NNS which_WDT influence_VBP one_CD another_DT =_JJ -_: =[_NN 12_CD ,_, 9_CD ,_, 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Since_IN exact_JJ inference_NN is_VBZ known_VBN to_TO be_VB an_DT NP-hard_JJ problem_NN and_CC there_EX is_VBZ no_DT guarantee_NN that_IN data_NNS network_NN satisfy_VBP the_DT conditions_NNS that_WDT make_VBP exact_JJ inference_NN tractable_JJ for_IN collective_JJ learning_NN ,_, most_JJS of_IN the_DT re_NN
on_IN -LRB-_-LRB- see_VB e.g._NNP ,_, Getoor_NNP and_CC Taskar_NNP -LRB-_-LRB- 2007_CD -RRB-_-RRB- -RRB-_-RRB- ._.
There_EX has_VBZ also_RB been_VBN some_DT work_NN that_WDT augments_VBZ the_DT observed_VBN relational_JJ data_NNS with_IN additional_JJ `_`` sources_NNS '_'' of_IN link_NN information_NN to_TO improve_VB performance_NN -LRB-_-LRB- Macskassy_NN 2007_CD ;_: =_JJ -_: =_JJ Eliassi-Rad_NNP et_FW al._FW 2008_CD -_: =--RRB-_NN ._.
However_RB ,_, once_RB again_RB ,_, these_DT methods_NNS combine_VBP this_DT information_NN before_IN learning_NN and_CC inference_NN ._.
Our_PRP$ MR_NN results_NNS are_VBP intended_VBN to_TO serve_VB as_IN a_DT baseline_NN to_TO compare_VB to_TO this_DT broad_JJ class_NN of_IN methods_NNS ,_, while_IN contro_NN
e_LS following_VBG Markov_NNP assumption_NN :_: P_NN -LRB-_-LRB- yi_FW |_FW A_NN -RRB-_-RRB- =_JJ P_NN -LRB-_-LRB- yi_FW |_FW Ni_FW -RRB-_-RRB- -LRB-_-LRB- 1_LS -RRB-_-RRB- where_WRB Ni_NN is_VBZ a_DT set_NN of_IN ``_`` neighbors_NNS ''_'' of_IN vertex_NN vi_LS ._.
The_DT neighbors_NNS are_VBP normally_RB defined_VBN as_IN vertices_NNS that_WDT are_VBP 1-hop_JJ or_CC 2-hop_JJ away_RB from_IN vi_LS in_IN the_DT network_NN =_JJ -_: =[_NN 14_CD ,_, 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT relational_JJ classifier_NN based_VBN upon_IN the_DT labels_NNS of_IN neighbors_NNS can_MD be_VB learned_VBN via_IN the_DT labeled_JJ vertices_NNS V_NN L_NN ._.
For_IN prediction_NN ,_, the_DT labels_NNS of_IN unlabeled_JJ vertices_NNS are_VBP initialized_VBN ._.
Then_RB the_DT constructed_VBN relati_NNS
alidated_VBN our_PRP$ claims_NNS ._.
In_IN this_DT section_NN we_PRP look_VBP at_IN transformations_NNS of_IN a_DT given_VBN relational_JJ data_NNS graph_NN which_WDT have_VBP been_VBN considered_VBN in_IN the_DT literature_NN -LRB-_-LRB- Kok_NNP and_CC Domingos_NNP 2007_CD ;_: Macskassy_NNP and_CC Provost_NNP 2003_CD ;_: 2007_CD ;_: =_JJ -_: =_JJ Gallagher_NNP et_FW al._FW 2008_CD -_: =-]_CD and_CC discuss_VB its_PRP$ effects_NNS on_IN the_DT claims_NNS made_VBN in_IN this_DT paper_NN ._.
We_PRP also_RB discuss_VBP the_DT implications_NNS of_IN the_DT observations_NNS reported_VBN in_IN -LRB-_-LRB- Jensen_NNP et_FW al._FW 2004_CD -RRB-_-RRB- ,_, where_WRB Indirect_JJ features_NNS were_VBD increased_VBN ,_, has_VBZ on_IN our_PRP$ an_DT
