Generative_JJ model-based_JJ clustering_NN of_IN directional_JJ data_NNS
High_JJ dimensional_JJ directional_JJ data_NNS is_VBZ becoming_VBG increasingly_RB important_JJ in_IN contemporary_JJ applications_NNS such_JJ as_IN analysis_NN of_IN text_NN and_CC gene-expression_NN data_NNS ._.
A_DT natural_JJ model_NN for_IN multi-variate_JJ directional_JJ data_NNS is_VBZ provided_VBN by_IN the_DT von_NN Mises-Fisher_NN -LRB-_-LRB- vMF_NN -RRB-_-RRB- distribution_NN on_IN the_DT unit_NN hypersphere_NN that_WDT is_VBZ analogous_JJ to_TO the_DT multi-variate_JJ Gaussian_JJ distribution_NN in_IN Rd._NNP ._.
In_IN this_DT paper_NN ,_, we_PRP propose_VBP modeling_NN complex_NN directional_JJ data_NNS as_IN a_DT mixture_NN of_IN vMF_NN distributions_NNS ._.
We_PRP derive_VBP and_CC analyze_VBP two_CD variants_NNS of_IN the_DT Expectation_NN Maximization_NN -LRB-_-LRB- EM_NN -RRB-_-RRB- framework_NN for_IN estimating_VBG the_DT parameters_NNS of_IN this_DT mixture_NN ._.
We_PRP also_RB propose_VBP two_CD clustering_NN algorithms_NNS corresponding_VBG to_TO these_DT variants_NNS ._.
An_DT interesting_JJ aspect_NN of_IN our_PRP$ methodology_NN is_VBZ that_IN the_DT spherical_JJ kmeans_NNS algorithm_NN -LRB-_-LRB- kmeans_NNS with_IN cosine_NN similarity_NN -RRB-_-RRB- can_MD be_VB shown_VBN to_TO be_VB a_DT special_JJ case_NN of_IN both_CC our_PRP$ algorithms_NNS ._.
Thus_RB ,_, modeling_NN text_NN data_NNS by_IN vMF_NN distributions_NNS lends_VBZ theoretical_JJ validity_NN to_TO the_DT use_NN of_IN cosine_NN similarity_NN which_WDT has_VBZ been_VBN widely_RB used_VBN by_IN the_DT information_NN retrieval_NN community_NN ._.
As_IN part_NN of_IN experimental_JJ validation_NN ,_, we_PRP present_VBP results_NNS on_IN modeling_NN high-dimensional_JJ text_NN and_CC gene-expression_NN data_NNS as_IN a_DT mixture_NN of_IN vMF_NN distributions_NNS ._.
The_DT results_NNS indicate_VBP that_IN our_PRP$ approach_NN yields_VBZ superior_JJ clusterings_NNS especially_RB for_IN difficult_JJ clustering_NN tasks_NNS in_IN high-dimensional_JJ spaces_NNS ._.
component_NN vectors_NNS in_IN Section_NNP 5_CD ._.
The_DT von_NNP Mises-Fisher_NNP distribution_NN -LRB-_-LRB- vMF_NN distribution_NN -RRB-_-RRB- is_VBZ the_DT most_RBS natural_JJ distribution_NN for_IN directional_JJ data_NNS in_IN that_IN it_PRP can_MD be_VB derived_VBN using_VBG the_DT maximum_NN entropy_NN principle_NN =_JJ -_: =[_NN 1_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
3.3_CD Problem_NNP Description_NN Here_RB ,_, we_PRP clearly_RB describe_VBP the_DT problem_NN once_RB more_JJR ._.
Let_VB us_PRP assume_VB that_IN we_PRP have_VBP telemetry_NN data_NNS in_IN normal_JJ operation_NN ._.
The_DT telemetry_NN data_NNS have_VBP thousands_NNS of_IN time_NN series_NN and_CC each_DT elem_NN
based_VBN approaches_NNS are_VBP not_RB appropriate_JJ in_IN this_DT case_NN since_IN the_DT signs_NNS of_IN faults_NNS are_VBP hidden_VBN deep_RB inside_IN the_DT systems_NNS -RRB-_-RRB- ._.
However_RB ,_, the_DT normal_JJ mixtures_NNS are_VBP not_RB appropriate_JJ to_TO handle_VB directional_JJ data_NNS ._.
Reference_NNP =_SYM -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: employs_VBZ a_DT mixture_NN of_IN the_DT von_NNP Mises-Fisher_NNP distribution_NN ,_, and_CC discusses_VBZ the_DT connection_NN to_TO the_DT cosine_NN measure_NN ._.
We_PRP also_RB consider_VBP the_DT von_NNP Mises-Fisher_NNP distribution_NN ._.
Our_PRP$ contribution_NN is_VBZ to_TO derive_VB a_DT probabi_NN
n_NN the_DT data_NNS ._.
If_IN is_VBZ the_DT random_JJ variable_NN denoting_VBG the_DT cluster_NN assignments_NNS of_IN the_DT points_NNS ,_, and_CC is_VBZ the_DT random_JJ variable_NN denoting_VBG the_DT underlying_VBG class_NN labels_NNS on_IN the_DT points_NNS ,_, then_RB the_DT NMI_NNP measure_NN is_VBZ defined_VBN as_IN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: :_: q_NN 0_CD -RRB-_-RRB- -LRB-_-LRB- 0_CD P_NN o_NN 0_CD Y_NN 0_CD q_NN where_WRB is_VBZ the_DT mutual_JJ information_NN between_IN the_DT random_JJ variables_NNS and_CC 0_CD ,_, is_VBZ the_DT Shannon_NNP entropy_NN of_IN ,_, 0_CD q_NN and_CC is_VBZ the_DT conditional_JJ entropy_NN of_IN given_VBN ._.
Pairwise_JJ F-measure_NN is_VBZ defined_VBN as_IN
the_DT PAC-MDL_NN bound_VBD -LRB-_-LRB- 3_CD -RRB-_-RRB- on_IN the_DT accuracy_NN of_IN a_DT test_NN set_NN ._.
Our_PRP$ proposed_VBN criterion_NN has_VBZ several_JJ natural_JJ properties_NNS :_: 1_CD ._.
It_PRP applies_VBZ to_TO every_DT clustering_NN algorithm_NN ._.
2_CD ._.
It_PRP is_VBZ inherently_RB normalized_VBN to_TO the_DT interval_NN =_JJ -_: =[_NN 0_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
3_LS ._.
All_DT possible_JJ values_NNS are_VBP exercised_VBN on_IN natural_JJ datasets_NNS ._.
4_LS ._.
The_DT metric_NN can_MD flexibly_RB incorporate_VB prior_JJ information_NN by_IN proper_JJ design_NN of_IN a_DT description_NN language_NN ._.
5_CD ._.
It_PRP can_MD be_VB used_VBN for_IN model_NN selection_NN ._.
d_NN on_IN a_DT discriminative_JJ model_NN ._.
A_DT generative_JJ model_NN can_MD create_VB other_JJ examples_NNS of_IN the_DT data_NNS ,_, usually_RB provides_VBZ good_JJ insight_NN into_IN the_DT nature_NN of_IN the_DT data_NNS and_CC facilitates_VBZ easy_JJ incorporation_NN of_IN domain_NN knowledge_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP observe_VBP that_IN an_DT author_NN 's_POS citations_NNS usually_RB contain_VBP the_DT information_NN of_IN the_DT author_NN 's_POS research_NN area_NN and_CC his_PRP$ or_CC her_PRP$ individual_JJ patterns_NNS of_IN coauthoring_VBG ._.
Therefore_RB ,_, we_PRP propose_VBP a_DT naive_JJ Bayes_NNP model_NN ,_, a_DT ge_NN
s_VBZ a_DT wide_JJ variety_NN of_IN distribution_NN types_NNS ,_, including_VBG Gaussian_NNP ,_, Bernoulli_NNP ,_, and_CC Poisson_NNP ._.
As_IN well_RB ,_, it_PRP uses_VBZ learning_VBG techniques_NNS to_TO estimate_VB the_DT number_NN of_IN distributions_NNS ._.
A_DT more_RBR recent_JJ work_NN by_IN Banerjee_NNP et_FW al._FW =_SYM -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: uses_VBZ Von_NNP Mises-Fisher_NNP distributions_NNS in_IN EM_NN clustering_NN ._.
Von_NNP Mises-Fisher_NNP distributions_NNS are_VBP designed_VBN to_TO deal_VB with_IN directional_JJ data_NNS -LRB-_-LRB- e.g._FW ,_, numeric_JJ vector_NN ,_, where_WRB Di_NNP =_JJ 1_CD -RRB-_-RRB- ._.
Such_JJ data_NNS representations_NNS produ_VBP
as_IN described_VBN above_IN ._.
To_TO estimate_VB the_DT parameters_NNS of_IN a_DT Gaussian_JJ mixture_NN ,_, the_DT Expectation_NN Maximization_NN -LRB-_-LRB- EM_NN -RRB-_-RRB- algorithm_NN is_VBZ widely_RB used_VBN for_IN its_PRP$ numerical_JJ stability_NN and_CC simplicity_NN ._.
Recently_RB ,_, Banerjee_NNP et_FW al._FW =_SYM -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: proposed_VBD two_CD variants_NNS -LRB-_-LRB- called_VBN the_DT hard-assignment_NN scheme_NN ,_, soft-assignment_JJ scheme_NN -RRB-_-RRB- of_IN the_DT EM_NNP algorithm_NN for_IN estimating_VBG the_DT parameters_NNS of_IN a_DT mixture_NN of_IN vMF_NN distributions_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP adopt_VBP Banerjee_NNP
n_NN that_IN the_DT Cosine_NNP similarity_NN measure_NN is_VBZ the_DT natural_JJ distortion_NN measure_NN for_IN prototype-based_JJ clustering_NN under_IN the_DT assumption_NN that_IN the_DT data_NNS were_VBD generated_VBN by_IN a_DT mixture_NN of_IN von-Mises_NNP Fisher_NNP distributions_NNS -LRB-_-LRB- =_JJ -_: =_JJ Banerjee_NNP et_FW al._FW ,_, 2003_CD -_: =--RRB-_NN ._.
This_DT similarity_NN measure_NN has_VBZ been_VBN widely_RB used_VBN in_IN information_NN retrieval_NN applications_NNS including_VBG text_NN analysis_NN -LRB-_-LRB- Aggarwal_NNP ,_, 2003_CD -RRB-_-RRB- ,_, bioinformatics_NNS and_CC collaborative_JJ filtering_VBG -LRB-_-LRB- Banerjee_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- ._.
It_PRP h_NN
orm_VB a_DT preprocessing_VBG step_NN to_TO identify_VB a_DT small_JJ number_NN of_IN representative_JJ states_NNS ._.
This_DT step_NN is_VBZ as_RB much_JJ art_NN as_IN science_NN ,_, and_CC is_VBZ usually_RB performed_VBN through_IN the_DT use_NN of_IN a_DT clustering_NN algorithm_NN ._.
Banerjee_FW et_FW ._.
al._FW =_SYM -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP given_VBN an_DT excellent_JJ formulation_NN to_TO the_DT problem_NN of_IN clustering_VBG high_JJ dimensional_JJ data_NNS based_VBN on_IN the_DT von_NN Mises_NNP Fischer_NNP distribution_NN ._.
We_PRP use_VBP their_PRP$ algorithm_NN along_IN with_IN standard_JJ clustering_NN methods_NNS such_JJ
d_NN on_IN a_DT discriminative_JJ model_NN ._.
A_DT generative_JJ model_NN can_MD create_VB other_JJ examples_NNS of_IN the_DT data_NNS ,_, usually_RB provides_VBZ good_JJ insight_NN into_IN the_DT nature_NN of_IN the_DT data_NNS and_CC facilitates_VBZ easy_JJ incorporation_NN of_IN domain_NN knowledge_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP observe_VBP that_IN an_DT author_NN 's_POS citations_NNS usually_RB contain_VBP the_DT information_NN of_IN the_DT author_NN 's_POS research_NN area_NN and_CC his_PRP$ or_CC her_PRP$ individual_JJ patterns_NNS of_IN coauthoring_VBG ._.
Therefore_RB ,_, we_PRP propose_VBP a_DT naive_JJ Bayes_NNP model_NN ,_, a_DT ge_NN
t_NN among_IN the_DT non-RSN_JJ algorithms_NNS ._.
Note_VB that_IN since_IN the_DT document_NN vector_NN is_VBZ L2-normalized_JJ ,_, the_DT KM-ED_NN is_VBZ actually_RB based_VBN on_IN von_NNP Mises-Fisher_NNP distribution_NN -LRB-_-LRB- 24_CD -RRB-_-RRB- ,_, which_WDT proved_VBD efficient_JJ for_IN document_NN clustering_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP also_RB observe_VBP that_IN for_IN these_DT graphs_NNS ,_, in_IN general_JJ the_DT algorithms_NNS based_VBN on_IN logistic_JJ loss_NN provide_VB better_JJR performance_NN ._.
The_DT possible_JJ reason_NN is_VBZ that_IN logistic_JJ loss_NN corresponds_VBZ to_TO Bernoulli_NNP distribution_NN wh_NN
cribed_VBN above_IN ._.
For_IN estimating_VBG the_DT parameters_NNS of_IN a_DT Gaussian_JJ mixture_NN ,_, the_DT Expectation_NN Maximization_NN -LRB-_-LRB- EM_NN -RRB-_-RRB- algorithm_NN is_VBZ widely_RB used_VBN for_IN its_PRP$ numerical_JJ stability_NN and_CC simplicity_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
Recently_RB ,_, Banerjee_NNP et_FW al._FW =_SYM -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: proposed_VBD two_CD variants_NNS -LRB-_-LRB- called_VBN the_DT hard-assignment_NN scheme_NN ,_, softassignment_NN scheme_NN -RRB-_-RRB- of_IN the_DT EM_NNP algorithm_NN for_IN estimating_VBG the_DT parameters_NNS of_IN a_DT mixture_NN of_IN vMF_NN distributions_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP adopt_VBP Banerjee_NNP
Normalized_VBN mutual_JJ information_NN ._.
For_IN the_DT datasets_NNS that_WDT have_VBP more_JJR than_IN five_CD classes_NNS ,_, due_JJ to_TO the_DT expensive_JJ computation_NN involved_VBN in_IN finding_VBG the_DT optimal_JJ alignment_NN ,_, we_PRP use_VBP the_DT normalized_VBN mutual_JJ information_NN -LRB-_-LRB- =_JJ -_: =_JJ Banerjee_NNP et_FW al._FW ,_, 2003_CD -_: =--RRB-_NN as_IN the_DT alternative_JJ evaluation_NN metric_NN ._.
If_IN Tu_NN and_CC Tl_NN denote_VBP the_DT cluster_NN labels_NNS and_CC true_JJ class_NN labels_NNS assigned_VBN to_TO data_NNS points_NNS ,_, the_DT normalized_VBN mutual_JJ information_NN ``_`` nmi_NN ''_'' is_VBZ defined_VBN as_IN nmi_NN =_JJ 2I_NN -LRB-_-LRB- Tu_NN ,_, Tl_NN -RRB-_-RRB- -LRB-_-LRB- H_NN -LRB-_-LRB- T_NN
µ_NN h_NN +_CC λh_NN -LRB-_-LRB- µ_NN T_NN h_NN µ_NN h_NN −_NN 1_CD -RRB-_-RRB- k_NN h_NN =_JJ 1_CD λh_NN -LRB-_-LRB- µ_NN T_NN h_NN µ_NN h_NN −_NN 1_CD -RRB-_-RRB- ,_, 1_CD One_NN can_MD also_RB formulate_VB a_DT soft_JJ assignment_NN based_VBN algorithm_NN based_VBN on_IN vMF_NN distributions_NNS ,_, but_CC soft_JJ clustering_NN is_VBZ outside_IN the_DT scope_NN of_IN this_DT chapter_NN ._.
See_VB =_JJ -_: =_JJ -LRB-_-LRB- BDGS03_NN -RRB-_-RRB- -_: =_SYM -_: for_IN details_NNS ._.
2_CD There_EX is_VBZ a_DT subtle_JJ difference_NN between_IN the_DT constraints_NNS µh_VBP =_JJ 1_CD and_CC µ_NN T_NN h_NN µ_NN h_NN =_JJ 1_CD ._.
Since_IN this_DT difference_NN is_VBZ not_RB important_JJ in_IN the_DT present_JJ analysis_NN ,_, we_PRP choose_VBP to_TO ignore_VB it_PRP for_IN simplicity_NN ._.
measure_NN based_VBN on_IN the_DT angle_NN between_IN vectors_NNS is_VBZ more_RBR appropriate_JJ -LRB-_-LRB- 1_LS -RRB-_-RRB- ._.
Consequently_RB ,_, clustering_NN algorithms_NNS that_WDT utilize_VBP distortion_NN measures_NNS appropriate_JJ for_IN directional_JJ data_NNS have_VBP recently_RB been_VBN developed_VBN =_JJ -_: =[_NN 18_CD ,_, 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Our_PRP$ unified_JJ semi-supervised_JJ clustering_NN framework_NN based_VBN on_IN HMRFs_NNS is_VBZ also_RB applicable_JJ to_TO such_JJ directional_JJ similarity_NN measures_NNS ._.
To_TO summarize_VB ,_, the_DT proposed_VBN approach_NN aids_VBZ unsupervised_JJ clustering_NN by_IN incorp_NN
comparison_NN with_IN SGC_NN ,_, METIS_NN and_CC a_DT state-of-the-art_JJ document_NN clustering_NN algorithm_NN ,_, VMF_NNP ,_, which_WDT is_VBZ based_VBN on_IN von_NNP Mises-Fisher_NNP distribution_NN and_CC was_VBD reported_VBN as_IN one_CD of_IN the_DT best_JJS document_NN clustering_NN algorithm_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP observe_VBP that_IN although_IN there_EX is_VBZ no_DT single_JJ winner_NN on_IN all_PDT the_DT graphs_NNS ,_, for_IN most_JJS graphs_NNS CLGA_NNP algorithms_NNS perform_VBP better_RBR than_IN or_CC close_JJ to_TO SGC_NNP ,_, METIS_NNP and_CC VMF_NNP ._.
The_DT CLGA_NNP algorithms_NNS provide_VBP the_DT best_JJS perform_VB
f_FW vMF_FW distributions_NNS ,_, as_IN described_VBN above_IN ._.
For_IN estimating_VBG the_DT parameters_NNS of_IN a_DT Gaussian_JJ mixture_NN ,_, the_DT EM_NNP algorithm_NN is_VBZ widely_RB used_VBN for_IN its_PRP$ numerical_JJ stability_NN and_CC simplicity_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
Recently_RB ,_, Banerjee_NNP et_FW al._FW =_SYM -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: proposed_VBD two_CD variants_NNS -LRB-_-LRB- called_VBN the_DT hard-assignment_NN scheme_NN and_CC the_DT soft-assignment_JJ scheme_NN -RRB-_-RRB- of_IN the_DT EM_NNP algorithm_NN for_IN estimating_VBG the_DT parameters_NNS of_IN a_DT mixture_NN of_IN vMF_NN distributions_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP adopt_VBP B_NN
the_DT PAC-MDL_NN bound_VBD -LRB-_-LRB- 3_CD -RRB-_-RRB- on_IN the_DT accuracy_NN of_IN a_DT test_NN set_NN ._.
Our_PRP$ proposed_VBN criterion_NN has_VBZ several_JJ natural_JJ properties_NNS :_: 1_CD ._.
It_PRP applies_VBZ to_TO every_DT clustering_NN algorithm_NN ._.
2_CD ._.
It_PRP is_VBZ inherently_RB normalized_VBN to_TO the_DT interval_NN =_JJ -_: =[_NN 0_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
3_LS ._.
All_DT possible_JJ values_NNS are_VBP exercised_VBN on_IN natural_JJ datasets_NNS ._.
4_LS ._.
The_DT metric_NN can_MD flexibly_RB incorporate_VB prior_JJ information_NN by_IN proper_JJ design_NN of_IN a_DT description_NN language_NN ._.
5_CD ._.
It_PRP can_MD be_VB used_VBN for_IN model_NN selection_NN ._.
ion_NN of_IN deterministic_JJ annealing_NN ,_, however_RB ,_, multinomial_JJ models_NNS perform_VBP comparably_RB with_IN vMF_NN models_NNS ._.
Here_RB is_VBZ why_WRB we_PRP use_VBP multinomial_JJ models_NNS instead_RB of_IN vMF_NN models_NNS underlying_VBG the_DT spherical_JJ k-means_NN algorithm_NN -LRB-_-LRB- =_JJ -_: =_JJ Banerjee_NNP et_FW al._FW ,_, 2003_CD -_: =--RRB-_NN :_: Even_RB though_IN the_DT spherical_JJ kmeans_NNS algorithm_NN is_VBZ simple_JJ and_CC efficient_JJ ,_, the_DT mixture-of-vMFs_NN ,_, a_DT soft_JJ version_NN of_IN spherical_JJ k-means_NN ,_, involves_VBZ Bessel_NNP function_NN in_IN its_PRP$ parameterization_NN and_CC requires_VBZ intensive_JJ
the_DT data_NNS ._.
Ifsis_NNP the_DT random_JJ variable_NN denoting_VBG the_DT cluster_NN assignments_NNS of_IN the_DT points_NNS ,_, and_CC ¡_NN is_VBZ the_DT random_JJ variable_NN denoting_VBG the_DT underlying_VBG class_NN labels_NNS on_IN the_DT points_NNS ,_, then_RB the_DT NMI_NNP measure_NN is_VBZ defined_VBN as_IN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: :_: #_# cents_NNS ¥_VBP $_$ ¡_CD $_$ ¦_CD ¨_CD §_FW ©_FW ¡_FW ¦_FW ¡_FW ¦_FW ¦_FW where_WRB $_$ §_CD ©_CD ¡_NN is_VBZ the_DT mutual_JJ information_NN between_IN the_DT random_JJ variables_NNS and_CC ,_, is_VBZ the_DT Shannon_NNP entropy_NN of_IN ,_, and_CC
ghted_VBN by_IN the_DT association_NN probabilities_NNS ,_, which_WDT is_VBZ to_TO be_VB maximized_VBN ._.
Indeed_RB ,_, maximizing_VBG this_DT objective_JJ function_NN leads_VBZ to_TO a_DT well-known_JJ hard_JJ clustering_NN algorithm_NN -LRB-_-LRB- Kearns_NNP et_FW al._FW ,_, 1997_CD ;_: Li_NNP and_CC Biswas_NNP ,_, 2002_CD ;_: =_JJ -_: =_JJ Banerjee_NNP et_FW al._FW ,_, 2003_CD -_: =_SYM -_: b_LS -RRB-_-RRB- ._.
We_PRP will_MD show_VB in_IN the_DT next_JJ section_NN that_IN soft_JJ modelbased_JJ clustering_NN can_MD be_VB obtained_VBN by_IN adding_VBG entropy_NN constraints_NNS to_TO the_DT objective_JJ function_NN ._.
Similar_JJ to_TO deterministic_JJ annealing_NN ,_, a_DT temperature_NN paramete_NN
t_NN al_NNP proposed_VBD two_CD variants_NNS of_IN the_DT EM_NNP algorithm_NN for_IN soft_JJ clustering_NN ,_, where_WRB each_DT object_NN is_VBZ allowed_VBN to_TO belong_VB to_TO more_JJR than_IN one_CD cluster_NN ,_, and_CC applied_VBD them_PRP to_TO text_NN clustering_NN and_CC gene_NN expression_NN clustering_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN 2002_CD ,_, Lodhi_NNP et_NNP al_NNP attempted_VBD to_TO solve_VB the_DT two_CD main_JJ problems_NNS from_IN representing_VBG documents_NNS into_IN numerical_JJ vectors_NNS by_IN proposing_VBG the_DT string_NN kernel_NN for_IN SVM_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
The_DT string_NN kernel_NN proposed_VBN by_IN them_PRP is_VBZ th_DT
