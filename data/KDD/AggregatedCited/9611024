Structured_VBN learning_NN for_IN non-smooth_JJ ranking_NN losses_NNS
Learning_NNP to_TO rank_VB from_IN relevance_NN judgment_NN is_VBZ an_DT active_JJ research_NN area_NN ._.
Itemwise_JJ score_NN regression_NN ,_, pairwise_JJ preference_NN satisfaction_NN ,_, and_CC listwise_NN structured_JJ learning_NN are_VBP the_DT major_JJ techniques_NNS in_IN use_NN ._.
Listwise_JJ structured_JJ learning_NN has_VBZ been_VBN applied_VBN recently_RB to_TO optimize_VB important_JJ non-decomposable_JJ ranking_NN criteria_NNS like_IN AUC_NN -LRB-_-LRB- area_NN under_IN ROC_NN curve_NN -RRB-_-RRB- and_CC MAP_NN -LRB-_-LRB- mean_JJ average_JJ precision_NN -RRB-_-RRB- ._.
We_PRP propose_VBP new_JJ ,_, almost-linear-time_JJ algorithms_NNS to_TO optimize_VB for_IN two_CD other_JJ criteria_NNS widely_RB used_VBN to_TO evaluate_VB search_NN systems_NNS :_: MRR_NN -LRB-_-LRB- mean_NN reciprocal_JJ rank_NN -RRB-_-RRB- and_CC NDCG_NN -LRB-_-LRB- normalized_VBN discounted_JJ cumulative_JJ gain_NN -RRB-_-RRB- in_IN the_DT max-margin_JJ structured_JJ learning_NN framework_NN ._.
We_PRP also_RB demonstrate_VBP that_IN ,_, for_IN different_JJ ranking_JJ criteria_NNS ,_, one_PRP may_MD need_VB to_TO use_VB different_JJ feature_NN maps_NNS ._.
Search_VB applications_NNS should_MD not_RB be_VB optimized_VBN in_IN favor_NN of_IN a_DT single_JJ criterion_NN ,_, because_IN they_PRP need_VBP to_TO cater_VB to_TO a_DT variety_NN of_IN queries_NNS ._.
E.g._NN ,_, MRR_NN is_VBZ best_JJS for_IN navigational_JJ queries_NNS ,_, while_IN NDCG_NN is_VBZ best_JJS for_IN informational_JJ queries_NNS ._.
A_DT key_JJ contribution_NN of_IN this_DT paper_NN is_VBZ to_TO fold_VB multiple_JJ ranking_JJ loss_NN functions_NNS into_IN a_DT multi-criteria_JJ max-margin_NN optimization_NN ._.
The_DT result_NN is_VBZ a_DT single_JJ ,_, robust_JJ ranking_NN model_NN that_WDT is_VBZ close_JJ to_TO the_DT best_JJS accuracy_NN of_IN learners_NNS trained_VBN on_IN individual_JJ criteria_NNS ._.
In_IN fact_NN ,_, experiments_NNS over_IN the_DT popular_JJ LETOR_NN and_CC TREC_NN data_NNS sets_NNS show_VBP that_IN ,_, contrary_JJ to_TO conventional_JJ wisdom_NN ,_, a_DT test_NN criterion_NN is_VBZ often_RB not_RB best_RBS served_VBN by_IN training_NN with_IN the_DT same_JJ individual_JJ criterion_NN ._.
perfect_JJ ._.
The_DT ``_`` defect_NN ''_'' of_IN a_DT ranking_NN y_FW wrt_FW the_DT ideal_JJ ranking_NN yq_NN is_VBZ encoded_VBN in_IN a_DT loss_NN function_NN -LRB-_-LRB- 17_CD -RRB-_-RRB- ∆_NN -LRB-_-LRB- y_NN ,_, yq_NN -RRB-_-RRB- ≥_NN 0_CD ,_, sometimes_RB shorthanded_VBD to_TO ∆_CD q_NN -LRB-_-LRB- y_NN -RRB-_-RRB- ._.
Naturally_RB ,_, ∆_FW q_FW -LRB-_-LRB- yq_NN -RRB-_-RRB- =_JJ 0_CD ._.
The_DT second_JJ piece_NN is_VBZ a_DT feature_NN map_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: φ_NN -LRB-_-LRB- xq_NN ,_, y_NN -RRB-_-RRB- ∈_NN Rd_NN that_WDT combines_VBZ individual_JJ document_NN feature_NN vectors_NNS xqi_VBP into_IN a_DT single_JJ vector_NN ,_, using_VBG the_DT proposed_JJ ranking_JJ y._NN As_IN a_DT simple_JJ example_NN ,_, one_PRP may_MD add_VB up_RP the_DT vectors_NNS at_IN ranks_NNS 1_CD through_IN 10_CD ,_, then_RB sub_NN
ze_NN by_IN learning_VBG algorithms_NNS ._.
Despite_IN the_DT combinatorial_JJ difficulties_NNS of_IN ranking_JJ problems_NNS ,_, there_EX are_VBP now_RB several_JJ algorithmic_JJ techniques_NNS for_IN optimizing_VBG various_JJ ranking_JJ evaluation_NN measures_NNS -LRB-_-LRB- Joachims_NNP ,_, 2005_CD ;_: =_JJ -_: =_JJ Chakrabarti_NNP et_FW al._FW ,_, 2008_CD -_: =_JJ -_: ;_: Volkovs_NNP &_CC Zemel_NNP ,_, 2009_CD -RRB-_-RRB- ._.
In_IN the_DT present_JJ work_NN ,_, we_PRP seek_VBP to_TO bridge_VB the_DT gap_NN between_IN metric_JJ learning_NN and_CC ranking_NN ._.
By_IN adapting_VBG techniques_NNS from_IN information_NN retrieval_NN ,_, we_PRP derive_VBP a_DT general_JJ metric_JJ learning_NN alg_NN
ted_VBN ,_, can_MD be_VB divided_VBN into_IN two_CD categories_NNS ._.
The_DT methods_NNS in_IN the_DT first_JJ major_JJ category_NN attempt_NN to_TO formulate_VB an_DT explicit_JJ smooth_NN objective_NN function_NN which_WDT are_VBP then_RB approached_VBN by_IN various_JJ optimization_NN strategies_NNS =_JJ -_: =[_NN 8_CD ,_, 14_CD ,_, 16_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT second_JJ category_NN of_IN methods_NNS ,_, however_RB ,_, works_VBZ with_IN implicit_JJ objective_NN functions_NNS which_WDT faciliate_VBP us_PRP to_TO specify_VB some_DT rules_NNS about_IN how_WRB to_TO change_VB rank_NN orders_NNS for_IN a_DT given_JJ sorted_VBN instances_NNS ,_, represented_VBN by_IN
are_VBP averaged_VBN across_IN the_DT texts_NNS in_IN the_DT held-out_JJ half_NN of_IN the_DT training_NN set_NN ._.
The_DT ``_`` No_DT ranking_NN ''_'' row_NN shows_VBZ the_DT overall_JJ acceptability_NN rate_NN for_IN all_DT questions_NNS in_IN the_DT held-out_JJ half_NN ._.
optimize_VB evaluation_NN metrics_NNS -LRB-_-LRB- =_JJ -_: =_JJ Chakrabarti_NNP et_FW al._FW ,_, 2008_CD -_: =_JJ -_: ;_: Xu_NNP and_CC Li_NNP ,_, 2007_CD -RRB-_-RRB- ,_, could_MD lead_VB to_TO improved_JJ ranking_JJ performance_NN ._.
21_CD We_PRP leave_VBP the_DT exploration_NN of_IN such_JJ models_NNS to_TO future_JJ work_NN ._.
4.8_CD Further_JJ Analyses_NNS of_IN Question_NNP Ranking_NNP Next_NNP ,_, we_PRP discuss_VBP some_DT exploratory_NN an_DT
ng_NN models_NNS were_VBD limited_VBN ,_, and_CC do_VBP not_RB permit_VB pairwise_JJ interactions_NNS between_IN output_NN labels_NNS ._.
The_DT method_NN of_IN Yue_NNP et_FW al._FW -LRB-_-LRB- 29_CD -RRB-_-RRB- takes_VBZ a_DT similar_JJ approach_NN to_TO optimize_VB against_IN Mean_NN Average_NNP Precision_NNP ._.
Khanna_NNP et_FW al._FW =_SYM -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: present_JJ an_DT algorithm_NN in_IN the_DT same_JJ framework_NN to_TO optimize_VB against_IN normalized_VBN discounted_JJ cumulative_JJ gain_NN -LRB-_-LRB- NDCG_NN -RRB-_-RRB- ._.
Rather_RB than_IN solving_VBG a_DT convex_NN relaxation_NN of_IN the_DT expected_VBN loss_NN ,_, McAllester_NNP et_FW al._FW -LRB-_-LRB- 13_CD -RRB-_-RRB- propo_NN
listwise_NN techniques_NNS are_VBP obtained_VBN with_IN a_DT loss_NN function_NN that_WDT optimally_RB resembles_VBZ the_DT evaluation_NN measure_NN ._.
In_IN that_DT respect_NN ,_, it_PRP would_MD be_VB interesting_JJ to_TO experiment_NN with_IN the_DT lesser_JJR known_JJ algorithm_NN SV_NN M_NN mrr_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
5.2_CD The_DT effect_NN of_IN data_NNS imbalance_NN As_IN pointed_VBN out_RP in_IN the_DT machine_NN learning_NN literature_NN -LRB-_-LRB- see_VB Section_NNP 2.3_CD -RRB-_-RRB- ,_, classifiers_NNS are_VBP in_IN general_JJ sensitive_JJ to_TO data_NN imbalance_NN ._.
Table_NNP 3_CD shows_VBZ that_IN especially_RB pointwise_JJ
or_CC ranking_NN ,_, and_CC applying_VBG 1-norm_JJ SVM_NN -LRB-_-LRB- 24_CD -RRB-_-RRB- ._.
More_RBR complex_JJ ranking_JJ losses_NNS have_VBP been_VBN proposedActive_JJ Learning_NNP of_IN Combinatorial_JJ Features_NNS for_IN Interactive_JJ Optimization_NN 349_CD in_IN the_DT literature_NN -LRB-_-LRB- see_VB for_IN instance_NN =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =--RRB-_NN ,_, especially_RB to_TO increase_VB the_DT importance_NN of_IN correctly_RB ranking_VBG the_DT best_JJS solutions_NNS ,_, and_CC could_MD be_VB combined_VBN with_IN 1-norm_JJ regularization_NN ._.
Our_PRP$ experimental_JJ evaluation_NN is_VBZ focused_VBN on_IN small-scale_JJ problems_NNS ,_, typi_NN
gorithms_NNS have_VBP focused_VBN on_IN optimizing_VBG ranking_JJ performance_NN measures_NNS such_JJ as_IN the_DT average_JJ precision_NN or_CC the_DT discounted_JJ cumulative_JJ gain_NN -LRB-_-LRB- DCG_NN -RRB-_-RRB- ,_, both_DT of_IN which_WDT emphasize_VBP ranking_JJ accuracy_NN at_IN the_DT top_NN of_IN the_DT list_NN =_JJ -_: =[_NN 8_CD ,_, 34_CD ,_, 12_CD ,_, 33_CD ,_, 16_CD ,_, 30_CD ,_, 10_CD ,_, 25_CD ,_, 13_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, we_PRP describe_VBP a_DT new_JJ ranking_JJ algorithm_NN that_WDT directly_RB optimizes_VBZ accuracy_NN at_IN the_DT absolute_JJ top_NN of_IN the_DT list_NN ._.
For_IN simplicity_NN ,_, we_PRP consider_VBP the_DT bipartite_JJ setting_NN -LRB-_-LRB- 19_CD ,_, 3_CD -RRB-_-RRB- in_IN which_WDT objects_NNS are_VBP ei_FW
pared_VBD our_PRP$ best_JJS DBGD_NN models_NNS with_IN a_DT ranking_JJ SVM_NNP ,_, which_WDT optimizes_VBZ over_IN pairwise_JJ document_NN preferences_NNS and_CC is_VBZ a_DT standard_JJ baseline_NN in_IN supervised_JJ learning_NN to_TO rank_VB settings_NNS ._.
More_RBR sophisticated_JJ methods_NNS -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =_JJ Chakrabarti_NNP et_FW al._FW ,_, 2008_CD -_: =_JJ -_: ;_: Donmez_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- can_MD further_RB improve_VB performance_NN ._.
Table_NNP 3_CD shows_VBZ that_IN DBGD_NN approaches_VBZ ranking_JJ SVM_NN performance_NN despite_IN making_VBG fundamentally_RB different_JJ assumptions_NNS -LRB-_-LRB- e.g._FW ,_, ranking_JJ SVMs_NNS have_VBP access_NN to_TO
._.
We_PRP clean_VBP the_DT dataset_NN by_IN removing_VBG documents_NNS of_IN a_DT particular_JJ query_NN that_WDT has_VBZ conflicting_JJ relevance_NN labels_NNS ._.
Cleaning_VBG also_RB involves_VBZ removing_VBG those_DT queries_NNS that_WDT have_VBP no_DT relevant_JJ document_NN -LRB-_-LRB- for_IN details_NNS see_VBP =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Yandex_NNP ._.
Recently_RB ,_, a_DT Russian_JJ Internet_NN company_NN called_VBN Yandex_NNP has_VBZ released_VBN another_DT LETOR-like_JJ dataset_NN ,_, as_IN part_NN of_IN the_DT Internet_NNP Mathematics_NNP Contest_NNP 2009_CD 3_CD ._.
Specific_JJ permission_NN was_VBD obtained_VBN from_IN the_DT pu_NN
