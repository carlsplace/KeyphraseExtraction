New_JJ ensemble_NN methods_NNS for_IN evolving_VBG data_NNS streams_NNS
Advanced_NNP analysis_NN of_IN data_NNS streams_NNS is_VBZ quickly_RB becoming_VBG a_DT key_JJ area_NN of_IN data_NNS mining_NN research_NN as_IN the_DT number_NN of_IN applications_NNS demanding_VBG such_JJ processing_NN increases_NNS ._.
Online_JJ mining_NN when_WRB such_JJ data_NNS streams_NNS evolve_VBP over_IN time_NN ,_, that_WDT is_VBZ when_WRB concepts_NNS drift_VBP or_CC change_VBP completely_RB ,_, is_VBZ becoming_VBG one_CD of_IN the_DT core_NN issues_NNS ._.
When_WRB tackling_VBG non-stationary_JJ concepts_NNS ,_, ensembles_NNS of_IN classifiers_NNS have_VBP several_JJ advantages_NNS over_IN single_JJ classifier_NN methods_NNS :_: they_PRP are_VBP easy_JJ to_TO scale_NN and_CC parallelize_NN ,_, they_PRP can_MD adapt_VB to_TO change_VB quickly_RB by_IN pruning_NN under-performing_JJ parts_NNS of_IN the_DT ensemble_NN ,_, and_CC they_PRP therefore_RB usually_RB also_RB generate_VBP more_RBR accurate_JJ concept_NN descriptions_NNS ._.
This_DT paper_NN proposes_VBZ a_DT new_JJ experimental_JJ data_NNS stream_NN framework_NN for_IN studying_VBG concept_NN drift_NN ,_, and_CC two_CD new_JJ variants_NNS of_IN Bagging_NNP :_: ADWIN_NNP Bagging_NNP and_CC Adaptive-Size_NNP Hoeffding_NNP Tree_NNP -LRB-_-LRB- ASHT_NNP -RRB-_-RRB- Bagging_NNP ._.
Using_VBG the_DT new_JJ experimental_JJ framework_NN ,_, an_DT evaluation_NN study_NN on_IN synthetic_JJ and_CC real-world_JJ datasets_NNS comprising_VBG up_RB to_TO ten_CD million_CD examples_NNS shows_VBZ that_IN the_DT new_JJ ensemble_NN methods_NNS perform_VBP very_RB well_RB compared_VBN to_TO several_JJ known_JJ methods_NNS ._.
eral_JJ Terms_NNS Algorithms_NNPS Keywords_NNPS ensemble_NN learning_NN ,_, ensemble_NN pruning_NN 1_CD ._.
INTRODUCTION_NN The_DT construction_NN of_IN classifier_NN ensembles_NNS is_VBZ an_DT active_JJ research_NN field_NN in_IN machine_NN learning_NN and_CC data_NN mining_NN communities_NNS =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Rather_RB Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN all_DT or_CC part_NN of_IN this_DT work_NN for_IN personal_JJ or_CC classroom_NN use_NN is_VBZ granted_VBN without_IN fee_NN provided_VBN that_IN copies_NNS are_VBP not_RB made_VBN or_CC distributed_VBN for_IN profit_NN or_CC comme_NN
of_IN the_DT FIMT_NNP algorithm_NN to_TO time-changing_JJ distributions_NNS ._.
FIMT_NN and_CC FIRT-DD_NN use_VBP a_DT perceptron_NN learner_NN at_IN the_DT leaves_NNS to_TO perform_VB regression_NN ._.
Considering_VBG classification_NN methods_NNS for_IN data_NNS streams_NNS ,_, Bifet_NNP et_FW al._FW =_SYM -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: presented_VBN two_CD new_JJ ensemble_NN learning_NN methods_NNS :_: one_CD using_VBG bagging_VBG with_IN decision_NN trees_NNS of_IN different_JJ size_NN and_CC one_CD using_VBG ADWIN_NNP ,_, an_DT adaptive_JJ sliding_VBG window_NN method_NN that_WDT detects_VBZ change_NN and_CC adjusts_VBZ the_DT size_NN of_IN
ing_NN or_CC voting_NN -RRB-_-RRB- to_TO form_VB a_DT final_JJ prediction_NN ._.
Often_RB ,_, ensemble_NN learning_NN classifiers_NNS provide_VBP superior_JJ predictive_JJ performance_NN and_CC they_PRP are_VBP easier_JJR to_TO scale_VB and_CC parallelize_VB than_IN single_JJ classifier_NN methods_NNS ._.
In_IN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: two_CD new_JJ state-of-the-art_JJ bagging_NN methods_NNS were_VBD presented_VBN :_: ASHT_NNP Bagging_NNP using_VBG trees_NNS of_IN different_JJ sizes_NNS ,_, and_CC ADWIN_NNP Bagging_NNP using_VBG a_DT change_NN detector_NN to_TO decide_VB when_WRB to_TO discard_VB underperforming_VBG ensemble_NN memb_NN
constructed_VBN models_NNS ._.
The_DT intuitive_JJ idea_NN of_IN boosting_VBG is_VBZ to_TO give_VB more_JJR weight_NN to_TO misclassified_VBN examples_NNS ,_, and_CC reducing_VBG the_DT weight_NN of_IN the_DT correctly_RB classified_VBN ones_NNS ._.
From_IN studies_NNS appearing_VBG in_IN the_DT literature_NN =_JJ -_: =[_NN 25_CD ,_, 24_CD ,_, 6_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Online_NNP Bagging_NNP seems_VBZ to_TO perform_VB better_RBR than_IN online_JJ boosting_VBG methods_NNS ._.
Why_WRB bagging_VBG outperforms_VBZ boosting_VBG in_IN the_DT data_NNS stream_NN setting_NN is_VBZ still_RB an_DT open_JJ question_NN ._.
Adding_VBG more_RBR random_JJ weight_NN to_TO all_DT instances_NNS
mproving_VBG Adaptive_NNP Bagging_NNP Methods_NNS for_IN Evolving_NNP Data_NNP Streams_NNP Abstract_NNP ._.
We_PRP propose_VBP two_CD new_JJ improvements_NNS for_IN bagging_VBG methods_NNS on_IN evolving_VBG data_NNS streams_NNS ._.
Recently_RB ,_, two_CD new_JJ variants_NNS of_IN Bagging_NNP were_VBD proposed_VBN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: :_: ADWIN_NNP Bagging_NNP and_CC Adaptive-Size_NNP Hoeffding_NNP Tree_NNP -LRB-_-LRB- ASHT_NNP -RRB-_-RRB- Bagging_NNP ._.
ASHT_NNP Bagging_NNP uses_VBZ trees_NNS of_IN different_JJ sizes_NNS ,_, and_CC ADWIN_NNP Bagging_NNP uses_VBZ ADWIN_NNP as_IN a_DT change_NN detector_NN to_TO decide_VB when_WRB to_TO discard_VB underperformin_NN
has_VBZ long_RB been_VBN overlooked_VBN ,_, is_VBZ that_DT of_IN concept-evolution_NN ._.
Concept-evolution_NN refers_VBZ to_TO the_DT emergence_NN of_IN a_DT new_JJ class_NN ._.
Most_JJS existing_VBG data_NNS stream_NN classifiers_NNS assume_VBP that_IN the_DT number_NN of_IN classes_NNS are_VBP fixed_VBN -LRB-_-LRB- 1_LS -RRB-_-RRB- --_: =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, in_IN data_NNS streams_NNS ,_, new_JJ classes_NNS may_MD often_RB appear_VB ._.
For_IN example_NN ,_, a_DT new_JJ kind_NN of_IN intrusion_NN may_MD appear_VB in_IN network_NN traffic_NN ,_, or_CC a_DT new_JJ category_NN of_IN text_NN may_MD appear_VB in_IN a_DT social_JJ text_NN stream_NN such_JJ as_IN Twitt_NN
roach_NN is_VBZ a_DT hybrid_JJ batch-incremental_JJ approach_NN ,_, in_IN which_WDT each_DT model_NN is_VBZ built_VBN using_VBG a_DT batch_NN learning_NN technique_NN ._.
However_RB ,_, older_JJR models_NNS are_VBP replaced_VBN by_IN newer_JJR models_NNS when_WRB the_DT older_JJR models_NNS become_VBP obsolete_JJ -LRB-_-LRB- =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 9_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 10_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Some_DT of_IN these_DT hybrid_NN approaches_NNS use_VBP a_DT single_JJ model_NN to_TO classify_VB the_DT unlabeled_JJ data_NNS -LRB-_-LRB- e.g._FW -LRB-_-LRB- 10_CD -RRB-_-RRB- -RRB-_-RRB- ,_, whereas_IN others_NNS use_VBP an_DT ensemble_NN of_IN models_NNS -LRB-_-LRB- e.g._FW -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 9_CD -RRB-_-RRB- -RRB-_-RRB- ._.
The_DT advantage_NN of_IN the_DT hybrid_NN
emaining_VBG ones_NNS ._.
Testing_VBG is_VBZ done_VBN using_VBG a_DT holdout_NN data_NN with_IN 825_CD examples_NNS from_IN the_DT current_JJ concept_NN ._.
Gradual_JJ drifts_NNS were_VBD simulated_JJ by_IN smooth_JJ transition_NN of_IN b_NN over_IN 1_CD ,_, 000_CD examples_NNS ._.
Random_NNP RBF_NNP synthetic_JJ data_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT generator_NN can_MD create_VB data_NNS which_WDT contains_VBZ a_DT rigorous_JJ concept_NN change_NN type_NN ._.
First_RB ,_, a_DT fixed_JJ number_NN of_IN centroinds_NNS are_VBP generated_VBN in_IN feature_NN space_NN ,_, each_DT assigned_VBD a_DT single_JJ class_NN label_NN ,_, weight_NN and_CC stand_NN
n_NN be_VB stored_VBN permanently_RB -_: they_PRP are_VBP observed_VBN and_CC then_RB forgotten_VBN ._.
Many_JJ incremental_JJ learners_NNS and_CC stream_NN mining_NN algorithms_NNS have_VBP been_VBN proposed_VBN in_IN the_DT last_JJ years_NNS ,_, accompanied_VBN by_IN methods_NNS for_IN evaluating_VBG them_PRP =_JJ -_: =[_NN 3_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, modern_JJ applications_NNS ask_VB for_IN more_RBR sophisticated_JJ stream_NN learners_NNS than_IN can_MD currently_RB be_VB evaluated_VBN on_IN synthetically_RB generated_VBN data_NNS ._.
In_IN this_DT work_NN ,_, we_PRP propose_VBP a_DT generator_NN for_IN complex_JJ stream_NN data_NNS
