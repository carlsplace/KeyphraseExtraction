Active_JJ learning_NN using_VBG adaptive_JJ resampling_NN
rithm_NN and_CC noise-free_JJ data_NNS ._.
Several_JJ variations_NNS of_IN the_DT original_JJ QBC_NN algorithm_NN have_VBP been_VBN proposed_VBN ,_, such_JJ as_IN the_DT Query_NNP by_IN Bagging_NNP and_CC Query_NNP by_IN Boosting_VBG algorithms_NNS -LRB-_-LRB- 29_CD -RRB-_-RRB- and_CC the_DT adaptive_JJ resampling_NN approach_NN =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Saar-Tsechansky_NNP and_CC Provost_NNP apply_VBP active_JJ learning_VBG principles_NNS to_TO obtain_VB better_JJR class_NN -LRB-_-LRB- a_DT posteriori_NN -RRB-_-RRB- probability_NN estimates_NNS -LRB-_-LRB- 31_CD -RRB-_-RRB- ._.
Given_VBN a_DT probabilistic_JJ classifier_NN ,_, the_DT Bootstrap-LV_NN attempts_VBZ to_TO select_VB ˆ_NN
sult_NN in_IN oversimplified_JJ model_NN ._.
4_LS ._.
Selective_JJ sampling_NN methods_NNS In_IN the_DT context_NN of_IN pattern_NN classification_NN systems_NNS selective_JJ sampling_NN techniques_NNS have_VBP been_VBN most_RBS frequently_RB used_VBN in_IN active_JJ learning_NN approaches_VBZ =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB samples_NNS for_IN labeling_NN are_VBP selected_VBN in_IN a_DT dynamic_JJ manner_NN -LRB-_-LRB- one_CD at_IN a_DT time_NN -RRB-_-RRB- ._.
In_IN the_DT research_NN presented_VBN here_RB the_DT static_JJ -LRB-_-LRB- one-step_JJ -RRB-_-RRB- selection_NN techniques_NNS will_MD be_VB examined_VBN ._.
In_IN contrast_NN to_TO the_DT active_JJ se_FW
Sampling_NN :_: The_DT ability_NN to_TO actively_RB select_VB the_DT most_RBS useful_JJ training_NN samples_NNS is_VBZ an_DT important_JJ aspect_NN of_IN building_VBG an_DT efficient_JJ classifier_NN ._.
Boosting_VBG and_CC bagging_VBG are_VBP being_VBG increasingly_RB used_VBN for_IN this_DT purpose_NN =_JJ -_: =[_NN 5,10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Boosting_VBG uses_VBZ all_DT instances_NNS of_IN the_DT datasets_NNS at_IN each_DT iteration_NN ,_, but_CC associates_VBZ a_DT weight_NN for_IN each_DT sample_NN ._.
Bagging_NNP ,_, on_IN the_DT other_JJ hand_NN ,_, takes_VBZ the_DT available_JJ training_NN samples_NNS and_CC generates_VBZ a_DT new_JJ sample_NN se_FW
thm_NN and_CC noise-free_JJ data_NNS ._.
A_DT number_NN of_IN variations_NNS to_TO the_DT original_JJ QBC_NN algorithm_NN have_VBP been_VBN proposed_VBN ,_, such_JJ as_IN the_DT Query_NNP by_IN Bagging_NNP and_CC Query_NNP by_IN Boosting_VBG algorithm_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- and_CC the_DT adaptive_JJ resampling_NN approach_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Active_JJ learning_NN has_VBZ also_RB been_VBN applied_VBN in_IN the_DT multi-view_JJ setting_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ._.
In_IN the_DT multi-view_JJ problem_NN ,_, features_NNS can_MD be_VB partitioned_VBN into_IN subsets_NNS each_DT of_IN which_WDT is_VBZ sufficient_JJ for_IN learning_VBG the_DT mapping_NN from_IN th_DT
ampling_NN -LRB-_-LRB- 8_CD ,_, 9_CD -RRB-_-RRB- ._.
Since_IN its_PRP$ introduction_NN there_EX have_VBP been_VBN many_JJ enhancements_NNS to_TO the_DT basic_JJ algorithm_NN ._.
These_DT include_VBP Weighted_JJ Uncertainty_NN Sampling_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, Error_NN Reduction_NN Sampling_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, and_CC Adaptive_JJ Sampling_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_JJS of_IN these_DT perform_VBP additional_JJ computation_NN to_TO choose_VB a_DT better_JJR sample_NN in_IN order_NN to_TO reduce_VB the_DT number_NN of_IN queries_NNS required_VBN to_TO achieve_VB a_DT given_VBN error_NN rate_NN ._.
The_DT algorithm_NN described_VBN in_IN this_DT paper_NN could_MD be_VB
t_NN applications_NNS ,_, including_VBG combining_VBG active_JJ learning_NN and_CC semi-supervised_JJ learning_NN under_IN boosting_VBG -LRB-_-LRB- COMB_NN -RRB-_-RRB- for_IN spoken_VBN language_NN understanding_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- and_CC adaptive_JJ resampling_VBG approach_NN for_IN image_NN identification_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, there_EX still_RB remains_VBZ some_DT problems_NNS for_IN this_DT type_NN of_IN methods_NNS ._.
•_CD There_EX lacks_VBZ more_RBR theoretical_JJ analysis_NN for_IN these_DT boosting_VBG based_VBN active_JJ learning_NN methods_NNS ._.
There_EX is_VBZ no_DT explicit_JJ consistent_JJ objecti_NNS
oping_VBG with_IN both_DT types_NNS of_IN data_NNS ._.
3_CD Selective_JJ Sampling_NN Methods_NNS In_IN the_DT context_NN of_IN pattern_NN classification_NN systems_NNS selective_JJ sampling_NN techniques_NNS have_VBP been_VBN most_RBS frequently_RB used_VBN in_IN active_JJ learning_NN approaches_VBZ =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB samples_NNS for_IN labeling_NN are_VBP selected_VBN in_IN a_DT dynamic_JJ manner_NN -LRB-_-LRB- one_CD at_IN a_DT time_NN -RRB-_-RRB- ._.
In_IN the_DT research_NN presented_VBN here_RB the_DT preliminary_JJ selection_NN techniques_NNS will_MD be_VB examined_VBN ._.
In_IN contrast_NN to_TO the_DT active_JJ selectio_NN
and_CC noise-free_JJ data_NNS ._.
A_DT number_NN of_IN variations_NNS to_TO the_DT original_JJ QBC_NN algorithm_NN have_VBP been_VBN proposed_VBN ,_, such_JJ as_IN the_DT Query_NNP by_IN Bagging_NNP and_CC Query_NNP by_IN Boosting_VBG algorithm_NN -LRB-_-LRB- AM98_NN -RRB-_-RRB- and_CC the_DT adaptive_JJ resampling_NN approach_NN =_JJ -_: =_JJ -LRB-_-LRB- IAZ00_NN -RRB-_-RRB- -_: =_SYM -_: ._.
Tsechansky_NNP et_FW al._FW -LRB-_-LRB- STP01_NN -RRB-_-RRB- apply_VBP active_JJ learning_VBG principles_NNS to_TO obtain_VB bet23ster_NN class_NN -LRB-_-LRB- A_NN Posteriori_NN -RRB-_-RRB- probability_NN estimates_NNS ._.
Given_VBN a_DT probabilistic_JJ classifier_NN ,_, the_DT Bootstrap-LV_NN attempts_VBZ to_TO choose_VB the_DT d_NN
s_VBZ the_DT investigation_NN of_IN the_DT problem_NN of_IN the_DT sufficient_JJ level_NN of_IN labeled_JJ samples_NNS -LRB-_-LRB- SLLS_NNS -RRB-_-RRB- is_VBZ crucial_JJ for_IN minimizing_VBG the_DT cost_NN of_IN classification_NN ._.
Its_PRP$ existence_NN has_VBZ been_VBN mentioned_VBN by_IN some_DT researchers_NNS -LRB-_-LRB- -LRB-_-LRB- 16_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 45_CD -RRB-_-RRB- -_: =--RRB-_NN but_CC no_DT proper_JJ analysis_NN has_VBZ yet_RB been_VBN done_VBN ._.
There_EX is_VBZ a_DT '_POS catch_NN 22_CD '_'' associated_VBN with_IN this_DT problem_NN :_: on_IN one_CD side_NN we_PRP have_VBP to_TO estimate_VB the_DT sufficient_JJ level_NN based_VBN only_RB on_IN the_DT small_JJ labeled_JJ subset_NN available_JJ b_NN
iction_NN error_NN ._.
Abe_NN and_CC Mamitsuka_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- proposed_VBD two_CD variants_NNS of_IN the_DT QBC_NNP algorithm_NN ,_, query-by-bagging_JJ and_CC query-by-boosting_JJ ._.
Both_DT of_IN them_PRP did_VBD better_RBR than_IN QBC_NNP ,_, C4_NN .5_NN ,_, and_CC boosting_VBG with_IN C4_NN .5_CD ._.
Recent_JJ research_NN =_JJ -_: =[_NN 19_CD ,_, 16_CD ,_, 29_CD ,_, 30_CD -RRB-_-RRB- -_: =_SYM -_: concentrates_VBZ on_IN algorithms_NNS to_TO process_VB data_NNS automatically_RB and_CC algorithms_NNS that_WDT involve_VBP much_RB less_RBR human_JJ expert_NN involvement_NN ._.
A_DT variant_NN of_IN an_DT active_JJ learning_NN algorithm_NN has_VBZ been_VBN suggested_VBN -LRB-_-LRB- 19_CD -RRB-_-RRB- that_WDT learns_VBZ
was_VBD also_RB shown_VBN to_TO be_VB useful_JJ in_IN improving_VBG query_NN answering_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
The_DT authors_NNS demonstrated_VBD how_WRB selective_JJ sampling_NN can_MD be_VB approximately_RB implemented_VBN using_VBG neural_JJ networks_NNS ._.
Another_DT line_NN of_IN recent_JJ research_NN =_JJ -_: =[_NN 21_CD ,_, 18_CD ,_, 37_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: concentrates_VBZ on_IN developing_VBG algorithms_NNS to_TO process_VB data_NNS automatically_RB so_IN that_DT much_RB less_RBR expert_JJ involvement_NN is_VBZ needed_VBN ._.
A_DT variant_NN of_IN an_DT Active_JJ Learning_NNP algorithm_NN has_VBZ been_VBN suggested_VBN in_IN -LRB-_-LRB- 21_CD -RRB-_-RRB- to_TO learn_VB from_IN
In_IN addition_NN ,_, to_TO overcome_VB data_NNS sparseness_NN ,_, which_WDT is_VBZ often_RB a_DT problem_NN for_IN achieving_VBG semantic_JJ descriptions_NNS from_IN data_NNS mining_NN ,_, there_EX is_VBZ the_DT possibility_NN to_TO 4_CD actively_RB collect_VB data_NNS -LRB-_-LRB- also_RB cf._VBP Active_JJ Learning_NNP =_SYM -_: =[_NN 48_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
For_IN instance_NN ,_, data_NNS mining_NN based_VBN on_IN Web_NN resources_NNS to_TO achieve_VB emergent_JJ semantics_NNS uses_VBZ globally_RB available_JJ Web_NN data_NNS and_CC structures_NNS to_TO define_VB new_JJ local_JJ semantics_NNS ._.
Blueprints_NNS for_IN this_DT paradigm_NN are_VBP found_VBN
at_IN active_JJ learning_NN can_MD significantly_RB reduce_VB the_DT amount_NN of_IN labeled_JJ data_NNS required_VBN to_TO build_VB accurate_JJ models_NNS in_IN some_DT e-commerce_NN related_JJ domains_NNS ,_, such_JJ as_IN direct_JJ marketing_NN -LRB-_-LRB- 53_CD -RRB-_-RRB- and_CC identifying_VBG internet_NN ads_NNS =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
4.3_CD Active_JJ feature-value_JJ acquisition_NN In_IN the_DT active_JJ learning_NN setting_NN we_PRP assume_VBP we_PRP have_VBP unlabeled_JJ instances_NNS ,_, and_CC the_DT learner_NN dynamically_RB selects_VBZ the_DT instances_NNS to_TO be_VB labeled_VBN ._.
Consider_VB instead_RB the_DT follo_NN
and_CC their_PRP$ applications_NNS ,_, and_CC have_VBP observed_VBN dramatic_JJ improvements_NNS in_IN the_DT accuracy_NN results_VBZ in_IN many_JJ instances_NNS ._.
These_DT include_VBP financial_JJ portfolio_NN management_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, text_NN categorization_NN -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, active_JJ learning_NN =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC fast_JJ methods_NNS for_IN rule-based_JJ classification_NN and_CC regression_NN -LRB-_-LRB- 27_CD ,_, 28_CD -RRB-_-RRB- ._.
6_CD Conclusion_NN Increased_VBN attention_NN and_CC focus_NN on_IN decision_NN support_NN solutions_NNS using_VBG data_NN mining_NN techniques_NNS has_VBZ refueled_VBN a_DT big_JJ inter_NN
examples_NNS more_JJR Itkely_NNP to_TO be_VB informative_JJ regarding_VBG other_JJ examples_NNS in_IN the_DT space_NN ._.
Note_VB that_DT weight_NN sampling_NN also_RB is_VBZ employed_VBN in_IN the_DT ,_, ldaBoost_NN algorithm_NN -LRB-_-LRB- Freund_NNP and_CC Shapire_NNP ,_, 1996_CD -RRB-_-RRB- on_IN which_WDT Iyengar_NNP et_FW al._FW -LRB-_-LRB- =_JJ -_: =_JJ Iyengar_NNP et_FW al._FW ,_, 2000_CD -_: =--RRB-_NN base_VBP their_PRP$ active_JJ learning_NN approach_NN ._.
Their_PRP$ algorithm_NN results_VBZ in_IN an_DT ensemble_NN of_IN classif3ers_NNS where_WRB weight_NN sampling_NN is_VBZ used_VBN both_DT to_TO select_VB examples_NNS from_IN which_WDT successive_JJ classifiers_NNS in_IN the_DT ensemble_NN are_VBP
their_PRP$ applications_NNS ,_, and_CC have_VBP observed_VBN dramatic_JJ improvements_NNS in_IN the_DT accuracy_NN of_IN results_NNS in_IN many_JJ instances_NNS ._.
These_DT include_VBP financial_JJ portfolio_NN management_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, text_NN categorization_NN -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, active_JJ learning_NN =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC fast_JJ methods_NNS for_IN rule-based_JJ classification_NN and_CC regression_NN -LRB-_-LRB- 27_CD ,_, 28_CD -RRB-_-RRB- ._.
Conclusion_NN Increased_VBD attention_NN and_CC focus_NN on_IN decision_NN support_NN solutions_NNS using_VBG data_NN mining_NN techniques_NNS has_VBZ refueled_VBN interest_NN in_IN c_NN
ampling_NN -LRB-_-LRB- 7_CD ,_, 8_CD -RRB-_-RRB- ._.
Since_IN its_PRP$ introduction_NN there_EX have_VBP been_VBN many_JJ enhancements_NNS to_TO the_DT basic_JJ algorithm_NN ._.
These_DT include_VBP Weighted_JJ Uncertainty_NN Sampling_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, Error_NN Reduction_NN Sampling_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, and_CC Adaptive_JJ Sampling_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_JJS of_IN these_DT perform_VBP additional_JJ computation_NN to_TO choose_VB a_DT better_JJR sample_NN in_IN order_NN to_TO reduce_VB the_DT number_NN of_IN queries_NNS required_VBN to_TO achieve_VB a_DT given_VBN error_NN rate_NN ._.
The_DT algorithm_NN described_VBN in_IN this_DT paper_NN could_MD be_VB
._.
In_IN practice_NN ,_, however_RB ,_, these_DT heuristics_NNS are_VBP computationally_RB expensive_JJ since_IN they_PRP require_VBP that_IN the_DT SVM_NNP is_VBZ trained_VBN twice_RB using_VBG a_DT positive_JJ and_CC negative_JJ label_NN ._.
3.5_CD Reducing_VBG Future_JJ Error_NN Another_DT approach_NN =_JJ -_: =[_NN 8_CD ,_, 12_CD ,_, 15_CD ,_, 21_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ to_TO select_VB examples_NNS that_WDT are_VBP helpful_JJ in_IN building_VBG up_RP confidence_NN in_IN low_JJ future_JJ error_NN ._.
It_PRP is_VBZ impossible_JJ to_TO know_VB the_DT exact_JJ future_JJ error_NN without_IN knowing_VBG the_DT target_NN concept_NN ,_, but_CC approximations_NNS make_VBP this_DT
examples_NNS more_RBR likely_JJ to_TO be_VB informative_JJ regarding_VBG other_JJ examples_NNS in_IN the_DT space_NN ._.
Note_VB that_DT weight_NN sampling_NN also_RB is_VBZ employed_VBN in_IN the_DT AdaBoost_NNP algorithm_NN -LRB-_-LRB- Freund_NNP and_CC Shapire_NNP ,_, 1996_CD -RRB-_-RRB- on_IN which_WDT Iyengar_NNP et_FW al._FW -LRB-_-LRB- =_JJ -_: =_JJ Iyengar_NNP et_FW al._FW ,_, 2000_CD -_: =-]_CD base_NN their_PRP$ active_JJ learning_NN approach_NN ._.
Their_PRP$ algorithm_NN results_VBZ in_IN an_DT ensemble_NN of_IN classifiers_NNS where_WRB weight_NN sampling_NN is_VBZ used_VBN both_DT to_TO select_VB examples_NNS from_IN which_WDT successive_JJ classifiers_NNS in_IN the_DT ensemble_NN are_VBP
at_IN active_JJ learning_NN can_MD significantly_RB reduce_VB the_DT amount_NN of_IN labeled_JJ data_NNS required_VBN to_TO build_VB accurate_JJ models_NNS in_IN some_DT e-commerce_NN related_JJ domains_NNS ,_, such_JJ as_IN direct_JJ marketing_NN -LRB-_-LRB- 53_CD -RRB-_-RRB- and_CC identifying_VBG internet_NN ads_NNS =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
4.3_CD Active_JJ feature-value_JJ acquisition_NN In_IN the_DT active_JJ learning_NN setting_NN we_PRP assume_VBP we_PRP have_VBP unlabeled_JJ instances_NNS ,_, and_CC the_DT learner_NN dynamically_RB selects_VBZ the_DT instances_NNS to_TO be_VB labeled_VBN ._.
Consider_VB instead_RB the_DT follo_NN
learning_VBG and_CC learning_VBG from_IN labeled_JJ and_CC unlabeled_JJ data_NNS have_VBP been_VBN proposed_VBN ._.
In_IN active_JJ learning_VBG new_JJ samples_NNS to_TO be_VB labeled_VBN are_VBP typicallysselected_VBN to_TO maximize_VB the_DT performance_NN of_IN the_DT classifier_NN in_IN some_DT way_NN =_JJ -_: =[_NN 4_CD ,_, 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Some_DT attempts_NNS for_IN learning_VBG with_IN both_CC labeled_JJ and_CC unlabeled_JJ data_NNS sets_NNS have_VBP also_RB been_VBN done_VBN ._.
See_NNP ,_, for_IN example_NN ,_, a_DT review_NN of_IN Seeger_NNP -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
Our_PRP$ goal_NN is_VBZ label_NN textures_NNS with_IN only_RB a_DT small_JJ human_JJ effort_NN ._.
In_IN our_PRP$
