Combining_VBG linguistic_JJ and_CC statistical_JJ analysis_NN to_TO extract_VB relations_NNS from_IN web_NN documents_NNS
The_DT World_NNP Wide_NN Web_NN provides_VBZ a_DT nearly_RB endless_JJ source_NN of_IN knowledge_NN ,_, which_WDT is_VBZ mostly_RB given_VBN in_IN natural_JJ language_NN ._.
A_DT first_JJ step_NN towards_IN exploiting_VBG this_DT data_NNS automatically_RB could_MD be_VB to_TO extract_VB pairs_NNS of_IN a_DT given_VBN semantic_JJ relation_NN from_IN text_NN documents_NNS -_: for_IN example_NN all_DT pairs_NNS of_IN a_DT person_NN and_CC her_PRP$ birthdate_NN ._.
One_CD strategy_NN for_IN this_DT task_NN is_VBZ to_TO find_VB text_NN patterns_NNS that_WDT express_VBP the_DT semantic_JJ relation_NN ,_, to_TO generalize_VB these_DT patterns_NNS ,_, and_CC to_TO apply_VB them_PRP to_TO a_DT corpus_NN to_TO find_VB new_JJ pairs_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP show_VBP that_IN this_DT approach_NN profits_NNS significantly_RB when_WRB deep_JJ linguistic_JJ structures_NNS are_VBP used_VBN instead_RB of_IN surface_NN text_NN patterns_NNS ._.
We_PRP demonstrate_VBP how_WRB linguistic_JJ structures_NNS can_MD be_VB represented_VBN for_IN machine_NN learning_NN ,_, and_CC we_PRP provide_VBP a_DT theoretical_JJ analysis_NN of_IN the_DT pattern_NN matching_NN approach_NN ._.
We_PRP show_VBP the_DT benefits_NNS of_IN our_PRP$ approach_NN by_IN extensive_JJ experiments_NNS with_IN our_PRP$ prototype_NN system_NN LEILA_NNP ._.
ten_CD be_VB unacceptable_JJ ._.
This_DT led_VBD to_TO a_DT series_NN of_IN improvements_NNS in_IN a_DT variety_NN of_IN projects_NNS and_CC tool_NN developments_NNS ,_, most_RBS notably_RB ,_, Snowball_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ,_, Semagix\/SWETO_NN -LRB-_-LRB- 5_CD ,_, 118_CD -RRB-_-RRB- ,_, KnowItAll_NN -LRB-_-LRB- 59_CD -RRB-_-RRB- ,_, Text2Onto_NN -LRB-_-LRB- 21_CD ,_, 40_CD -RRB-_-RRB- ,_, LEILA_NN =_JJ -_: =[_NN 122_CD -RRB-_-RRB- -_: =_JJ -_: ,_, TextRunner_NN -LRB-_-LRB- 13_CD ,_, 142_CD -RRB-_-RRB- ,_, SEAL_NN -LRB-_-LRB- 134_CD -RRB-_-RRB- ,_, and_CC the_DT work_NN by_IN -LRB-_-LRB- 23_CD -RRB-_-RRB- and_CC -LRB-_-LRB- 141_CD -RRB-_-RRB- -LRB-_-LRB- and_CC others_NNS -RRB-_-RRB- ._.
Snowball_NNP ,_, KnowItAll_NNP ,_, and_CC Text2Onto_NN improved_VBD the_DT statistical_JJ assessment_NN of_IN fact_NN candidates_NNS and_CC patterns_NNS in_IN a_DT variety_NN of_IN
er_IN difficult_JJ task_NN ._.
Other_JJ methods_NNS exploiting_VBG information_NN redundancy_NN can_MD be_VB found_VBN in_IN -LRB-_-LRB- 7_CD -RRB-_-RRB- -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
These_DT systems_NNS generally_RB face_VBP the_DT problem_NN that_IN many_JJ parameters_NNS need_VBP to_TO be_VB specified_VBN for_IN each_DT relation_NN ._.
LEILA_NN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: automatically_RB generated_VBN negative_JJ examples_NNS using_VBG information_NN about_IN the_DT cardinality_NN of_IN relations_NNS ._.
Work_NN conducted_VBN in_IN -LRB-_-LRB- 19_CD -RRB-_-RRB- -LRB-_-LRB- 20_CD -RRB-_-RRB- employed_VBN semi-supervised_JJ learning_NN algorithms_NNS and_CC achieved_VBD good_JJ performance_NN
c_NN techniques_NNS ._.
2_CD ._.
Related_JJ Work_NN Numerous_JJ approaches_NNS have_VBP been_VBN proposed_VBN to_TO construct_VB general-purpose_JJ ontologies_NNS ._.
One_CD class_NN of_IN techniques_NNS focuses_VBZ on_IN extracting_VBG information_NN automatically_RB from_IN text_NN corpora_NN =_JJ -_: =[_NN 10_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Despite_IN good_JJ results_NNS ,_, the_DT quality_NN remains_VBZ below_IN that_DT of_IN well-designed_JJ hand-crafted_JJ ontologies_NNS ._.
Furthermore_RB ,_, the_DT facts_NNS are_VBP not_RB canonic_JJ ,_, i.e._FW different_JJ identifiers_NNS are_VBP used_VBN for_IN the_DT same_JJ entity_NN and_CC no_DT
e_LS relations_NNS between_IN these_DT ,_, as_RB well_RB as_IN smaller_JJR events_NNS that_WDT do_VBP not_RB have_VB a_DT proper_JJ name_NN we_PRP will_MD first_RB employ_VB state_NN of_IN the_DT art_NN named_VBN entity_NN and_CC term_NN recognition_NN techniques_NNS -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, followed_VBN by_IN relation_NN finding_NN =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Once_RB we_PRP are_VBP able_JJ to_TO detect_VB references_NNS to_TO events_NNS ,_, we_PRP will_MD need_VB to_TO identify_VB which_WDT references_NNS belong_VBP to_TO distinct_JJ events_NNS ,_, and_CC which_WDT are_VBP a_DT variation_NN on_IN the_DT description_NN of_IN the_DT same_JJ event_NN ._.
From_IN manual_FW extr_FW
r_NN of_IN useful_JJ lexico-syntactic_JJ patterns_NNS ._.
Snow_NNP et_FW al._FW -LRB-_-LRB- 5_CD -RRB-_-RRB- proposed_VBD a_DT generic_JJ method_NN that_WDT formalizes_VBZ lexico-syntactic_JJ patterns_NNS with_IN dependency_NN paths_NNS as_IN features_NNS for_IN prediction_NN of_IN hypernyms_NNS ._.
Suchanek_NNP et_FW al._FW =_SYM -_: =[_NN 1_CD ,_, 2_CD -RRB-_-RRB- -_: =_SYM -_: applied_VBD a_DT supervised_JJ learning_NN algorithm_NN to_TO fact_NN extraction_NN from_IN Wikipedia_NNP yielding_VBG a_DT common_JJ ontology_NN as_IN social_JJ semantic_JJ knowledge_NN ._.
Generic_JJ pattern_NN classification_NN is_VBZ one_CD of_IN the_DT most_RBS significant_JJ issues_NNS
extract_NN taxonomic_JJ relations_NNS and_CC Yago_NNP is_VBZ limited_VBN to_TO a_DT predefined_JJ set_NN of_IN relations_NNS ,_, Wanderlust_NNP is_VBZ capable_JJ of_IN extracting_VBG arbitrary_JJ relations_NNS ._.
Recent_JJ work_NN most_RBS similar_JJ to_TO our_PRP$ approach_NN are_VBP -LRB-_-LRB- 17_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 27_CD -RRB-_-RRB- and_CC =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
While_IN previously_RB mentioned_VBN approaches_NNS exclusively_RB rely_VBP on_IN the_DT existence_NN of_IN structured_JJ data_NNS ,_, these_DT systems_NNS allow_VBP to_TO extract_VB semantic_JJ relations_NNS from_IN natural_JJ language_NN text_NN ._.
Like_IN Wanderlust_NNP ,_, -LRB-_-LRB- 17_CD ,_, 25_CD -RRB-_-RRB- ma_FW
631WWW_CD 2009_CD MADRID_NNP !_.
The_DT accuracy_NN of_IN this_DT technique_NN critically_RB depends_VBZ on_IN having_VBG a_DT variety_NN of_IN meaningful_JJ patterns_NNS ._.
It_PRP can_MD be_VB further_RB boosted_VBN if_IN counter-productive_JJ patterns_NNS are_VBP excluded_VBN systematically_RB =_JJ -_: =[_NN 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Thus_RB ,_, discovering_VBG and_CC assessing_VBG patterns_NNS is_VBZ a_DT key_JJ task_NN of_IN IE_NN ._.
Entity_NN disambiguation_NN :_: For_IN ontological_JJ IE_NN ,_, the_DT words_NNS or_CC phrases_NNS from_IN the_DT text_NN have_VBP to_TO be_VB mapped_VBN to_TO entities_NNS in_IN the_DT ontology_NN ._.
In_IN many_JJ cas_NNS
without_IN signif161icantly_RB affecting_VBG the_DT outcome_NN of_IN the_DT computation_NN ._.
We_PRP have_VBP validated_VBN in_IN our_PRP$ experiments_NNS that_IN it_PRP is_VBZ indeed_RB the_DT case_NN ._.
Our_PRP$ implementation_NN is_VBZ in_IN Java_NNP ,_, using_VBG the_DT Java_NNP Tools_NNP developed_VBD for_IN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Berkeley_NNP DB_NNP ._.
We_PRP used_VBD the_DT Jena_NNP framework_NN to_TO load_VB and_CC convert_VB the_DT ontologies_NNS ._.
The_DT algorithm_NN turns_VBZ out_RP to_TO be_VB heavily_RB IO-bound_JJ ._.
Therefore_RB ,_, we_PRP used_VBD a_DT solid-state_JJ drive_NN -LRB-_-LRB- SSD_NN -RRB-_-RRB- with_IN high_JJ read_NN bandwidth_NN t_NN
acting_VBG knowledge_NN structures_NNS automatically_RB from_IN text_NN corpora_NN ._.
These_DT approaches_NNS use_VBP information_NN extraction_NN technologies_NNS that_WDT include_VBP pattern_NN matching_JJ ,_, natural-language_JJ parsing_NN ,_, and_CC statistical_JJ learning_NN =_JJ -_: =[_NN 25_CD ,_, 9_CD ,_, 4_CD ,_, 1_CD ,_, 23_CD ,_, 20_CD ,_, 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
These_DT techniques_NNS have_VBP also_RB been_VBN used_VBN to_TO extend_VB WordNet_NNP by_IN Wikipedia_NNP individuals_NNS -LRB-_-LRB- 21_CD -RRB-_-RRB- ._.
Another_DT project_NN along_IN these_DT lines_NNS is_VBZ KnowItAll_NNP -LRB-_-LRB- 9_CD -RRB-_-RRB- ,_, which_WDT aims_VBZ at_IN extracting_VBG and_CC compiling_VBG instances_NNS of_IN unary_JJ an_DT
responding_VBG fact_NN was_VBD found_VBN ._.
NAGA_NNP 's_POS knowledge_NN base_NN is_VBZ a_DT projection_NN of_IN YAGO_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- ._.
It_PRP contains_VBZ about_IN 1_CD million_CD entities_NNS and_CC 6_CD million_CD facts_NNS ,_, partlysWWW_NN 2007_CD \/_: Poster_NNP Paper_NNP Topic_NNP :_: Search_VB extracted_VBN by_IN LEILA_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT sample_NN of_IN this_DT knowledge-base_NN is_VBZ shown_VBN below_IN :_: 3_CD ._.
QUERY_NN AND_CC ANSWER_NN MODEL_NN In_IN the_DT spirit_NN of_IN the_DT example_NN query_NN in_IN the_DT introduction_NN we_PRP present_VBP a_DT taxonomy_NN of_IN queries_NNS supported_VBN by_IN NAGA_NN ._.
Basically_RB ,_, a_DT NAGA_NN
cted_VBN from_IN semi-structured_JJ Web-based_JJ sources_NNS such_JJ as_IN Wikipedia_NNP and_CC IMDB_NNP as_RB well_RB as_IN hand-crafted_JJ ontologies_NNS such_JJ as_IN WordNet_NNP -LRB-_-LRB- 28_CD -RRB-_-RRB- ._.
Additionally_RB ,_, we_PRP utilize_VBP state-of-the-art_JJ extraction_NN tools_NNS such_JJ as_IN Leila_NN =_JJ -_: =[_NN 47_CD -RRB-_-RRB- -_: =_SYM -_: in_IN order_NN to_TO extract_VB facts_NNS from_IN unstructured_JJ Web-pages_NNS containing_VBG natural_JJ language_NN text_NN ._.
Figure_NN 1.1_CD :_: Query_NN :_: Physicists_NNS born_VBN in_IN the_DT same_JJ year_NN as_IN Max_NNP Planck_NNP In_IN order_NN to_TO query_VB the_DT knowledge-graph_NN ,_, NAGA_NN p_NN
of_IN these_DT relationships_NNS from_IN the_DT corpus_NN ._.
For_IN example_NN ,_, with_IN respect_NN to_TO the_DT is-a_NN relationship_NN possible_JJ instances_NNS might_MD be_VB :_: ``_`` Einstein_NNP is_VBZ a_DT physicist_NN ''_'' ,_, ``_`` Paris_NNP is_VBZ a_DT city_NN ''_'' ,_, etc._NN ._.
The_DT LEILA_NN tool_NN presented_VBN in_IN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: suits_NNS this_DT task_NN ._.
We_PRP are_VBP also_RB using_VBG GATE_NN 3_CD as_IN a_DT named_VBN entity_NN recognition_NN tool_NN ._.
The_DT recognized_VBN entities_NNS and_CC their_PRP$ concepts_NNS are_VBP regarded_VBN as_IN instances_NNS of_IN the_DT is-a_NN relationship_NN ._.
The_DT extracted_VBN instances_NNS ar_IN
lysis_NN ,_, pattern_NN matching_NN ,_, and_CC statistical_JJ learning_NN to_TO identify_VB ,_, for_IN example_NN ,_, person_NN names_NNS or_CC locations_NNS and_CC to_TO extract_VB instances_NNS of_IN binary_JJ relations_NNS such_JJ as_IN located-at_NN -LRB-_-LRB- city_NN ,_, the_DT LEILA_NNP prototype_NN system_NN =_JJ -_: =[_NN 31_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT method_NN is_VBZ almost_RB unsupervised_JJ by_IN starting_VBG with_IN merely_RB a_DT small_JJ set_NN of_IN userprovided_JJ positive_JJ examples_NNS such_JJ as_IN -LRB-_-LRB- Paris_NNP ,_, Seine_NNP -RRB-_-RRB- ,_, -LRB-_-LRB- Calcutta_NNP ,_, Ganges_NNP -RRB-_-RRB- ,_, -LRB-_-LRB- London_NNP ,_, Thames_NNP -RRB-_-RRB- and_CC either_CC explicit_JJ or_CC token-base_JJ
revenue_NN in_IN the_DT year_NN when_WRB it_PRP acquired_VBD YouTube_NNP ?_.
There_EX are_VBP many_JJ good_JJ IE_NN systems_NNS available_JJ for_IN extracting_VBG binary_JJ relations_NNS from_IN text_NN documents_NNS ,_, such_JJ as_IN Gate\/Annie_NN -LRB-_-LRB- 28_CD -RRB-_-RRB- ,_, Snowball_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ,_, Text2Onto_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ,_, Leila_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: ,_, TextRunner_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- ._.
But_CC unfortunately_RB ,_, none_NN of_IN these_DT systems_NNS works_VBZ for_IN temporal_JJ relations_NNS with_IN satisfactory_JJ precision_NN ._.
We_PRP propose_VBP a_DT suite_NN of_IN methods_NNS for_IN extracting_VBG and_CC inferring_VBG temporal_JJ relations_NNS from_IN
cted_VBN from_IN semi-structured_JJ Web-based_JJ sources_NNS such_JJ as_IN Wikipedia_NNP and_CC IMDB_NNP as_RB well_RB as_IN hand-crafted_JJ ontologies_NNS such_JJ as_IN WordNet_NNP -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
Additionally_RB ,_, we_PRP utilize_VBP state-of-theart_JJ extraction_NN tools_NNS such_JJ as_IN LEILA_NN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_SYM -_: in_IN order_NN to_TO extract_VB facts_NNS from_IN unstructured_JJ Web-pages_NNS containing_VBG natural_JJ language_NN text_NN ._.
As_IN of_IN now_RB ,_, NAGA_NNP understands_VBZ 26_CD predefined_VBN relationships_NNS such_JJ as_IN isA_NN ,_, bornInYear_NN ,_, establishedInYear_NN ,_, hasWonPrize_NN
