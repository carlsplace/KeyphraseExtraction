SECRET_NN :_: a_DT scalable_JJ linear_JJ regression_NN tree_NN algorithm_NN
Developing_VBG regression_NN models_NNS for_IN large_JJ datasets_NNS that_WDT are_VBP both_DT accurate_JJ and_CC easy_JJ to_TO interpret_VB is_VBZ a_DT very_RB important_JJ data_NNS mining_NN problem_NN ._.
Regression_NN trees_NNS with_IN linear_JJ models_NNS in_IN the_DT leaves_NNS satisfy_VBP both_DT these_DT requirements_NNS ,_, but_CC thus_RB far_RB ,_, no_DT truly_RB scalable_JJ regression_NN tree_NN algorithm_NN is_VBZ known_VBN ._.
This_DT paper_NN proposes_VBZ a_DT novel_JJ regression_NN tree_NN construction_NN algorithm_NN -LRB-_-LRB- SECRET_NN -RRB-_-RRB- that_WDT produces_VBZ trees_NNS of_IN high_JJ quality_NN and_CC scales_NNS to_TO very_RB large_JJ datasets_NNS ._.
At_IN every_DT node_NN ,_, SECRET_NNP uses_VBZ the_DT EM_NNP algorithm_NN for_IN Gaussian_JJ mixtures_NNS to_TO find_VB two_CD clusters_NNS in_IN the_DT data_NNS and_CC to_TO locally_RB transform_VB the_DT regression_NN problem_NN into_IN a_DT classification_NN problem_NN based_VBN on_IN closeness_NN to_TO these_DT clusters_NNS ._.
Goodness_NN of_IN split_JJ measures_NNS ,_, like_IN the_DT gini_NNS gain_NN ,_, can_MD then_RB be_VB used_VBN to_TO determine_VB the_DT split_NN variable_NN and_CC the_DT split_NN point_NN much_RB like_IN in_IN classification_NN tree_NN construction_NN ._.
Scalability_NN of_IN the_DT algorithm_NN can_MD be_VB achieved_VBN by_IN employing_VBG scalable_JJ versions_NNS of_IN the_DT EM_NN and_CC classification_NN tree_NN construction_NN algorithms_NNS ._.
An_DT experimental_JJ evaluation_NN on_IN real_JJ and_CC artificial_JJ data_NNS shows_VBZ that_IN SECRET_NNP has_VBZ accuracy_NN comparable_JJ to_TO other_JJ linear_JJ regression_NN tree_NN algorithms_NNS but_CC takes_VBZ orders_NNS of_IN magnitude_NN less_RBR computation_JJ time_NN for_IN large_JJ datasets_NNS ._.
-RRB-_-RRB- ,_, where_WRB internal_JJ nodes_NNS -LRB-_-LRB- splitting_NN nodes_NNS -RRB-_-RRB- are_VBP generally_RB associated_VBN with_IN a_DT logical_JJ test_NN on_IN predictor_NN variables_NNS ,_, while_IN leaves_NNS -LRB-_-LRB- i.e._FW bottom_JJ nodes_NNS in_IN the_DT hierarchy_NN -RRB-_-RRB- are_VBP associated_VBN with_IN -LRB-_-LRB- linear_NN -RRB-_-RRB- functions_VBZ =_JJ -_: =[_NN 16,10,19,17,18,2,11,4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT different_JJ tree_NN structure_NN with_IN both_CC regression_NN and_CC splitting_NN nodes_NNS is_VBZ mined_VBN by_IN the_DT system_NN SMOTI_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ._.
Regression_NN nodes_NNS perform_VBP straight-line_JJ regression_NN ,_, while_IN splitting_JJ nodes_NNS partition_NN the_DT training_NN
odels_NNS in_IN the_DT leaves_NNS ,_, but_CC at_IN each_DT node_NN transforms_VBZ the_DT regression_NN problem_NN into_IN a_DT classification_NN problem_NN in_IN order_NN to_TO use_VB more_RBR efficient_JJ search_NN strategies_NNS ._.
Examples_NNS are_VBP Support_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, Guide_NNP -LRB-_-LRB- 9_CD -RRB-_-RRB- ,_, and_CC Secret_NNP =_SYM -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT first_JJ two_CD systems_NNS make_VBP use_NN of_IN statistical_JJ methods_NNS for_IN variable_JJ 5sx_FW â‰¤_FW 0.665_CD LM2_NN LM3_NN 1.2_CD ..._: ..._: ..._: ._.
0.8_CD ..._: ..._: ..._: ..._: ..._: ..._: ..._: ._. ._.
ple_NN authors_NNS have_VBP proposed_VBN methods_NNS to_TO improve_VB upon_IN the_DT accuracy_NN of_IN regression_NN trees_NNS by_IN generating_VBG models_NNS in_IN the_DT leaf_NN nodes_NNS of_IN the_DT tree_NN rather_RB than_IN to_TO simply_RB predict_VB the_DT mean_NN ._.
M5_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, HTL_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ,_, SECRET_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: ,_, incremental_JJ learning_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, SUPPORT_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ,_, GUIDE_NNP -LRB-_-LRB- 8_CD -RRB-_-RRB- ,_, PHDRT_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- and_CC SMOTI_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- are_VBP some_DT of_IN the_DT model_NN tree_NN algorithms_NNS that_WDT have_VBP been_VBN proposed_VBN ._.
We_PRP refer_VBP to_TO the_DT term_NN ``_`` model_NN tree_NN ''_'' as_IN the_DT more_RBR general_JJ form_NN o_NN
oolbox_NN based_VBN on_IN Gustafson_NNP --_: Kessel_NNP clustering_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- ;_: GUIDE_NNP -LRB-_-LRB- linear_JJ regression_NN tree_NN -RRB-_-RRB- -LRB-_-LRB- 117_CD -RRB-_-RRB- ;_: and_CC Scalable_JJ Linear_JJ Regression_NN Tree_NN Algorithm_NN -LRB-_-LRB- SECRET_NN -RRB-_-RRB- and_CC its_PRP$ modified_VBN version_NN with_IN oblique_JJ splits_VBZ -LRB-_-LRB- SECRET_NN -LRB-_-LRB- O_NN -RRB-_-RRB- -RRB-_-RRB- =_JJ -_: =[_NN 47_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT last_JJ three_CD methods_NNS can_MD use_VB constant_JJ regressors_NNS -LRB-_-LRB- special_JJ ,_, zero-order_JJ linear_JJ regressor_NN -RRB-_-RRB- or_CC linear_JJ ones_NNS ._.
This_DT section_NN compares_VBZ the_DT result_NN of_IN the_DT presented_VBN method_NN ,_, which_WDT is_VBZ based_VBN on_IN linear_JJ regressor_NN
