Extracting_VBG discriminative_JJ concepts_NNS for_IN domain_NN adaptation_NN in_IN text_NN mining_NN
One_CD common_JJ predictive_JJ modeling_NN challenge_NN occurs_VBZ in_IN text_NN mining_NN problems_NNS is_VBZ that_IN the_DT training_NN data_NNS and_CC the_DT operational_JJ -LRB-_-LRB- testing_NN -RRB-_-RRB- data_NNS are_VBP drawn_VBN from_IN different_JJ underlying_JJ distributions_NNS ._.
This_DT poses_VBZ a_DT great_JJ difficulty_NN for_IN many_JJ statistical_JJ learning_NN methods_NNS ._.
However_RB ,_, when_WRB the_DT distribution_NN in_IN the_DT source_NN domain_NN and_CC the_DT target_NN domain_NN are_VBP not_RB identical_JJ but_CC related_JJ ,_, there_EX may_MD exist_VB a_DT shared_JJ concept_NN space_NN to_TO preserve_VB the_DT relation_NN ._.
Consequently_RB a_DT good_JJ feature_NN representation_NN can_MD encode_VB this_DT concept_NN space_NN and_CC minimize_VB the_DT distribution_NN gap_NN ._.
To_TO formalize_VB this_DT intuition_NN ,_, we_PRP propose_VBP a_DT domain_NN adaptation_NN method_NN that_WDT parameterizes_VBZ this_DT concept_NN space_NN by_IN linear_JJ transformation_NN under_IN which_WDT we_PRP explicitly_RB minimize_VBP the_DT distribution_NN difference_NN between_IN the_DT source_NN domain_NN with_IN sufficient_JJ labeled_JJ data_NNS and_CC target_NN domains_NNS with_IN only_JJ unlabeled_JJ data_NNS ,_, while_IN at_IN the_DT same_JJ time_NN minimizing_VBG the_DT empirical_JJ loss_NN on_IN the_DT labeled_JJ data_NNS in_IN the_DT source_NN domain_NN ._.
Another_DT characteristic_NN of_IN our_PRP$ method_NN is_VBZ its_PRP$ capability_NN for_IN considering_VBG multiple_JJ classes_NNS and_CC their_PRP$ interactions_NNS simultaneously_RB ._.
We_PRP have_VBP conducted_VBN extensive_JJ experiments_NNS on_IN two_CD common_JJ text_NN mining_NN problems_NNS ,_, namely_RB ,_, information_NN extraction_NN and_CC document_NN classification_NN to_TO demonstrate_VB the_DT effectiveness_NN of_IN our_PRP$ proposed_VBN method_NN ._.
aims_NNS at_IN transferring_VBG knowledge_NN across_IN domains_NNS or_CC tasks_NNS ._.
Besides_IN sentiment_NN classification_NN ,_, domain_NN adaptation_NN techniques_NNS have_VBP been_VBN widely_RB applied_VBN to_TO other_JJ Web_NN applications_NNS ,_, such_JJ as_IN text_NN classification_NN =_JJ -_: =[_NN 11_CD ,_, 8_CD ,_, 33_CD ,_, 10_CD -RRB-_-RRB- -_: =_JJ -_: ,_, part_NN of_IN speech_NN tagging_NN -LRB-_-LRB- 2_CD ,_, 7_CD ,_, 20_CD ,_, 12_CD -RRB-_-RRB- ,_, named-entity_JJ recognition_NN and_CC shallow_JJ parsing_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ._.
Most_JJS existing_VBG domain_NN adaptation_NN methods_NNS can_MD be_VB classified_VBN into_IN two_CD categories_NNS :_: feature-representation_JJ adapta_NN
rn_IN a_DT set_NN of_IN common_JJ transfer_NN components_NNS across_IN domains_NNS for_IN reducing_VBG the_DT distribution_NN gap_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
Compared_VBN to_TO MMDE_NNP ,_, TCA_NNP is_VBZ much_RB more_RBR efficient_JJ and_CC can_MD be_VB generalized_VBN to_TO out-of-sample_JJ patterns_NNS ._.
Chen_NNP et_FW al._FW =_SYM -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: also_RB developed_VBD an_DT algorithm_NN that_WDT incorporates_VBZ the_DT MMD_NNP criterion_NN into_IN the_DT Empirical_JJ Risk_NN Minimization_NN -LRB-_-LRB- ERM_NN -RRB-_-RRB- framework_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ._.
It_PRP tries_VBZ to_TO learn_VB the_DT linear_JJ feature_NN subspace_NN where_WRB the_DT distribution_NN gap_NN and_CC
s_NNS -RRB-_-RRB- ._.
In_IN practice_NN ,_, cross-domain_JJ learning_NN methods_NNS have_VBP been_VBN successfully_RB used_VBN in_IN many_JJ real-world_JJ applications_NNS ,_, such_JJ as_IN sentiment_NN classification_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, natural_JJ language_NN processing_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, text_NN categorization_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 21_CD -RRB-_-RRB- ,_, information_NN extraction_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- ,_, WiFi_NN localization_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ,_, and_CC visual_JJ concept_NN classification_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 17_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 36_CD -RRB-_-RRB- ._.
Recall_VB that_IN the_DT feature_NN distributions_NNS of_IN training_NN samples_NNS from_IN different_JJ domains_NNS change_VBP
in_IN the_DT context_NN of_IN named_VBN entity_NN recognition_NN -LRB-_-LRB- Daume_NNP III_NNP ,_, 2007_CD -RRB-_-RRB- ,_, sentiment_NN analysis_NN -LRB-_-LRB- Blitzer_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ,_, dependency_NN parsing_NN -LRB-_-LRB- Sagae_NNP and_CC Tsujii_NNP ,_, 2007_CD ;_: Kawahara_NNP and_CC Uchimoto_NNP ,_, 2009_CD -RRB-_-RRB- ,_, text_NN classification_NN -LRB-_-LRB- =_JJ -_: =_JJ Chen_NNP et_FW al._FW ,_, 2009_CD -_: =--RRB-_NN ,_, context-free_JJ parsing_NN -LRB-_-LRB- McClosky_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- and_CC machine_NN translation_NN -LRB-_-LRB- Foster_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- ._.
Domain_NN adaptation_NN is_VBZ the_DT problem_NN of_IN learning_VBG a_DT target_NN distribution_NN from_IN a_DT labeled_JJ sample_NN of_IN source_NN data_NNS w_NN
in_IN the_DT context_NN of_IN named_VBN entity_NN recognition_NN -LRB-_-LRB- Daume_NNP III_NNP ,_, 2007_CD -RRB-_-RRB- ,_, sentiment_NN analysis_NN -LRB-_-LRB- Blitzer_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ,_, dependency_NN parsing_NN -LRB-_-LRB- Sagae_NNP and_CC Tsujii_NNP ,_, 2007_CD ;_: Kawahara_NNP and_CC Uchimoto_NNP ,_, 2009_CD -RRB-_-RRB- ,_, text_NN classification_NN -LRB-_-LRB- =_JJ -_: =_JJ Chen_NNP et_FW al._FW ,_, 2009_CD -_: =--RRB-_NN ,_, context-free_JJ parsing_NN -LRB-_-LRB- McClosky_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- and_CC machine_NN translation_NN -LRB-_-LRB- Foster_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- ._.
Domain_NN adaptation_NN is_VBZ the_DT problem_NN of_IN learning_VBG a_DT target_NN distribution_NN from_IN a_DT labeled_JJ sample_NN of_IN source_NN data_NNS w_NN
aims_NNS at_IN transferring_VBG knowledge_NN across_IN domains_NNS or_CC tasks_NNS ._.
Besides_IN sentiment_NN classification_NN ,_, domain_NN adaptation_NN techniques_NNS have_VBP been_VBN widely_RB applied_VBN to_TO other_JJ Web_NN applications_NNS ,_, such_JJ as_IN text_NN classification_NN =_JJ -_: =[_NN 11_CD ,_, 8_CD ,_, 33_CD ,_, 10_CD -RRB-_-RRB- -_: =_JJ -_: ,_, part_NN of_IN speech_NN tagging_NN -LRB-_-LRB- 2_CD ,_, 7_CD ,_, 20_CD ,_, 12_CD -RRB-_-RRB- ,_, named-entity_JJ recognition_NN and_CC shallow_JJ parsing_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ._.
Most_JJS existing_VBG domain_NN adaptation_NN methods_NNS can_MD be_VB classified_VBN into_IN two_CD categories_NNS :_: feature-representation_JJ adapta_NN
wo_MD methods_NNS -LRB-_-LRB- 23_CD ,_, 26_CD -RRB-_-RRB- are_VBP not_RB compared_VBN due_JJ to_TO their_PRP$ problem_NN settings_NNS which_WDT ,_, unlike_IN ours_PRP ,_, assume_VB a_DT few_JJ data_NNS in_IN the_DT target_NN task_NN are_VBP labeled_VBN ._.
We_PRP use_VBP two_CD metrics_NNS ,_, clustering_NN accuracy_NN -LRB-_-LRB- AC_NN -RRB-_-RRB- -LRB-_-LRB- 24_CD -RRB-_-RRB- and_CC F1-Score_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: ,_, to_TO measure_VB the_DT clustering_NN performance_NN ._.
For_IN each_DT data_NNS set_VBN ,_, we_PRP repeated_VBD the_DT experiments_NNS for_IN 10_CD trails_VBZ ,_, and_CC report_VBP the_DT averages_NNS and_CC standard_JJ deviations_NNS ._.
Recall_VB that_IN the_DT useful_JJ knowledge_NN from_IN multiple_JJ s_NN
