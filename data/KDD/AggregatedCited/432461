A_DT refinement_NN approach_NN to_TO handling_NN model_NN misfit_NN in_IN text_NN categorization_NN
Text_NN categorization_NN or_CC classification_NN is_VBZ the_DT automated_JJ assigning_NN of_IN text_NN documents_NNS to_TO pre-defined_JJ classes_NNS based_VBN on_IN their_PRP$ contents_NNS ._.
This_DT problem_NN has_VBZ been_VBN studied_VBN in_IN information_NN retrieval_NN ,_, machine_NN learning_NN and_CC data_NN mining_NN ._.
So_RB far_RB ,_, many_JJ effective_JJ techniques_NNS have_VBP been_VBN proposed_VBN ._.
However_RB ,_, most_JJS techniques_NNS are_VBP based_VBN on_IN some_DT underlying_VBG models_NNS and\/or_CC assumptions_NNS ._.
When_WRB the_DT data_NN fits_VBZ the_DT model_NN well_RB ,_, the_DT classification_NN accuracy_NN will_MD be_VB high_JJ ._.
However_RB ,_, when_WRB the_DT data_NN does_VBZ not_RB fit_VB the_DT model_NN well_RB ,_, the_DT classification_NN accuracy_NN can_MD be_VB very_RB low_JJ ._.
In_IN this_DT paper_NN ,_, we_PRP propose_VBP a_DT refinement_NN approach_NN to_TO dealing_VBG with_IN this_DT problem_NN of_IN model_NN misfit_NN ._.
We_PRP show_VBP that_IN we_PRP do_VBP not_RB need_VB to_TO change_VB the_DT classification_NN technique_NN itself_PRP -LRB-_-LRB- or_CC its_PRP$ underlying_JJ model_NN -RRB-_-RRB- to_TO make_VB it_PRP more_RBR flexible_JJ ._.
Instead_RB ,_, we_PRP propose_VBP to_TO use_VB successive_JJ refinements_NNS of_IN classification_NN on_IN the_DT training_NN data_NNS to_TO correct_VB the_DT model_NN misfit_NN ._.
We_PRP apply_VBP the_DT proposed_VBN technique_NN to_TO improve_VB the_DT classification_NN performance_NN of_IN two_CD simple_JJ and_CC efficient_JJ text_NN classifiers_NNS ,_, the_DT Rocchio_NNP classifier_NN and_CC the_DT naïve_JJ Bayesian_JJ classifier_NN ._.
These_DT techniques_NNS are_VBP suitable_JJ for_IN very_RB large_JJ text_NN collections_NNS because_IN they_PRP allow_VBP the_DT data_NNS to_TO reside_VB on_IN disk_NN and_CC need_VBP only_RB one_CD scan_VB of_IN the_DT data_NNS to_TO build_VB a_DT text_NN classifier_NN ._.
Extensive_JJ experiments_NNS on_IN two_CD benchmark_JJ document_NN corpora_NN show_VBP that_IN the_DT proposed_VBN technique_NN is_VBZ able_JJ to_TO improve_VB text_NN categorization_NN accuracy_NN of_IN the_DT two_CD techniques_NNS dramatically_RB ._.
In_IN particular_JJ ,_, our_PRP$ refined_JJ model_NN is_VBZ able_JJ to_TO improve_VB the_DT naïve_JJ Bayesian_NNP or_CC Rocchio_NNP classifier_NN 's_POS prediction_NN performance_NN by_IN 45_CD %_NN on_IN average_NN ._.
eriments_NNS on_IN the_DT ModApte_NNP version_NN of_IN the_DT Reuters-21578_JJ TC_NN task_NN 5_CD ._.
Many_JJ evaluations_NNS have_VBP been_VBN documented_VBN based_VBN on_IN this_DT corpus_NN -LRB-_-LRB- Denoyer_NNP ,_, et_FW al._FW 2001_CD ,_, Joachims_NNP 1998_CD ,_, Lewis_NNP ,_, et_FW al._FW 1994_CD ,_, Liu_NNP ,_, et_FW al._FW 2001_CD ,_, =_JJ -_: =_JJ Wu_NNP ,_, et_FW al._FW 2002_CD -_: =_JJ -_: ,_, Yang_NNP ,_, et_FW al._FW 1999_CD -RRB-_-RRB- ._.
The_DT original_JJ format_NN of_IN the_DT text_NN documents_NNS in_IN this_DT corpus_NN is_VBZ in_IN SGML_NNP ._.
We_PRP first_RB remove_VB all_DT unlabeled_JJ documents_NNS ,_, and_CC perform_VB some_DT preprocessing_NN on_IN the_DT remaining_VBG documents_NNS to_TO filter_NN
n_NN document_NN in_IN relationship_NN to_TO such_PDT a_DT hyper-surface_NN ,_, etc._NN ._.
The_DT overall_JJ classification_NN accuracy_NN of_IN such_JJ machine_NN learning_NN classifiers_NNS often_RB suffers_VBZ from_IN what_WP is_VBZ known_VBN as_IN an_DT inductive_JJ bias_NN or_CC model_NN misfit_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
When_WRB the_DT nature_NN of_IN the_DT data_NN fits_VBZ the_DT assumptions_NNS of_IN the_DT underlying_VBG classification_NN strategy_NN well_RB ,_, thesclassification_NN accuracy_NN can_MD be_VB very_RB high_JJ ,_, and_CC vice_NN versa_RB ._.
For_IN example_NN ,_, the_DT Centroid_NNP Classifier_NNP is_VBZ
n_NN the_DT subset_NN of_IN the_DT data_NNS that_WDT could_MD not_RB be_VB classified_VBN by_IN the_DT previous_JJ model_NN with_IN high_JJ enough_JJ confidence_NN ._.
In_IN -LRB-_-LRB- 35_CD -RRB-_-RRB- ,_, this_DT method_NN was_VBD shown_VBN to_TO be_VB particularly_RB effective_JJ for_IN NB_NN ._.
In_IN related_JJ work_NN ,_, Wu_NNP et_FW al._FW =_SYM -_: =[_NN 34_CD -RRB-_-RRB- -_: =_SYM -_: considered_VBN building_VBG a_DT tree_NN of_IN Naive_JJ Bayes_NNP classifier_NN ,_, with_IN the_DT root_NN of_IN the_DT tree_NN building_NN using_VBG all_DT data_NNS ,_, and_CC all_DT other_JJ nodes_NNS conditioned_VBN on_IN the_DT partition_NN of_IN the_DT data_NNS -LRB-_-LRB- at_IN default_NN threshold_NN -RRB-_-RRB- by_IN the_DT par_NN
mplicity_NN and_CC straightforwardness_NN ,_, Centroid_NNP Classifier_NNP has_VBZ proved_VBN to_TO be_VB an_DT effective_JJ and_CC yet_RB robust_JJ method_NN for_IN text_NN categorization_NN ._.
However_RB ,_, it_PRP is_VBZ often_RB plagued_VBN with_IN inductive_JJ bias_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- or_CC model_NN misfit_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, Centroid_NNP Classifier_NNP makes_VBZ a_DT simple_JJ assumption_NN that_IN a_DT given_VBN document_NN should_MD be_VB assigned_VBN a_DT particular_JJ class_NN if_IN the_DT similarity_NN of_IN this_DT document_NN to_TO the_DT centroid_NN of_IN the_DT class_NN is_VBZ the_DT largest_JJS ._.
le_DT could_MD be_VB a_DT statement_NN ,_, like_IN ``_`` if_IN feature_NN X_NN -LRB-_-LRB- 5.0_CD ?_. ''_''
or_CC ``_`` Y_NN =_JJ =_JJ male_NN ?_. ''_'' ._.
A_DT parametric_JJ example_NN could_MD be_VB a_DT linear_JJ discriminatnt_NN function_NN -LRB-_-LRB- 4,33_CD -RRB-_-RRB- ,_, a_DT neural_JJ network_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, the_DT Rocchio_NNP algorithm_NN or_CC Naïve_JJ Bayesian_NN =_JJ -_: =[_NN 35_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Some_DT DT_NNP tools_NNS ,_, such_JJ as_IN CART_NN ,_, ID3_NN and_CC C4_NN .5_CD ,_, have_VBP been_VBN widely_RB adopted_VBN -LRB-_-LRB- 3,28_CD -RRB-_-RRB- for_IN TC_NN applications_NNS ._.
2.2_CD Binary_JJ Tree_NN Classifier_NN TC_NN is_VBZ often_RB solved_VBN by_IN designing_VBG a_DT set_NN of_IN N_NN binary_JJ classifiers_NNS ,_, each_DT only_RB de_IN
test_NN Bidimensional_JJ Heuristic_JJ approach_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- 0.871_CD Not_RB extensively_RB confirmed_VBN MD_NN and_CC ER_NN based_JJ SECTILE_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- -RRB-_-RRB- 0.950_CD \*_SYM \*_SYM Only_RB tested_VBN in_IN a_DT Chinese_JJ corpus_NN ,_, estimated_VBD Wu_NNP 's_POS Refinement_NN Rocchio\/NB_NN refined_VBD =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_SYM -_: 0.9_CD \/_: 0.926_CD A_DT little_JJ complex_NN in_IN training_NN Tsay_NNP 's_POS refinement_NN Rocchio_NNP refined_VBD -LRB-_-LRB- 38_CD -RRB-_-RRB- +0.018_CD \*_NN \*_NN Improvement_NN ,_, a_DT Chinese_JJ corpus_NN Gener_NNP ._.
instance_NN set_VBD GIS-R_NN GIE-W_NN -LRB-_-LRB- 37_CD -RRB-_-RRB- 0.860_CD More_RBR efficient_JJ than_IN k-NN_FW in_FW te_FW
._.
To_TO classify_VB an_DT unseen_JJ document_NN ,_, a_DT feature_NN vector_NN is_VBZ constructed_VBN by_IN using_VBG the_DT same_JJ set_NN of_IN n_NN features_NNS and_CC then_RB passed_VBD to_TO the_DT model_NN as_IN the_DT input_NN ._.
These_DT methods_NNS suffer_VBP from_IN the_DT nature_NN of_IN text_NN documents_NNS =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
It_PRP is_VBZ not_RB feasible_JJ to_TO organize_VB a_DT document_NN into_IN a_DT fixed_JJ set_NN of_IN features_NNS because_IN most_JJS text_NN documents_NNS are_VBP semi-structured_JJ or_CC completely_RB not_RB structured_VBN ._.
An_DT alternative_JJ type_NN of_IN approaches_NNS ,_, keyword-based_JJ
abel_NN TC_NN is_VBZ binary_JJ TC_NN ''_'' -LRB-_-LRB- 14_CD -RRB-_-RRB- ,_, which_WDT in_IN particular_JJ assigns_VBZ either_CC a_DT predefined_JJ category_NN or_CC its_PRP$ complement_NN to_TO an_DT ``_`` unseen_JJ ''_'' document_NN ._.
Many_JJ studies_NNS have_VBP addressed_VBN this_DT approach_NN in_IN the_DT past_NN ,_, i.e._FW -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 14_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_JJ -_: ,_, etc._NN ._.
In_IN contrast_NN ,_, single-label_JJ TC_NN tasks_NNS other_JJ than_IN the_DT binary_JJ approach_NN are_VBP recognized_VBN as_IN multi-class_JJ approaches_NNS ,_, and_CC simultaneously_RB deal_VB with_IN all_DT given_VBN categories_NNS and_CC assign_VB the_DT most_RBS appropriate_JJ cat_NN
ment_NN ,_, where_WRB data_NNS used_VBN to_TO train_VB individual_JJ models_NNS represent_VBP subsamples_NNS of_IN the_DT original_JJ set_NN ,_, depending_VBG in_IN composition_NN on_IN the_DT previous_JJ elements_NNS of_IN the_DT cascade_NN ._.
Cascaded_VBN models_NNS proposed_VBN in_IN the_DT literature_NN =_JJ -_: =[_NN 9,29_CD -RRB-_-RRB- -_: =_JJ -_: form_NN either_CC a_DT chain_NN or_CC a_DT tree_NN ._.
At_IN each_DT stage_NN of_IN a_DT chain_NN cascade_NN ,_, an_DT instance_NN can_MD either_RB be_VB classified_VBN or_CC passed_VBN to_TO the_DT next_JJ stage_NN of_IN the_DT chain_NN ._.
Conversely_RB ,_, in_IN tree_NN cascades_NNS ,_, the_DT internal_JJ node_NN classif_NN
