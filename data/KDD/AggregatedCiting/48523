Exploiting_VBG unlabeled_JJ data_NNS in_IN ensemble_NN methods_NNS
An_DT adaptive_JJ semi-supervised_JJ ensemble_NN method_NN ,_, ASSEMBLE_NNP ,_, is_VBZ proposed_VBN that_IN constructs_NNS classification_NN ensembles_NNS based_VBN on_IN both_CC labeled_JJ and_CC unlabeled_JJ data_NNS ._.
ASSEMBLE_NNP alternates_VBZ between_IN assigning_VBG ``_`` pseudo-classes_NNS ''_'' to_TO the_DT unlabeled_JJ data_NNS using_VBG the_DT existing_VBG ensemble_NN and_CC constructing_VBG the_DT next_JJ base_NN classifier_NN using_VBG both_CC the_DT labeled_JJ and_CC pseudolabeled_JJ data_NNS ._.
Mathematically_RB ,_, this_DT intuitive_JJ algorithm_NN corresponds_VBZ to_TO maximizing_VBG the_DT classification_NN margin_NN in_IN hypothesis_NN space_NN as_IN measured_VBN on_IN both_CC the_DT labeled_JJ and_CC unlabeled_JJ of_IN data_NNS ._.
Unlike_IN alternative_JJ approaches_NNS ,_, ASSEMBLE_NNP does_VBZ not_RB require_VB a_DT semi-supervised_JJ learning_NN method_NN for_IN the_DT base_NN classifier_NN ._.
ASSEMBLE_NN can_MD be_VB used_VBN in_IN conjunction_NN with_IN any_DT cost-sensitive_JJ classification_NN algorithm_NN for_IN both_CC two-class_JJ and_CC multi-class_JJ problems_NNS ._.
ASSEMBLE_VB using_VBG decision_NN trees_NNS won_VBD the_DT NIPS_NNP 2001_CD Unlabeled_NNP Data_NNP Competition_NNP ._.
In_IN addition_NN ,_, strong_JJ results_NNS on_IN several_JJ benchmark_JJ datasets_NNS using_VBG both_DT decision_NN trees_NNS and_CC neural_JJ networks_NNS support_VBP the_DT proposed_VBN method_NN ._.
0_CD 820_CD 300_CD 50.67_CD 26.67_CD CP3_NN 10_CD 5_CD 1000 1269 500_CD 41.20_CD 6.74_CD 4.1_CD Results_NNS from_IN DT_NN Experiments_NNS ASSEMBLE_VBP ._.
AdaBoost_NN used_VBN with_IN decision_NN trees_NNS was_VBD tested_VBN on_IN 3_CD benchmark_NN datasets_NNS obtained_VBN from_IN boosting_VBG literature_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT benchmark_JJ datasets_NNS were_VBD used_VBN without_IN any_DT data_NNS transformation_NN ._.
Each_DT dataset_NN consists_VBZ of_IN 100_CD random_JJ instances_NNS of_IN training_NN and_CC test_NN dataset_NN pairs_NNS ._.
The_DT detailed_JJ information_NN about_IN datasets_NNS can_MD be_VB fou_VBN
cation_NN task_NN ._.
Semi-supervised_JJ learning_NN has_VBZ been_VBN the_DT topic_NN of_IN four_CD di_FW #erent_FW Neural_JJ Information_NN Processing_NN Workshops_NNS -LRB-_-LRB- 5_CD ,_, 10_CD ,_, 15_CD ,_, 14_CD -RRB-_-RRB- ._.
Existing_VBG approaches_NNS include_VBP semi-supervised_JJ SVM_NN -LRB-_-LRB- 2_CD ,_, 22_CD -RRB-_-RRB- ,_, co-training_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC mixture_NN models_NNS -LRB-_-LRB- 17_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP #_# http:\/\/www.math.rpi.edu\/#bennek_JJ Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN all_DT or_CC part_NN of_IN this_DT work_NN for_IN personal_JJ or_CC classroom_NN use_NN is_VBZ granted_VBN without_IN fe_NN
unlabeled_JJ data_NNS in_IN addition_NN to_TO the_DT labeled_JJ data_NNS to_TO improve_VB performance_NN on_IN the_DT classification_NN task_NN ._.
Semi-supervised_JJ learning_NN has_VBZ been_VBN the_DT topic_NN of_IN four_CD di_FW #erent_FW Neural_NNP Information_NNP Processing_NNP Workshops_NNPS =_SYM -_: =[_NN 5_CD ,_, 10_CD ,_, 15_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Existing_VBG approaches_NNS include_VBP semi-supervised_JJ SVM_NN -LRB-_-LRB- 2_CD ,_, 22_CD -RRB-_-RRB- ,_, co-training_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, and_CC mixture_NN models_NNS -LRB-_-LRB- 17_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP #_# http:\/\/www.math.rpi.edu\/#bennek_JJ Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN al_FW
unlabeled_JJ data_NNS in_IN addition_NN to_TO the_DT labeled_JJ data_NNS to_TO improve_VB performance_NN on_IN the_DT classification_NN task_NN ._.
Semi-supervised_JJ learning_NN has_VBZ been_VBN the_DT topic_NN of_IN four_CD di_FW #erent_FW Neural_NNP Information_NNP Processing_NNP Workshops_NNPS =_SYM -_: =[_NN 5_CD ,_, 10_CD ,_, 15_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Existing_VBG approaches_NNS include_VBP semi-supervised_JJ SVM_NN -LRB-_-LRB- 2_CD ,_, 22_CD -RRB-_-RRB- ,_, co-training_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, and_CC mixture_NN models_NNS -LRB-_-LRB- 17_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP #_# http:\/\/www.math.rpi.edu\/#bennek_JJ Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN al_FW
unlabeled_JJ data_NNS in_IN addition_NN to_TO the_DT labeled_JJ data_NNS to_TO improve_VB performance_NN on_IN the_DT classification_NN task_NN ._.
Semi-supervised_JJ learning_NN has_VBZ been_VBN the_DT topic_NN of_IN four_CD di_FW #erent_FW Neural_NNP Information_NNP Processing_NNP Workshops_NNPS =_SYM -_: =[_NN 5_CD ,_, 10_CD ,_, 15_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Existing_VBG approaches_NNS include_VBP semi-supervised_JJ SVM_NN -LRB-_-LRB- 2_CD ,_, 22_CD -RRB-_-RRB- ,_, co-training_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, and_CC mixture_NN models_NNS -LRB-_-LRB- 17_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP #_# http:\/\/www.math.rpi.edu\/#bennek_JJ Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN al_FW
unlabeled_JJ data_NNS in_IN addition_NN to_TO the_DT labeled_JJ data_NNS to_TO improve_VB performance_NN on_IN the_DT classification_NN task_NN ._.
Semi-supervised_JJ learning_NN has_VBZ been_VBN the_DT topic_NN of_IN four_CD di_FW #erent_FW Neural_NNP Information_NNP Processing_NNP Workshops_NNPS =_SYM -_: =[_NN 5_CD ,_, 10_CD ,_, 15_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Existing_VBG approaches_NNS include_VBP semi-supervised_JJ SVM_NN -LRB-_-LRB- 2_CD ,_, 22_CD -RRB-_-RRB- ,_, co-training_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, and_CC mixture_NN models_NNS -LRB-_-LRB- 17_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP #_# http:\/\/www.math.rpi.edu\/#bennek_JJ Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN al_FW
ised_VBN learning_NN has_VBZ been_VBN the_DT topic_NN of_IN four_CD di_FW #erent_FW Neural_JJ Information_NN Processing_NN Workshops_NNS -LRB-_-LRB- 5_CD ,_, 10_CD ,_, 15_CD ,_, 14_CD -RRB-_-RRB- ._.
Existing_VBG approaches_NNS include_VBP semi-supervised_JJ SVM_NN -LRB-_-LRB- 2_CD ,_, 22_CD -RRB-_-RRB- ,_, co-training_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, and_CC mixture_NN models_NNS =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, we_PRP #_# http:\/\/www.math.rpi.edu\/#bennek_JJ Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN all_DT or_CC part_NN of_IN this_DT work_NN for_IN personal_JJ or_CC classroom_NN use_NN is_VBZ granted_VBN without_IN fee_NN provided_VBN that_IN copies_NNS ar_IN
._.
We_PRP plan_VBP to_TO apply_VB ASSEMBLE_NNP to_TO larger_JJR datasets_NNS in_IN order_NN to_TO determine_VB how_WRB well_RB the_DT algorithm_NN scales_NNS for_IN larger_JJR problems_NNS ._.
ASSEMBLE_NNP should_MD be_VB readily_RB adaptable_JJ to_TO scalable_JJ boosting_VBG algorithms_NNS such_JJ as_IN in_IN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
An_DT intersting_JJ open_JJ problem_NN is_VBZ how_WRB to_TO exploit_VB unlabeled_JJ data_NNS in_IN regression_NN problems_NNS ._.
For_IN classification_NN ASSEMBLE_NNP favors_VBZ ensembles_NNS that_WDT vote_VBP consistently_RB on_IN the_DT unlabeled_JJ data_NNS ._.
The_DT analogous_JJ strategy_NN
est_NN neighbor_NN assignment_NN was_VBD used_VBN to_TO assign_VB the_DT initial_JJ pseudo-class_JJ labels_NNS ._.
While_IN the_DT above_JJ algorithm_NN is_VBZ potentially_RB applicable_JJ to_TO any_DT supervised_JJ learning_NN method_NN ,_, we_PRP used_VBD limited_JJ depth_NN decision_NN trees_NNS =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: in_IN the_DT competition_NN ._.
The_DT depth_NN of_IN the_DT decision_NN trees_NNS was_VBD set_VBN to_TO a_DT level_NN that_WDT minimizes_VBZ the_DT AdaBoost_NNP training_NN error_NN ._.
The_DT rationale_NN behind_IN using_VBG decision_NN trees_NNS was_VBD to_TO show_VB that_IN semisupervised_JJ approach_NN c_NN
mance_NN on_IN the_DT classification_NN task_NN ._.
Semi-supervised_JJ learning_NN has_VBZ been_VBN the_DT topic_NN of_IN four_CD di_FW #erent_FW Neural_JJ Information_NN Processing_NN Workshops_NNS -LRB-_-LRB- 5_CD ,_, 10_CD ,_, 15_CD ,_, 14_CD -RRB-_-RRB- ._.
Existing_VBG approaches_NNS include_VBP semi-supervised_JJ SVM_NN =_JJ -_: =[_NN 2_CD ,_, 22_CD -RRB-_-RRB- -_: =_JJ -_: ,_, co-training_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, and_CC mixture_NN models_NNS -LRB-_-LRB- 17_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP #_# http:\/\/www.math.rpi.edu\/#bennek_JJ Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN all_DT or_CC part_NN of_IN this_DT work_NN for_IN personal_JJ or_CC classroom_NN use_NN is_VBZ g_NN
classifier_NN to_TO the_DT current_JJ ensemble_NN with_IN an_DT appropriate_JJ scalar_NN multiplier_NN -LRB-_-LRB- the_DT step-size_NN -RRB-_-RRB- ._.
It_PRP is_VBZ well_RB known_VBN that_IN such_JJ algorithms_NNS are_VBP performing_VBG gradient_NN descent_NN of_IN an_DT error_NN function_NN in_IN function_NN space_NN =_JJ -_: =[_NN 13_CD ,_, 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Depending_VBG on_IN the_DT measure_NN of_IN quality_NN of_IN the_DT classifier_NN ,_, di_FW #erent_FW criteria_NNS are_VBP produced_VBN for_IN choosing_VBG the_DT base_NN classifier_NN and_CC assigning_VBG the_DT step-size_NN ._.
D'Alche-Buc_NN et_FW al._FW ,_, -LRB-_-LRB- 6_CD -RRB-_-RRB- showed_VBD that_IN these_DT error_NN me_PRP
iated_VBN with_IN unlabeled_JJ data_NNS points_NNS ._.
While_IN the_DT strategy_NN is_VBZ in_IN general_JJ applicable_JJ to_TO many_JJ di_FW #erent_FW margin_NN cost_NN functions_NNS ,_, we_PRP focus_VBP on_IN the_DT one_CD used_VBN in_IN AdaBoost_NNP ._.
Let_VB the_DT base_NN classifiers_NNS be_VB f_FW j_FW -LRB-_-LRB- x_NN -RRB-_-RRB- :_: R_NN n_NN #_# =_JJ -_: =[_NN 1_CD ,_, -1_CD -RRB-_-RRB- -_: =_SYM -_: where_WRB f_FW j_FW is_VBZ the_DT jth_NN classifier_NN in_IN the_DT ensemble_NN ._.
Let_VB the_DT labeled_JJ training_NN data_NNS ,_, L_NN ,_, be_VB the_DT n-dimensional_JJ points_NNS x1_NN ,_, ..._: ,_, x_CC #_# with_IN know_VBP labels_NNS ,_, y1_NN ,_, ..._: ,_, y_NN #_# ._.
For_IN now_RB assume_VBP the_DT problem_NN has_VBZ two_CD
er_IN 100_CD participants_NNS utilizing_VBG unlabeled_JJ data_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
ASSEMBLE_NNP was_VBD used_VBN to_TO assimilate_VB unlabeled_JJ data_NNS into_IN a_DT multiclass_JJ version_NN of_IN AdaBoost_NNP ._.
AdaBoost_NNP was_VBD adopted_VBN to_TO multiclass_NNS using_VBG a_DT similar_JJ approach_NN to_TO =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Specifically_RB ,_, f_FW t_NN -LRB-_-LRB- x_NN i_LS -RRB-_-RRB- =_JJ 1_CD if_IN an_DT instance_NN x_NN i_FW is_VBZ correctly_RB classified_VBN and_CC f_FW t_NN -LRB-_-LRB- x_NN i_LS -RRB-_-RRB- =_JJ -1_CD otherwise_RB ._.
This_DT makes_VBZ AdaBoost_NNP increase_VB the_DT weight_NN of_IN a_DT misclassified_VBN point_NN and_CC decrease_VB it_PRP otherwise_RB ._.
The_DT
classifier_NN to_TO the_DT current_JJ ensemble_NN with_IN an_DT appropriate_JJ scalar_NN multiplier_NN -LRB-_-LRB- the_DT step-size_NN -RRB-_-RRB- ._.
It_PRP is_VBZ well_RB known_VBN that_IN such_JJ algorithms_NNS are_VBP performing_VBG gradient_NN descent_NN of_IN an_DT error_NN function_NN in_IN function_NN space_NN =_JJ -_: =[_NN 13_CD ,_, 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Depending_VBG on_IN the_DT measure_NN of_IN quality_NN of_IN the_DT classifier_NN ,_, di_FW #erent_FW criteria_NNS are_VBP produced_VBN for_IN choosing_VBG the_DT base_NN classifier_NN and_CC assigning_VBG the_DT step-size_NN ._.
D'Alche-Buc_NN et_FW al._FW ,_, -LRB-_-LRB- 6_CD -RRB-_-RRB- showed_VBD that_IN these_DT error_NN me_PRP
ion_NN in_IN function_NN space_NN -LRB-_-LRB- 13_CD ,_, 16_CD -RRB-_-RRB- ._.
Depending_VBG on_IN the_DT measure_NN of_IN quality_NN of_IN the_DT classifier_NN ,_, di_FW #erent_FW criteria_NNS are_VBP produced_VBN for_IN choosing_VBG the_DT base_NN classifier_NN and_CC assigning_VBG the_DT step-size_NN ._.
D'Alche-Buc_NN et_FW al._FW ,_, =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: showed_VBD that_IN these_DT error_NN measures_NNS can_MD be_VB extended_VBN to_TO semi-supervised_JJ learning_NN ,_, but_CC the_DT resulting_VBG algorithm_NN ,_, SSMBoost_NN ,_, is_VBZ of_IN limited_JJ utility_NN because_IN it_PRP requires_VBZ the_DT base_NN learner_NN to_TO be_VB a_DT semi-supervised_JJ
mance_NN on_IN the_DT classification_NN task_NN ._.
Semi-supervised_JJ learning_NN has_VBZ been_VBN the_DT topic_NN of_IN four_CD di_FW #erent_FW Neural_JJ Information_NN Processing_NN Workshops_NNS -LRB-_-LRB- 5_CD ,_, 10_CD ,_, 15_CD ,_, 14_CD -RRB-_-RRB- ._.
Existing_VBG approaches_NNS include_VBP semi-supervised_JJ SVM_NN =_JJ -_: =[_NN 2_CD ,_, 22_CD -RRB-_-RRB- -_: =_JJ -_: ,_, co-training_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, and_CC mixture_NN models_NNS -LRB-_-LRB- 17_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP #_# http:\/\/www.math.rpi.edu\/#bennek_JJ Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN all_DT or_CC part_NN of_IN this_DT work_NN for_IN personal_JJ or_CC classroom_NN use_NN is_VBZ g_NN
ior_FW specic_FW permission_NN and\/or_CC a_DT fee_NN ._.
SIGKDD_FW '02_FW Edmonton_NNP ,_, Alberta_NNP CA_NNP Copyright_NNP 2001_CD ACM_NNP X-XXXXX-XX-X_NN \/_: XX\/XX_NN ..._: $_$ 5.00_CD ._.
examine_VB the_DT problem_NN from_IN an_DT ensemble_NN perspective_NN ._.
Ensemble_NN methods_NNS such_JJ as_IN AdaBoost_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: work_NN by_IN iteratively_RB using_VBG a_DT base_NN learning_VBG mechanism_NN to_TO construct_VB a_DT classifier_NN to_TO improve_VB the_DT ensemble_NN classifier_NN and_CC then_RB adding_VBG the_DT classifier_NN to_TO the_DT current_JJ ensemble_NN with_IN an_DT appropriate_JJ scalar_JJ mult_NN
nstances_NNS of_IN training_NN and_CC test_NN dataset_NN pairs_NNS ._.
The_DT detailed_JJ information_NN about_IN datasets_NNS can_MD be_VB found_VBN at_IN -LRB-_-LRB- 19_CD -RRB-_-RRB- ._.
To_TO conform_VB with_IN previous_JJ approaches_NNS in_IN empirical_JJ studies_NNS of_IN semi-supervised_JJ learning_NN methods_NNS =_JJ -_: =[_NN 6_CD ,_, 11_CD ,_, 9_CD ,_, 7_CD -RRB-_-RRB- -_: =_JJ -_: ,_, we_PRP left_VBD some_DT of_IN the_DT training_NN data_NNS as_IN unlabeled_JJ data_NNS and_CC then_RB evaluated_VBD the_DT algorithm_NN on_IN test_NN data_NNS ._.
Training_NN data_NNS were_VBD sampled_VBN 10_CD times_NNS at_IN 3_CD di_FW #erent_FW levels_NNS to_TO form_VB labeled_JJ and_CC unlabeled_JJ data_NNS ._.
Specif_NN
of_IN ASSEMBLE_NNP across_IN di_FW #erent_FW classifier_NN methodologies_NNS ,_, we_PRP performed_VBD experiments_NNS using_VBG decision_NN trees_NNS and_CC neural_JJ networks_NNS ,_, methods_NNS that_WDT have_VBP proven_VBN very_RB e_SYM #ective_JJ in_IN previous_JJ experiments_NNS with_IN ensembles_NNS =_JJ -_: =[_NN 1_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Table_NNP 1_CD :_: Results_NNS for_IN ASSEMBLE_NNP ._.
AdaBoost_NNP in_IN NIPS_NNP 2001_CD Semi-Supervised_NNP Competition_NNP ._.
Acc_NNP is_VBZ the_DT test_NN set_NN accuracy_NN and_CC Impr_NN is_VBZ the_DT percentage_NN improvement_NN of_IN ASSEMBLE_NNP ._.
AdaBoost_NNP over_IN AdaBoost_NNP ._.
Data_NNP Dim_NNP ._.
No_DT
ng_NN rate_NN of_IN 0.15_CD and_CC a_DT momentum_NN value_NN of_IN 0.90_CD ._.
The_DT datasets_NNS for_IN the_DT experiments_NNS are_VBP breast-cancer-wisconsin_JJ ,_, pima-indiansdiabetes_NNS ,_, and_CC letter-recognition_NN drawn_VBN from_IN the_DT UCI_NNP Machine_NNP Learning_NNP repository_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT number_NN of_IN units_NNS in_IN the_DT hidden_JJ layer_NN for_IN the_DT datasets_NNS was_VBD 5_CD for_IN the_DT breast-cancer_NN and_CC diabetes_NN datasets_NNS and_CC 40_CD in_IN the_DT letter-recognition_NN dataset_NN ._.
The_DT number_NN of_IN training_NN epochs_NNS was_VBD set_VBN to_TO 20_CD for_IN b_NN
nstances_NNS of_IN training_NN and_CC test_NN dataset_NN pairs_NNS ._.
The_DT detailed_JJ information_NN about_IN datasets_NNS can_MD be_VB found_VBN at_IN -LRB-_-LRB- 19_CD -RRB-_-RRB- ._.
To_TO conform_VB with_IN previous_JJ approaches_NNS in_IN empirical_JJ studies_NNS of_IN semi-supervised_JJ learning_NN methods_NNS =_JJ -_: =[_NN 6_CD ,_, 11_CD ,_, 9_CD ,_, 7_CD -RRB-_-RRB- -_: =_JJ -_: ,_, we_PRP left_VBD some_DT of_IN the_DT training_NN data_NNS as_IN unlabeled_JJ data_NNS and_CC then_RB evaluated_VBD the_DT algorithm_NN on_IN test_NN data_NNS ._.
Training_NN data_NNS were_VBD sampled_VBN 10_CD times_NNS at_IN 3_CD di_FW #erent_FW levels_NNS to_TO form_VB labeled_JJ and_CC unlabeled_JJ data_NNS ._.
Specif_NN
It_PRP is_VBZ now_RB well_RB known_VBN that_IN for_IN classification_NN boosting_VBG can_MD be_VB regarded_VBN as_IN maximizing_VBG a_DT measure_NN of_IN the_DT margin_NN in_IN functions_NNS space_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- and_CC that_IN margin_NN measures_NNS can_MD be_VB adopted_VBN to_TO semi-supervised_JJ learning_NN =_JJ -_: =[_NN 2_CD ,_, 6_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
As_IN in_FW SSMBoost_FW -LRB-_-LRB- 6_CD -RRB-_-RRB- ,_, we_PRP adopt_VBP the_DT Margin_NN Boost_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- notation_NN and_CC strategy_NN adapted_VBN to_TO the_DT margin_NN measured_VBN on_IN both_CC the_DT labeled_JJ and_CC unlabeled_JJ data_NNS ._.
But_CC the_DT ASSEMBLE_NN analysis_NN and_CC resulting_VBG algorithms_NNS ar_IN
