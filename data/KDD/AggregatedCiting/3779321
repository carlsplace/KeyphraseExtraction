Interestingness_NN of_IN frequent_JJ itemsets_NNS using_VBG Bayesian_JJ networks_NNS as_IN background_NN knowledge_NN
The_DT paper_NN presents_VBZ a_DT method_NN for_IN pruning_NN frequent_JJ itemsets_NNS based_VBN on_IN background_NN knowledge_NN represented_VBN by_IN a_DT Bayesian_JJ network_NN ._.
The_DT interestingness_NN of_IN an_DT itemset_NN is_VBZ defined_VBN as_IN the_DT absolute_JJ difference_NN between_IN its_PRP$ support_NN estimated_VBN from_IN data_NNS and_CC from_IN the_DT Bayesian_JJ network_NN ._.
Efficient_JJ algorithms_NNS are_VBP presented_VBN for_IN finding_VBG interestingness_NN of_IN a_DT collection_NN of_IN frequent_JJ itemsets_NNS ,_, and_CC for_IN finding_VBG all_DT attribute_NN sets_VBZ with_IN a_DT given_VBN minimum_NN interestingness_NN ._.
Practical_NNP usefulness_NN of_IN the_DT algorithms_NNS and_CC their_PRP$ efficiency_NN have_VBP been_VBN verified_VBN experimentally_RB ._.
dundant_JJ rules_NNS ._.
Full_JJ review_NN of_IN such_JJ methods_NNS is_VBZ beyond_IN the_DT scope_NN of_IN this_DT paper_NN ._.
Overviews_NNS of_IN interestingness_NN measures_NNS can_MD be_VB found_VBN for_IN example_NN in_IN -LRB-_-LRB- 3_CD ,_, 13_CD ,_, 11_CD ,_, 32_CD -RRB-_-RRB- ,_, some_DT of_IN the_DT papers_NNS on_IN rule_NN pruning_NN are_VBP =_JJ -_: =[_NN 30_CD ,_, 31_CD ,_, 7_CD ,_, 14_CD ,_, 28_CD ,_, 16_CD ,_, 17_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Many_JJ interestingness_NN measures_NNS are_VBP based_VBN on_IN the_DT divergence_NN between_IN true_JJ probability_NN distributions_NNS and_CC distributions_NNS obtained_VBN under_IN the_DT independence_NN assumption_NN ._.
Pruning_NN methods_NNS are_VBP usually_RB based_VBN on_IN co_NN
dundant_JJ rules_NNS ._.
Full_JJ review_NN of_IN such_JJ methods_NNS is_VBZ beyond_IN the_DT scope_NN of_IN this_DT paper_NN ._.
Overviews_NNS of_IN interestingness_NN measures_NNS can_MD be_VB found_VBN for_IN example_NN in_IN -LRB-_-LRB- 3_CD ,_, 13_CD ,_, 11_CD ,_, 32_CD -RRB-_-RRB- ,_, some_DT of_IN the_DT papers_NNS on_IN rule_NN pruning_NN are_VBP =_JJ -_: =[_NN 30_CD ,_, 31_CD ,_, 7_CD ,_, 14_CD ,_, 28_CD ,_, 16_CD ,_, 17_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Many_JJ interestingness_NN measures_NNS are_VBP based_VBN on_IN the_DT divergence_NN between_IN true_JJ probability_NN distributions_NNS and_CC distributions_NNS obtained_VBN under_IN the_DT independence_NN assumption_NN ._.
Pruning_NN methods_NNS are_VBP usually_RB based_VBN on_IN co_NN
ed_VBN neural_JJ networks_NNS -LRB-_-LRB- KBANNs_NNS -RRB-_-RRB- and_CC uses_NNS of_IN background_NN knowledge_NN in_IN Inductive_NNP Logic_NNP Programming_NNP ._.
See_NNP Chapter_NNP 12_CD in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- for_IN an_DT overview_NN of_IN those_DT methods_NNS and_CC a_DT list_NN of_IN further_JJ references_NNS ._.
Tuzhilin_FW et_FW ._.
al._FW =_SYM -_: =[_NN 23_CD ,_, 22_CD ,_, 29_CD -RRB-_-RRB- -_: =_SYM -_: worked_VBD on_IN applying_VBG background_NN knowledge_NN to_TO finding_VBG interesting_JJ rules_NNS ._.
In_IN -LRB-_-LRB- 29_CD ,_, 22_CD -RRB-_-RRB- interestingness_NN measures_NNS are_VBP presented_VBN ,_, which_WDT take_VBP into_IN account_NN prior_JJ beliefs_NNS ;_: in_IN another_DT paper_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, the_DT authors_NNS pre_JJ
Here_RB we_PRP use_VBP exact_JJ methods_NNS for_IN computing_VBG the_DT marginals_NNS ._.
Approximate_JJ methods_NNS like_IN Gibbs_NNP sampling_NN are_VBP an_DT interesting_JJ topic_NN for_IN future_JJ work_NN ._.
Best_NN known_JJ approaches_NNS to_TO exact_JJ marginalizations_NNS are_VBP join_VB trees_NNS =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_JJ -_: and_CC bucket_NN elimination_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
We_PRP chose_VBD bucket_NN elimination_NN method_NN which_WDT is_VBZ easier_JJR to_TO implement_VB and_CC according_VBG to_TO -LRB-_-LRB- 5_CD -RRB-_-RRB- as_RB efficient_JJ as_IN join_VB tree_NN based_JJ methods_NNS ._.
Also_RB ,_, join_VB trees_NNS are_VBP mainly_RB useful_JJ for_IN comput_NN
from_IN the_DT positive_JJ border_NN can_MD be_VB covered_VBN by_IN a_DT single_JJ set_NN only_RB slightly_RB larger_JJR then_RB the_DT covered_JJ ones_NNS ._.
The_DT algorithm_NN for_IN selecting_VBG the_DT marginal_JJ distribution_NN to_TO compute_VB is_VBZ motivated_VBN by_IN the_DT algorithm_NN from_IN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: for_IN computing_VBG views_NNS that_WDT should_MD be_VB materialized_VBN for_IN OLAP_NN query_NN processing_NN ._.
Bucket_NN elimination_NN corresponds_VBZ to_TO creating_VBG a_DT materialized_VBN view_NN ,_, and_CC marginalizing_VBG thus_RB obtained_VBN distribution_NN to_TO answering_VBG OL_NN
terestingness_NN measure_NN ,_, and_CC pruning_NN aiming_VBG at_IN removing_VBG redundant_JJ rules_NNS ._.
Full_JJ review_NN of_IN such_JJ methods_NNS is_VBZ beyond_IN the_DT scope_NN of_IN this_DT paper_NN ._.
Overviews_NNS of_IN interestingness_NN measures_NNS can_MD be_VB found_VBN for_IN example_NN in_IN =_JJ -_: =[_NN 3_CD ,_, 13_CD ,_, 11_CD ,_, 32_CD -RRB-_-RRB- -_: =_JJ -_: ,_, some_DT of_IN the_DT papers_NNS on_IN rule_NN pruning_NN are_VBP -LRB-_-LRB- 30_CD ,_, 31_CD ,_, 7_CD ,_, 14_CD ,_, 28_CD ,_, 16_CD ,_, 17_CD ,_, 33_CD -RRB-_-RRB- ._.
Many_JJ interestingness_NN measures_NNS are_VBP based_VBN on_IN the_DT divergence_NN between_IN true_JJ probability_NN distributions_NNS and_CC distributions_NNS obtained_VBN un_IN
ent_JJ methods_NNS for_IN computing_NN interestingness_NN of_IN large_JJ numbers_NNS of_IN itemsets_NNS and_CC for_IN finding_VBG all_DT attribute_NN sets_VBZ with_IN given_VBN minimum_NN interestingness_NN ._.
There_EX are_VBP some_DT analogies_NNS between_IN mining_NN emerging_VBG patterns_NNS =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: and_CC our_PRP$ approach_NN ,_, the_DT main_JJ di_FW #erences_FW being_VBG that_IN in_IN our_PRP$ case_NN a_DT Bayesian_JJ network_NN is_VBZ used_VBN instead_RB of_IN a_DT second_JJ dataset_NN ,_, and_CC that_IN we_PRP use_VBP a_DT di_FW #erent_FW measure_NN for_IN comparing_VBG supports_NNS ._.
Due_JJ to_TO those_DT di_FW #erences_FW
terestingness_NN measure_NN ,_, and_CC pruning_NN aiming_VBG at_IN removing_VBG redundant_JJ rules_NNS ._.
Full_JJ review_NN of_IN such_JJ methods_NNS is_VBZ beyond_IN the_DT scope_NN of_IN this_DT paper_NN ._.
Overviews_NNS of_IN interestingness_NN measures_NNS can_MD be_VB found_VBN for_IN example_NN in_IN =_JJ -_: =[_NN 3_CD ,_, 13_CD ,_, 11_CD ,_, 32_CD -RRB-_-RRB- -_: =_JJ -_: ,_, some_DT of_IN the_DT papers_NNS on_IN rule_NN pruning_NN are_VBP -LRB-_-LRB- 30_CD ,_, 31_CD ,_, 7_CD ,_, 14_CD ,_, 28_CD ,_, 16_CD ,_, 17_CD ,_, 33_CD -RRB-_-RRB- ._.
Many_JJ interestingness_NN measures_NNS are_VBP based_VBN on_IN the_DT divergence_NN between_IN true_JJ probability_NN distributions_NNS and_CC distributions_NNS obtained_VBN un_IN
An_DT Illustrative_JJ Example_NN We_PRP first_RB present_VBP a_DT simple_JJ example_NN demonstrating_VBG the_DT usefulness_NN of_IN the_DT method_NN ._.
We_PRP use_VBP the_DT KSL_NNP dataset_NN of_IN Danish_JJ 70_CD year_NN olds_NNS ,_, distributed_VBN with_IN the_DT DEAL_NN Bayesian_JJ network_NN package_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
There_EX are_VBP nine_CD attributes_NNS ,_, described_VBN in_IN Table_NNP 1_CD ,_, related_VBN to_TO the_DT person_NN 's_POS general_JJ health_NN and_CC lifestyle_NN ._.
All_DT continuous_JJ attributes_NNS have_VBP been_VBN discretized_VBN into_IN 3_CD levels_NNS using_VBG the_DT equal_JJ weight_NN method_NN ._.
We_PRP
his_PRP$ way_NN we_PRP can_MD directly_RB apply_VB marginalization_NN to_TO obtain_VB distributions_NNS for_IN subsets_NNS of_IN I_NN -LRB-_-LRB- see_VB below_IN -RRB-_-RRB- ._.
Since_IN bucket_NN elimination_NN is_VBZ performed_VBN repeatedly_RB we_PRP use_VBP memoization_NN to_TO speed_VB it_PRP up_RP ,_, as_IN suggested_VBN in_IN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP re1_NN A_NN ._.
member_NN each_DT partial_JJ sum_NN and_CC reuse_VB it_PRP if_IN possible_JJ ._.
In_IN the_DT example_NN above_IN P_NN b_NN ∈_CD Dom_NNP -LRB-_-LRB- B_NN -RRB-_-RRB- computed_VBD P_NN BN_NN A_NN PB_NN |_NN A_NN ,_, P_NN c_NN ∈_CD Dom_NNP -LRB-_-LRB- C_NN -RRB-_-RRB- PC_NN |_NN A_NN ,_, and_CC the_DT would_MD have_VB been_VBN remembered_VBN ._.
Another_DT method_NN of_IN obtaining_VBG a_DT
ed_VBN neural_JJ networks_NNS -LRB-_-LRB- KBANNs_NNS -RRB-_-RRB- and_CC uses_NNS of_IN background_NN knowledge_NN in_IN Inductive_NNP Logic_NNP Programming_NNP ._.
See_NNP Chapter_NNP 12_CD in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- for_IN an_DT overview_NN of_IN those_DT methods_NNS and_CC a_DT list_NN of_IN further_JJ references_NNS ._.
Tuzhilin_FW et_FW ._.
al._FW =_SYM -_: =[_NN 23_CD ,_, 22_CD ,_, 29_CD -RRB-_-RRB- -_: =_SYM -_: worked_VBD on_IN applying_VBG background_NN knowledge_NN to_TO finding_VBG interesting_JJ rules_NNS ._.
In_IN -LRB-_-LRB- 29_CD ,_, 22_CD -RRB-_-RRB- interestingness_NN measures_NNS are_VBP presented_VBN ,_, which_WDT take_VBP into_IN account_NN prior_JJ beliefs_NNS ;_: in_IN another_DT paper_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, the_DT authors_NNS pre_JJ
n_NN the_DT network_NN instead_RB ,_, see_VB -LRB-_-LRB- 15_CD ,_, Chap_NNP ._.
3_CD ,_, Sect_NNP ._.
4_LS -RRB-_-RRB- for_IN details_NNS ._.
sAs_VBZ a_DT method_NN of_IN scoring_VBG network_NN structures_NNS we_PRP used_VBD the_DT natural_JJ logarithm_NN of_IN the_DT probability_NN of_IN the_DT structure_NN conditioned_VBN on_IN the_DT data_NNS ,_, see_VBP =_JJ -_: =[_NN 10_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: for_IN details_NNS on_IN computing_VBG the_DT score_NN ._.
The_DT modified_VBN network_NN structure_NN had_VBD the_DT score_NN of_IN −_NN 7162.71_CD which_WDT is_VBZ better_JJR than_IN that_DT of_IN the_DT original_JJ network_NN :_: −_NN 7356.68_CD ._.
With_IN the_DT modified_VBN structure_NN ,_, the_DT most_JJS interes_NNS
from_IN the_DT positive_JJ border_NN can_MD be_VB covered_VBN by_IN a_DT single_JJ set_NN only_RB slightly_RB larger_JJR then_RB the_DT covered_JJ ones_NNS ._.
The_DT algorithm_NN for_IN selecting_VBG the_DT marginal_JJ distribution_NN to_TO compute_VB is_VBZ motivated_VBN by_IN the_DT algorithm_NN from_IN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: for_IN computing_VBG views_NNS that_WDT should_MD be_VB materialized_VBN for_IN OLAP_NN query_NN processing_NN ._.
Bucket_NN elimination_NN corresponds_VBZ to_TO creating_VBG a_DT materialized_VBN view_NN ,_, and_CC marginalizing_VBG thus_RB obtained_VBN distribution_NN to_TO answering_VBG OL_NN
ed_VBN neural_JJ networks_NNS -LRB-_-LRB- KBANNs_NNS -RRB-_-RRB- and_CC uses_NNS of_IN background_NN knowledge_NN in_IN Inductive_NNP Logic_NNP Programming_NNP ._.
See_NNP Chapter_NNP 12_CD in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- for_IN an_DT overview_NN of_IN those_DT methods_NNS and_CC a_DT list_NN of_IN further_JJ references_NNS ._.
Tuzhilin_FW et_FW ._.
al._FW =_SYM -_: =[_NN 23_CD ,_, 22_CD ,_, 29_CD -RRB-_-RRB- -_: =_SYM -_: worked_VBD on_IN applying_VBG background_NN knowledge_NN to_TO finding_VBG interesting_JJ rules_NNS ._.
In_IN -LRB-_-LRB- 29_CD ,_, 22_CD -RRB-_-RRB- interestingness_NN measures_NNS are_VBP presented_VBN ,_, which_WDT take_VBP into_IN account_NN prior_JJ beliefs_NNS ;_: in_IN another_DT paper_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, the_DT authors_NNS pre_JJ
to_TO account_VB transitivity_NN ._.
Indeed_RB ,_, in_IN the_DT presence_NN of_IN the_DT background_NN knowledge_NN represented_VBN by_IN the_DT rules_NNS A_DT ⇒_NN B_NN andsB_NN ⇒_NN C_NN ,_, the_DT rule_NN A_NN ⇒_NN C_NN is_VBZ uninteresting_JJ ._.
However_RB ,_, this_DT can_MD not_RB be_VB discovered_VBN locally_RB ._.
See_VB =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_SYM -_: for_IN a_DT detailed_JJ discussion_NN of_IN advantages_NNS of_IN global_JJ versus_CC local_JJ methods_NNS ._.
Some_DT more_JJR comparisons_NNS can_MD be_VB found_VBN in_IN -LRB-_-LRB- 18_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN we_PRP present_VBP a_DT method_NN of_IN finding_VBG interesting_JJ patterns_NNS using_VBG background_NN
PI_NN |_CD J_NN be_VB a_DT distribution_NN of_IN I_PRP conditioned_VBD on_IN J._NNP When_WRB used_VBN in_IN arithmetic_NN operations_NNS such_JJ distributions_NNS will_MD be_VB treated_VBN as_IN functions_NNS of_IN attributes_NNS in_IN I_NNP and_CC I_NNP ∪_NNP J_NNP respectively_RB ,_, with_IN values_NNS in_IN the_DT interval_NN =_JJ -_: =[_NN 0_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN PI_NN -LRB-_-LRB- i_LS -RRB-_-RRB- denotes_VBZ the_DT probability_NN that_IN I_NN =_JJ i._NNP Let_NNP PI_NN be_VB a_DT probability_NN distribution_NN ,_, and_CC let_VB J_NNP ⊂_NNP I._NNP Dethe_NNP marginalization_NN of_IN PI_NN onto_IN J_NN ,_, that_WDT is_VBZ X_NN =_JJ PI_NN ,_, -LRB-_-LRB- 1_LS -RRB-_-RRB- note_NN by_IN P_NN ↓_NN J_NN I_CD P_NN ↓_NN J_NN I_CD where_WRB the_DT sum_NN
dundant_JJ rules_NNS ._.
Full_JJ review_NN of_IN such_JJ methods_NNS is_VBZ beyond_IN the_DT scope_NN of_IN this_DT paper_NN ._.
Overviews_NNS of_IN interestingness_NN measures_NNS can_MD be_VB found_VBN for_IN example_NN in_IN -LRB-_-LRB- 3_CD ,_, 13_CD ,_, 11_CD ,_, 32_CD -RRB-_-RRB- ,_, some_DT of_IN the_DT papers_NNS on_IN rule_NN pruning_NN are_VBP =_JJ -_: =[_NN 30_CD ,_, 31_CD ,_, 7_CD ,_, 14_CD ,_, 28_CD ,_, 16_CD ,_, 17_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Many_JJ interestingness_NN measures_NNS are_VBP based_VBN on_IN the_DT divergence_NN between_IN true_JJ probability_NN distributions_NNS and_CC distributions_NNS obtained_VBN under_IN the_DT independence_NN assumption_NN ._.
Pruning_NN methods_NNS are_VBP usually_RB based_VBN on_IN co_NN
dundant_JJ rules_NNS ._.
Full_JJ review_NN of_IN such_JJ methods_NNS is_VBZ beyond_IN the_DT scope_NN of_IN this_DT paper_NN ._.
Overviews_NNS of_IN interestingness_NN measures_NNS can_MD be_VB found_VBN for_IN example_NN in_IN -LRB-_-LRB- 3_CD ,_, 13_CD ,_, 11_CD ,_, 32_CD -RRB-_-RRB- ,_, some_DT of_IN the_DT papers_NNS on_IN rule_NN pruning_NN are_VBP =_JJ -_: =[_NN 30_CD ,_, 31_CD ,_, 7_CD ,_, 14_CD ,_, 28_CD ,_, 16_CD ,_, 17_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Many_JJ interestingness_NN measures_NNS are_VBP based_VBN on_IN the_DT divergence_NN between_IN true_JJ probability_NN distributions_NNS and_CC distributions_NNS obtained_VBN under_IN the_DT independence_NN assumption_NN ._.
Pruning_NN methods_NNS are_VBP usually_RB based_VBN on_IN co_NN
dundant_JJ rules_NNS ._.
Full_JJ review_NN of_IN such_JJ methods_NNS is_VBZ beyond_IN the_DT scope_NN of_IN this_DT paper_NN ._.
Overviews_NNS of_IN interestingness_NN measures_NNS can_MD be_VB found_VBN for_IN example_NN in_IN -LRB-_-LRB- 3_CD ,_, 13_CD ,_, 11_CD ,_, 32_CD -RRB-_-RRB- ,_, some_DT of_IN the_DT papers_NNS on_IN rule_NN pruning_NN are_VBP =_JJ -_: =[_NN 30_CD ,_, 31_CD ,_, 7_CD ,_, 14_CD ,_, 28_CD ,_, 16_CD ,_, 17_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Many_JJ interestingness_NN measures_NNS are_VBP based_VBN on_IN the_DT divergence_NN between_IN true_JJ probability_NN distributions_NNS and_CC distributions_NNS obtained_VBN under_IN the_DT independence_NN assumption_NN ._.
Pruning_NN methods_NNS are_VBP usually_RB based_VBN on_IN co_NN
ls_NNS decreased_VBD between_IN the_DT two_CD years_NNS in_IN which_WDT the_DT study_NN was_VBD made_VBN ,_, and_CC that_IN cholesterol_NN level_NN depends_VBZ on_IN sex_NN ._.
We_PRP found_VBD similar_JJ trends_NNS in_IN the_DT U.S._NNP population_NN based_VBN on_IN data_NNS from_IN American_NNP Heart_NNP Association_NNP =_SYM -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Adding_VBG edges_NNS Y_NN ear_NN →_CD Kol_NN and_CC Sex_NN →_NN Kol_NN improved_VBD the_DT network_NN score_NN to_TO −_CD 7095.25_CD ._.
-LCB-_-LRB- F_NN EV_NN ,_, Alc_NN ,_, Y_NN ear_NN -RCB-_-RRB- became_VBD the_DT most_RBS interesting_JJ attribute_NN set_VBN with_IN the_DT interestingness_NN of_IN 0.0286_CD ._.
Its_PRP$ interestingness_NN is_VBZ
erestingness_NN ,_, and_CC top_JJ 10_CD results_NNS were_VBD kept_VBN ._.
The_DT two_CD most_RBS interesting_JJ attribute_NN sets_NNS were_VBD -LCB-_-LRB- F_NN EV_NN ,_, Sex_NN -RCB-_-RRB- with_IN interestingness_NN 0.0812_CD and_CC -LCB-_-LRB- Alc_NNP ,_, Y_NN ear_NN -RCB-_-RRB- with_IN interestingness_NN 0.0810_CD ._.
Indeed_RB ,_, it_PRP is_VBZ known_VBN -LRB-_-LRB- see_VB =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =--RRB-_NN that_IN women_NNS 's_POS lungs_NNS are_VBP on_IN average_JJ 20_CD %_NN −_CD 25_CD %_NN smaller_JJR than_IN men_NNS 's_POS lungs_NNS ,_, so_IN sex_NN influences_VBZ the_DT forced_JJ ejection_NN volume_NN -LRB-_-LRB- FEV_NN -RRB-_-RRB- much_RB more_JJR than_IN smoking_NN does_VBZ -LRB-_-LRB- which_WDT we_PRP thought_VBD was_VBD the_DT primary_JJ influence_NN -RRB-_-RRB- ._.
Thi_NNP
a_DT reviewer_NN -RRB-_-RRB- could_MD be_VB to_TO iteratively_RB apply_VB interesting_JJ patterns_NNS to_TO modify_VB the_DT network_NN structure_NN until_IN no_DT further_JJ improvement_NN in_IN the_DT network_NN score_NN can_MD be_VB achieved_VBN ._.
A_DT similar_JJ procedure_NN has_VBZ been_VBN used_VBN in_IN =_JJ -_: =[_NN 24_CD -RRB-_-RRB- -_: =_SYM -_: for_IN background_NN knowledge_NN represented_VBN by_IN rules_NNS ._.
It_PRP should_MD be_VB noted_VBN however_RB that_IN it_PRP might_MD be_VB better_JJR to_TO just_RB inform_VB the_DT user_NN about_IN interesting_JJ patterns_NNS and_CC let_VB him\/her_NN use_VB their_PRP$ experience_NN to_TO update_VB the_DT
i_LS -RRB-_-RRB- ,_, -LRB-_-LRB- 2_LS -RRB-_-RRB- analogously_RB ,_, I_PRP is_VBZ ɛ-interesting_NN if_IN I_NN -LRB-_-LRB- I_NN -RRB-_-RRB- ≥_FW ɛ_FW ._.
An_DT alternative_JJ approach_NN would_MD be_VB to_TO use_VB generalizations_NNS of_IN Bayesian_JJ networks_NNS allowing_VBG dependencies_NNS to_TO vary_VB for_IN different_JJ values_NNS of_IN attributes_NNS ,_, see_VBP =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC deal_NN with_IN itemset_NN interestingness_NN directly_RB ._.
3.1_CD Extensions_NNS to_TO the_DT Definition_NN of_IN Interestingness_NN Even_RB though_IN applying_VBG the_DT above_JJ definition_NN and_CC sorting_NN attribute_NN sets_NNS on_IN their_PRP$ interestingness_NN work_NN
An_DT Illustrative_JJ Example_NN We_PRP first_RB present_VBP a_DT simple_JJ example_NN demonstrating_VBG the_DT usefulness_NN of_IN the_DT method_NN ._.
We_PRP use_VBP the_DT KSL_NNP dataset_NN of_IN Danish_JJ 70_CD year_NN olds_NNS ,_, distributed_VBN with_IN the_DT DEAL_NN Bayesian_JJ network_NN package_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
There_EX are_VBP nine_CD attributes_NNS ,_, described_VBN in_IN Table_NNP 1_CD ,_, related_VBN to_TO the_DT person_NN 's_POS general_JJ health_NN and_CC lifestyle_NN ._.
All_DT continuous_JJ attributes_NNS have_VBP been_VBN discretized_VBN into_IN 3_CD levels_NNS using_VBG the_DT equal_JJ weight_NN method_NN ._.
FE_NNP
C_NN ,_, the_DT rule_NN A_NN ⇒_NN C_NN is_VBZ uninteresting_JJ ._.
However_RB ,_, this_DT can_MD not_RB be_VB discovered_VBN locally_RB ._.
See_VB -LRB-_-LRB- 25_CD -RRB-_-RRB- for_IN a_DT detailed_JJ discussion_NN of_IN advantages_NNS of_IN global_JJ versus_CC local_JJ methods_NNS ._.
Some_DT more_JJR comparisons_NNS can_MD be_VB found_VBN in_IN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN we_PRP present_VBP a_DT method_NN of_IN finding_VBG interesting_JJ patterns_NNS using_VBG background_NN knowledge_NN represented_VBN by_IN a_DT Bayesian_JJ network_NN ._.
The_DT main_JJ advantage_NN of_IN Bayesian_JJ networks_NNS is_VBZ that_IN they_PRP concisely_RB represe_VBP
n_NN the_DT network_NN instead_RB ,_, see_VB -LRB-_-LRB- 15_CD ,_, Chap_NNP ._.
3_CD ,_, Sect_NNP ._.
4_LS -RRB-_-RRB- for_IN details_NNS ._.
sAs_VBZ a_DT method_NN of_IN scoring_VBG network_NN structures_NNS we_PRP used_VBD the_DT natural_JJ logarithm_NN of_IN the_DT probability_NN of_IN the_DT structure_NN conditioned_VBN on_IN the_DT data_NNS ,_, see_VBP =_JJ -_: =[_NN 10_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: for_IN details_NNS on_IN computing_VBG the_DT score_NN ._.
The_DT modified_VBN network_NN structure_NN had_VBD the_DT score_NN of_IN −_NN 7162.71_CD which_WDT is_VBZ better_JJR than_IN that_DT of_IN the_DT original_JJ network_NN :_: −_NN 7356.68_CD ._.
With_IN the_DT modified_VBN structure_NN ,_, the_DT most_JJS interes_NNS
r_NN computing_VBG the_DT marginals_NNS ._.
Approximate_JJ methods_NNS like_IN Gibbs_NNP sampling_NN are_VBP an_DT interesting_JJ topic_NN for_IN future_JJ work_NN ._.
Best_NN known_JJ approaches_NNS to_TO exact_JJ marginalizations_NNS are_VBP join_VB trees_NNS -LRB-_-LRB- 12_CD -RRB-_-RRB- and_CC bucket_NN elimination_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP chose_VBD bucket_NN elimination_NN method_NN which_WDT is_VBZ easier_JJR to_TO implement_VB and_CC according_VBG to_TO -LRB-_-LRB- 5_CD -RRB-_-RRB- as_RB efficient_JJ as_IN join_VB tree_NN based_JJ methods_NNS ._.
Also_RB ,_, join_VB trees_NNS are_VBP mainly_RB useful_JJ for_IN computing_VBG marginals_NNS for_IN single_JJ at_IN
ork_NN ._.
The_DT main_JJ advantage_NN of_IN Bayesian_JJ networks_NNS is_VBZ that_IN they_PRP concisely_RB represent_VBP full_JJ joint_JJ probability_NN distributions_NNS ,_, and_CC allow_VB for_IN practically_RB feasible_JJ probabilistic_JJ inference_NN from_IN those_DT distributions_NNS =_JJ -_: =[_NN 25_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Other_JJ advantages_NNS include_VBP the_DT ability_NN to_TO represent_VB causal_JJ relationships_NNS ,_, easy_JJ to_TO understand_VB graphical_JJ structure_NN ,_, as_RB well_RB as_IN wide_JJ availability_NN of_IN modelling_NN tools_NNS ._.
Bayesian_JJ networks_NNS are_VBP also_RB easy_JJ to_TO mo_NN
terestingness_NN measure_NN ,_, and_CC pruning_NN aiming_VBG at_IN removing_VBG redundant_JJ rules_NNS ._.
Full_JJ review_NN of_IN such_JJ methods_NNS is_VBZ beyond_IN the_DT scope_NN of_IN this_DT paper_NN ._.
Overviews_NNS of_IN interestingness_NN measures_NNS can_MD be_VB found_VBN for_IN example_NN in_IN =_JJ -_: =[_NN 3_CD ,_, 13_CD ,_, 11_CD ,_, 32_CD -RRB-_-RRB- -_: =_JJ -_: ,_, some_DT of_IN the_DT papers_NNS on_IN rule_NN pruning_NN are_VBP -LRB-_-LRB- 30_CD ,_, 31_CD ,_, 7_CD ,_, 14_CD ,_, 28_CD ,_, 16_CD ,_, 17_CD ,_, 33_CD -RRB-_-RRB- ._.
Many_JJ interestingness_NN measures_NNS are_VBP based_VBN on_IN the_DT divergence_NN between_IN true_JJ probability_NN distributions_NNS and_CC distributions_NNS obtained_VBN un_IN
dundant_JJ rules_NNS ._.
Full_JJ review_NN of_IN such_JJ methods_NNS is_VBZ beyond_IN the_DT scope_NN of_IN this_DT paper_NN ._.
Overviews_NNS of_IN interestingness_NN measures_NNS can_MD be_VB found_VBN for_IN example_NN in_IN -LRB-_-LRB- 3_CD ,_, 13_CD ,_, 11_CD ,_, 32_CD -RRB-_-RRB- ,_, some_DT of_IN the_DT papers_NNS on_IN rule_NN pruning_NN are_VBP =_JJ -_: =[_NN 30_CD ,_, 31_CD ,_, 7_CD ,_, 14_CD ,_, 28_CD ,_, 16_CD ,_, 17_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Many_JJ interestingness_NN measures_NNS are_VBP based_VBN on_IN the_DT divergence_NN between_IN true_JJ probability_NN distributions_NNS and_CC distributions_NNS obtained_VBN under_IN the_DT independence_NN assumption_NN ._.
Pruning_NN methods_NNS are_VBP usually_RB based_VBN on_IN co_NN
dundant_JJ rules_NNS ._.
Full_JJ review_NN of_IN such_JJ methods_NNS is_VBZ beyond_IN the_DT scope_NN of_IN this_DT paper_NN ._.
Overviews_NNS of_IN interestingness_NN measures_NNS can_MD be_VB found_VBN for_IN example_NN in_IN -LRB-_-LRB- 3_CD ,_, 13_CD ,_, 11_CD ,_, 32_CD -RRB-_-RRB- ,_, some_DT of_IN the_DT papers_NNS on_IN rule_NN pruning_NN are_VBP =_JJ -_: =[_NN 30_CD ,_, 31_CD ,_, 7_CD ,_, 14_CD ,_, 28_CD ,_, 16_CD ,_, 17_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Many_JJ interestingness_NN measures_NNS are_VBP based_VBN on_IN the_DT divergence_NN between_IN true_JJ probability_NN distributions_NNS and_CC distributions_NNS obtained_VBN under_IN the_DT independence_NN assumption_NN ._.
Pruning_NN methods_NNS are_VBP usually_RB based_VBN on_IN co_NN
terestingness_NN measure_NN ,_, and_CC pruning_NN aiming_VBG at_IN removing_VBG redundant_JJ rules_NNS ._.
Full_JJ review_NN of_IN such_JJ methods_NNS is_VBZ beyond_IN the_DT scope_NN of_IN this_DT paper_NN ._.
Overviews_NNS of_IN interestingness_NN measures_NNS can_MD be_VB found_VBN for_IN example_NN in_IN =_JJ -_: =[_NN 3_CD ,_, 13_CD ,_, 11_CD ,_, 32_CD -RRB-_-RRB- -_: =_JJ -_: ,_, some_DT of_IN the_DT papers_NNS on_IN rule_NN pruning_NN are_VBP -LRB-_-LRB- 30_CD ,_, 31_CD ,_, 7_CD ,_, 14_CD ,_, 28_CD ,_, 16_CD ,_, 17_CD ,_, 33_CD -RRB-_-RRB- ._.
Many_JJ interestingness_NN measures_NNS are_VBP based_VBN on_IN the_DT divergence_NN between_IN true_JJ probability_NN distributions_NNS and_CC distributions_NNS obtained_VBN un_IN
ent_JJ methods_NNS for_IN computing_NN interestingness_NN of_IN large_JJ numbers_NNS of_IN itemsets_NNS and_CC for_IN finding_VBG all_DT attribute_NN sets_VBZ with_IN given_VBN minimum_NN interestingness_NN ._.
There_EX are_VBP some_DT analogies_NNS between_IN mining_NN emerging_VBG patterns_NNS =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: and_CC our_PRP$ approach_NN ,_, the_DT main_JJ differences_NNS being_VBG that_IN in_IN our_PRP$ case_NN a_DT Bayesian_JJ network_NN is_VBZ used_VBN instead_RB of_IN a_DT second_JJ dataset_NN ,_, and_CC that_IN we_PRP use_VBP a_DT different_JJ measure_NN for_IN comparing_VBG supports_NNS ._.
Due_JJ to_TO those_DT differen_NNS
dundant_JJ rules_NNS ._.
Full_JJ review_NN of_IN such_JJ methods_NNS is_VBZ beyond_IN the_DT scope_NN of_IN this_DT paper_NN ._.
Overviews_NNS of_IN interestingness_NN measures_NNS can_MD be_VB found_VBN for_IN example_NN in_IN -LRB-_-LRB- 3_CD ,_, 13_CD ,_, 11_CD ,_, 32_CD -RRB-_-RRB- ,_, some_DT of_IN the_DT papers_NNS on_IN rule_NN pruning_NN are_VBP =_JJ -_: =[_NN 30_CD ,_, 31_CD ,_, 7_CD ,_, 14_CD ,_, 28_CD ,_, 16_CD ,_, 17_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Many_JJ interestingness_NN measures_NNS are_VBP based_VBN on_IN the_DT divergence_NN between_IN true_JJ probability_NN distributions_NNS and_CC distributions_NNS obtained_VBN under_IN the_DT independence_NN assumption_NN ._.
Pruning_NN methods_NNS are_VBP usually_RB based_VBN on_IN co_NN
