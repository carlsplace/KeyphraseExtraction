Serendipitous_JJ learning_NN :_: learning_VBG beyond_IN the_DT predefined_JJ label_NN space_NN
Most_RBS traditional_JJ supervised_JJ learning_NN methods_NNS are_VBP developed_VBN to_TO learn_VB a_DT model_NN from_IN labeled_JJ examples_NNS and_CC use_VB this_DT model_NN to_TO classify_VB the_DT unlabeled_JJ ones_NNS into_IN the_DT same_JJ label_NN space_NN predefined_VBN by_IN the_DT models_NNS ._.
However_RB ,_, in_IN many_JJ real_JJ world_NN applications_NNS ,_, the_DT label_NN spaces_NNS for_IN both_CC the_DT labeled\/training_NN and_CC unlabeled\/testing_JJ examples_NNS can_MD be_VB different_JJ ._.
To_TO solve_VB this_DT problem_NN ,_, this_DT paper_NN proposes_VBZ a_DT novel_JJ notion_NN of_IN Serendipitous_NNP Learning_NNP -LRB-_-LRB- SL_NNP -RRB-_-RRB- ,_, which_WDT is_VBZ defined_VBN to_TO address_VB the_DT learning_NN scenarios_NNS in_IN which_WDT the_DT label_NN space_NN can_MD be_VB enlarged_JJ during_IN the_DT testing_NN phase_NN ._.
In_IN particular_JJ ,_, a_DT large_JJ margin_NN approach_NN is_VBZ proposed_VBN to_TO solve_VB SL_NNP ._.
The_DT basic_JJ idea_NN is_VBZ to_TO leverage_NN the_DT knowledge_NN in_IN the_DT labeled_JJ examples_NNS to_TO help_VB identify_VB novel\/unknown_JJ classes_NNS ,_, and_CC the_DT large_JJ margin_NN formulation_NN is_VBZ proposed_VBN to_TO incorporate_VB both_CC the_DT classification_NN loss_NN on_IN the_DT examples_NNS within_IN the_DT known_JJ categories_NNS ,_, as_RB well_RB as_IN the_DT clustering_NN loss_NN on_IN the_DT examples_NNS in_IN unknown_JJ categories_NNS ._.
An_DT efficient_JJ optimization_NN algorithm_NN based_VBN on_IN CCCP_NNP and_CC the_DT bundle_NN method_NN is_VBZ proposed_VBN to_TO solve_VB the_DT optimization_NN problem_NN of_IN the_DT large_JJ margin_NN formulation_NN of_IN SL_NNP ._.
Moreover_RB ,_, an_DT efficient_JJ online_JJ learning_NN method_NN is_VBZ proposed_VBN to_TO address_VB the_DT issue_NN of_IN large_JJ scale_NN data_NNS in_IN online_JJ learning_NN scenario_NN ,_, which_WDT has_VBZ been_VBN shown_VBN to_TO have_VB a_DT guaranteed_VBN learning_NN regret_NN ._.
An_DT extensive_JJ set_NN of_IN experimental_JJ results_NNS on_IN two_CD synthetic_JJ datasets_NNS and_CC two_CD datasets_NNS from_IN real_JJ world_NN applications_NNS demonstrate_VBP the_DT advantages_NNS of_IN the_DT proposed_VBN method_NN over_IN several_JJ other_JJ baseline_NN algorithms_NNS ._.
One_CD limitation_NN of_IN the_DT proposed_VBN method_NN is_VBZ that_IN the_DT number_NN of_IN unknown_JJ classes_NNS is_VBZ given_VBN in_IN advance_NN ._.
It_PRP may_MD be_VB possible_JJ to_TO remove_VB this_DT constraint_NN if_IN we_PRP model_VBP it_PRP by_IN using_VBG a_DT non-parametric_JJ way_NN ._.
We_PRP also_RB plan_VBP to_TO do_VB experiments_NNS on_IN more_RBR real_JJ world_NN applications_NNS in_IN the_DT future_NN ._.
ised_VBN and_CC unsupervised_JJ problems_NNS ._.
To_TO solve_VB this_DT formulation_NN ,_, we_PRP propose_VBP an_DT efficient_JJ and_CC effective_JJ way_NN based_VBN on_IN the_DT Constrained_VBN Concave-Convex_NN Procedure_NN -LRB-_-LRB- CCCP_NN -RRB-_-RRB- -LRB-_-LRB- 17_CD -RRB-_-RRB- and_CC an_DT adaption_NN of_IN the_DT bundle_NN method_NN =_JJ -_: =[_NN 13_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN order_NN to_TO handle_VB large-scale_JJ data_NNS for_IN online_JJ learning_NN applications_NNS ,_, an_DT online_JJ version_NN of_IN the_DT proposed_VBN method_NN is_VBZ developed_VBN thereafter_RB ._.
According_VBG to_TO Theorem_NNP 3.1_CD ,_, the_DT regret_NN of_IN the_DT proposed_VBN method_NN ,_, i_FW
mans_NNS need_VBP to_TO expand_VB their_PRP$ knowledge_NN base_NN accordingly_RB ,_, and_CC draw_VB the_DT common_JJ features_NNS of_IN the_DT novel_JJ categories_NNS ._.
Several_JJ recent_JJ research_NN works_NNS share_VBP similar_JJ spirits_NNS with_IN our_PRP$ serendipitous_JJ learning_NN problem_NN =_JJ -_: =[_NN 1_CD ,_, 3_CD ,_, 4_CD ,_, 11_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Unsupervised_JJ transfer_NN classification_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- builds_VBZ the_DT classification_NN model_NN for_IN a_DT target\/novel_NN class_NN in_IN the_DT absence_NN of_IN any_DT labeled_JJ training_NN example_NN but_CC with_IN given_VBN labeled_JJ examples_NNS belonging_VBG to_TO auxilia_VB
another_DT 3_CD categories_NNS are_VBP used_VBN as_IN the_DT novel_JJ categories_NNS ._.
Please_VB refer_VB to_TO Table_NNP 3_CD for_IN more_JJR details_NNS ._.
Reuters-Volume_NN I_CD -LRB-_-LRB- ReutersV1_NN -RRB-_-RRB- :_: It_PRP is_VBZ an_DT archive_NN of_IN over_IN 800_CD ,_, 000_CD manually_RB categorized_VBN newswire_NN stories_NNS =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT subset_NN of_IN ReutersV1_NN is_VBZ used_VBN ._.
There_EX are_VBP in_IN total_JJ 126_CD categories_NNS in_IN this_DT dataset_NN ._.
This_DT dataset_NN is_VBZ split_VBN into_IN a_DT labeled_JJ set_NN and_CC an_DT unlabeled_JJ set_NN ._.
There_EX are_VBP in_IN total_JJ 3_CD categories_NNS in_IN the_DT labeled_JJ set_NN ,_, a_DT
mans_NNS need_VBP to_TO expand_VB their_PRP$ knowledge_NN base_NN accordingly_RB ,_, and_CC draw_VB the_DT common_JJ features_NNS of_IN the_DT novel_JJ categories_NNS ._.
Several_JJ recent_JJ research_NN works_NNS share_VBP similar_JJ spirits_NNS with_IN our_PRP$ serendipitous_JJ learning_NN problem_NN =_JJ -_: =[_NN 1_CD ,_, 3_CD ,_, 4_CD ,_, 11_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Unsupervised_JJ transfer_NN classification_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- builds_VBZ the_DT classification_NN model_NN for_IN a_DT target\/novel_NN class_NN in_IN the_DT absence_NN of_IN any_DT labeled_JJ training_NN example_NN but_CC with_IN given_VBN labeled_JJ examples_NNS belonging_VBG to_TO auxilia_VB
mans_NNS need_VBP to_TO expand_VB their_PRP$ knowledge_NN base_NN accordingly_RB ,_, and_CC draw_VB the_DT common_JJ features_NNS of_IN the_DT novel_JJ categories_NNS ._.
Several_JJ recent_JJ research_NN works_NNS share_VBP similar_JJ spirits_NNS with_IN our_PRP$ serendipitous_JJ learning_NN problem_NN =_JJ -_: =[_NN 1_CD ,_, 3_CD ,_, 4_CD ,_, 11_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Unsupervised_JJ transfer_NN classification_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- builds_VBZ the_DT classification_NN model_NN for_IN a_DT target\/novel_NN class_NN in_IN the_DT absence_NN of_IN any_DT labeled_JJ training_NN example_NN but_CC with_IN given_VBN labeled_JJ examples_NNS belonging_VBG to_TO auxilia_VB
e_LS want_VBP the_DT classification_NN and_CC clustering_NN assignments_NNS for_IN the_DT unlabeled_JJ examples_NNS to_TO be_VB as_RB determined_VBN as_IN possible_JJ ._.
Actually_RB ,_, a_DT similar_JJ motivation_NN is_VBZ given_VBN in_IN Transductive_JJ Support_NN Vector_NNP Machines_NNP -LRB-_-LRB- TSVM_NNP -RRB-_-RRB- =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Semi-Supervised_JJ Support_NN Vector_NNP Machines_NNP -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, in_IN which_WDT the_DT authors_NNS require_VBP that_IN the_DT classification_NN margins_NNS for_IN the_DT unlabeled_JJ examples_NNS should_MD be_VB maximized_VBN so_IN that_IN the_DT distribution_NN of_IN unlabeled_JJ exam_NN
ayes_NNS and_CC Logistic_JJ Regression_NN in_IN text_NN classification_NN applications_NNS ,_, Enhanced_VBN SVM_NN as_IN an_DT adapted_VBN form_NN of_IN SVM_NN for_IN serendipitous_JJ learning_NN as_IN described_VBN below_IN ;_: the_DT generative_JJ method_NN --_: Gaussian_JJ Mixture_NN Models_NNS =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_JJ -_: ;_: as_RB well_RB as_IN the_DT Topic_JJ Detection_NN and_CC Tracking_VBG method_NN --_: TDT_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ._.
In_IN particular_JJ ,_, for_IN SVM_NNP ,_, we_PRP train_VBP a_DT set_NN of_IN large_JJ margin_NN classifiers_NNS on_IN the_DT labeled_JJ set_NN ,_, and_CC directly_RB use_VB these_DT classifiers_NNS to_TO infer_VB the_DT
ustering_NN ,_, Label_NN Space_NN 1_CD ._.
INTRODUCTION_NN One_CD of_IN the_DT basic_JJ assumptions_NNS in_IN most_JJS supervised_JJ machine_NN learning_NN algorithms_NNS is_VBZ that_IN the_DT label_NN space_NN is_VBZ predefined_VBN and_CC shared_VBN by_IN the_DT training_NN and_CC testing_NN examples_NNS =_JJ -_: =[_NN 5_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, this_DT assumption_NN is_VBZ often_RB violated_VBN in_IN many_JJ open-domain_JJ applications_NNS of_IN classification_NN ._.
For_IN example_NN ,_, in_IN online_JJ webpage_NN classification_NN ,_, we_PRP might_MD be_VB able_JJ to_TO provide_VB a_DT list_NN of_IN common_JJ classes_NNS ,_, su_FW
pace_NN ._.
Moreover_RB ,_, TDT_NN does_VBZ not_RB provide_VB theoretical_JJ analysis_NN as_IN that_DT in_IN this_DT paper_NN ._.
As_IN a_DT means_NN of_IN incorporating_VBG the_DT unlabeled_JJ examples_NNS to_TO improve_VB the_DT classification_NN performance_NN ,_, semi-supervised_JJ learning_NN =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_SYM -_: learns_VBZ a_DT better_JJR model_NN by_IN utilizing_VBG the_DT distribution_NN similarities_NNS between_IN the_DT labeled_JJ and_CC unlabeled_JJ examples_NNS on_IN the_DT same_JJ label_NN space_NN while_IN serendipitous_JJ learning_NN needs_VBZ to_TO find_VB similarities_NNS between_IN exi_NN
dered_VBN as_IN an_DT integration_NN of_IN both_CC the_DT supervised_JJ and_CC unsupervised_JJ problems_NNS ._.
To_TO solve_VB this_DT formulation_NN ,_, we_PRP propose_VBP an_DT efficient_JJ and_CC effective_JJ way_NN based_VBN on_IN the_DT Constrained_VBN Concave-Convex_NN Procedure_NN -LRB-_-LRB- CCCP_NN -RRB-_-RRB- =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_JJ -_: and_CC an_DT adaption_NN of_IN the_DT bundle_NN method_NN -LRB-_-LRB- 13_CD ,_, 15_CD -RRB-_-RRB- ._.
In_IN order_NN to_TO handle_VB large-scale_JJ data_NNS for_IN online_JJ learning_NN applications_NNS ,_, an_DT online_JJ version_NN of_IN the_DT proposed_VBN method_NN is_VBZ developed_VBN thereafter_RB ._.
According_VBG to_TO The_DT
ents_NNS for_IN the_DT unlabeled_JJ examples_NNS to_TO be_VB as_RB determined_VBN as_IN possible_JJ ._.
Actually_RB ,_, a_DT similar_JJ motivation_NN is_VBZ given_VBN in_IN Transductive_JJ Support_NN Vector_NNP Machines_NNP -LRB-_-LRB- TSVM_NNP -RRB-_-RRB- -LRB-_-LRB- 7_CD -RRB-_-RRB- and_CC Semi-Supervised_JJ Support_NN Vector_NNP Machines_NNP =_SYM -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: ,_, in_IN which_WDT the_DT authors_NNS require_VBP that_IN the_DT classification_NN margins_NNS for_IN the_DT unlabeled_JJ examples_NNS should_MD be_VB maximized_VBN so_IN that_IN the_DT distribution_NN of_IN unlabeled_JJ examples_NNS can_MD serve_VB as_IN the_DT prior_JJ knowledge_NN for_IN design_NN
+1_CD ,_, ..._: ,_, l_NN +_CC k_NN -RCB-_-RRB- ,_, ∀_FW q_FW ∈_FW -LCB-_-LRB- l_NN +1_CD ,_, ..._: ,_, l_NN +_CC k_NN -RCB-_-RRB- ,_, −_CD e_SYM ≤_FW ∑_FW m_NN j_NN =_JJ 1_CD ˜w_NN T_NN ˜x_NN U_NN -LRB-_-LRB- p_NN -RRB-_-RRB- −_FW j_FW ∑_FW m_NN j_NN =_JJ 1_CD ˜w_NN T_NN ˜x_NN U_NN -LRB-_-LRB- q_NN -RRB-_-RRB- ≤_FW e._FW j_NN 8_CD ._.
end_NN for_IN Table_NNP 2_CD :_: Algorithm_NN Description_NN :_: The_DT Online_NNP Learning_NNP Algorithm_NNP for_IN Serendipitous_NNP Learning_NNP method_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
As_IN we_PRP shall_MD see_VB later_RB ,_, the_DT regret_NN of_IN the_DT proposed_VBN method_NN is_VBZ guaranteed_VBN to_TO be_VB upper_JJ bounded_VBN by_IN O_NN -LRB-_-LRB- log_NN -LRB-_-LRB- t_NN -RRB-_-RRB- -RRB-_-RRB- ._.
3.4_CD Theoretical_JJ Analysis_NNP THEOREM_NNP 3.1_CD ._.
At_IN time_NN t_NN ,_, the_DT regret_NN defined_VBN in_IN Eq_NN ._.
-LRB-_-LRB- 6_CD -RRB-_-RRB- will_MD be_VB upper_JJ b_NN
ised_VBN and_CC unsupervised_JJ problems_NNS ._.
To_TO solve_VB this_DT formulation_NN ,_, we_PRP propose_VBP an_DT efficient_JJ and_CC effective_JJ way_NN based_VBN on_IN the_DT Constrained_VBN Concave-Convex_NN Procedure_NN -LRB-_-LRB- CCCP_NN -RRB-_-RRB- -LRB-_-LRB- 17_CD -RRB-_-RRB- and_CC an_DT adaption_NN of_IN the_DT bundle_NN method_NN =_JJ -_: =[_NN 13_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN order_NN to_TO handle_VB large-scale_JJ data_NNS for_IN online_JJ learning_NN applications_NNS ,_, an_DT online_JJ version_NN of_IN the_DT proposed_VBN method_NN is_VBZ developed_VBN thereafter_RB ._.
According_VBG to_TO Theorem_NNP 3.1_CD ,_, the_DT regret_NN of_IN the_DT proposed_VBN method_NN ,_, i_FW
he_PRP two_CD class_NN separation_NN problem_NN ._.
In_IN the_DT later_JJ work_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- ,_, it_PRP is_VBZ extended_VBN to_TO the_DT multi-class_JJ case_NN ._.
However_RB ,_, one_CD of_IN the_DT potential_JJ problems_NNS in_IN these_DT methods_NNS is_VBZ that_IN they_PRP are_VBP often_RB very_JJ time_NN consuming_NN ._.
In_IN =_JJ -_: =[_NN 22_CD ,_, 23_CD ,_, 24_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT authors_NNS relax_VBP the_DT original_JJ problem_NN and_CC solve_VB the_DT relaxed_VBN problem_NN in_IN a_DT more_RBR efficient_JJ way_NN ._.
The_DT previous_JJ MMC_NN works_NNS have_VBP already_RB shown_VBN their_PRP$ superior_JJ performances_NNS in_IN dealing_VBG with_IN clustering_NN problem_NN
abels_NNS assigned_VBN by_IN the_DT clustering_NN algorithms_NNS as_IN :_: ∑_CD n_NN n_NN i_FW =_JJ 1_CD Acc_NN =_JJ 1_CD δ_NN -LRB-_-LRB- yi_NN ,_, map_NN -LRB-_-LRB- ci_NN -RRB-_-RRB- -RRB-_-RRB- ,_, where_WRB ,_, map_NN -LRB-_-LRB- ·_NN -RRB-_-RRB- is_VBZ a_DT function_NN that_WDT maps_VBZ each_DT cluster_NN index_NN to_TO a_DT class_NN label_NN ,_, which_WDT can_MD be_VB found_VBN by_IN the_DT Hungarian_JJ algorithm_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
ci_NN and_CC yi_NN are_VBP the_DT cluster_NN index_NN of_IN xi_FW and_CC the_DT true_JJ class_NN label_NN ._.
δ_NN -LRB-_-LRB- a_DT ,_, b_NN -RRB-_-RRB- is_VBZ a_DT function_NN that_WDT equals_VBZ 1_CD when_WRB a_DT equals_VBZ b_NN ,_, and0otherwise_NN ._.
It_PRP is_VBZ clear_JJ that_IN clustering_NN accuracy_NN discovers_VBZ the_DT one-to-one_JJ relat_NN
m_NN margin_NN clustering_NN method_NN has_VBZ a_DT solid_JJ theoretical_JJ foundation_NN and_CC performs_VBZ much_RB better_JJR than_IN the_DT previous_JJ methods_NNS ._.
But_CC in_IN -LRB-_-LRB- 18_CD -RRB-_-RRB- it_PRP can_MD only_RB deal_VB with_IN the_DT two_CD class_NN separation_NN problem_NN ._.
In_IN the_DT later_JJ work_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, it_PRP is_VBZ extended_VBN to_TO the_DT multi-class_JJ case_NN ._.
However_RB ,_, one_CD of_IN the_DT potential_JJ problems_NNS in_IN these_DT methods_NNS is_VBZ that_IN they_PRP are_VBP often_RB very_JJ time_NN consuming_NN ._.
In_IN -LRB-_-LRB- 22_CD ,_, 23_CD ,_, 24_CD -RRB-_-RRB- ,_, the_DT authors_NNS relax_VBP the_DT original_JJ problem_NN an_DT
hould_RB be_VB as_RB certain\/determined_VBN as_IN possible_JJ ._.
Recently_RB ,_, the_DT idea_NN of_IN maximum_NN margin_NN learning_NN has_VBZ also_RB been_VBN applied_VBN to_TO data_NNS clustering_NN ,_, which_WDT is_VBZ usually_RB referred_VBN to_TO as_IN Maximum_NNP Margin_NN Clustering_NN -LRB-_-LRB- MMC_NN -RRB-_-RRB- ._.
In_IN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT authors_NNS assign_VBP instances_NNS to_TO two_CD classes_NNS -LCB-_-LRB- −_NN 1_CD ,_, +1_CD -RCB-_-RRB- so_IN that_IN the_DT separation_NN between_IN the_DT two_CD classes_NNS can_MD be_VB as_RB large_JJ as_IN possible_JJ ._.
The_DT maximum_JJ margin_NN clustering_NN method_NN has_VBZ a_DT solid_JJ theoretical_JJ foundati_NNS
mans_NNS need_VBP to_TO expand_VB their_PRP$ knowledge_NN base_NN accordingly_RB ,_, and_CC draw_VB the_DT common_JJ features_NNS of_IN the_DT novel_JJ categories_NNS ._.
Several_JJ recent_JJ research_NN works_NNS share_VBP similar_JJ spirits_NNS with_IN our_PRP$ serendipitous_JJ learning_NN problem_NN =_JJ -_: =[_NN 1_CD ,_, 3_CD ,_, 4_CD ,_, 11_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Unsupervised_JJ transfer_NN classification_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- builds_VBZ the_DT classification_NN model_NN for_IN a_DT target\/novel_NN class_NN in_IN the_DT absence_NN of_IN any_DT labeled_JJ training_NN example_NN but_CC with_IN given_VBN labeled_JJ examples_NNS belonging_VBG to_TO auxilia_VB
ns_RB ,_, Enhanced_VBN SVM_NN as_IN an_DT adapted_VBN form_NN of_IN SVM_NN for_IN serendipitous_JJ learning_NN as_IN described_VBN below_IN ;_: the_DT generative_JJ method_NN --_: Gaussian_JJ Mixture_NN Models_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- ;_: as_RB well_RB as_IN the_DT Topic_JJ Detection_NN and_CC Tracking_VBG method_NN --_: TDT_NN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN particular_JJ ,_, for_IN SVM_NNP ,_, we_PRP train_VBP a_DT set_NN of_IN large_JJ margin_NN classifiers_NNS on_IN the_DT labeled_JJ set_NN ,_, and_CC directly_RB use_VB these_DT classifiers_NNS to_TO infer_VB the_DT labels_NNS of_IN the_DT unlabeled_JJ examples_NNS ._.
But_CC by_IN using_VBG this_DT method_NN ,_, the_DT
rther_NN verified_VBD through_IN the_DT experiments_NNS in_IN Section_NN 4_CD ._.
2.4_CD Maximum_NNP Margin_NN Classification_NN and_CC Clustering_NNP Maximum_NNP Margin_NN learning_NN is_VBZ an_DT important_JJ technique_NN for_IN classification_NN and_CC dimensionality_NN reduction_NN =_JJ -_: =[_NN 12_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
As_IN a_DT typical_JJ Maximum_NNP Margin_NN classification_NN method_NN ,_, Support_NN Vector_NNP Machines_NNP -LRB-_-LRB- SVM_NNP -RRB-_-RRB- has_VBZ received_VBN considerable_JJ attentions_NNS in_IN the_DT past_JJ decade_NN ._.
In_IN SVM_NNP ,_, the_DT margin_NN is_VBZ defined_VBN as_IN the_DT distance_NN between_IN the_DT cl_NN
he_PRP two_CD class_NN separation_NN problem_NN ._.
In_IN the_DT later_JJ work_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- ,_, it_PRP is_VBZ extended_VBN to_TO the_DT multi-class_JJ case_NN ._.
However_RB ,_, one_CD of_IN the_DT potential_JJ problems_NNS in_IN these_DT methods_NNS is_VBZ that_IN they_PRP are_VBP often_RB very_JJ time_NN consuming_NN ._.
In_IN =_JJ -_: =[_NN 22_CD ,_, 23_CD ,_, 24_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT authors_NNS relax_VBP the_DT original_JJ problem_NN and_CC solve_VB the_DT relaxed_VBN problem_NN in_IN a_DT more_RBR efficient_JJ way_NN ._.
The_DT previous_JJ MMC_NN works_NNS have_VBP already_RB shown_VBN their_PRP$ superior_JJ performances_NNS in_IN dealing_VBG with_IN clustering_NN problem_NN
he_PRP two_CD class_NN separation_NN problem_NN ._.
In_IN the_DT later_JJ work_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- ,_, it_PRP is_VBZ extended_VBN to_TO the_DT multi-class_JJ case_NN ._.
However_RB ,_, one_CD of_IN the_DT potential_JJ problems_NNS in_IN these_DT methods_NNS is_VBZ that_IN they_PRP are_VBP often_RB very_JJ time_NN consuming_NN ._.
In_IN =_JJ -_: =[_NN 22_CD ,_, 23_CD ,_, 24_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT authors_NNS relax_VBP the_DT original_JJ problem_NN and_CC solve_VB the_DT relaxed_VBN problem_NN in_IN a_DT more_RBR efficient_JJ way_NN ._.
The_DT previous_JJ MMC_NN works_NNS have_VBP already_RB shown_VBN their_PRP$ superior_JJ performances_NNS in_IN dealing_VBG with_IN clustering_NN problem_NN
mans_NNS need_VBP to_TO expand_VB their_PRP$ knowledge_NN base_NN accordingly_RB ,_, and_CC draw_VB the_DT common_JJ features_NNS of_IN the_DT novel_JJ categories_NNS ._.
Several_JJ recent_JJ research_NN works_NNS share_VBP similar_JJ spirits_NNS with_IN our_PRP$ serendipitous_JJ learning_NN problem_NN =_JJ -_: =[_NN 1_CD ,_, 3_CD ,_, 4_CD ,_, 11_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Unsupervised_JJ transfer_NN classification_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- builds_VBZ the_DT classification_NN model_NN for_IN a_DT target\/novel_NN class_NN in_IN the_DT absence_NN of_IN any_DT labeled_JJ training_NN example_NN but_CC with_IN given_VBN labeled_JJ examples_NNS belonging_VBG to_TO auxilia_VB
