Get_VB another_DT label_NN ?_.
improving_VBG data_NNS quality_NN and_CC data_NN mining_NN using_VBG multiple_JJ ,_, noisy_JJ labelers_NNS
This_DT paper_NN addresses_VBZ the_DT repeated_JJ acquisition_NN of_IN labels_NNS for_IN data_NNS items_NNS when_WRB the_DT labeling_NN is_VBZ imperfect_JJ ._.
We_PRP examine_VBP the_DT improvement_NN -LRB-_-LRB- or_CC lack_NN thereof_RB -RRB-_-RRB- in_IN data_NNS quality_NN via_IN repeated_VBN labeling_NN ,_, and_CC focus_NN especially_RB on_IN the_DT improvement_NN of_IN training_NN labels_NNS for_IN supervised_JJ induction_NN ._.
With_IN the_DT outsourcing_NN of_IN small_JJ tasks_NNS becoming_VBG easier_JJR ,_, for_IN example_NN via_IN Rent-A-Coder_NNP or_CC Amazon_NNP 's_POS Mechanical_JJ Turk_NNP ,_, it_PRP often_RB is_VBZ possible_JJ to_TO obtain_VB less-than-expert_JJ labeling_NN at_IN low_JJ cost_NN ._.
With_IN low-cost_JJ labeling_NN ,_, preparing_VBG the_DT unlabeled_JJ part_NN of_IN the_DT data_NNS can_MD become_VB considerably_RB more_RBR expensive_JJ than_IN labeling_NN ._.
We_PRP present_VBP repeated-labeling_JJ strategies_NNS of_IN increasing_VBG complexity_NN ,_, and_CC show_VBP several_JJ main_JJ results_NNS ._.
-LRB-_-LRB- i_LS -RRB-_-RRB- Repeated-labeling_NN can_MD improve_VB label_NN quality_NN and_CC model_NN quality_NN ,_, but_CC not_RB always_RB ._.
-LRB-_-LRB- ii_LS -RRB-_-RRB- When_WRB labels_NNS are_VBP noisy_JJ ,_, repeated_JJ labeling_NN can_MD be_VB preferable_JJ to_TO single_JJ labeling_NN even_RB in_IN the_DT traditional_JJ setting_NN where_WRB labels_NNS are_VBP not_RB particularly_RB cheap_JJ ._.
-LRB-_-LRB- iii_LS -RRB-_-RRB- As_RB soon_RB as_IN the_DT cost_NN of_IN processing_VBG the_DT unlabeled_JJ data_NN is_VBZ not_RB free_JJ ,_, even_RB the_DT simple_JJ strategy_NN of_IN labeling_NN everything_NN multiple_JJ times_NNS can_MD give_VB considerable_JJ advantage_NN ._.
-LRB-_-LRB- iv_LS -RRB-_-RRB- Repeatedly_RB labeling_VBG a_DT carefully_RB chosen_VBN set_NN of_IN points_NNS is_VBZ generally_RB preferable_JJ ,_, and_CC we_PRP present_VBP a_DT robust_JJ technique_NN that_WDT combines_VBZ different_JJ notions_NNS of_IN uncertainty_NN to_TO select_VB data_NNS points_NNS for_IN which_WDT quality_NN should_MD be_VB improved_VBN ._.
The_DT bottom_JJ line_NN :_: the_DT results_NNS show_VBP clearly_RB that_IN when_WRB labeling_NN is_VBZ not_RB perfect_JJ ,_, selective_JJ acquisition_NN of_IN multiple_JJ labels_NNS is_VBZ a_DT strategy_NN that_IN data_NNS miners_NNS should_MD have_VB in_IN their_PRP$ repertoire_NN ;_: for_IN certain_JJ label-quality\/cost_JJ regimes_NNS ,_, the_DT benefit_NN is_VBZ substantial_JJ ._.
here_RB are_VBP various_JJ costs_NNS associated_VBN with_IN the_DT preprocessing_VBG stage_NN of_IN the_DT KDD_NNP process_NN ,_, including_VBG costs_NNS of_IN acquiring_VBG features_NNS ,_, formulating_VBG data_NNS ,_, cleaning_NN data_NNS ,_, obtaining_VBG expert_JJ labeling_NN of_IN data_NNS ,_, and_CC so_RB on_IN =_JJ -_: =[_NN 31_CD ,_, 32_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, in_IN order_NN to_TO build_VB a_DT model_NN to_TO recognize_VB whether_IN two_CD products_NNS described_VBN on_IN two_CD web_NN pages_NNS are_VBP the_DT same_JJ ,_, one_PRP must_MD extract_VB the_DT product_NN information_NN from_IN the_DT pages_NNS ,_, formulate_VB features_NNS for_IN comp_NN
f_LS data_NN acquisition_NN costs_NNS has_VBZ seen_VBN increasing_VBG research_NN attention_NN ,_, both_DT explicitly_RB -LRB-_-LRB- e.g._FW ,_, cost-sensitive_JJ learning_NN -LRB-_-LRB- 31_CD -RRB-_-RRB- ,_, utility-based_JJ data_NNS mining_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- -RRB-_-RRB- and_CC implicitly_RB ,_, as_IN in_IN the_DT case_NN of_IN active_JJ learning_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Turney_NN -LRB-_-LRB- 31_CD -RRB-_-RRB- provides_VBZ a_DT short_JJ but_CC comprehensive_JJ survey_NN of_IN the_DT different_JJ sorts_NNS of_IN costs_NNS that_WDT should_MD be_VB considered_VBN ,_, including_VBG data_NNS acquisition_NN costs_NNS and_CC labeling_NN costs_NNS ._.
Most_RBS previous_JJ work_NN on_IN cost-sensi_NNS
we_PRP do_VBP not_RB consider_VB in_IN this_DT paper_NN ._.
Prior_JJ research_NN has_VBZ addressed_VBN important_JJ problems_NNS necessary_JJ for_IN a_DT full_JJ labeling_NN solution_NN that_WDT uses_VBZ multiple_JJ noisy_JJ labelers_NNS ,_, such_JJ as_IN estimating_VBG the_DT quality_NN of_IN labelers_NNS =_JJ -_: =[_NN 6_CD ,_, 26_CD ,_, 28_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC learning_VBG with_IN uncertain_JJ labels_NNS -LRB-_-LRB- 13_CD ,_, 24_CD ,_, 25_CD -RRB-_-RRB- ._.
So_RB we_PRP treat_VBP these_DT topics_NNS quickly_RB when_WRB they_PRP arise_VBP ,_, and_CC lean_VB on_IN the_DT prior_JJ work_NN ._.
Repeated-labeling_JJ using_VBG multiple_JJ noisy_JJ labelers_NNS is_VBZ different_JJ from_IN multi_NNS
with_IN a_DT summary_NN of_IN the_DT key_JJ limitations_NNS ,_, and_CC some_DT suggestions_NNS for_IN future_JJ work_NN ._.
2_CD ._.
RELATED_NNS WORK_VBP Repeatedly_RB labeling_VBG the_DT same_JJ data_NNS point_NN is_VBZ practiced_VBN in_IN applications_NNS where_WRB labeling_NN is_VBZ not_RB perfect_JJ -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 27_CD ,_, 28_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
We_PRP are_VBP not_RB aware_JJ of_IN a_DT systematic_JJ assessment_NN of_IN the_DT relationship_NN between_IN the_DT resultant_JJ quality_NN of_IN supervised_JJ modeling_NN and_CC the_DT number_NN of_IN ,_, quality_NN of_IN ,_, and_CC method_NN of_IN selection_NN of_IN data_NNS points_NNS for_IN repeat_NN
te_IN value_NN with_IN probability_NN 1_CD −_CD p._NN After_IN obtaining_VBG the_DT labels_NNS ,_, we_PRP add_VBP them_PRP to_TO the_DT training_NN set_VBN to_TO induce_VB a_DT classifier_NN ._.
For_IN the_DT results_NNS presented_VBN ,_, models_NNS are_VBP induced_VBN with_IN J48_NN ,_, the_DT implementation_NN of_IN C4_NN .5_NN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: in_IN WEKA_NNP -LRB-_-LRB- 34_CD -RRB-_-RRB- ._.
The_DT classifier_NN is_VBZ evaluated_VBN on_IN the_DT test_NN set_NN -LRB-_-LRB- with_IN the_DT true_JJ labels_NNS -RRB-_-RRB- ._.
Each_DT experiment_NN is_VBZ repeated_VBN 10_CD times_NNS with_IN a_DT different_JJ random_JJ data_NNS partition_NN ,_, and_CC average_JJ results_NNS are_VBP reported_VBN ._.
4.2_CD Ge_NN
re_IN P_NN r_NN -LRB-_-LRB- +_CC |_CD x_NN ,_, Hi_NN -RRB-_-RRB- is_VBZ the_DT probability_NN of_IN classifying_VBG the_DT example_NN x_NN into_IN +_CC by_IN the_DT learned_VBN model_NN Hi_NN ,_, and_CC m_NN is_VBZ the_DT number_NN of_IN learned_VBN models_NNS ._.
In_IN our_PRP$ experiments_NNS ,_, m_NN =_JJ 10_CD ,_, and_CC the_DT model_NN set_NN is_VBZ a_DT random_JJ forest_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- generated_VBN by_IN WEKA_NN -RRB-_-RRB- ._.
Of_IN course_NN ,_, by_IN ignoring_VBG the_DT label_NN set_NN ,_, MU_NN has_VBZ the_DT complementary_JJ problem_NN to_TO LU_NNP :_: even_RB if_IN the_DT model_NN is_VBZ uncertain_JJ about_IN a_DT case_NN ,_, should_MD we_PRP acquire_VB more_JJR labels_NNS if_IN the_DT existing_VBG label_NN mu_NN
we_PRP do_VBP not_RB consider_VB in_IN this_DT paper_NN ._.
Prior_JJ research_NN has_VBZ addressed_VBN important_JJ problems_NNS necessary_JJ for_IN a_DT full_JJ labeling_NN solution_NN that_WDT uses_VBZ multiple_JJ noisy_JJ labelers_NNS ,_, such_JJ as_IN estimating_VBG the_DT quality_NN of_IN labelers_NNS =_JJ -_: =[_NN 6_CD ,_, 26_CD ,_, 28_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC learning_VBG with_IN uncertain_JJ labels_NNS -LRB-_-LRB- 13_CD ,_, 24_CD ,_, 25_CD -RRB-_-RRB- ._.
So_RB we_PRP treat_VBP these_DT topics_NNS quickly_RB when_WRB they_PRP arise_VBP ,_, and_CC lean_VB on_IN the_DT prior_JJ work_NN ._.
Repeated-labeling_JJ using_VBG multiple_JJ noisy_JJ labelers_NNS is_VBZ different_JJ from_IN multi_NNS
tain_NN labels_NNS -LRB-_-LRB- 13_CD ,_, 24_CD ,_, 25_CD -RRB-_-RRB- ._.
So_RB we_PRP treat_VBP these_DT topics_NNS quickly_RB when_WRB they_PRP arise_VBP ,_, and_CC lean_VB on_IN the_DT prior_JJ work_NN ._.
Repeated-labeling_JJ using_VBG multiple_JJ noisy_JJ labelers_NNS is_VBZ different_JJ from_IN multiple_JJ label_NN classification_NN =_JJ -_: =[_NN 3_CD ,_, 15_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB one_CD example_NN could_MD have_VB multiple_JJ correct_JJ class_NN labels_NNS ._.
As_IN we_PRP discuss_VBP in_IN Section_NN 5_CD ,_, repeated-labeling_NN can_MD apply_VB regardless_RB of_IN the_DT number_NN of_IN true_JJ class_NN labels_NNS ._.
The_DT key_JJ difference_NN is_VBZ whether_IN the_DT l_NN
tting_NN ._. -RRB-_-RRB-
The_DT performance_NN of_IN model_NN uncertainty_NN alone_RB -LRB-_-LRB- MU_NN -RRB-_-RRB- ,_, which_WDT can_MD be_VB viewed_VBN as_IN the_DT active_JJ learning_NN baseline_NN ,_, is_VBZ more_RBR variable_JJ :_: in_IN three_CD cases_NNS giving_VBG the_DT best_JJS accuracy_NN ,_, but_CC in_IN other_JJ cases_NNS not_RB 7_CD From_IN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: :_: ``_`` No_DT two_CD experts_NNS ,_, of_IN the_DT 5_CD experts_NNS surveyed_VBN ,_, agreed_VBD upon_IN diagnoses_NNS more_JJR than_IN 65_CD %_NN of_IN the_DT time_NN ._.
This_DT might_MD be_VB evidence_NN for_IN the_DT differences_NNS that_WDT exist_VBP between_IN sites_NNS ,_, as_IN the_DT experts_NNS surveyed_VBN had_VBD gained_VBN t_NN
h_NN has_VBZ addressed_VBN important_JJ problems_NNS necessary_JJ for_IN a_DT full_JJ labeling_NN solution_NN that_WDT uses_VBZ multiple_JJ noisy_JJ labelers_NNS ,_, such_JJ as_IN estimating_VBG the_DT quality_NN of_IN labelers_NNS -LRB-_-LRB- 6_CD ,_, 26_CD ,_, 28_CD -RRB-_-RRB- ,_, and_CC learning_VBG with_IN uncertain_JJ labels_NNS =_JJ -_: =[_NN 13_CD ,_, 24_CD ,_, 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
So_RB we_PRP treat_VBP these_DT topics_NNS quickly_RB when_WRB they_PRP arise_VBP ,_, and_CC lean_VB on_IN the_DT prior_JJ work_NN ._.
Repeated-labeling_JJ using_VBG multiple_JJ noisy_JJ labelers_NNS is_VBZ different_JJ from_IN multiple_JJ label_NN classification_NN -LRB-_-LRB- 3_CD ,_, 15_CD -RRB-_-RRB- ,_, where_WRB one_CD examp_NN
ng_NN learning_NN -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 7_CD ,_, 8_CD ,_, 30_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Active_JJ learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- focuses_VBZ on_IN the_DT problem_NN of_IN costly_JJ label_NN acquisition_NN ,_, although_IN often_RB the_DT cost_NN is_VBZ not_RB made_VBN explicit_JJ ._.
Active_JJ learning_NN -LRB-_-LRB- cf._VBP ,_, optimal_JJ experimental_JJ design_NN =_JJ -_: =[_NN 33_CD -RRB-_-RRB- -_: =--RRB-_NN uses_VBZ the_DT existing_VBG model_NN to_TO help_VB select_VB additional_JJ data_NNS for_IN which_WDT to_TO acquire_VB labels_NNS -LRB-_-LRB- 1_CD ,_, 14_CD ,_, 23_CD -RRB-_-RRB- ._.
The_DT usual_JJ problem_NN setting_VBG for_IN active_JJ learning_NN is_VBZ in_IN direct_JJ contrast_NN to_TO the_DT setting_NN we_PRP consider_VBP for_IN rep_NN
h_NN has_VBZ addressed_VBN important_JJ problems_NNS necessary_JJ for_IN a_DT full_JJ labeling_NN solution_NN that_WDT uses_VBZ multiple_JJ noisy_JJ labelers_NNS ,_, such_JJ as_IN estimating_VBG the_DT quality_NN of_IN labelers_NNS -LRB-_-LRB- 6_CD ,_, 26_CD ,_, 28_CD -RRB-_-RRB- ,_, and_CC learning_VBG with_IN uncertain_JJ labels_NNS =_JJ -_: =[_NN 13_CD ,_, 24_CD ,_, 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
So_RB we_PRP treat_VBP these_DT topics_NNS quickly_RB when_WRB they_PRP arise_VBP ,_, and_CC lean_VB on_IN the_DT prior_JJ work_NN ._.
Repeated-labeling_JJ using_VBG multiple_JJ noisy_JJ labelers_NNS is_VBZ different_JJ from_IN multiple_JJ label_NN classification_NN -LRB-_-LRB- 3_CD ,_, 15_CD -RRB-_-RRB- ,_, where_WRB one_CD examp_NN
h_NN has_VBZ addressed_VBN important_JJ problems_NNS necessary_JJ for_IN a_DT full_JJ labeling_NN solution_NN that_WDT uses_VBZ multiple_JJ noisy_JJ labelers_NNS ,_, such_JJ as_IN estimating_VBG the_DT quality_NN of_IN labelers_NNS -LRB-_-LRB- 6_CD ,_, 26_CD ,_, 28_CD -RRB-_-RRB- ,_, and_CC learning_VBG with_IN uncertain_JJ labels_NNS =_JJ -_: =[_NN 13_CD ,_, 24_CD ,_, 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
So_RB we_PRP treat_VBP these_DT topics_NNS quickly_RB when_WRB they_PRP arise_VBP ,_, and_CC lean_VB on_IN the_DT prior_JJ work_NN ._.
Repeated-labeling_JJ using_VBG multiple_JJ noisy_JJ labelers_NNS is_VBZ different_JJ from_IN multiple_JJ label_NN classification_NN -LRB-_-LRB- 3_CD ,_, 15_CD -RRB-_-RRB- ,_, where_WRB one_CD examp_NN
bly_RB higher_JJR than_IN the_DT cost_NN of_IN obtaining_VBG unlabeled_JJ examples_NNS -LRB-_-LRB- essentially_RB zero_VB for_IN ``_`` pool-based_JJ ''_'' active_JJ learning_NN -RRB-_-RRB- ._.
Some_DT previous_JJ work_NN studies_NNS data_NNS acquisition_NN cost_NN explicitly_RB ._.
For_IN example_NN ,_, several_JJ authors_NNS =_JJ -_: =[_NN 11_CD ,_, 12_CD ,_, 16_CD ,_, 17_CD ,_, 22_CD ,_, 32_CD ,_, 37_CD -RRB-_-RRB- -_: =_SYM -_: study_VB the_DT costly_JJ acquisition_NN of_IN feature_NN information_NN ,_, assuming_VBG that_IN the_DT labels_NNS are_VBP known_VBN in_IN advance_NN ._.
Saar-Tsechansky_NNP et_FW al._FW -LRB-_-LRB- 22_CD -RRB-_-RRB- consider_VBP acquiring_VBG both_DT costly_JJ feature_NN and_CC label_NN information_NN ._.
None_NN of_IN t_NN
with_IN a_DT summary_NN of_IN the_DT key_JJ limitations_NNS ,_, and_CC some_DT suggestions_NNS for_IN future_JJ work_NN ._.
2_CD ._.
RELATED_NNS WORK_VBP Repeatedly_RB labeling_VBG the_DT same_JJ data_NNS point_NN is_VBZ practiced_VBN in_IN applications_NNS where_WRB labeling_NN is_VBZ not_RB perfect_JJ -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 27_CD ,_, 28_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
We_PRP are_VBP not_RB aware_JJ of_IN a_DT systematic_JJ assessment_NN of_IN the_DT relationship_NN between_IN the_DT resultant_JJ quality_NN of_IN supervised_JJ modeling_NN and_CC the_DT number_NN of_IN ,_, quality_NN of_IN ,_, and_CC method_NN of_IN selection_NN of_IN data_NNS points_NNS for_IN repeat_NN
bly_RB higher_JJR than_IN the_DT cost_NN of_IN obtaining_VBG unlabeled_JJ examples_NNS -LRB-_-LRB- essentially_RB zero_VB for_IN ``_`` pool-based_JJ ''_'' active_JJ learning_NN -RRB-_-RRB- ._.
Some_DT previous_JJ work_NN studies_NNS data_NNS acquisition_NN cost_NN explicitly_RB ._.
For_IN example_NN ,_, several_JJ authors_NNS =_JJ -_: =[_NN 11_CD ,_, 12_CD ,_, 16_CD ,_, 17_CD ,_, 22_CD ,_, 32_CD ,_, 37_CD -RRB-_-RRB- -_: =_SYM -_: study_VB the_DT costly_JJ acquisition_NN of_IN feature_NN information_NN ,_, assuming_VBG that_IN the_DT labels_NNS are_VBP known_VBN in_IN advance_NN ._.
Saar-Tsechansky_NNP et_FW al._FW -LRB-_-LRB- 22_CD -RRB-_-RRB- consider_VBP acquiring_VBG both_DT costly_JJ feature_NN and_CC label_NN information_NN ._.
None_NN of_IN t_NN
eing_NN modeled_VBD ,_, and_CC so_RB we_PRP shift_VBP to_TO an_DT empirical_JJ analysis_NN based_VBN on_IN experiments_NNS with_IN benchmark_JJ data_NNS sets_NNS ._.
To_TO investigate_VB the_DT questions_NNS above_IN ,_, we_PRP present_VBP experiments_NNS on_IN 12_CD real-world_JJ datasets_NNS from_IN -LRB-_-LRB- 2_CD -RRB-_-RRB- and_CC =_JJ -_: =[_NN 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
These_DT datasets_NNS were_VBD chosen_VBN because_IN they_PRP are_VBP classification_NN problems_NNS with_IN a_DT moderate_JJ number_NN of_IN examples_NNS ,_, allowing_VBG the_DT development_NN of_IN Data_NNP Set_NNP #Attributes_NNP #Examples_NNP Pos_NNP Neg_NNP bmg_FW 41 2417 547 1840_FW expedi_FW
of_IN occurrences_NNS of_IN this_DT label_NN in_IN Li_NNP ._.
These_DT weighted_JJ replicas_NNS can_MD be_VB used_VBN in_IN different_JJ ways_NNS by_IN different_JJ learning_NN algorithms_NNS ,_, e.g._FW ,_, in_IN algorithms_NNS that_WDT take_VBP weights_NNS directly_RB -LRB-_-LRB- such_JJ as_IN cost-sensitive_JJ tree_NN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =--RRB-_NN ,_, or_CC in_IN techniques_NNS like_IN naive_JJ Bayes_NNS that_WDT naturally_RB incorporate_VBP uncertain_JJ labels_NNS ._.
Moreover_RB ,_, any_DT importance-weighted_JJ classification_NN problem_NN can_MD be_VB reduced_VBN to_TO a_DT uniform-weighted_JJ classification_NN problem_NN -LRB-_-LRB-
bly_RB higher_JJR than_IN the_DT cost_NN of_IN obtaining_VBG unlabeled_JJ examples_NNS -LRB-_-LRB- essentially_RB zero_VB for_IN ``_`` pool-based_JJ ''_'' active_JJ learning_NN -RRB-_-RRB- ._.
Some_DT previous_JJ work_NN studies_NNS data_NNS acquisition_NN cost_NN explicitly_RB ._.
For_IN example_NN ,_, several_JJ authors_NNS =_JJ -_: =[_NN 11_CD ,_, 12_CD ,_, 16_CD ,_, 17_CD ,_, 22_CD ,_, 32_CD ,_, 37_CD -RRB-_-RRB- -_: =_SYM -_: study_VB the_DT costly_JJ acquisition_NN of_IN feature_NN information_NN ,_, assuming_VBG that_IN the_DT labels_NNS are_VBP known_VBN in_IN advance_NN ._.
Saar-Tsechansky_NNP et_FW al._FW -LRB-_-LRB- 22_CD -RRB-_-RRB- consider_VBP acquiring_VBG both_DT costly_JJ feature_NN and_CC label_NN information_NN ._.
None_NN of_IN t_NN
tain_NN labels_NNS -LRB-_-LRB- 13_CD ,_, 24_CD ,_, 25_CD -RRB-_-RRB- ._.
So_RB we_PRP treat_VBP these_DT topics_NNS quickly_RB when_WRB they_PRP arise_VBP ,_, and_CC lean_VB on_IN the_DT prior_JJ work_NN ._.
Repeated-labeling_JJ using_VBG multiple_JJ noisy_JJ labelers_NNS is_VBZ different_JJ from_IN multiple_JJ label_NN classification_NN =_JJ -_: =[_NN 3_CD ,_, 15_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB one_CD example_NN could_MD have_VB multiple_JJ correct_JJ class_NN labels_NNS ._.
As_IN we_PRP discuss_VBP in_IN Section_NN 5_CD ,_, repeated-labeling_NN can_MD apply_VB regardless_RB of_IN the_DT number_NN of_IN true_JJ class_NN labels_NNS ._.
The_DT key_JJ difference_NN is_VBZ whether_IN the_DT l_NN
bly_RB higher_JJR than_IN the_DT cost_NN of_IN obtaining_VBG unlabeled_JJ examples_NNS -LRB-_-LRB- essentially_RB zero_VB for_IN ``_`` pool-based_JJ ''_'' active_JJ learning_NN -RRB-_-RRB- ._.
Some_DT previous_JJ work_NN studies_NNS data_NNS acquisition_NN cost_NN explicitly_RB ._.
For_IN example_NN ,_, several_JJ authors_NNS =_JJ -_: =[_NN 11_CD ,_, 12_CD ,_, 16_CD ,_, 17_CD ,_, 22_CD ,_, 32_CD ,_, 37_CD -RRB-_-RRB- -_: =_SYM -_: study_VB the_DT costly_JJ acquisition_NN of_IN feature_NN information_NN ,_, assuming_VBG that_IN the_DT labels_NNS are_VBP known_VBN in_IN advance_NN ._.
Saar-Tsechansky_NNP et_FW al._FW -LRB-_-LRB- 22_CD -RRB-_-RRB- consider_VBP acquiring_VBG both_DT costly_JJ feature_NN and_CC label_NN information_NN ._.
None_NN of_IN t_NN
f_LS error_NN in_IN labeling_NN is_VBZ a_DT key_JJ factor_NN ._.
The_DT consideration_NN of_IN data_NN acquisition_NN costs_NNS has_VBZ seen_VBN increasing_VBG research_NN attention_NN ,_, both_DT explicitly_RB -LRB-_-LRB- e.g._FW ,_, cost-sensitive_JJ learning_NN -LRB-_-LRB- 31_CD -RRB-_-RRB- ,_, utility-based_JJ data_NNS mining_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =--RRB-_NN and_CC implicitly_RB ,_, as_IN in_IN the_DT case_NN of_IN active_JJ learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
Turney_NN -LRB-_-LRB- 31_CD -RRB-_-RRB- provides_VBZ a_DT short_JJ but_CC comprehensive_JJ survey_NN of_IN the_DT different_JJ sorts_NNS of_IN costs_NNS that_WDT should_MD be_VB considered_VBN ,_, including_VBG data_NNS acquisition_NN cos_NNS
bly_RB higher_JJR than_IN the_DT cost_NN of_IN obtaining_VBG unlabeled_JJ examples_NNS -LRB-_-LRB- essentially_RB zero_VB for_IN ``_`` pool-based_JJ ''_'' active_JJ learning_NN -RRB-_-RRB- ._.
Some_DT previous_JJ work_NN studies_NNS data_NNS acquisition_NN cost_NN explicitly_RB ._.
For_IN example_NN ,_, several_JJ authors_NNS =_JJ -_: =[_NN 11_CD ,_, 12_CD ,_, 16_CD ,_, 17_CD ,_, 22_CD ,_, 32_CD ,_, 37_CD -RRB-_-RRB- -_: =_SYM -_: study_VB the_DT costly_JJ acquisition_NN of_IN feature_NN information_NN ,_, assuming_VBG that_IN the_DT labels_NNS are_VBP known_VBN in_IN advance_NN ._.
Saar-Tsechansky_NNP et_FW al._FW -LRB-_-LRB- 22_CD -RRB-_-RRB- consider_VBP acquiring_VBG both_DT costly_JJ feature_NN and_CC label_NN information_NN ._.
None_NN of_IN t_NN
bly_RB higher_JJR than_IN the_DT cost_NN of_IN obtaining_VBG unlabeled_JJ examples_NNS -LRB-_-LRB- essentially_RB zero_VB for_IN ``_`` pool-based_JJ ''_'' active_JJ learning_NN -RRB-_-RRB- ._.
Some_DT previous_JJ work_NN studies_NNS data_NNS acquisition_NN cost_NN explicitly_RB ._.
For_IN example_NN ,_, several_JJ authors_NNS =_JJ -_: =[_NN 11_CD ,_, 12_CD ,_, 16_CD ,_, 17_CD ,_, 22_CD ,_, 32_CD ,_, 37_CD -RRB-_-RRB- -_: =_SYM -_: study_VB the_DT costly_JJ acquisition_NN of_IN feature_NN information_NN ,_, assuming_VBG that_IN the_DT labels_NNS are_VBP known_VBN in_IN advance_NN ._.
Saar-Tsechansky_NNP et_FW al._FW -LRB-_-LRB- 22_CD -RRB-_-RRB- consider_VBP acquiring_VBG both_DT costly_JJ feature_NN and_CC label_NN information_NN ._.
None_NN of_IN t_NN
l_NN acquisition_NN ,_, although_IN often_RB the_DT cost_NN is_VBZ not_RB made_VBN explicit_JJ ._.
Active_JJ learning_NN -LRB-_-LRB- cf._VBP ,_, optimal_JJ experimental_JJ design_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- -RRB-_-RRB- uses_VBZ the_DT existing_VBG model_NN to_TO help_VB select_VB additional_JJ data_NNS for_IN which_WDT to_TO acquire_VB labels_NNS =_JJ -_: =[_NN 1_CD ,_, 14_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT usual_JJ problem_NN setting_VBG for_IN active_JJ learning_NN is_VBZ in_IN direct_JJ contrast_NN to_TO the_DT setting_NN we_PRP consider_VBP for_IN repeated-labeling_NN ._.
For_IN active_JJ learning_NN ,_, the_DT assumption_NN is_VBZ that_IN the_DT cost_NN of_IN labeling_NN is_VBZ considerably_RB
5_CD ,_, repeated-labeling_NN can_MD apply_VB regardless_RB of_IN the_DT number_NN of_IN true_JJ class_NN labels_NNS ._.
The_DT key_JJ difference_NN is_VBZ whether_IN the_DT labels_NNS are_VBP noisy_JJ ._.
A_DT closely_RB related_JJ problem_NN setting_NN is_VBZ described_VBN by_IN Jin_NN and_CC Ghahramani_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN their_PRP$ variant_NN of_IN the_DT multiple_JJ label_NN classification_NN problem_NN ,_, each_DT example_NN presents_VBZ itself_PRP with_IN a_DT set_NN mutually_RB exclusive_JJ labels_NNS ,_, one_CD of_IN which_WDT is_VBZ correct_JJ ._.
The_DT setting_NN for_IN repeated-labeling_NN has_VBZ impor_VBN
l_NN acquisition_NN ,_, although_IN often_RB the_DT cost_NN is_VBZ not_RB made_VBN explicit_JJ ._.
Active_JJ learning_NN -LRB-_-LRB- cf._VBP ,_, optimal_JJ experimental_JJ design_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- -RRB-_-RRB- uses_VBZ the_DT existing_VBG model_NN to_TO help_VB select_VB additional_JJ data_NNS for_IN which_WDT to_TO acquire_VB labels_NNS =_JJ -_: =[_NN 1_CD ,_, 14_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT usual_JJ problem_NN setting_VBG for_IN active_JJ learning_NN is_VBZ in_IN direct_JJ contrast_NN to_TO the_DT setting_NN we_PRP consider_VBP for_IN repeated-labeling_NN ._.
For_IN active_JJ learning_NN ,_, the_DT assumption_NN is_VBZ that_IN the_DT cost_NN of_IN labeling_NN is_VBZ considerably_RB
here_RB are_VBP various_JJ costs_NNS associated_VBN with_IN the_DT preprocessing_VBG stage_NN of_IN the_DT KDD_NNP process_NN ,_, including_VBG costs_NNS of_IN acquiring_VBG features_NNS ,_, formulating_VBG data_NNS ,_, cleaning_NN data_NNS ,_, obtaining_VBG expert_JJ labeling_NN of_IN data_NNS ,_, and_CC so_RB on_IN =_JJ -_: =[_NN 31_CD ,_, 32_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, in_IN order_NN to_TO build_VB a_DT model_NN to_TO recognize_VB whether_IN two_CD products_NNS described_VBN on_IN two_CD web_NN pages_NNS are_VBP the_DT same_JJ ,_, one_PRP must_MD extract_VB the_DT product_NN information_NN from_IN the_DT pages_NNS ,_, formulate_VB features_NNS for_IN comp_NN
-_: sensitive_JJ learning_NN does_VBZ not_RB consider_VB labeling_NN cost_NN ,_, assuming_VBG that_IN a_DT fixed_JJ set_NN of_IN labeled_JJ training_NN examples_NNS is_VBZ given_VBN ,_, and_CC that_IN the_DT learner_NN can_MD not_RB acquire_VB additional_JJ information_NN during_IN learning_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 7_CD ,_, 8_CD ,_, 30_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Active_JJ learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- focuses_VBZ on_IN the_DT problem_NN of_IN costly_JJ label_NN acquisition_NN ,_, although_IN often_RB the_DT cost_NN is_VBZ not_RB made_VBN explicit_JJ ._.
Active_JJ learning_NN -LRB-_-LRB- cf._VBP ,_, optimal_JJ experimental_JJ design_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- -RRB-_-RRB- uses_VBZ the_DT existing_VBG model_NN
-RRB-_-RRB- -RRB-_-RRB- ,_, or_CC in_IN techniques_NNS like_IN naive_JJ Bayes_NNS that_WDT naturally_RB incorporate_VBP uncertain_JJ labels_NNS ._.
Moreover_RB ,_, any_DT importance-weighted_JJ classification_NN problem_NN can_MD be_VB reduced_VBN to_TO a_DT uniform-weighted_JJ classification_NN problem_NN =_JJ -_: =[_NN 35_CD -RRB-_-RRB- -_: =_JJ -_: ,_, often_RB performing_VBG better_RBR than_IN handcrafted_VBN weighted-classification_NN algorithms_NNS ._.
4_LS ._.
REPEATED-LABELING_NN AND_CC MODELING_NN The_DT previous_JJ section_NN examined_VBN when_WRB repeated-labeling_NN can_MD improve_VB quality_NN ._.
We_PRP now_RB consid_VBP
-_: sensitive_JJ learning_NN does_VBZ not_RB consider_VB labeling_NN cost_NN ,_, assuming_VBG that_IN a_DT fixed_JJ set_NN of_IN labeled_JJ training_NN examples_NNS is_VBZ given_VBN ,_, and_CC that_IN the_DT learner_NN can_MD not_RB acquire_VB additional_JJ information_NN during_IN learning_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 7_CD ,_, 8_CD ,_, 30_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Active_JJ learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- focuses_VBZ on_IN the_DT problem_NN of_IN costly_JJ label_NN acquisition_NN ,_, although_IN often_RB the_DT cost_NN is_VBZ not_RB made_VBN explicit_JJ ._.
Active_JJ learning_NN -LRB-_-LRB- cf._VBP ,_, optimal_JJ experimental_JJ design_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- -RRB-_-RRB- uses_VBZ the_DT existing_VBG model_NN
utions_NNS being_VBG modeled_VBN ,_, and_CC so_RB we_PRP shift_VBP to_TO an_DT empirical_JJ analysis_NN based_VBN on_IN experiments_NNS with_IN benchmark_JJ data_NNS sets_NNS ._.
To_TO investigate_VB the_DT questions_NNS above_IN ,_, we_PRP present_VBP experiments_NNS on_IN 12_CD real-world_JJ datasets_NNS from_IN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: and_CC -LRB-_-LRB- 36_CD -RRB-_-RRB- ._.
These_DT datasets_NNS were_VBD chosen_VBN because_IN they_PRP are_VBP classification_NN problems_NNS with_IN a_DT moderate_JJ number_NN of_IN examples_NNS ,_, allowing_VBG the_DT development_NN of_IN Data_NNP Set_NNP #Attributes_NNP #Examples_NNP Pos_NNP Neg_NNP bmg_VBD 41 2417 547_CD 18_CD
quality_NN varies_VBZ as_IN we_PRP vary_VBP CU_NN and_CC CL_NN ,_, and_CC to_TO build_VB models_NNS that_WDT dynamically_RB increase_VB or_CC decrease_VB the_DT amounts_NNS paid_VBN to_TO the_DT labelers_NNS ,_, depending_VBG on_IN the_DT quality_NN requirements_NNS of_IN the_DT task_NN ._.
Morrison_NNP and_CC Cohen_NNP =_SYM -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: determine_VB the_DT optimal_JJ amount_NN to_TO pay_VB for_IN noisy_JJ information_NN in_IN a_DT decision-making_JJ context_NN ,_, where_WRB the_DT amount_NN paid_VBN affects_VBZ the_DT level_NN of_IN noise_NN ._.
•_FW In_FW our_PRP$ experiments_NNS ,_, we_PRP introduced_VBD noise_NN to_TO existing_VBG ,_, benchm_NN
l_NN acquisition_NN ,_, although_IN often_RB the_DT cost_NN is_VBZ not_RB made_VBN explicit_JJ ._.
Active_JJ learning_NN -LRB-_-LRB- cf._VBP ,_, optimal_JJ experimental_JJ design_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- -RRB-_-RRB- uses_VBZ the_DT existing_VBG model_NN to_TO help_VB select_VB additional_JJ data_NNS for_IN which_WDT to_TO acquire_VB labels_NNS =_JJ -_: =[_NN 1_CD ,_, 14_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT usual_JJ problem_NN setting_VBG for_IN active_JJ learning_NN is_VBZ in_IN direct_JJ contrast_NN to_TO the_DT setting_NN we_PRP consider_VBP for_IN repeated-labeling_NN ._.
For_IN active_JJ learning_NN ,_, the_DT assumption_NN is_VBZ that_IN the_DT cost_NN of_IN labeling_NN is_VBZ considerably_RB
-_: sensitive_JJ learning_NN does_VBZ not_RB consider_VB labeling_NN cost_NN ,_, assuming_VBG that_IN a_DT fixed_JJ set_NN of_IN labeled_JJ training_NN examples_NNS is_VBZ given_VBN ,_, and_CC that_IN the_DT learner_NN can_MD not_RB acquire_VB additional_JJ information_NN during_IN learning_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 7_CD ,_, 8_CD ,_, 30_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Active_JJ learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- focuses_VBZ on_IN the_DT problem_NN of_IN costly_JJ label_NN acquisition_NN ,_, although_IN often_RB the_DT cost_NN is_VBZ not_RB made_VBN explicit_JJ ._.
Active_JJ learning_NN -LRB-_-LRB- cf._VBP ,_, optimal_JJ experimental_JJ design_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- -RRB-_-RRB- uses_VBZ the_DT existing_VBG model_NN
