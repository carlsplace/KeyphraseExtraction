Time_NN and_CC sample_NN efficient_JJ discovery_NN of_IN Markov_NNP blankets_NNS and_CC direct_JJ causal_JJ relations_NNS
Data_NNP Mining_NNP with_IN Bayesian_NNP Network_NNP learning_NN has_VBZ two_CD important_JJ characteristics_NNS :_: under_IN conditions_NNS learned_VBD edges_NNS between_IN variables_NNS correspond_VBP to_TO casual_JJ influences_NNS ,_, and_CC second_JJ ,_, for_IN every_DT variable_JJ T_NN in_IN the_DT network_NN a_DT special_JJ subset_NN -LRB-_-LRB- Markov_NNP Blanket_NNP -RRB-_-RRB- identifiable_JJ by_IN the_DT network_NN is_VBZ the_DT minimal_JJ variable_JJ set_NN required_VBN to_TO predict_VB T._NNP However_RB ,_, all_DT known_JJ algorithms_NNS learning_VBG a_DT complete_JJ BN_NN do_VBP not_RB scale_VB up_RP beyond_IN a_DT few_JJ hundred_CD variables_NNS ._.
On_IN the_DT other_JJ hand_NN ,_, all_DT known_JJ sound_JJ algorithms_NNS learning_VBG a_DT local_JJ region_NN of_IN the_DT network_NN require_VBP an_DT exponential_JJ number_NN of_IN training_NN instances_NNS to_TO the_DT size_NN of_IN the_DT learned_VBN region_NN ._.
The_DT contribution_NN of_IN this_DT paper_NN is_VBZ two-fold_JJ ._.
We_PRP introduce_VBP a_DT novel_JJ local_JJ algorithm_NN that_WDT returns_VBZ all_DT variables_NNS with_IN direct_JJ edges_NNS to_TO and_CC from_IN a_DT target_NN variable_JJ T_NN as_RB well_RB as_IN a_DT local_JJ algorithm_NN that_WDT returns_VBZ the_DT Markov_NNP Blanket_NNP of_IN T._NNP Both_DT algorithms_NNS -LRB-_-LRB- i_LS -RRB-_-RRB- are_VBP sound_JJ ,_, -LRB-_-LRB- ii_LS -RRB-_-RRB- can_MD be_VB run_VBN efficiently_RB in_IN datasets_NNS with_IN thousands_NNS of_IN variables_NNS ,_, and_CC -LRB-_-LRB- iii_LS -RRB-_-RRB- significantly_RB outperform_JJ in_IN terms_NNS of_IN approximating_VBG the_DT true_JJ neighborhood_NN previous_JJ state-of-the-art_JJ algorithms_NNS using_VBG only_RB a_DT fraction_NN of_IN the_DT training_NN size_NN required_VBN by_IN the_DT existing_VBG methods_NNS ._.
A_DT fundamental_JJ difference_NN between_IN our_PRP$ approach_NN and_CC existing_VBG ones_NNS is_VBZ that_IN the_DT required_JJ sample_NN depends_VBZ on_IN the_DT generating_VBG graph_NN connectivity_NN and_CC not_RB the_DT size_NN of_IN the_DT local_JJ region_NN ;_: this_DT yields_VBZ up_RP to_TO exponential_JJ savings_NNS in_IN sample_NN relative_JJ to_TO previously_RB known_VBN algorithms_NNS ._.
The_DT results_NNS presented_VBN here_RB are_VBP promising_VBG not_RB only_RB for_IN discovery_NN of_IN local_JJ causal_JJ structure_NN ,_, and_CC variable_JJ selection_NN for_IN classification_NN ,_, but_CC also_RB for_IN the_DT induction_NN of_IN complete_JJ BNs_NNS ._.
above_IN property_NN ,_, the_DT Markov_NNP Blanket_NNP is_VBZ inextricably_RB connected_VBN to_TO the_DT variable_JJ selection_NN problem_NN ,_, i.e._FW ,_, the_DT problem_NN of_IN choosing_VBG a_DT minimum_JJ set_NN of_IN predictors_NNS that_WDT optimally_RB classify_VBP T_NN ._.
In_IN particular_JJ ,_, in_IN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_JJ -_: we_PRP prove_VBP that_IN under_IN certain_JJ broad_JJ conditions_NNS the_DT Markov_NNP Blanket_NNP is_VBZ the_DT solution_NN to_TO the_DT variable_JJ selection_NN problem_NN ._.
Several_JJ algorithms_NNS are_VBP currently_RB available_JJ that_WDT can_MD induce_VB the_DT BN_NN that_WDT captures_VBZ the_DT
ests_NNS and_CC considering_VBG the_DT d-separation_NN relations_NNS they_PRP entail_VBP ,_, one_PRP can_MD reconstruct_VB the_DT BN_NN that_WDT captures_VBZ the_DT data_NNS generating_VBG process_NN ._.
This_DT is_VBZ the_DT main_JJ idea_NN behind_IN constraint-based_JJ BN_NN learning_NN approaches_VBZ =_JJ -_: =[_NN 8_CD ,_, 3_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT following_VBG theorem_NN in_IN -LRB-_-LRB- 8_CD -RRB-_-RRB- is_VBZ foundational_JJ for_IN the_DT both_CC the_DT PC_NN and_CC the_DT MMPC_NNP algorithms_NNS of_IN Section_NN 3_CD :_: Theorem_NN 2_CD ._.
If_IN a_DT BN_NN N_NN is_VBZ faithful_JJ to_TO a_DT joint_JJ probability_NN distribution_NN J_NN then_RB :_: 1_CD ._.
There_EX is_VBZ an_DT edg_NN
iously_RB known_VBN algorithms_NNS for_IN inducing_VBG Markov_NNP Blankets_NNPS ,_, namely_RB the_DT Incremental_JJ Association_NN Markov_NN Blanket_NN -LRB-_-LRB- IAMB_NN -RRB-_-RRB- algorithm_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, the_DT Grow-Shrink_NN -LRB-_-LRB- GS_NN -RRB-_-RRB- algorithm_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, and_CC the_DT Koller-Sahami_NNP algorithm_NN -LRB-_-LRB- KS_NN -RRB-_-RRB- =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
MMMB_NN trades-off_NN computation_NN time_NN for_IN required_VBN training_NN sample_NN size_NN ,_, while_IN still_RB being_VBG efficient_JJ enough_RB to_TO scale_VB up_RP to_TO thousands_NNS of_IN variables_NNS ._.
MMMB_NN yields_NNS up_IN to_TO exponential_JJ savings_NNS in_IN sample_NN relative_NN
smaller_JJR real_JJ BNs_NNS in_IN a_DT way_NN that_WDT retains_VBZ their_PRP$ structural_JJ and_CC probabilistic_JJ properties_NNS ,_, hoping_VBG that_IN the_DT simulated_JJ network_NN will_MD exhibit_VB the_DT same_JJ characteristics_NNS as_IN the_DT real_JJ BN_NN tiles_NNS -LRB-_-LRB- the_DT details_NNS are_VBP in_IN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
More_RBR specifically_RB ,_, we_PRP randomly_RB generated_VBD ALARM-5K_NN by_IN tiling_VBG 135_CD copies_NNS of_IN ALARM_NN ._.
Similarly_RB ,_, for_IN Pigs-5K_NN -LRB-_-LRB- 11_CD copies_NNS of_IN original_JJ Pigs_NNS -RRB-_-RRB- and_CC Hailfinder5K_NN -LRB-_-LRB- 89_CD copies_NNS of_IN original_JJ Hailfinder_NN -RRB-_-RRB- ._.
We_PRP did_VBD not_RB
ales_NNS up_RB to_TO datasets_NNS with_IN thousands_NNS of_IN variables_NNS ._.
MMMB_NN is_VBZ compared_VBN with_IN all_DT previously_RB known_VBN algorithms_NNS for_IN inducing_VBG Markov_NNP Blankets_NNPS ,_, namely_RB the_DT Incremental_JJ Association_NN Markov_NN Blanket_NN -LRB-_-LRB- IAMB_NN -RRB-_-RRB- algorithm_NN =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT Grow-Shrink_NN -LRB-_-LRB- GS_NN -RRB-_-RRB- algorithm_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, and_CC the_DT Koller-Sahami_NNP algorithm_NN -LRB-_-LRB- KS_NN -RRB-_-RRB- -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
MMMB_NN trades-off_NN computation_NN time_NN for_IN required_VBN training_NN sample_NN size_NN ,_, while_IN still_RB being_VBG efficient_JJ enough_RB to_TO scale_VB up_RP to_TO th_DT
