Training_VBG linear_JJ SVMs_NNS in_IN linear_JJ time_NN
Linear_JJ Support_NN Vector_NNP Machines_NNP -LRB-_-LRB- SVMs_NNS -RRB-_-RRB- have_VBP become_VBN one_CD of_IN the_DT most_RBS prominent_JJ machine_NN learning_NN techniques_NNS for_IN high-dimensional_JJ sparse_JJ data_NNS commonly_RB encountered_VBN in_IN applications_NNS like_IN text_NN classification_NN ,_, word-sense_JJ disambiguation_NN ,_, and_CC drug_NN design_NN ._.
These_DT applications_NNS involve_VBP a_DT large_JJ number_NN of_IN examples_NNS n_NN as_RB well_RB as_IN a_DT large_JJ number_NN of_IN features_NNS N_NN ,_, while_IN each_DT example_NN has_VBZ only_RB s_NN -LRB-_-LRB- -LRB-_-LRB- N_NN non-zero_JJ features_NNS ._.
This_DT paper_NN presents_VBZ a_DT Cutting_JJ Plane_NN Algorithm_NN for_IN training_NN linear_NN SVMs_NNS that_WDT provably_RB has_VBZ training_NN time_NN 0_CD -LRB-_-LRB- s_NN ,_, n_NN -RRB-_-RRB- for_IN classification_NN problems_NNS and_CC o_NN -LRB-_-LRB- sn_NN log_NN -LRB-_-LRB- n_NN -RRB-_-RRB- -RRB-_-RRB- for_IN ordinal_JJ regression_NN problems_NNS ._.
The_DT algorithm_NN is_VBZ based_VBN on_IN an_DT alternative_NN ,_, but_CC equivalent_JJ formulation_NN of_IN the_DT SVM_NNP optimization_NN problem_NN ._.
Empirically_RB ,_, the_DT Cutting-Plane_NNP Algorithm_NNP is_VBZ several_JJ orders_NNS of_IN magnitude_NN faster_RBR than_IN decomposition_NN methods_NNS like_IN svm_NN light_NN for_IN large_JJ datasets_NNS ._.
