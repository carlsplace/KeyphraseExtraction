Partial_JJ least_JJS squares_NNS regression_NN for_IN graph_NN mining_NN
Attributed_VBN graphs_NNS are_VBP increasingly_RB more_RBR common_JJ in_IN many_JJ application_NN domains_NNS such_JJ as_IN chemistry_NN ,_, biology_NN and_CC text_NN processing_NN ._.
A_DT central_JJ issue_NN in_IN graph_NN mining_NN is_VBZ how_WRB to_TO collect_VB informative_JJ subgraph_NN patterns_NNS for_IN a_DT given_VBN learning_NN task_NN ._.
We_PRP propose_VBP an_DT iterative_JJ mining_NN method_NN based_VBN on_IN partial_JJ least_JJS squares_NNS regression_NN -LRB-_-LRB- PLS_NN -RRB-_-RRB- ._.
To_TO apply_VB PLS_NN to_TO graph_NN data_NNS ,_, a_DT sparse_JJ version_NN of_IN PLS_NN is_VBZ developed_VBN first_RB and_CC then_RB it_PRP is_VBZ combined_VBN with_IN a_DT weighted_JJ pattern_NN mining_NN algorithm_NN ._.
The_DT mining_NN algorithm_NN is_VBZ iteratively_RB called_VBN with_IN different_JJ weight_NN vectors_NNS ,_, creating_VBG one_CD latent_JJ component_NN per_IN one_CD mining_NN call_NN ._.
Our_PRP$ method_NN ,_, graph_NN PLS_NN ,_, is_VBZ efficient_JJ and_CC easy_JJ to_TO implement_VB ,_, because_IN the_DT weight_NN vector_NN is_VBZ updated_VBN with_IN elementary_JJ matrix_NN calculations_NNS ._.
In_IN experiments_NNS ,_, our_PRP$ graph_NN PLS_NN algorithm_NN showed_VBD competitive_JJ prediction_NN accuracies_NNS in_IN many_JJ chemical_JJ datasets_NNS and_CC its_PRP$ efficiency_NN was_VBD significantly_RB superior_JJ to_TO graph_NN boosting_VBG -LRB-_-LRB- gBoost_NN -RRB-_-RRB- and_CC the_DT naive_JJ method_NN based_VBN on_IN frequent_JJ graph_NN mining_NN ._.
tegory_RB ,_, the_DT whole_JJ feature_NN space_NN is_VBZ built_VBN by_IN one_CD mining_NN run_NN before_IN the_DT subsequent_JJ machine_NN learning_NN algorithm_NN is_VBZ started_VBN ._.
A_DT naive_JJ approach_NN is_VBZ to_TO use_VB a_DT frequent_JJ substructure_NN mining_NN algorithm_NN such_JJ as_IN AGM_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_JJ -_: ,_, gSpan_NN -LRB-_-LRB- 36_CD -RRB-_-RRB- or_CC Gaston_NNP -LRB-_-LRB- 20_CD -RRB-_-RRB- to_TO collect_VB frequently_RB appearing_VBG patterns_NNS ._.
This_DT approach_NN was_VBD employed_VBN by_IN -LRB-_-LRB- 7_CD -RRB-_-RRB- and_CC -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, where_WRB a_DT linear_JJ support_NN vector_NN machine_NN is_VBZ used_VBN for_IN classification_NN ._.
A_DT more_RBR advanced_JJ appr_NN
parse_VB PLS_NNP We_PRP now_RB present_VBP an_DT alternative_JJ derivation_NN of_IN PLS_NN that_WDT avoids_VBZ the_DT deflation_NN step_NN and_CC that_DT is_VBZ based_VBN on_IN the_DT connection_NN of_IN PLS_NN the_DT the_DT Lanczos_NNP method_NN and_CC that_DT uses_VBZ recursive_JJ fitting_NN of_IN residuals_NNS =_JJ -_: =[_NN 5_CD ,_, 13_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Substituting_VBG the_DT definition_NN of_IN the_DT projection_NN matrix_NN to_TO the_DT preweight_JJ vector_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- ,_, we_PRP obtain_VBP v_LS =_JJ 1_CD η_NN X_NN ⊤_NN -LRB-_-LRB- I_PRP −_FW Ti_FW −_FW 1T_FW ⊤_FW i_FW −_FW 1_LS -RRB-_-RRB- y._NN -LRB-_-LRB- 10_CD -RRB-_-RRB- The_DT NIPALS_NN algorithm_NN first_RB computes_VBZ the_DT deflated_JJ matrix_NN X_NNP ⊤_NNP -LRB-_-LRB- I_NNP −_NNP Ti_NNP −_NNP 1T_NNP
aBoost_NN is_VBZ not_RB efficient_JJ in_IN graph_NN mining_NN ,_, because_IN it_PRP takes_VBZ too_RB many_JJ iterations_NNS to_TO finish_VB ._.
Thus_RB recent_JJ papers_NNS use_VBP mathematical_JJ programming-based_JJ approaches_NNS such_JJ as_IN linear_JJ programming_NN boosting_VBG -LRB-_-LRB- LPBoost_NN -RRB-_-RRB- =_JJ -_: =[_NN 3_CD ,_, 24_CD -RRB-_-RRB- -_: =_JJ -_: and_CC quadratic_JJ programming_NN boosting_VBG -LRB-_-LRB- QPBoost_NN -RRB-_-RRB- -LRB-_-LRB- 26_CD -RRB-_-RRB- ._.
Furthermore_RB ,_, to_TO reduce_VB the_DT number_NN of_IN iterations_NNS ,_, several_JJ patterns_NNS are_VBP collected_VBN at_IN the_DT same_JJ time_NN in_IN one_CD iteration_NN by_IN multiple_JJ pricing_NN -LRB-_-LRB- 22_CD -RRB-_-RRB- ._.
Neverthe_NNP
o_NN create_VB the_DT ``_`` real_JJ ''_'' weight_NN vector_NN wi_NN ._.
Based_VBN on_IN vi_LS ,_, the_DT optimal_JJ latent_JJ component_NN is_VBZ obtained_VBN as_IN ti_NN =_JJ ˜Xi_NN vi_LS ._.
Finally_RB ,_, we_PRP have_VBP to_TO recover_VB the_DT optimal_JJ weight_NN vector_NN wi_NN based_VBN on_IN the_DT following_JJ equation_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Xwi_NN =_JJ ti_IN =_JJ ˜Xi_NNS vi_LS =_JJ Xvi_FW −_FW Pi_FW −_FW 1_CD Xvi_NN ._.
Assuming_VBG the_DT linear_JJ independence_NN of_IN rows_NNS of_IN X_NN ,_, the_DT equation_NN is_VBZ solved_VBN as_IN ∑_FW i_FW −_NN 1_CD wi_NN =_JJ vi_LS −_NN -LRB-_-LRB- w_NN ⊤_CD j_NN X_NNP ⊤_NNP Xvi_NNP -RRB-_-RRB- w_NN j_NN ,_, -LRB-_-LRB- 9_CD -RRB-_-RRB- j_NN =_JJ 1_CD which_WDT corresponds_VBZ to_TO the_DT optimal_JJ solution_NN of_IN
._.
When_WRB all_DT possible_JJ subgraphs_NNS are_VBP used_VBN ,_, the_DT dimensionality_NN of_IN the_DT feature_NN space_NN is_VBZ too_RB large_JJ for_IN usual_JJ statistical_JJ methods_NNS ._.
Therefore_RB ,_, feature_NN collection_NN is_VBZ a_DT central_JJ issue_NN in_IN graph_NN mining_NN algorithms_NNS =_JJ -_: =[_NN 30_CD ,_, 1_CD ,_, 35_CD -RRB-_-RRB- -_: =_SYM -_: ._.
To_TO summarize_VB the_DT feature_NN collection_NN methods_NNS proposed_VBN so_RB far_RB ,_, let_VB us_PRP classify_VB them_PRP into_IN two_CD categories_NNS :_: mine-at-once_JJ and_CC iterative_JJ mining_NN ._.
In_IN the_DT first_JJ category_NN ,_, the_DT whole_JJ feature_NN space_NN is_VBZ built_VBN by_IN o_NN
output_NN variable_NN is_VBZ predicted_VBN ._.
In_IN classification_NN ,_, the_DT output_NN variable_NN is_VBZ binary_JJ ._.
In_IN learning_VBG from_IN graph_NN data_NNS ,_, one_PRP can_MD rely_VB on_IN the_DT similarity_NN measures_NNS derived_VBN from_IN graph_NN alignment_NN -LRB-_-LRB- 28_CD -RRB-_-RRB- or_CC graph_NN kernels_NNS =_JJ -_: =[_NN 10_CD ,_, 23_CD ,_, 6_CD ,_, 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, one_CD drawback_NN is_VBZ that_IN the_DT features_NNS used_VBN in_IN learning_NN are_VBP implicitly_RB defined_VBN ,_, and_CC derived_VBN clusters_NNS are_VBP hard_JJ to_TO interpret_VB ._.
Another_DT approach_NN is_VBZ based_VBN on_IN graph_NN mining_NN ,_, where_WRB a_DT set_NN of_IN small_JJ graphs_NNS
ur_IN publicly_RB available_JJ chemical_JJ datasets_NNS :_: EDKB_NN 2_CD ,_, CPDB_NN 3_CD ,_, CAS_NN 4_CD and_CC AIDS_NNP 5_CD ._.
Links_NNP to_TO these_DT datasets_NNS can_MD be_VB found_VBN in_IN ChemDB_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- ._.
Table_NNP 1_CD shows_VBZ the_DT summary_NN of_IN the_DT datasets_NNS ._.
Among_IN them_PRP ,_, the_DT AIDS_NNP dataset_NN =_JJ -_: =[_NN 14_CD ,_, 4_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ by_IN far_RB the_DT largest_JJS both_CC in_IN the_DT number_NN of_IN examples_NNS and_CC the_DT graph_NN size_NN ._.
EDKB_NN is_VBZ a_DT regression_NN dataset_NN ,_, but_CC the_DT others_NNS are_VBP classification_NN datasets_NNS ._.
In_IN gPLS_NN ,_, we_PRP solved_VBD classification_NN problems_NNS by_IN regres_NNS
CPDB_NN dataset_NN ._.
4_LS ._.
EXPERIMENTS_NNS In_IN this_DT section_NN ,_, we_PRP evaluate_VBP our_PRP$ method_NN using_VBG four_CD publicly_RB available_JJ chemical_JJ datasets_NNS :_: EDKB_NN 2_CD ,_, CPDB_NN 3_CD ,_, CAS_NN 4_CD and_CC AIDS_NNP 5_CD ._.
Links_NNP to_TO these_DT datasets_NNS can_MD be_VB found_VBN in_IN ChemDB_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Table_NNP 1_CD shows_VBZ the_DT summary_NN of_IN the_DT datasets_NNS ._.
Among_IN them_PRP ,_, the_DT AIDS_NNP dataset_NN -LRB-_-LRB- 14_CD ,_, 4_CD -RRB-_-RRB- is_VBZ by_IN far_RB the_DT largest_JJS both_CC in_IN the_DT number_NN of_IN examples_NNS and_CC the_DT graph_NN size_NN ._.
EDKB_NN is_VBZ a_DT regression_NN dataset_NN ,_, but_CC the_DT others_NNS
output_NN variable_NN is_VBZ predicted_VBN ._.
In_IN classification_NN ,_, the_DT output_NN variable_NN is_VBZ binary_JJ ._.
In_IN learning_VBG from_IN graph_NN data_NNS ,_, one_PRP can_MD rely_VB on_IN the_DT similarity_NN measures_NNS derived_VBN from_IN graph_NN alignment_NN -LRB-_-LRB- 28_CD -RRB-_-RRB- or_CC graph_NN kernels_NNS =_JJ -_: =[_NN 10_CD ,_, 23_CD ,_, 6_CD ,_, 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, one_CD drawback_NN is_VBZ that_IN the_DT features_NNS used_VBN in_IN learning_NN are_VBP implicitly_RB defined_VBN ,_, and_CC derived_VBN clusters_NNS are_VBP hard_JJ to_TO interpret_VB ._.
Another_DT approach_NN is_VBZ based_VBN on_IN graph_NN mining_NN ,_, where_WRB a_DT set_NN of_IN small_JJ graphs_NNS
._.
Specifically_RB ,_, each_DT graph_NN is_VBZ represented_VBN as_IN a_DT binary_JJ vector_NN of_IN pattern_NN indicators_NNS -LRB-_-LRB- Figure_NN 1_CD -RRB-_-RRB- ._.
Graph_NN mining_NN is_VBZ especially_RB popular_JJ in_IN chemoinformatics_NNS ,_, where_WRB the_DT task_NN is_VBZ to_TO classify_VB chemical_JJ compounds_NNS =_JJ -_: =[_NN 11_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
When_WRB all_DT possible_JJ subgraphs_NNS are_VBP used_VBN ,_, the_DT dimensionality_NN of_IN the_DT feature_NN space_NN is_VBZ too_RB large_JJ for_IN usual_JJ statistical_JJ methods_NNS ._.
Therefore_RB ,_, feature_NN collection_NN is_VBZ a_DT central_JJ issue_NN in_IN graph_NN mining_NN algorithms_NNS
