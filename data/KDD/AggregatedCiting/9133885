Relational_JJ learning_NN via_IN collective_JJ matrix_NN factorization_NN
Relational_JJ learning_NN is_VBZ concerned_VBN with_IN predicting_VBG unknown_JJ values_NNS of_IN a_DT relation_NN ,_, given_VBN a_DT database_NN of_IN entities_NNS and_CC observed_VBN relations_NNS among_IN entities_NNS ._.
An_DT example_NN of_IN relational_JJ learning_NN is_VBZ movie_NN rating_NN prediction_NN ,_, where_WRB entities_NNS could_MD include_VB users_NNS ,_, movies_NNS ,_, genres_NNS ,_, and_CC actors_NNS ._.
Relations_NNS encode_VBP users_NNS '_POS ratings_NNS of_IN movies_NNS ,_, movies_NNS '_POS genres_NNS ,_, and_CC actors_NNS '_POS roles_NNS in_IN movies_NNS ._.
A_DT common_JJ prediction_NN technique_NN given_VBN one_CD pairwise_JJ relation_NN ,_, for_IN example_NN a_DT #users_CD x_CC #movies_CD ratings_NNS matrix_NN ,_, is_VBZ low-rank_JJ matrix_NN factorization_NN ._.
In_IN domains_NNS with_IN multiple_JJ relations_NNS ,_, represented_VBN as_IN multiple_JJ matrices_NNS ,_, we_PRP may_MD improve_VB predictive_JJ accuracy_NN by_IN exploiting_VBG information_NN from_IN one_CD relation_NN while_IN predicting_VBG another_DT ._.
To_TO this_DT end_NN ,_, we_PRP propose_VBP a_DT collective_JJ matrix_NN factorization_NN model_NN :_: we_PRP simultaneously_RB factor_VBP several_JJ matrices_NNS ,_, sharing_VBG parameters_NNS among_IN factors_NNS when_WRB an_DT entity_NN participates_VBZ in_IN multiple_JJ relations_NNS ._.
Each_DT relation_NN can_MD have_VB a_DT different_JJ value_NN type_NN and_CC error_NN distribution_NN ;_: so_RB ,_, we_PRP allow_VBP nonlinear_JJ relationships_NNS between_IN the_DT parameters_NNS and_CC outputs_NNS ,_, using_VBG Bregman_NNP divergences_NNS to_TO measure_VB error_NN ._.
We_PRP extend_VBP standard_JJ alternating_VBG projection_NN algorithms_NNS to_TO our_PRP$ model_NN ,_, and_CC derive_VB an_DT efficient_JJ Newton_NNP update_VB for_IN the_DT projection_NN ._.
Furthermore_RB ,_, we_PRP propose_VBP stochastic_JJ optimization_NN methods_NNS to_TO deal_VB with_IN large_JJ ,_, sparse_JJ matrices_NNS ._.
Our_PRP$ model_NN generalizes_VBZ several_JJ existing_VBG matrix_NN factorization_NN methods_NNS ,_, and_CC therefore_RB yields_VBZ new_JJ large-scale_JJ optimization_NN algorithms_NNS for_IN these_DT problems_NNS ._.
Our_PRP$ model_NN can_MD handle_VB any_DT pairwise_JJ relational_JJ schema_NN and_CC a_DT wide_JJ variety_NN of_IN error_NN models_NNS ._.
We_PRP demonstrate_VBP its_PRP$ efficiency_NN ,_, as_RB well_RB as_IN the_DT benefit_NN of_IN sharing_VBG parameters_NNS among_IN relations_NNS ._.
uality_NN constraint_NN on_IN each_DT update_VBP of_IN U_NN -LRB-_-LRB- r_NN -RRB-_-RRB- i_FW ·_FW ._.
This_DT additional_JJ equality_NN constraint_NN can_MD be_VB folded_VBN into_IN the_DT Newton_NNP step_NN using_VBG a_DT Lagrange_NNP multiplier_NN ,_, yielding_VBG an_DT unconstrained_JJ optimization_NN -LRB-_-LRB- c.f._NN ,_, ch_NN ._.
10_CD =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Comparing_VBG the_DT extension_NN of_IN collective_JJ matrix_NN factorization_NN to_TO the_DT alternatives_NNS above_IN is_VBZ a_DT topic_NN for_IN future_JJ work_NN ._.
It_PRP should_MD be_VB noted_VBN that_IN our_PRP$ choice_NN of_IN X_NN =_JJ UV_NN T_NN is_VBZ not_RB the_DT only_JJ one_NN for_IN matrix_NN factor_NN
column_NN in_IN V_NN -LRB-_-LRB- and_CC vice-versa_NN -RRB-_-RRB- ._.
If_IN the_DT prediction_NN link_NN and_CC loss_NN correspond_VBP to_TO a_DT Bernoulli_NNP distribution_NN ,_, then_RB margin_NN losses_NNS are_VBP special_JJ cases_NNS of_IN biases_NNS ;_: -LRB-_-LRB- iv_LS -RRB-_-RRB- methods_NNS based_VBN on_IN plate_NN models_NNS ,_, such_JJ as_IN pLSI_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, can_MD be_VB placed_VBN in_IN our_PRP$ framework_NN just_RB as_RB well_RB as_IN methods_NNS that_IN factor_NN data_NN matrices_NNS ._.
While_IN these_DT features_NNS can_MD be_VB added_VBN to_TO collective_JJ matrix_NN factorization_NN ,_, we_PRP focus_VBP primarily_RB on_IN relational_JJ issues_NNS herein_RB
minimizing_VBG squared_VBN error_NN with_IN an_DT identity_NN link_NN yields_VBZ the_DT singular_JJ value_NN decomposition_NN -LRB-_-LRB- corresponding_VBG to_TO a_DT Gaussian_JJ error_NN model_NN -RRB-_-RRB- ,_, while_IN other_JJ choices_NNS extend_VBP generalized_JJ linear_JJ models_NNS -LRB-_-LRB- 26_CD -RRB-_-RRB- to_TO matrices_NNS =_JJ -_: =[_NN 14_CD ,_, 17_CD -RRB-_-RRB- -_: =_JJ -_: and_CC lead_VB to_TO error_NN models_NNS such_JJ as_IN Poisson_NNP ,_, Gamma_NNP ,_, or_CC Bernoulli_NNP distributions_NNS ._.
In_IN domains_NNS with_IN more_JJR than_IN one_CD relation_NN matrix_NN ,_, one_PRP could_MD fit_VB each_DT relation_NN separately_RB ;_: however_RB ,_, this_DT approach_NN would_MD not_RB ta_VB
ifferent_JJ models_NNS :_: minimizing_VBG squared_VBD error_NN with_IN an_DT identity_NN link_NN yields_VBZ the_DT singular_JJ value_NN decomposition_NN -LRB-_-LRB- corresponding_VBG to_TO a_DT Gaussian_JJ error_NN model_NN -RRB-_-RRB- ,_, while_IN other_JJ choices_NNS extend_VBP generalized_JJ linear_JJ models_NNS =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_SYM -_: to_TO matrices_NNS -LRB-_-LRB- 14_CD ,_, 17_CD -RRB-_-RRB- and_CC lead_VB to_TO error_NN models_NNS such_JJ as_IN Poisson_NNP ,_, Gamma_NNP ,_, or_CC Bernoulli_NNP distributions_NNS ._.
In_IN domains_NNS with_IN more_JJR than_IN one_CD relation_NN matrix_NN ,_, one_PRP could_MD fit_VB each_DT relation_NN separately_RB ;_: however_RB ,_, this_DT
ots_NNS of_IN the_DT equations_NNS -LCB-_-LRB- q_NN -LRB-_-LRB- Ui_NN ·_NN -RRB-_-RRB- -RCB-_-RRB- m_NN i_FW =_JJ 1_CD ,_, -LCB-_-LRB- q_NN -LRB-_-LRB- Vi_NN ·_NN -RRB-_-RRB- -RCB-_-RRB- n_NN i_LS =_JJ 1_CD ,_, and_CC -LCB-_-LRB- q_NN -LRB-_-LRB- Zi_NN ·_NN -RRB-_-RRB- -RCB-_-RRB- r_NN i_LS =_JJ 1_CD ._.
We_PRP derive_VBP the_DT Newton_NNP step_NN for_IN Ui_NNP ·_NNP ,_, U_NNP new_JJ i_FW ·_FW =_JJ Ui_FW ·_FW −_FW η_FW ·_FW q_FW -LRB-_-LRB- Ui_FW ·_FW -RRB-_-RRB- -LRB-_-LRB- q_FW ′_FW -LRB-_-LRB- Ui_FW ·_FW -RRB-_-RRB- -RRB-_-RRB- −_NN 1_CD ,_, -LRB-_-LRB- 7_CD -RRB-_-RRB- where_WRB we_PRP suggest_VBP using_VBG the_DT Armijo_NNP criterion_NN =_JJ -_: =[_NN 28_CD -RRB-_-RRB- -_: =_SYM -_: to_TO set_VB η_NN ._.
To_TO concisely_RB describe_VB the_DT Hessian_JJ we_PRP introduce_VBP terms_NNS for_IN the_DT contribution_NN of_IN the_DT regularizer_NN ,_, Gi_NN ≡_NN diag_NN -LRB-_-LRB- ∇_NN 2_CD G_NN ∗_NN -LRB-_-LRB- Ui_NN ·_NN -RRB-_-RRB- -RRB-_-RRB- ,_, Hi_FW ≡_FW diag_NN -LRB-_-LRB- ∇_NN 2_CD H_NN ∗_NN -LRB-_-LRB- Vi_NN ·_NN -RRB-_-RRB- -RRB-_-RRB- ,_, Ii_NN ≡_NN diag_NN -LRB-_-LRB- ∇_NN 2_CD I_NN ∗_NN -LRB-_-LRB- Zi_NN ·_NN -RRB-_-RRB- -RRB-_-RRB- ,_, and_CC terms_NNS for_IN the_DT
ase_VB its_PRP$ membership_NN in_IN others_NNS clusters_NNS ._.
Examples_NNS of_IN matrix_NN and_CC relational_JJ co-clustering_NN include_VBP pLSI_NN ,_, pLSI-pHITS_NN ,_, the_DT symmetric_JJ block_NN models_NNS of_IN Long_NNP et_NNP ._.
al._FW -LRB-_-LRB- 23_CD ,_, 24_CD ,_, 25_CD -RRB-_-RRB- ,_, and_CC Bregman_NNP tensor_NN clustering_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- which_WDT can_MD handle_VB higher_JJR arity_NN relations_NNS -RRB-_-RRB- ._.
Matrix_NNP analogs_NNS of_IN factor_NN analysis_NN place_NN no_DT stochastic_JJ constraint_NN on_IN the_DT parameters_NNS ._.
Collective_JJ matrix_NN factorization_NN has_VBZ been_VBN presented_VBN using_VBG matrix_NN factor_NN
its_PRP$ membership_NN in_IN one_CD cluster_NN ,_, it_PRP must_MD decrease_VB its_PRP$ membership_NN in_IN others_NNS clusters_NNS ._.
Examples_NNS of_IN matrix_NN and_CC relational_JJ co-clustering_NN include_VBP pLSI_NN ,_, pLSI-pHITS_NN ,_, the_DT symmetric_JJ block_NN models_NNS of_IN Long_NNP et_NNP ._.
al._FW =_SYM -_: =[_NN 23_CD ,_, 24_CD ,_, 25_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC Bregman_NNP tensor_NN clustering_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- -LRB-_-LRB- which_WDT can_MD handle_VB higher_JJR arity_NN relations_NNS -RRB-_-RRB- ._.
Matrix_NNP analogs_NNS of_IN factor_NN analysis_NN place_NN no_DT stochastic_JJ constraint_NN on_IN the_DT parameters_NNS ._.
Collective_JJ matrix_NN factorization_NN has_VBZ
ave_NN that_IN Xij_NN is_VBZ drawn_VBN from_IN the_DT distribution_NN in_IN ψF_NN with_IN natural_JJ parameter_NN -LRB-_-LRB- UV_NN T_NN -RRB-_-RRB- ij_NN ._.
Decomposable_JJ losses_NNS ,_, which_WDT can_MD be_VB expressed_VBN as_IN the_DT sum_NN of_IN losses_NNS over_IN elements_NNS ,_, follows_VBZ from_IN matrix_NN exchangeability_NN =_JJ -_: =[_NN 2_CD ,_, 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT matrix_NN X_NN is_VBZ row-and-column_NN exchangeable_JJ if_IN permuting_VBG the_DT rows_NNS and_CC columns_NNS of_IN X_NN does_VBZ not_RB change_VB the_DT distribution_NN of_IN X_NN ._.
For_IN example_NN ,_, if_IN X_NN is_VBZ a_DT document-word_JJ matrix_NN of_IN counts_NNS ,_, the_DT relative_JJ position_NN
aints_NNS allow_VBP us_PRP to_TO place_VB methods_NNS like_IN non-negative_JJ matrix_NN factorization_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- or_CC matrix_NN co-clustering_NN into_IN our_PRP$ framework_NN ._.
-LRB-_-LRB- ii_LS -RRB-_-RRB- non-Bregman_JJ matrix_NN factorizations_NNS ,_, such_JJ as_IN max-margin_JJ matrix_NN factorization_NN =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT can_MD immediately_RB take_VB advantage_NN of_IN the_DT large_JJ scale_NN optimization_NN techniques_NNS in_IN Sections_NNS 4-5_CD ;_: -LRB-_-LRB- iii_LS -RRB-_-RRB- row_NN and_CC column_NN biases_NNS ,_, where_WRB a_DT column_NN of_IN U_NN is_VBZ paired_VBN with_IN a_DT fixed_JJ ,_, constant_JJ column_NN in_IN V_NN -LRB-_-LRB- and_CC vi_LS
ss_RB ,_, with_IN an_DT orthogonality_NN constraint_NN on_IN the_DT shared_JJ factors_NNS ._.
Principal_NN components_NNS analysis_NN ,_, which_WDT factors_VBZ a_DT doubly_RB centered_JJ matrix_NN under_IN squared_VBN loss_NN ,_, has_VBZ also_RB been_VBN extended_VBN to_TO the_DT three-factor_JJ schema_NN =_JJ -_: =[_NN 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Another_DT interesting_JJ type_NN of_IN schema_NN contains_VBZ multiple_JJ parallel_JJ relations_NNS between_IN two_CD entity_NN types_NNS ._.
An_DT example_NN of_IN this_DT sort_NN of_IN schema_NN is_VBZ max-margin_JJ matrix_NN factorization_NN -LRB-_-LRB- MMMF_NN -RRB-_-RRB- -LRB-_-LRB- 30_CD -RRB-_-RRB- ._.
In_IN MMMF_NNP ,_, the_DT goal_NN
e_LS or_CC more_RBR related_JJ concepts_NNS -LRB-_-LRB- one_CD concept_NN per_IN row_NN -RRB-_-RRB- ,_, while_IN X_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- lists_VBZ the_DT features_NNS of_IN each_DT entity_NN ._.
An_DT example_NN of_IN a_DT supervised_JJ matrix_NN factorization_NN algorithm_NN is_VBZ the_DT support_NN vector_NN decomposition_NN machine_NN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_JJ -_: :_: in_IN SVDMs_NNS ,_, the_DT features_NNS X_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- are_VBP factored_JJ under_IN squared_VBN loss_NN ,_, while_IN the_DT labels_NNS X_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- are_VBP factored_JJ under_IN Hinge_NN loss_NN ._.
A_DT similar_JJ model_NN was_VBD proposed_VBN by_IN Zhu_NNP et_FW al._FW -LRB-_-LRB- 37_CD -RRB-_-RRB- ,_, using_VBG a_DT once-differentiable_JJ var_NN
loss_NN ,_, while_IN the_DT labels_NNS X_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- are_VBP factored_JJ under_IN Hinge_NN loss_NN ._.
A_DT similar_JJ model_NN was_VBD proposed_VBN by_IN Zhu_NNP et_FW al._FW -LRB-_-LRB- 37_CD -RRB-_-RRB- ,_, using_VBG a_DT once-differentiable_JJ variant_NN of_IN the_DT Hinge_NNP loss_NN ._.
Another_DT example_NN is_VBZ supervised_VBN LSI_NNP =_SYM -_: =[_NN 35_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT factors_NNS both_CC the_DT data_NNS and_CC label_NN matrices_NNS under_IN squared_VBN loss_NN ,_, with_IN an_DT orthogonality_NN constraint_NN on_IN the_DT shared_JJ factors_NNS ._.
Principal_NN components_NNS analysis_NN ,_, which_WDT factors_VBZ a_DT doubly_RB centered_JJ matrix_NN under_IN
ort_NN vector_NN decomposition_NN machine_NN -LRB-_-LRB- 29_CD -RRB-_-RRB- :_: in_IN SVDMs_NNS ,_, the_DT features_NNS X_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- are_VBP factored_JJ under_IN squared_VBN loss_NN ,_, while_IN the_DT labels_NNS X_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- are_VBP factored_JJ under_IN Hinge_NN loss_NN ._.
A_DT similar_JJ model_NN was_VBD proposed_VBN by_IN Zhu_NNP et_FW al._FW =_SYM -_: =[_NN 37_CD -RRB-_-RRB- -_: =_JJ -_: ,_, using_VBG a_DT once-differentiable_JJ variant_NN of_IN the_DT Hinge_NNP loss_NN ._.
Another_DT example_NN is_VBZ supervised_VBN LSI_NNP -LRB-_-LRB- 35_CD -RRB-_-RRB- ,_, which_WDT factors_NNS both_CC the_DT data_NNS and_CC label_NN matrices_NNS under_IN squared_VBN loss_NN ,_, with_IN an_DT orthogonality_NN constraint_NN on_IN
its_PRP$ membership_NN in_IN one_CD cluster_NN ,_, it_PRP must_MD decrease_VB its_PRP$ membership_NN in_IN others_NNS clusters_NNS ._.
Examples_NNS of_IN matrix_NN and_CC relational_JJ co-clustering_NN include_VBP pLSI_NN ,_, pLSI-pHITS_NN ,_, the_DT symmetric_JJ block_NN models_NNS of_IN Long_NNP et_NNP ._.
al._FW =_SYM -_: =[_NN 23_CD ,_, 24_CD ,_, 25_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC Bregman_NNP tensor_NN clustering_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- -LRB-_-LRB- which_WDT can_MD handle_VB higher_JJR arity_NN relations_NNS -RRB-_-RRB- ._.
Matrix_NNP analogs_NNS of_IN factor_NN analysis_NN place_NN no_DT stochastic_JJ constraint_NN on_IN the_DT parameters_NNS ._.
Collective_JJ matrix_NN factorization_NN has_VBZ
ution_NN in_IN ψF_NN is_VBZ uniquely_RB identified_VBN by_IN its_PRP$ natural_JJ parameters_NNS ._.
For_IN regular_JJ exponential_JJ families_NNS log_VBP pF_NN -LRB-_-LRB- x_NN |_CD θ_NN -RRB-_-RRB- =_JJ log_NN p0_NN -LRB-_-LRB- x_NN -RRB-_-RRB- +_CC F_NN ∗_NN -LRB-_-LRB- x_NN -RRB-_-RRB- −_FW DF_FW ∗_NN -LRB-_-LRB- x_NN |_FW |_FW f_FW -LRB-_-LRB- θ_NN -RRB-_-RRB- -RRB-_-RRB- where_WRB the_DT matching_JJ prediction_NN link_NN is_VBZ f_LS -LRB-_-LRB- θ_NN -RRB-_-RRB- =_JJ ∇_NN F_NN -LRB-_-LRB- θ_NN -RRB-_-RRB- =_JJ -_: =[_NN 15_CD ,_, 4_CD ,_, 14_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Minimizing_VBG a_DT Bregman_NNP divergence_NN under_IN a_DT matching_JJ link_NN is_VBZ equivalent_JJ to_TO maximum_NN likelihood_NN for_IN the_DT corresponding_JJ exponential_JJ family_NN distribution_NN ._.
The_DT relationship_NN between_IN matrix_NN factorization_NN and_CC exp_NN
where_WRB A_DT ◦_NN B_NN is_VBZ the_DT matrix_NN dot_NN product_NN tr_NN -LRB-_-LRB- A_NN T_NN B_NN -RRB-_-RRB- =_JJ P_NN ij_FW AijBij_FW and_CC F_NN ∗_NN is_VBZ the_DT convex_JJ dual_JJ F_NN ∗_NN -LRB-_-LRB- µ_NN -RRB-_-RRB- =_JJ sup_NN θ_NN ∈_CD dom_NN F_NN -LRB-_-LRB- 〈_FW θ_FW ,_, µ_FW 〉_FW −_FW F_NN -LRB-_-LRB- θ_NN -RRB-_-RRB- -RRB-_-RRB- ._.
If_IN F_NN ∗_NN is_VBZ differentiable_JJ ,_, this_DT is_VBZ equivalent_JJ to_TO the_DT standard_JJ definition_NN =_JJ -_: =[_NN 10_CD ,_, 11_CD -RRB-_-RRB- -_: =_JJ -_: ,_, except_IN that_IN the_DT standard_JJ definition_NN uses_VBZ arguments_NNS Z_NN and_CC ∇_NN F_NN ∗_NN -LRB-_-LRB- Y_NN -RRB-_-RRB- instead_RB of_IN Z_NN and_CC Y_NN ._.
If_IN F_NN decomposes_VBZ into_IN a_DT sum_NN over_IN components_NNS of_IN Z_NN ,_, we_PRP can_MD define_VB a_DT weighted_JJ ~_NN ajit\/cmf_NN ._.
A_DT longer_JJR version_NN of_IN the_DT p_NN
orization_NN ._.
Other_JJ regularizers_NNS have_VBP been_VBN proposed_VBN specifically_RB for_IN factorization_NN ;_: for_IN example_NN ,_, the_DT trace_NN norm_NN of_IN UV_NN T_NN ,_, the_DT sum_NN of_IN its_PRP$ singular_JJ values_NNS ,_, has_VBZ been_VBN proposed_VBN as_IN a_DT continuous_JJ proxy_NN for_IN rank_NN =_JJ -_: =[_NN 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN clarity_NN ,_, we_PRP treat_VBP hard_JJ constraints_NNS C_NN separately_RB from_IN regularizers_NNS ._.
Examples_NNS of_IN hard_JJ constraints_NNS include_VBP orthogonality_NN ;_: stochasticity_NN of_IN rows_NNS ,_, columns_NNS ,_, or_CC blocks_NNS -LRB-_-LRB- for_IN example_NN ,_, in_IN matrix_NN co-cluste_NN
would_MD be_VB L2_NN -LRB-_-LRB- V_NN ,_, Z_NN |_FW ˜_FW W_NN -RRB-_-RRB- =_JJ DF2_NN -LRB-_-LRB- V_NN Z_NN T_NN |_FW |_FW Y_NN ,_, ˜_NN W_NN -RRB-_-RRB- +_CC DH_NN -LRB-_-LRB- 0_CD |_FW |_FW V_NN -RRB-_-RRB- +_CC DI_NN -LRB-_-LRB- 0_CD |_FW |_FW Z_NN -RRB-_-RRB- ._.
Since_IN V_NN is_VBZ a_DT shared_JJ factor_NN we_PRP average_VBP the_DT losses_NNS :_: L_NN -LRB-_-LRB- U_NN ,_, V_NN ,_, Z_NNP |_NNP W_NNP ,_, ˜_NNP W_NNP -RRB-_-RRB- =_JJ αL1_NN -LRB-_-LRB- U_NN ,_, V_NN |_NN W_NN -RRB-_-RRB- +_CC -LRB-_-LRB- 1_CD −_FW α_FW -RRB-_-RRB- L2_NN -LRB-_-LRB- V_NN ,_, Z_NN |_FW ˜_FW W_NN -RRB-_-RRB- ,_, -LRB-_-LRB- 3_CD -RRB-_-RRB- where_WRB α_FW ∈_FW =_SYM -_: =[_NN 0_CD ,_, 1_CD -RRB-_-RRB- -_: =_JJ -_: weights_NNS the_DT relative_JJ importance_NN of_IN relations_NNS ._.
Each_DT term_NN in_IN the_DT loss_NN ,_, L1_NN and_CC L2_NN ,_, is_VBZ decomposable_JJ and_CC twice-differentiable_JJ ,_, which_WDT is_VBZ all_DT that_WDT is_VBZ required_VBN for_IN the_DT alternating_VBG projections_NNS technique_NN descr_NN
its_PRP$ membership_NN in_IN one_CD cluster_NN ,_, it_PRP must_MD decrease_VB its_PRP$ membership_NN in_IN others_NNS clusters_NNS ._.
Examples_NNS of_IN matrix_NN and_CC relational_JJ co-clustering_NN include_VBP pLSI_NN ,_, pLSI-pHITS_NN ,_, the_DT symmetric_JJ block_NN models_NNS of_IN Long_NNP et_NNP ._.
al._FW =_SYM -_: =[_NN 23_CD ,_, 24_CD ,_, 25_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC Bregman_NNP tensor_NN clustering_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- -LRB-_-LRB- which_WDT can_MD handle_VB higher_JJR arity_NN relations_NNS -RRB-_-RRB- ._.
Matrix_NNP analogs_NNS of_IN factor_NN analysis_NN place_NN no_DT stochastic_JJ constraint_NN on_IN the_DT parameters_NNS ._.
Collective_JJ matrix_NN factorization_NN has_VBZ
minimizing_VBG squared_VBN error_NN with_IN an_DT identity_NN link_NN yields_VBZ the_DT singular_JJ value_NN decomposition_NN -LRB-_-LRB- corresponding_VBG to_TO a_DT Gaussian_JJ error_NN model_NN -RRB-_-RRB- ,_, while_IN other_JJ choices_NNS extend_VBP generalized_JJ linear_JJ models_NNS -LRB-_-LRB- 26_CD -RRB-_-RRB- to_TO matrices_NNS =_JJ -_: =[_NN 14_CD ,_, 17_CD -RRB-_-RRB- -_: =_JJ -_: and_CC lead_VB to_TO error_NN models_NNS such_JJ as_IN Poisson_NNP ,_, Gamma_NNP ,_, or_CC Bernoulli_NNP distributions_NNS ._.
In_IN domains_NNS with_IN more_JJR than_IN one_CD relation_NN matrix_NN ,_, one_PRP could_MD fit_VB each_DT relation_NN separately_RB ;_: however_RB ,_, this_DT approach_NN would_MD not_RB ta_VB
is_VBZ possible_JJ to_TO traverse_VB links_NNS from_IN any_DT entity_NN type_NN to_TO any_DT other_JJ ;_: if_IN not_RB ,_, we_PRP can_MD fit_VB each_DT connected_JJ component_NN in_IN the_DT schema_NN separately_RB ._.
This_DT corresponds_VBZ to_TO a_DT fully_RB connected_VBN entity-relationship_NN model_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP fit_VBP each_DT relation_NN matrix_NN as_IN the_DT product_NN of_IN latent_JJ factors_NNS ,_, X_NN -LRB-_-LRB- ij_NN -RRB-_-RRB- ≈_FW f_FW -LRB-_-LRB- ij_NN -RRB-_-RRB- -LRB-_-LRB- U_NN -LRB-_-LRB- i_LS -RRB-_-RRB- -LRB-_-LRB- U_NN -LRB-_-LRB- j_NN -RRB-_-RRB- -RRB-_-RRB- T_NN -RRB-_-RRB- ,_, where_WRB U_NN -LRB-_-LRB- i_LS -RRB-_-RRB- ∈_NN R_NN ni_FW ×_FW kij_NN and_CC U_NN -LRB-_-LRB- j_NN -RRB-_-RRB- ∈_NN R_NN nj_FW ×_FW kij_FW for_IN kij_FW ∈_FW -LCB-_-LRB- 1_CD ,_, 2_CD ,_, ..._: -RCB-_-RRB- ._.
Unless_IN otherwise_RB noted_VBN ,_, the_DT p_NN
ution_NN in_IN ψF_NN is_VBZ uniquely_RB identified_VBN by_IN its_PRP$ natural_JJ parameters_NNS ._.
For_IN regular_JJ exponential_JJ families_NNS log_VBP pF_NN -LRB-_-LRB- x_NN |_CD θ_NN -RRB-_-RRB- =_JJ log_NN p0_NN -LRB-_-LRB- x_NN -RRB-_-RRB- +_CC F_NN ∗_NN -LRB-_-LRB- x_NN -RRB-_-RRB- −_FW DF_FW ∗_NN -LRB-_-LRB- x_NN |_FW |_FW f_FW -LRB-_-LRB- θ_NN -RRB-_-RRB- -RRB-_-RRB- where_WRB the_DT matching_JJ prediction_NN link_NN is_VBZ f_LS -LRB-_-LRB- θ_NN -RRB-_-RRB- =_JJ ∇_NN F_NN -LRB-_-LRB- θ_NN -RRB-_-RRB- =_JJ -_: =[_NN 15_CD ,_, 4_CD ,_, 14_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Minimizing_VBG a_DT Bregman_NNP divergence_NN under_IN a_DT matching_JJ link_NN is_VBZ equivalent_JJ to_TO maximum_NN likelihood_NN for_IN the_DT corresponding_JJ exponential_JJ family_NN distribution_NN ._.
The_DT relationship_NN between_IN matrix_NN factorization_NN and_CC exp_NN
ediction_NN errors_NNS ._.
One_CD approach_NN to_TO reducing_VBG this_DT cost_NN is_VBZ to_TO compute_VB errors_NNS only_RB on_IN a_DT subset_NN of_IN observed_VBN relations_NNS ,_, picked_VBD randomly_RB at_IN each_DT iteration_NN ._.
This_DT technique_NN is_VBZ known_VBN as_IN stochastic_JJ approximation_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT best-known_JJ stochastic_JJ approximation_NN algorithm_NN is_VBZ stochastic_JJ gradient_NN descent_NN ;_: but_CC ,_, since_IN inverting_VBG the_DT Hessian_JJ is_VBZ not_RB a_DT significant_JJ part_NN of_IN our_PRP$ computational_JJ cost_NN ,_, we_PRP will_MD recommend_VB a_DT stochastic_JJ
lgorithm_NN ,_, which_WDT need_MD not_RB store_VB all_PDT the_DT data_NNS in_IN memory_NN ._.
As_IN mentioned_VBN above_RB ,_, we_PRP can_MD often_RB improve_VB the_DT rate_NN of_IN convergence_NN by_IN moving_VBG from_IN stochastic_JJ gradient_NN descent_NN to_TO stochastic_JJ Newton-Raphson_NNP updates_NNS =_JJ -_: =[_NN 7_CD ,_, 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN the_DT threefactor_JJ model_NN the_DT stochastic_JJ Hessians_NNPS are_VBP grows_VBZ linearly_RB in_IN the_DT number_NN of_IN entities_NNS related_VBN to_TO x_NN -LRB-_-LRB- i_LS -RRB-_-RRB- r_NN where_WRB ˆq_FW ′_FW τ_NN -LRB-_-LRB- Ui_NN ·_NN -RRB-_-RRB- =_JJ αV_NN T_NN s_NN ·_FW ˆ_FW D1_NN ,_, iVs_NN ·_NN +_CC Gi_NN ,_, ˆq_FW ′_FW τ_FW -LRB-_-LRB- Zi_FW ·_FW -RRB-_-RRB- =_JJ -LRB-_-LRB- 1_CD −_FW α_FW -RRB-_-RRB- V_NN T_NN s_NN ·_FW ˆ_FW D4_NN ,_, iVs_FW ·_FW
-LRB-_-LRB- 1_LS -RRB-_-RRB- The_DT loss_NN D_NN -LRB-_-LRB- ·_NN ,_, ·_NN -RRB-_-RRB- quantifies_VBZ ≈_NN in_IN the_DT model_NN ._.
It_PRP is_VBZ typically_RB convex_VBN in_IN its_PRP$ second_JJ argument_NN ,_, and_CC often_RB decomposes_VBZ into_IN a_DT weighted_JJ sum_NN over_IN the_DT elements_NNS of_IN X._NNP For_IN example_NN ,_, the_DT loss_NN for_IN weighted_JJ SVD_NN =_JJ -_: =[_NN 32_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ DW_NN -LRB-_-LRB- X_NN ,_, UV_NN T_NN -RRB-_-RRB- =_JJ |_FW |_FW W_NN ⊙_NN -LRB-_-LRB- X_NN −_NN UV_NN T_NN -RRB-_-RRB- |_FW |_FW 2_CD F_NN ro_NN ,_, where_WRB ⊙_NN denotes_VBZ the_DT element-wise_JJ product_NN of_IN matrices_NNS ._.
Prediction_NN links_VBZ f_FW allow_VB nonlinear_JJ relationships_NNS between_IN UV_NN T_NN and_CC the_DT data_NNS X._NNP The_NNP choices_NNS of_IN f_FW and_CC
ons_JJ approach_NN is_VBZ conceptually_RB simple_JJ ,_, and_CC allows_VBZ one_CD to_TO take_VB advantage_NN of_IN decomposability_NN ,_, there_EX is_VBZ a_DT panoply_NN of_IN alternatives_NNS for_IN factoring_VBG a_DT single_JJ matrix_NN ._.
The_DT more_RBR popular_JJ ones_NNS includes_VBZ majorization_NN =_JJ -_: =[_NN 22_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT iteratively_RB minimize_VBP a_DT sequence_NN of_IN convex_NN upper_JJ bounding_VBG functions_NNS tangent_JJ to_TO the_DT objective_NN ,_, including_VBG the_DT multiplicative_JJ update_VB for_IN NMF_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- and_CC the_DT EM_NNP algorithm_NN ,_, which_WDT is_VBZ used_VBN both_DT for_IN pLSI_NN
ave_NN that_IN Xij_NN is_VBZ drawn_VBN from_IN the_DT distribution_NN in_IN ψF_NN with_IN natural_JJ parameter_NN -LRB-_-LRB- UV_NN T_NN -RRB-_-RRB- ij_NN ._.
Decomposable_JJ losses_NNS ,_, which_WDT can_MD be_VB expressed_VBN as_IN the_DT sum_NN of_IN losses_NNS over_IN elements_NNS ,_, follows_VBZ from_IN matrix_NN exchangeability_NN =_JJ -_: =[_NN 2_CD ,_, 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT matrix_NN X_NN is_VBZ row-and-column_NN exchangeable_JJ if_IN permuting_VBG the_DT rows_NNS and_CC columns_NNS of_IN X_NN does_VBZ not_RB change_VB the_DT distribution_NN of_IN X_NN ._.
For_IN example_NN ,_, if_IN X_NN is_VBZ a_DT document-word_JJ matrix_NN of_IN counts_NNS ,_, the_DT relative_JJ position_NN
k_NN prediction_NN method_NN ,_, we_PRP choose_VBP a_DT measure_NN that_IN favors_NNS neither_CC inherently_RB :_: ranking_NN ._.
We_PRP induce_VBP a_DT ranking_NN of_IN movies_NNS for_IN each_DT user_NN ,_, measuring_VBG the_DT quality_NN of_IN the_DT ranking_NN using_VBG mean_JJ average_JJ precision_NN -LRB-_-LRB- MAP_NN -RRB-_-RRB- =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_JJ -_: :_: queries_NNS correspond_VBP to_TO user_NN 's_POS requests_NNS for_IN ratings_NNS ,_, ``_`` relevant_JJ ''_'' items_NNS are_VBP the_DT movies_NNS of_IN the_DT held-out_JJ links_NNS ,_, we_PRP use_VBP only_RB the_DT top_JJ 200_CD movies_NNS in_IN each_DT ranking_NN 2_CD ,_, and_CC the_DT averaging_NN is_VBZ over_IN users_NNS ._.
Most_JJS mov_NN
tasks_NNS :_: -LRB-_-LRB- i_LS -RRB-_-RRB- predicting_VBG whether_IN a_DT user_NN rated_VBD a_DT particular_JJ movie_NN :_: israted_VBN ;_: and_CC -LRB-_-LRB- ii_LS -RRB-_-RRB- predicting_VBG the_DT value_NN of_IN a_DT rating_NN for_IN a_DT particular_JJ movie_NN :_: rating_NN ._.
User_NN ratings_NNS are_VBP sampled_VBN from_IN the_DT Netflix_NNP Prize_NNP data_NN =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_JJ -_: :_: a_DT rating_NN can_MD be_VB viewed_VBN as_IN a_DT relation_NN taking_VBG on_RP five_CD ordinal_JJ values_NNS -LRB-_-LRB- 1-5_CD stars_NNS -RRB-_-RRB- ,_, i.e._FW ,_, Rating_NNP -LRB-_-LRB- user_NN ,_, movie_NN -RRB-_-RRB- ._.
We_PRP augment_VBP these_DT ratings_NNS with_IN two_CD additional_JJ sources_NNS of_IN movie_NN information_NN ,_, from_IN the_DT Interne_NNP
cific_JJ to_TO squared_VBN loss_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, while_IN later_JJ generalizations_NNS to_TO regular_JJ exponential_JJ families_NNS -LRB-_-LRB- 25_CD -RRB-_-RRB- use_NN EM_NN ._.
An_DT equivalent_JJ formulation_NN in_IN terms_NNS of_IN regular_JJ Bregman_NNP divergences_NNS -LRB-_-LRB- 24_CD -RRB-_-RRB- uses_VBZ iterative_JJ majorization_NN =_JJ -_: =[_NN 22_CD ,_, 34_CD -RRB-_-RRB- -_: =_SYM -_: as_IN the_DT inner_JJ loop_NN of_IN alternating_VBG projection_NN ._.
An_DT improvement_NN on_IN Bregman_NNP co-clustering_JJ accounts_NNS for_IN systematic_JJ biases_NNS ,_, block_NN effects_NNS ,_, in_IN the_DT matrix_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ._.
The_DT three-factor_JJ schema_NN E1_NN ∼_NN E2_NN ∼_NN E3_NN also_RB includ_VBD
-LRB-_-LRB- Zij_NN -RRB-_-RRB- +_CC F_NN ∗_NN -LRB-_-LRB- Yij_NN -RRB-_-RRB- −_FW YijZij_FW -RRB-_-RRB- ._.
Examples_NNS include_VBP weighted_JJ versions_NNS of_IN squared_VBN loss_NN ,_, F_NN -LRB-_-LRB- x_NN -RRB-_-RRB- =_JJ x_NN 2_CD ,_, and_CC I-divergence_NN ,_, F_NN -LRB-_-LRB- x_NN -RRB-_-RRB- =_JJ x_NN log_NN x_NN −_FW x._FW Our_PRP$ primary_JJ focus_NN is_VBZ on_IN decomposable_JJ regular_JJ Bregman_NNP divergences_NNS =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT correspond_VBP to_TO maximum_JJ likelihood_NN in_IN exponential_JJ families_NNS :_: Definition_NN 2_CD ._.
A_DT parametric_JJ family_NN of_IN distributions_NNS ψF_NN =_JJ -LCB-_-LRB- pF_NN -LRB-_-LRB- x_NN |_CD θ_NN -RRB-_-RRB- :_: θ_NN -RCB-_-RRB- is_VBZ a_DT regular_JJ exponential_JJ family_NN if_IN each_DT density_NN has_VBZ the_DT form_NN lo_FW
where_WRB A_DT ◦_NN B_NN is_VBZ the_DT matrix_NN dot_NN product_NN tr_NN -LRB-_-LRB- A_NN T_NN B_NN -RRB-_-RRB- =_JJ P_NN ij_FW AijBij_FW and_CC F_NN ∗_NN is_VBZ the_DT convex_JJ dual_JJ F_NN ∗_NN -LRB-_-LRB- µ_NN -RRB-_-RRB- =_JJ sup_NN θ_NN ∈_CD dom_NN F_NN -LRB-_-LRB- 〈_FW θ_FW ,_, µ_FW 〉_FW −_FW F_NN -LRB-_-LRB- θ_NN -RRB-_-RRB- -RRB-_-RRB- ._.
If_IN F_NN ∗_NN is_VBZ differentiable_JJ ,_, this_DT is_VBZ equivalent_JJ to_TO the_DT standard_JJ definition_NN =_JJ -_: =[_NN 10_CD ,_, 11_CD -RRB-_-RRB- -_: =_JJ -_: ,_, except_IN that_IN the_DT standard_JJ definition_NN uses_VBZ arguments_NNS Z_NN and_CC ∇_NN F_NN ∗_NN -LRB-_-LRB- Y_NN -RRB-_-RRB- instead_RB of_IN Z_NN and_CC Y_NN ._.
If_IN F_NN decomposes_VBZ into_IN a_DT sum_NN over_IN components_NNS of_IN Z_NN ,_, we_PRP can_MD define_VB a_DT weighted_JJ ~_NN ajit\/cmf_NN ._.
A_DT longer_JJR version_NN of_IN the_DT p_NN
._.
2.1_CD Bregman_NNP Divergences_NNP A_NNP large_JJ class_NN of_IN matrix_NN factorization_NN algorithms_NNS restrict_VBP D_NN to_TO generalized_JJ Bregman_NNP divergences_NNS :_: e.g._FW ,_, singular_JJ value_NN decomposition_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- and_CC non-negative_JJ matrix_NN factorization_NN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Definition_NN 1_CD -LRB-_-LRB- -LRB-_-LRB- 17_CD -RRB-_-RRB- -RRB-_-RRB- ._.
For_IN a_DT closed_JJ ,_, proper_JJ ,_, convex_JJ function_NN F_NN :_: R_NN m_NN ×_CD n_NN →_NN R_NN ,_, the_DT generalized_JJ Bregman_NNP divergence_NN between_IN matrices_NNS Z_NN and_CC Y_NN is_VBZ DF_NN -LRB-_-LRB- Z_NN |_FW |_FW Y_NN -RRB-_-RRB- =_JJ F_NN -LRB-_-LRB- Z_NN -RRB-_-RRB- +_CC F_NN ∗_NN -LRB-_-LRB- Y_NN -RRB-_-RRB- −_CD Y_NN ◦_NN Z_NN where_WRB A_DT ◦_NN B_NN is_VBZ the_DT matr_NN
r_NN methods_NNS ,_, such_JJ as_IN the_DT fast_JJ variant_NN of_IN maxmargin_NN matrix_NN factorization_NN -LRB-_-LRB- 30_CD -RRB-_-RRB- ._.
The_DT next_JJ level_NN of_IN generality_NN is_VBZ a_DT three-entity-type_JJ model_NN E1_NN ∼_NN E2_NN ∼_NN E3_NN ._.
A_DT well-known_JJ example_NN of_IN such_PDT a_DT schema_NN is_VBZ pLSI-pHITS_NN =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT models_NNS document-word_JJ counts_NNS and_CC document-document_JJ citations_NNS :_: E1_NN =_JJ words_NNS and_CC E2_NN =_JJ E3_NN =_JJ documents_NNS ,_, but_CC it_PRP is_VBZ trivial_JJ to_TO allow_VB E2_NN ̸_NN =_JJ E3_NN ._.
Given_VBN relations_NNS E1_NN ∼_NN E2_NN and_CC E2_NN ∼_NN E3_NN ,_, with_IN corresponding_VBG in_IN
