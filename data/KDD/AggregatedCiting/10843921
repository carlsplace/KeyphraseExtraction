Improving_NN classification_NN accuracy_NN using_VBG automatically_RB extracted_VBN training_NN data_NNS
Classification_NN is_VBZ a_DT core_NN task_NN in_IN knowledge_NN discovery_NN and_CC data_NN mining_NN ,_, and_CC there_EX has_VBZ been_VBN substantial_JJ research_NN effort_NN in_IN developing_VBG sophisticated_JJ classification_NN models_NNS ._.
In_IN a_DT parallel_JJ thread_NN ,_, recent_JJ work_NN from_IN the_DT NLP_NNP community_NN suggests_VBZ that_IN for_IN tasks_NNS such_JJ as_IN natural_JJ language_NN disambiguation_NN even_RB a_DT simple_JJ algorithm_NN can_MD outperform_VB a_DT sophisticated_JJ one_CD ,_, if_IN it_PRP is_VBZ provided_VBN with_IN large_JJ quantities_NNS of_IN high_JJ quality_NN training_NN data_NNS ._.
In_IN those_DT applications_NNS ,_, training_NN data_NNS occurs_VBZ naturally_RB in_IN text_NN corpora_NN ,_, and_CC high_JJ quality_NN training_NN data_NNS sets_VBZ running_VBG into_IN billions_NNS of_IN words_NNS have_VBP been_VBN reportedly_RB used_VBN ._.
We_PRP explore_VBP how_WRB we_PRP can_MD apply_VB the_DT lessons_NNS from_IN the_DT NLP_NNP community_NN to_TO KDD_NNP tasks_NNS ._.
Specifically_RB ,_, we_PRP investigate_VBP how_WRB to_TO identify_VB data_NNS sources_NNS that_WDT can_MD yield_VB training_NN data_NNS at_IN low_JJ cost_NN and_CC study_NN whether_IN the_DT quantity_NN of_IN the_DT automatically_RB extracted_VBN training_NN data_NNS can_MD compensate_VB for_IN its_PRP$ lower_JJR quality_NN ._.
We_PRP carry_VBP out_RP this_DT investigation_NN for_IN the_DT specific_JJ task_NN of_IN inferring_VBG whether_IN a_DT search_NN query_NN has_VBZ commercial_JJ intent_NN ._.
We_PRP mine_VBP toolbar_NN and_CC click_VB logs_NNS to_TO extract_VB queries_NNS from_IN sites_NNS that_WDT are_VBP predominantly_RB commercial_JJ -LRB-_-LRB- e.g._FW ,_, Amazon_NNP -RRB-_-RRB- and_CC non-commercial_JJ -LRB-_-LRB- e.g._FW ,_, Wikipedia_NNP -RRB-_-RRB- ._.
We_PRP compare_VBP the_DT accuracy_NN obtained_VBN using_VBG such_JJ training_NN data_NNS against_IN manually_RB labeled_VBN training_NN data_NNS ._.
Our_PRP$ results_NNS show_VBP that_IN we_PRP can_MD have_VB large_JJ accuracy_NN gains_NNS using_VBG automatically_RB extracted_VBN training_NN data_NNS at_IN much_RB lower_JJR cost_NN ._.
change_NN with_IN the_DT passage_NN of_IN time_NN ,_, new_JJ labeling_NN is_VBZ constantly_RB required_VBN ._.
Consequently_RB ,_, there_EX is_VBZ never_RB enough_JJ training_NN data_NNS ._.
Moreover_RB ,_, there_EX is_VBZ often_RB inconsistency_NN in_IN the_DT labels_NNS assigned_VBN even_RB by_IN experts_NNS =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN our_PRP$ study_NN ,_, we_PRP extract_VBP training_NN data_NNS by_IN mining_NN toolbar_NN and_CC click_VB logs_NNS ._.
We_PRP collect_VBP queries_NNS posed_VBN to_TO commerce-focused_JJ portals_NNS -LRB-_-LRB- Amazon_NNP ,_, Craigslist_NNP -RRB-_-RRB- as_IN the_DT source_NN of_IN positive_JJ examples_NNS ._.
We_PRP also_RB mine_VBP ne_NN
ta_NN ._.
For_IN example_NN ,_, 6,000_CD manually_RB labeled_VBN queries_NNS are_VBP used_VBN in_IN -LRB-_-LRB- 3_CD -RRB-_-RRB- to_TO learn_VB to_TO classify_VB a_DT query_NN as_IN having_VBG informational_JJ ,_, navigational_JJ ,_, or_CC transactional_JJ intent_NN ,_, and_CC only_RB 1,408_CD labeled_JJ queries_NNS are_VBP used_VBN in_IN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: to_TO train_VB a_DT commercial_JJ intent_NN detection_NN classifier_NN ._.
To_TO offset_VB the_DT problems_NNS with_IN small_JJ training_NN sets_NNS ,_, there_EX has_VBZ been_VBN work_NN on_IN using_VBG semi-supervised_JJ learning_NN ._.
For_IN instance_NN ,_, both_DT -LRB-_-LRB- 5_CD -RRB-_-RRB- and_CC -LRB-_-LRB- 11_CD -RRB-_-RRB- apply_VB semi-s_NNS
ing_NN out_IN of_IN the_DT NLP_NNP community_NN that_WDT suggests_VBZ that_IN for_IN tasks_NNS such_JJ as_IN natural_JJ language_NN disambiguation_NN a_DT simple_JJ algorithm_NN can_MD outperform_VB a_DT sophisticated_JJ algorithm_NN if_IN it_PRP is_VBZ provided_VBN with_IN more_JJR training_NN data_NN =_JJ -_: =[_NN 4_CD ,_, 10_CD ,_, 13_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN the_DT application_NN settings_NNS considered_VBN in_IN these_DT papers_NNS ,_, the_DT training_NN data_NNS occurs_VBZ naturally_RB in_IN text_NN corpora_NN ,_, and_CC high_JJ quality_NN training_NN data_NNS sets_VBZ running_VBG into_IN billions_NNS of_IN words_NNS have_VBP been_VBN used_VBN ._.
This_DT pa_NN
search_NN directions_NNS have_VBP been_VBN pursued_VBN :_: i_LS -RRB-_-RRB- designing_VBG complex_JJ feature_NN representations_NNS to_TO remedy_VB feature_NN sparseness_NN ,_, and_CC ii_LS -RRB-_-RRB- leveraging_VBG unlabeled_JJ data_NNS to_TO compensate_VB for_IN the_DT limited_JJ amounts_NNS of_IN labeled_JJ data_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT latter_JJ approaches_NNS are_VBP often_RB collectively_RB referred_VBN to_TO as_IN semi-supervised_JJ learning_NN -LRB-_-LRB- SSL_NN -RRB-_-RRB- ._.
We_PRP wish_VBP to_TO draw_VB a_DT distinction_NN between_IN SSL_NN and_CC our_PRP$ approach_NN of_IN automatically_RB extracting_VBG large_JJ amounts_NNS of_IN la_DT
d_NN queries_NNS are_VBP used_VBN in_IN -LRB-_-LRB- 7_CD -RRB-_-RRB- to_TO train_VB a_DT commercial_JJ intent_NN detection_NN classifier_NN ._.
To_TO offset_VB the_DT problems_NNS with_IN small_JJ training_NN sets_NNS ,_, there_EX has_VBZ been_VBN work_NN on_IN using_VBG semi-supervised_JJ learning_NN ._.
For_IN instance_NN ,_, both_DT =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: and_CC -LRB-_-LRB- 11_CD -RRB-_-RRB- apply_VBP semi-supervised_JJ learning_NN for_IN the_DT task_NN of_IN web_NN query_NN classification_NN ._.
While_IN -LRB-_-LRB- 5_CD -RRB-_-RRB- uses_VBZ query_NN logs_NNS as_IN unlabeled_JJ data_NNS ,_, -LRB-_-LRB- 11_CD -RRB-_-RRB- uses_VBZ the_DT query-click_JJ graph_NN ._.
While_IN semi-supervised_JJ techniques_NNS assume_VBP
elied_VBN on_IN measuring_VBG similarities_NNS between_IN data_NNS points_NNS ._.
Some_DT approaches_NNS assign_VBP probabilistic_JJ weights_NNS to_TO data_NNS points_NNS based_VBN on_IN ,_, for_IN instance_NN ,_, Gaussian_JJ mixture_NN models_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- or_CC feedback_NN from_IN a_DT neural_JJ network_NN =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, the_DT purity_NN of_IN neighborhood_NN graphs_NNS -LRB-_-LRB- constructed_VBN using_VBG data_NNS features_NNS -RRB-_-RRB- is_VBZ used_VBN to_TO remove_VB noisy_JJ data_NNS points_NNS ._.
In_IN contrast_NN ,_, we_PRP exploit_VBP metadata_NN -LRB-_-LRB- categories_NNS -RRB-_-RRB- and_CC background_NN knowledge_NN to_TO reduce_VB the_DT
+1_FW |_FW x_NN ,_, w_NN -RRB-_-RRB- =_JJ 1_CD 1_CD +_CC exp_NN -LRB-_-LRB- −_FW w_FW T_NN x_NN +_CC b_NN -RRB-_-RRB- ._.
We_PRP find_VBP the_DT optimal_JJ w_NN ,_, b_NN using_VBG the_DT Orthant-Wise_NNP LimitedMemory_NNP Quasi-Newton_NNP method_NN ,_, which_WDT enables_VBZ handling_VBG large_JJ feature_NN spaces_NNS and_CC a_DT large_JJ number_NN of_IN training_NN points_NNS =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Performance_NNP Metric_NNP We_PRP define_VBP precision_NN and_CC recall_NN as_IN follows_VBZ ._.
Let_VB C_NN be_VB the_DT set_NN of_IN queries_NNS that_WDT have_VBP true_JJ commercial_JJ intent_NN -LRB-_-LRB- as_IN decided_VBN by_IN manual_JJ labeling_NN -RRB-_-RRB- ._.
Also_RB ,_, for_IN a_DT particular_JJ threshold_NN θ_FW ∈_FW -LRB-_-LRB- 0_CD ,_, 1_CD
kground_JJ knowledge_NN to_TO reduce_VB the_DT number_NN of_IN undesirable_JJ queries_NNS ._.
Most_JJS work_NN on_IN query_NN intent_NN identification_NN has_VBZ used_VBN small_JJ amounts_NNS of_IN labeled_JJ data_NNS ._.
For_IN example_NN ,_, 6,000_CD manually_RB labeled_VBN queries_NNS are_VBP used_VBN in_IN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: to_TO learn_VB to_TO classify_VB a_DT query_NN as_IN having_VBG informational_JJ ,_, navigational_JJ ,_, or_CC transactional_JJ intent_NN ,_, and_CC only_RB 1,408_CD labeled_JJ queries_NNS are_VBP used_VBN in_IN -LRB-_-LRB- 7_CD -RRB-_-RRB- to_TO train_VB a_DT commercial_JJ intent_NN detection_NN classifier_NN ._.
To_TO offse_VB
the_DT reliability_NN of_IN training_NN data_NNS has_VBZ relied_VBN on_IN measuring_VBG similarities_NNS between_IN data_NNS points_NNS ._.
Some_DT approaches_NNS assign_VBP probabilistic_JJ weights_NNS to_TO data_NNS points_NNS based_VBN on_IN ,_, for_IN instance_NN ,_, Gaussian_JJ mixture_NN models_NNS =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: or_CC feedback_NN from_IN a_DT neural_JJ network_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- ._.
In_IN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, the_DT purity_NN of_IN neighborhood_NN graphs_NNS -LRB-_-LRB- constructed_VBN using_VBG data_NNS features_NNS -RRB-_-RRB- is_VBZ used_VBN to_TO remove_VB noisy_JJ data_NNS points_NNS ._.
In_IN contrast_NN ,_, we_PRP exploit_VBP metadata_NN -LRB-_-LRB- categories_NNS -RRB-_-RRB-
cally_RB extracted_VBN data_NNS to_TO the_DT performance_NN of_IN classifiers_NNS trained_VBN with_IN manually_RB labeled_VBN data_NNS ._.
We_PRP also_RB compare_VBP against_IN the_DT case_NN in_IN which_WDT a_DT semi-supervised_JJ learning_NN technique_NN -LRB-_-LRB- in_IN particular_JJ ,_, self-training_NN =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =--RRB-_NN is_VBZ used_VBN to_TO leverage_NN unlabeled_JJ data_NNS ._.
The_DT other_JJ goal_NN of_IN the_DT evaluation_NN is_VBZ to_TO validate_VB the_DT importance_NN of_IN enforcing_VBG the_DT properties_NNS proposed_VBN in_IN Section_NN 2_CD ._.
To_TO do_VB so_RB ,_, we_PRP study_VBD the_DT effect_NN of_IN training_NN sets_NNS e_SYM
measuring_VBG similarities_NNS between_IN data_NNS points_NNS ._.
Some_DT approaches_NNS assign_VBP probabilistic_JJ weights_NNS to_TO data_NNS points_NNS based_VBN on_IN ,_, for_IN instance_NN ,_, Gaussian_JJ mixture_NN models_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- or_CC feedback_NN from_IN a_DT neural_JJ network_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- ._.
In_IN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT purity_NN of_IN neighborhood_NN graphs_NNS -LRB-_-LRB- constructed_VBN using_VBG data_NNS features_NNS -RRB-_-RRB- is_VBZ used_VBN to_TO remove_VB noisy_JJ data_NNS points_NNS ._.
In_IN contrast_NN ,_, we_PRP exploit_VBP metadata_NN -LRB-_-LRB- categories_NNS -RRB-_-RRB- and_CC background_NN knowledge_NN to_TO reduce_VB the_DT number_NN o_NN
-_: scale_NN labeled_JJ data_NNS for_IN the_DT classification_NN task_NN at_IN hand_NN ._.
Related_JJ ,_, but_CC not_RB directly_RB relevant_JJ ,_, is_VBZ the_DT line_NN of_IN work_NN on_IN mining_NN search_NN engine_NN query_NN logs_NNS to_TO obtain_VB training_NN data_NNS for_IN learning_VBG ranking_JJ models_NNS =_JJ -_: =[_NN 1_CD ,_, 8_CD ,_, 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Their_PRP$ task_NN is_VBZ different_JJ and_CC the_DT source_NN of_IN the_DT training_NN data_NN is_VBZ closely_RB tied_VBN to_TO the_DT task_NN at_IN hand_NN ._.
In_IN particular_JJ ,_, the_DT click_VBP logs_NNS collected_VBN through_IN the_DT usage_NN of_IN the_DT ranker_NN is_VBZ utilized_VBN to_TO provide_VB implic_JJ
-_: scale_NN labeled_JJ data_NNS for_IN the_DT classification_NN task_NN at_IN hand_NN ._.
Related_JJ ,_, but_CC not_RB directly_RB relevant_JJ ,_, is_VBZ the_DT line_NN of_IN work_NN on_IN mining_NN search_NN engine_NN query_NN logs_NNS to_TO obtain_VB training_NN data_NNS for_IN learning_VBG ranking_JJ models_NNS =_JJ -_: =[_NN 1_CD ,_, 8_CD ,_, 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Their_PRP$ task_NN is_VBZ different_JJ and_CC the_DT source_NN of_IN the_DT training_NN data_NN is_VBZ closely_RB tied_VBN to_TO the_DT task_NN at_IN hand_NN ._.
In_IN particular_JJ ,_, the_DT click_VBP logs_NNS collected_VBN through_IN the_DT usage_NN of_IN the_DT ranker_NN is_VBZ utilized_VBN to_TO provide_VB implic_JJ
n_NN set_NN S_NN total_JJ count_NN of_IN features_NNS in_IN set_NN S_NN We_PRP measure_VBP similarity_NN between_IN distributions_NNS using_VBG JensenShannon_NN -LRB-_-LRB- JS_NN -RRB-_-RRB- divergence_NN ._.
This_DT symmetrized_VBN and_CC smoothed_VBN version_NN of_IN the_DT Kullback-Leibler_NNP -LRB-_-LRB- KL_NNP -RRB-_-RRB- divergence_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: provides_VBZ a_DT good_JJ estimate_NN of_IN the_DT true_JJ divergence_NN ,_, as_IN it_PRP takes_VBZ into_IN account_NN the_DT non-overlapping_JJ features_NNS of_IN the_DT two_CD distributions_NNS under_IN consideration_NN ._.
The_DT KL-divergence_NN between_IN two_CD distributions_NNS P_NN and_CC
ing_NN out_IN of_IN the_DT NLP_NNP community_NN that_WDT suggests_VBZ that_IN for_IN tasks_NNS such_JJ as_IN natural_JJ language_NN disambiguation_NN a_DT simple_JJ algorithm_NN can_MD outperform_VB a_DT sophisticated_JJ algorithm_NN if_IN it_PRP is_VBZ provided_VBN with_IN more_JJR training_NN data_NN =_JJ -_: =[_NN 4_CD ,_, 10_CD ,_, 13_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN the_DT application_NN settings_NNS considered_VBN in_IN these_DT papers_NNS ,_, the_DT training_NN data_NNS occurs_VBZ naturally_RB in_IN text_NN corpora_NN ,_, and_CC high_JJ quality_NN training_NN data_NNS sets_VBZ running_VBG into_IN billions_NNS of_IN words_NNS have_VBP been_VBN used_VBN ._.
This_DT pa_NN
s_NNS are_VBP used_VBN in_IN -LRB-_-LRB- 7_CD -RRB-_-RRB- to_TO train_VB a_DT commercial_JJ intent_NN detection_NN classifier_NN ._.
To_TO offset_VB the_DT problems_NNS with_IN small_JJ training_NN sets_NNS ,_, there_EX has_VBZ been_VBN work_NN on_IN using_VBG semi-supervised_JJ learning_NN ._.
For_IN instance_NN ,_, both_DT -LRB-_-LRB- 5_CD -RRB-_-RRB- and_CC =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: apply_VB semi-supervised_JJ learning_NN for_IN the_DT task_NN of_IN web_NN query_NN classification_NN ._.
While_IN -LRB-_-LRB- 5_CD -RRB-_-RRB- uses_VBZ query_NN logs_NNS as_IN unlabeled_JJ data_NNS ,_, -LRB-_-LRB- 11_CD -RRB-_-RRB- uses_VBZ the_DT query-click_JJ graph_NN ._.
While_IN semi-supervised_JJ techniques_NNS assume_VBP the_DT pres_NNS
