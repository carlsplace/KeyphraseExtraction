Ensemble_NN pruning_NN via_IN individual_JJ contribution_NN ordering_VBG
An_DT ensemble_NN is_VBZ a_DT set_NN of_IN learned_VBN models_NNS that_WDT make_VBP decisions_NNS collectively_RB ._.
Although_IN an_DT ensemble_NN is_VBZ usually_RB more_RBR accurate_JJ than_IN a_DT single_JJ learner_NN ,_, existing_VBG ensemble_NN methods_NNS often_RB tend_VBP to_TO construct_VB unnecessarily_RB large_JJ ensembles_NNS ,_, which_WDT increases_VBZ the_DT memory_NN consumption_NN and_CC computational_JJ cost_NN ._.
Ensemble_NN pruning_NN tackles_VBZ this_DT problem_NN by_IN selecting_VBG a_DT subset_NN of_IN ensemble_NN members_NNS to_TO form_VB subensembles_NNS that_WDT are_VBP subject_JJ to_TO less_JJR resource_NN consumption_NN and_CC response_NN time_NN with_IN accuracy_NN that_WDT is_VBZ similar_JJ to_TO or_CC better_JJR than_IN the_DT original_JJ ensemble_NN ._.
In_IN this_DT paper_NN ,_, we_PRP analyze_VBP the_DT accuracy\/diversity_NN trade-off_NN and_CC prove_VBP that_IN classifiers_NNS that_WDT are_VBP more_RBR accurate_JJ and_CC make_VB more_JJR predictions_NNS in_IN the_DT minority_NN group_NN are_VBP more_RBR important_JJ for_IN subensemble_JJ construction_NN ._.
Based_VBN on_IN the_DT gained_VBN insights_NNS ,_, a_DT heuristic_NN metric_NN that_WDT considers_VBZ both_CC accuracy_NN and_CC diversity_NN is_VBZ proposed_VBN to_TO explicitly_RB evaluate_VB each_DT individual_JJ classifier_NN 's_POS contribution_NN to_TO the_DT whole_JJ ensemble_NN ._.
By_IN incorporating_VBG ensemble_NN members_NNS in_IN decreasing_VBG order_NN of_IN their_PRP$ contributions_NNS ,_, subensembles_NNS are_VBP formed_VBN such_JJ that_IN users_NNS can_MD select_VB the_DT top_JJ $_$ p_NN $_$ percent_NN of_IN ensemble_NN members_NNS ,_, depending_VBG on_IN their_PRP$ resource_NN availability_NN and_CC tolerable_JJ waiting_VBG time_NN ,_, for_IN predictions_NNS ._.
Experimental_JJ results_NNS on_IN 26_CD UCI_NNP data_NNS sets_NNS show_VBP that_IN subensembles_NNS formed_VBN by_IN the_DT proposed_VBN EPIC_NN -LRB-_-LRB- Ensemble_NNP Pruning_NNP via_IN Individual_NNP Contribution_NN ordering_VBG -RRB-_-RRB- algorithm_NN outperform_VBP the_DT original_JJ ensemble_NN and_CC a_DT state-of-the-art_JJ ensemble_NN pruning_NN method_NN ,_, Orientation_NN Ordering_NN -LRB-_-LRB- OO_NN -RRB-_-RRB- ._.
a_DT strategy_NN that_WDT only_RB considers_VBZ diversity_NN for_IN pruning_NN ,_, Kappa_NN pruning_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- was_VBD shown_VBN to_TO have_VB ``_`` the_DT poorest_JJS overall_JJ performance_NN on_IN the_DT data_NNS sets_NNS investigated_VBD ''_'' of_IN the_DT ensemble_NN pruning_NN methods_NNS compared_VBN in_IN =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Many_JJ approaches_NNS -LRB-_-LRB- 15_CD -RRB-_-RRB- exist_VBP for_IN selecting_VBG good_JJ subensembles_NNS to_TO achieve_VB the_DT accuracy_NN gain_NN and_CC reduce_VB the_DT computational_JJ cost_NN ,_, where_WRB existing_VBG efforts_NNS roughly_RB fall_VBP into_IN the_DT following_JJ two_CD categories_NNS :_: -LRB-_-LRB- 1_LS -RRB-_-RRB-
that_IN considering_VBG all_DT four_CD cases_NNS is_VBZ crucial_JJ to_TO designing_VBG ensemble_NN diversity_NN measures_NNS and_CC ensemble_NN selection_NN techniques_NNS ._.
Although_IN the_DT designing_VBG of_IN EPIC_NN is_VBZ also_RB based_VBN on_IN the_DT four_CD cases_NNS ,_, itdiffers_NNS from_IN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: in_IN two_CD ways_NNS ._.
Firstly_RB ,_, while_IN both_DT algorithms_NNS agree_VBP that_IN considering_VBG the_DT four_CD cases_NNS is_VBZ crucial_JJ ,_, a_DT more_RBR important_JJ question_NN is_VBZ understanding_VBG the_DT relationship_NN among_IN the_DT four_CD cases_NNS and_CC using_VBG it_PRP for_IN pruning_NN
have_VB two_CD stages_NNS -LRB-_-LRB- 16_CD -RRB-_-RRB- :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- training_NN a_DT set_NN of_IN accurate_JJ and_CC diverse_JJ classifiers_NNS ;_: and_CC -LRB-_-LRB- 2_LS -RRB-_-RRB- combining_VBG individual_JJ classifiers_NNS ,_, using_VBG strategies_NNS such_JJ as_IN majority_NN voting_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, weighted_JJ voting_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- or_CC stacking_VBG =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_JJ -_: ,_, for_IN predictions_NNS ._.
Ensemble_NN pruning_NN can_MD be_VB viewed_VBN as_IN a_DT special_JJ case_NN of_IN the_DT weighted_JJ voting_NN approach_NN ,_, where_WRB each_DT individual_JJ member_NN is_VBZ associated_VBN with_IN a_DT binary_JJ number_NN indicating_VBG whether_IN or_CC not_RB it_PRP should_MD
antly_RB more_RBR accurate_JJ than_IN the_DT original_JJ ensembles_NNS ._.
In_IN all_DT experiments_NNS ,_, bagging_VBG is_VBZ chosen_VBN to_TO be_VB the_DT method_NN for_IN constructing_VBG the_DT original_JJ ensemble_NN because_IN it_PRP has_VBZ been_VBN shown_VBN to_TO be_VB a_DT safe_JJ and_CC robust_JJ method_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
To_TO compare_VB EPIC_NN with_IN peer_VBP ensemble_NN pruning_NN methods_NNS ,_, Orientation_NN Ordering_NN -LRB-_-LRB- OO_NN -RRB-_-RRB- -LRB-_-LRB- 16_CD -RRB-_-RRB- is_VBZ chosen_VBN to_TO be_VB the_DT control_NN case_NN ,_, because_IN it_PRP was_VBD shown_VBN to_TO exhibit_VB good_JJ performance_NN with_IN a_DT low_JJ computational_JJ cost_NN in_IN
rediction_NN ._.
Experimental_JJ results_NNS of_IN GASEN_NNP confirmed_VBD the_DT conclusion_NN that_IN ensembles_NNS can_MD be_VB pruned_VBN to_TO yield_VB similar_JJ or_CC better_JJR performance_NN ._.
A_DT similar_JJ approach_NN was_VBD used_VBN to_TO prune_VB ensembles_NNS of_IN decision_NN trees_NNS =_JJ -_: =[_NN 24_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Zhang_NNP et_FW al._FW -LRB-_-LRB- 23_CD -RRB-_-RRB- formulated_VBD the_DT ensemble_NN pruning_NN problem_NN as_IN a_DT quadratic_JJ integer_NN programming_NN problem_NN ,_, which_WDT is_VBZ NP-hard_JJ ._.
By_IN applying_VBG semi-definite_JJ programming_NN techniques_NNS ,_, approximate_JJ solutions_NNS can_MD be_VB
mate_NN solutions_NNS can_MD be_VB obtained_VBN in_IN polynomial_JJ time_NN for_IN this_DT NP-hard_JJ problem_NN ._.
Another_DT work_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- first_RB obtained_VBD an_DT extensive_JJ library_NN of_IN more_JJR than_IN 2000_CD classifiers_NNS trained_VBN by_IN existing_VBG methods_NNS such_JJ as_IN C4_NN .5_NN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: with_IN different_JJ parameters_NNS ,_, and_CC then_RB ensembles_NNS were_VBD constructed_VBN by_IN selecting_VBG classifiers_NNS using_VBG metrics_NNS such_JJ as_IN accuracy_NN and_CC ROC_NN area_NN ._.
The_DT approach_NN this_DT paper_NN takes_VBZ belongs_VBZ to_TO a_DT family_NN of_IN ensemble_NN prun_NN
ly_RB integrate_VB both_CC accuracy_NN and_CC diversity_NN ,_, which_WDT are_VBP two_CD critical_JJ measures_NNS for_IN ensemble_NN pruning_NN ._.
Indeed_RB ,_, while_IN the_DT correlation_NN between_IN diversity_NN and_CC ensemble_NN learning_NN have_VBP been_VBN observed_VBN for_IN many_JJ years_NNS =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT emphasis_NN has_VBZ been_VBN traditionally_RB on_IN the_DT characterization_NN of_IN the_DT diversity_NN and_CC the_DT creation_NN of_IN the_DT diverse_JJ classifiers_NNS ._.
We_PRP currently_RB lack_VBP effective_JJ pruning_NN principles_NNS to_TO assess_VB the_DT amount_NN of_IN ``_`` cont_NN
iate_JJ handling_NN of_IN the_DT trade-off_NN between_IN accuracy_NN and_CC diversity_NN ._.
Many_JJ approaches_NNS have_VBP been_VBN proposed_VBN to_TO create_VB accurate_JJ and_CC diverse_JJ ensembles_NNS ._.
Examples_NNS include_VBP bagging_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, boosting_VBG -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, random_JJ forests_NNS =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT random_JJ subspace_NN method_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- and_CC random_JJ decision_NN trees_NNS -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
In_IN most_JJS ensemble_NN methods_NNS ,_, the_DT diversity_NN and_CC accuracy_NN are_VBP acquired_VBN by_IN manipulating_VBG subsets_NNS of_IN data_NN points_NNS or_CC features_NNS ._.
One_CD problem_NN with_IN
method_NN is_VBZ the_DT appropriate_JJ handling_NN of_IN the_DT trade-off_NN between_IN accuracy_NN and_CC diversity_NN ._.
Many_JJ approaches_NNS have_VBP been_VBN proposed_VBN to_TO create_VB accurate_JJ and_CC diverse_JJ ensembles_NNS ._.
Examples_NNS include_VBP bagging_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, boosting_VBG =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_JJ -_: ,_, random_JJ forests_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, the_DT random_JJ subspace_NN method_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- and_CC random_JJ decision_NN trees_NNS -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
In_IN most_JJS ensemble_NN methods_NNS ,_, the_DT diversity_NN and_CC accuracy_NN are_VBP acquired_VBN by_IN manipulating_VBG subsets_NNS of_IN data_NN points_NNS or_CC featur_NN
ensemble_NN of_IN three_CD classifiers_NNS with_IN 67_CD %_NN accuracy_NN and_CC least_JJS pairwise_JJ correlated_JJ error_NN -LRB-_-LRB- which_WDT is_VBZ perfect_JJ !_. -RRB-_-RRB- ._. ''_''
At_IN the_DT other_JJ extreme_NN ,_, as_IN a_DT strategy_NN that_WDT only_RB considers_VBZ diversity_NN for_IN pruning_NN ,_, Kappa_NNP pruning_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: was_VBD shown_VBN to_TO have_VB ``_`` the_DT poorest_JJS overall_JJ performance_NN on_IN the_DT data_NNS sets_NNS investigated_VBD ''_'' of_IN the_DT ensemble_NN pruning_NN methods_NNS compared_VBN in_IN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
Many_JJ approaches_NNS -LRB-_-LRB- 15_CD -RRB-_-RRB- exist_VBP for_IN selecting_VBG good_JJ subensembles_NNS to_TO achie_VB
formed_VBN by_IN the_DT proposed_VBN EPIC_NN -LRB-_-LRB- Ensemble_NNP Pruning_NNP via_IN Individual_NNP Contribution_NN ordering_VBG -RRB-_-RRB- algorithm_NN outperform_VBP the_DT original_JJ ensemble_NN and_CC a_DT state-ofthe-art_JJ ensemble_NN pruning_NN method_NN ,_, Orientation_NN Ordering_NN -LRB-_-LRB- OO_NN -RRB-_-RRB- =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Categories_NNS and_CC Subject_NNP Descriptors_NNP H._NNP 2.8_CD -LRB-_-LRB- Database_NN applications_NNS -RRB-_-RRB- :_: Database_NN Applications_NNS -_: Data_NNP Mining_NNP General_NNP Terms_NNS Algorithms_FW Keywords_FW ensemble_NN learning_NN ,_, ensemble_NN pruning_NN 1_CD ._.
INTRODUCTION_NN The_DT constr_NN
s_NN based_JJ disagreement_NN measure_NN ,_, which_WDT was_VBD proposed_VBN by_IN Ho_NNP -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, to_TO characterize_VB the_DT pair-wise_JJ diversity_NN for_IN ensemble_NN members_NNS ._.
The_DT same_JJ analysis_NN apply_VB for_IN others_NNS ,_, such_JJ as_IN the_DT Q_NNP statistics_NNS or_CC κ_NN statistics_NNS =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_JJ -_: ,_, based_VBN measures_NNS ._.
Definition_NN 1_CD :_: Given_VBN two_CD classifiers_NNS ci_NN and_CC cj_NN ,_, where_WRB N_NN -LRB-_-LRB- 01_CD -RRB-_-RRB- denotes_VBZ the_DT number_NN of_IN data_NNS points_NNS incorrectly_RB predicted_VBN by_IN ci_FW but_CC correctly_RB predicted_VBN by_IN cj_NN ,_, and_CC N_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- is_VBZ the_DT opposite_NN of_IN
from_IN the_DT balanced_JJ accuracy\/diversity_NN trade-off_NN ,_, where_WRB choosing_VBG only_RB the_DT most_RBS accurate_JJ individual_JJ classifiers_NNS to_TO form_VB the_DT subensemble_NN is_VBZ theoretically_RB unsound_JJ ._.
As_IN an_DT informative_JJ example_NN ,_, Zhang_NNP et_FW al._FW =_SYM -_: =[_NN 23_CD -RRB-_-RRB- -_: =_SYM -_: has_VBZ demonstrated_VBN that_IN ``_`` an_DT ensemble_NN of_IN three_CD identical_JJ classifiers_NNS with_IN 95_CD %_NN accuracy_NN is_VBZ worse_JJR than_IN an_DT ensemble_NN of_IN three_CD classifiers_NNS with_IN 67_CD %_NN accuracy_NN and_CC least_JJS pairwise_JJ correlated_JJ error_NN -LRB-_-LRB- which_WDT is_VBZ perf_NN
,_, and_CC then_RB the_DT experimental_JJ results_NNS of_IN the_DT comparison_NN between_IN EPIC_NN ,_, OO_NN and_CC bagging_NN are_VBP given_VBN ._.
4.1_CD Experimental_JJ Settings_NNS and_CC Data_NNP Sets_VBZ 26_CD data_NNS sets_NNS were_VBD chosen_VBN from_IN the_DT UCI_NNP machine_NN learning_NN repository_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: to_TO evaluate_VB the_DT performance_NN of_IN EPIC_NN ._.
Each_DT data_NN set_NN was_VBD randomly_RB divided_VBN into_IN three_CD subsets_NNS with_IN equal_JJ sizes_NNS ._.
There_EX are_VBP six_CD permutations_NNS of_IN the_DT three_CD subsets_NNS ._.
Experiments_NNS on_IN each_DT data_NNS set_VBN consisted_VBD of_IN
mble_JJ learning_NN method_NN is_VBZ the_DT appropriate_JJ handling_NN of_IN the_DT trade-off_NN between_IN accuracy_NN and_CC diversity_NN ._.
Many_JJ approaches_NNS have_VBP been_VBN proposed_VBN to_TO create_VB accurate_JJ and_CC diverse_JJ ensembles_NNS ._.
Examples_NNS include_VBP bagging_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_JJ -_: ,_, boosting_VBG -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, random_JJ forests_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, the_DT random_JJ subspace_NN method_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- and_CC random_JJ decision_NN trees_NNS -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
In_IN most_JJS ensemble_NN methods_NNS ,_, the_DT diversity_NN and_CC accuracy_NN are_VBP acquired_VBN by_IN manipulating_VBG subsets_NNS of_IN data_NNS p_NN
ngle_JJ classifier_NN ,_, an_DT ensemble_NN is_VBZ a_DT set_NN of_IN classifiers_NNS that_WDT make_VBP decisions_NNS collectively_RB ._.
It_PRP is_VBZ well_RB accepted_VBN that_IN an_DT ensemble_NN usually_RB generalizes_VBZ better_JJR than_IN a_DT single_JJ classifier_NN -LRB-_-LRB- 22_CD -RRB-_-RRB- ._.
Dietterich_NNP stated_VBD =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: ``_`` A_DT necessary_JJ and_CC sufficient_JJ condition_NN for_IN an_DT ensemble_NN of_IN classifiers_NNS to_TO be_VB more_RBR accurate_JJ than_IN any_DT of_IN its_PRP$ individual_JJ members_NNS is_VBZ if_IN the_DT classifiers_NNS are_VBP accurate_JJ and_CC diverse_JJ ._. ''_''
Since_IN the_DT diversity_NN of_IN the_DT
etween_JJ accuracy_NN and_CC diversity_NN ._.
Many_JJ approaches_NNS have_VBP been_VBN proposed_VBN to_TO create_VB accurate_JJ and_CC diverse_JJ ensembles_NNS ._.
Examples_NNS include_VBP bagging_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, boosting_VBG -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, random_JJ forests_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, the_DT random_JJ subspace_NN method_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_JJ -_: and_CC random_JJ decision_NN trees_NNS -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
In_IN most_JJS ensemble_NN methods_NNS ,_, the_DT diversity_NN and_CC accuracy_NN are_VBP acquired_VBN by_IN manipulating_VBG subsets_NNS of_IN data_NN points_NNS or_CC features_NNS ._.
One_CD problem_NN with_IN these_DT ensembling_VBG approaches_NNS is_VBZ t_NN
dratic_JJ integer_NN programming_NN problem_NN ,_, which_WDT is_VBZ NP-hard_JJ ._.
By_IN applying_VBG semi-definite_JJ programming_NN techniques_NNS ,_, approximate_JJ solutions_NNS can_MD be_VB obtained_VBN in_IN polynomial_JJ time_NN for_IN this_DT NP-hard_JJ problem_NN ._.
Another_DT work_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: first_RB obtained_VBN an_DT extensive_JJ library_NN of_IN more_JJR than_IN 2000_CD classifiers_NNS trained_VBN by_IN existing_VBG methods_NNS such_JJ as_IN C4_NN .5_CD -LRB-_-LRB- 18_CD -RRB-_-RRB- with_IN different_JJ parameters_NNS ,_, and_CC then_RB ensembles_NNS were_VBD constructed_VBN by_IN selecting_VBG classifiers_NNS
his_PRP$ paper_NN ,_, both_DT EPIC_NNP and_CC OO_NNP used_VBD the_DT independent_JJ pruning_NN set_VBN for_IN pruning_NN ._.
A_DT bagging_VBG ensemble_NN was_VBD trained_VBN in_IN each_DT trial_NN ._.
The_DT base_NN learner_NN was_VBD J48_NN ,_, which_WDT is_VBZ a_DT Java_NNP implementation_NN of_IN C4_NN .5_CD -LRB-_-LRB- 18_CD -RRB-_-RRB- from_IN Weka_NN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN all_DT experiments_NNS ,_, the_DT ensemble_NN size_NN was_VBD 200_CD ._.
Both_CC EPIC_NN and_CC OO_NN were_VBD used_VBN to_TO reorder_VB the_DT same_JJ ensemble_NN in_IN each_DT trial_NN ._.
The_DT predictive_JJ accuracies_NNS of_IN the_DT original_JJ ensemble_NN ,_, the_DT EPIC-ordered_JJ ensemble_NN an_DT
rst_NN time_NN a_DT strict_JJ order_NN of_IN importance_NN for_IN the_DT four_CD cases_NNS ._.
Secondly_RB ,_, -LRB-_-LRB- 17_CD -RRB-_-RRB- is_VBZ an_DT iterative_JJ algorithm_NN with_IN a_DT polynomial_JJ pruning_NN time_NN ,_, while_IN EPIC_NN 's_POS pruning_NN time_NN is_VBZ O_NN -LRB-_-LRB- Mlog_NN -LRB-_-LRB- M_NN -RRB-_-RRB- -RRB-_-RRB- for_IN an_DT ensemble_NN with_IN size_NN M._NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ another_DT work_NN that_WDT considers_VBZ the_DT four_CD cases_NNS ._.
Like_IN -LRB-_-LRB- 17_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 2_CD -RRB-_-RRB- did_VBD not_RB show_VB the_DT relationship_NN among_IN the_DT four_CD cases_NNS ,_, and_CC its_PRP$ pruning_NN time_NN is_VBZ polynomial_JJ ._.
Recent_JJ work_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- gives_VBZ a_DT review_NN and_CC comparative_JJ s_NN
problem_NN of_IN finding_VBG the_DT subset_NN of_IN ensemble_NN members_NNS with_IN the_DT optimal_JJ generalization_NN ability_NN involves_VBZ searching_VBG the_DT space_NN of_IN 2_CD M_NN −_NN 1_CD non-empty_JJ subensembles_NNS ,_, which_WDT was_VBD proved_VBN to_TO be_VB an_DT NP-complete_JJ problem_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Like_IN other_JJ approaches_NNS in_IN ensemble_NN learning_NN ,_, the_DT performance_NN gain_NN of_IN the_DT ensemble_NN pruning_NN methods_NNS stems_VBZ from_IN the_DT balanced_JJ accuracy\/diversity_NN trade-off_NN ,_, where_WRB choosing_VBG only_RB the_DT most_RBS accurate_JJ individua_NN
00_CD ._.
than_IN relying_VBG on_IN a_DT single_JJ classifier_NN ,_, an_DT ensemble_NN is_VBZ a_DT set_NN of_IN classifiers_NNS that_WDT make_VBP decisions_NNS collectively_RB ._.
It_PRP is_VBZ well_RB accepted_VBN that_IN an_DT ensemble_NN usually_RB generalizes_VBZ better_JJR than_IN a_DT single_JJ classifier_NN =_JJ -_: =[_NN 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Dietterich_JJ stated_JJ -LRB-_-LRB- 8_CD -RRB-_-RRB- ``_`` A_DT necessary_JJ and_CC sufficient_JJ condition_NN for_IN an_DT ensemble_NN of_IN classifiers_NNS to_TO be_VB more_RBR accurate_JJ than_IN any_DT of_IN its_PRP$ individual_JJ members_NNS is_VBZ if_IN the_DT classifiers_NNS are_VBP accurate_JJ and_CC diverse_JJ ._. ''_''
Sin_NNP
ain_VB and_CC reduce_VB the_DT computational_JJ cost_NN ,_, where_WRB existing_VBG efforts_NNS roughly_RB fall_VBP into_IN the_DT following_JJ two_CD categories_NNS :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- regarding_VBG ensemble_NN pruning_NN as_IN a_DT mathematical_JJ programming_NN and_CC optimization_NN problem_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_JJ -_: ;_: and_CC -LRB-_-LRB- 2_LS -RRB-_-RRB- reordering_NN the_DT original_JJ ensemble_NN members_NNS based_VBN on_IN some_DT predefined_VBN criteria_NNS -LRB-_-LRB- 16_CD -RRB-_-RRB- ,_, such_JJ as_IN the_DT classifiers_NNS '_POS prediction_NN accuracies_NNS ,_, and_CC selecting_VBG a_DT subset_NN of_IN ensem-ble_JJ members_NNS from_IN the_DT sorted_VBN
Many_JJ approaches_NNS have_VBP been_VBN proposed_VBN to_TO create_VB accurate_JJ and_CC diverse_JJ ensembles_NNS ._.
Examples_NNS include_VBP bagging_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, boosting_VBG -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, random_JJ forests_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, the_DT random_JJ subspace_NN method_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- and_CC random_JJ decision_NN trees_NNS =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN most_JJS ensemble_NN methods_NNS ,_, the_DT diversity_NN and_CC accuracy_NN are_VBP acquired_VBN by_IN manipulating_VBG subsets_NNS of_IN data_NN points_NNS or_CC features_NNS ._.
One_CD problem_NN with_IN these_DT ensembling_VBG approaches_NNS is_VBZ that_IN they_PRP tend_VBP to_TO construct_VB unne_NN
eral_JJ Terms_NNS Algorithms_NNPS Keywords_NNPS ensemble_NN learning_NN ,_, ensemble_NN pruning_NN 1_CD ._.
INTRODUCTION_NN The_DT construction_NN of_IN classifier_NN ensembles_NNS is_VBZ an_DT active_JJ research_NN field_NN in_IN machine_NN learning_NN and_CC data_NN mining_NN communities_NNS =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Rather_RB Permission_NN to_TO make_VB digital_JJ or_CC hard_JJ copies_NNS of_IN all_DT or_CC part_NN of_IN this_DT work_NN for_IN personal_JJ or_CC classroom_NN use_NN is_VBZ granted_VBN without_IN fee_NN provided_VBN that_IN copies_NNS are_VBP not_RB made_VBN or_CC distributed_VBN for_IN profit_NN or_CC comme_NN
