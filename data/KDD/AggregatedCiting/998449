Combining_VBG email_NN models_NNS for_IN false_JJ positive_JJ reduction_NN
Machine_NN learning_NN and_CC data_NN mining_NN can_MD be_VB effectively_RB used_VBN to_TO model_VB ,_, classify_VB and_CC discover_VB interesting_JJ information_NN for_IN a_DT wide_JJ variety_NN of_IN data_NNS including_VBG email_NN ._.
The_DT Email_NNP Mining_NNP Toolkit_NNP ,_, EMT_NNP ,_, has_VBZ been_VBN designed_VBN to_TO provide_VB a_DT wide_JJ range_NN of_IN analyses_NNS for_IN arbitrary_JJ email_NN sources_NNS ._.
Depending_VBG upon_IN the_DT task_NN ,_, one_PRP can_MD usually_RB achieve_VB very_RB high_JJ accuracy_NN ,_, but_CC with_IN some_DT amount_NN of_IN false_JJ positive_JJ tradeoff_NN ._.
Generally_RB false_JJ positives_NNS are_VBP prohibitively_RB expensive_JJ in_IN the_DT real_JJ world_NN ._.
In_IN the_DT case_NN of_IN spam_NN detection_NN ,_, for_IN example_NN ,_, even_RB if_IN one_CD email_NN is_VBZ misclassified_VBN ,_, this_DT may_MD be_VB unacceptable_JJ if_IN it_PRP is_VBZ a_DT very_RB important_JJ email_NN ._.
Much_JJ work_NN has_VBZ been_VBN done_VBN to_TO improve_VB specific_JJ algorithms_NNS for_IN the_DT task_NN of_IN detecting_VBG unwanted_JJ messages_NNS ,_, but_CC less_JJR work_NN has_VBZ been_VBN report_NN on_IN leveraging_VBG multiple_JJ algorithms_NNS and_CC correlating_VBG models_NNS in_IN this_DT particular_JJ domain_NN of_IN email_NN analysis_NN ._.
EMT_NNP has_VBZ been_VBN updated_VBN with_IN new_JJ correlation_NN functions_NNS allowing_VBG the_DT analyst_NN to_TO integrate_VB a_DT number_NN of_IN EMT_NNP 's_POS user_NN behavior_NN models_NNS available_JJ in_IN the_DT core_NN technology_NN ._.
We_PRP present_VBP results_NNS of_IN combining_VBG classifier_NN outputs_NNS for_IN improving_VBG both_CC accuracy_NN and_CC reducing_VBG false_JJ positives_NNS for_IN the_DT problem_NN of_IN spam_NN detection_NN ._.
We_PRP apply_VBP these_DT methods_NNS to_TO a_DT very_RB large_JJ email_NN data_NNS set_VBP and_CC show_VBP results_NNS of_IN different_JJ combination_NN methods_NNS on_IN these_DT corpora_NNS ._.
We_PRP introduce_VBP a_DT new_JJ method_NN to_TO compare_VB multiple_JJ and_CC combined_JJ classifiers_NNS ,_, and_CC show_VB how_WRB it_PRP differs_VBZ from_IN past_JJ work_NN ._.
The_DT method_NN analyzes_VBZ the_DT relative_JJ gain_NN and_CC maximum_NN possible_JJ accuracy_NN that_WDT can_MD be_VB achieved_VBN for_IN certain_JJ combinations_NNS of_IN classifiers_NNS to_TO automatically_RB choose_VB the_DT best_JJS combination_NN ._.
cation_NN of_IN emails_NNS rather_RB than_IN words_NNS which_WDT appear_VBP infrequently_RB ._.
This_DT feature_NN of_IN EMT_NNP is_VBZ based_VBN upon_IN the_DT work_NN reported_VBN in_IN -LRB-_-LRB- 39_CD ,_, 40_CD -RRB-_-RRB- ._.
4.6_CD Limited_NNP N-Gram_NNP This_NNP classifier_NN is_VBZ influenced_VBN by_IN the_DT work_NN reported_VBN in_IN =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_SYM -_: on_IN finding_VBG matching_JJ files_NNS in_IN a_DT large_JJ file_NN system_NN ._.
We_PRP adapted_VBD that_IN work_NN to_TO limit_VB the_DT N-grams_NNS to_TO a_DT subset_NN of_IN the_DT possible_JJ N-grams_NNS for_IN dramatic_JJ reduction_NN in_IN computational_JJ expense_NN ._.
We_PRP calculate_VBP an_DT intege_NN
mples_NNS of_IN Spam_NNP emails_NNS ._.
For_IN example_NN ,_, Naïve_NNP Bayes_NNP models_NNS to_TO detect_VB Spam_NNP was_VBD first_RB introduced_VBN by_IN -LRB-_-LRB- 36_CD -RRB-_-RRB- with_IN a_DT Bernoulli_NNP word_NN vector_NN model_NN ._.
SVM-based_JJ spam_NN detection_NN models_NNS -LRB-_-LRB- 21_CD ,_, 24_CD -RRB-_-RRB- and_CC boosting_VBG spam_NN models_NNS =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: were_VBD compared_VBN in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC genetic_JJ algorithms_NNS versus_CC Naïve_JJ Bayes_NNS were_VBD introduced_VBN and_CC evaluated_VBN in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Text_NN distance_NN models_NNS -LRB-_-LRB- 39_CD ,_, 40_CD -RRB-_-RRB- and_CC pattern_NN extraction_NN versus_CC Naïve_JJ Bayes_NNS were_VBD compared_VBN in_IN -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
F_NN
h_NN a_DT Bernoulli_NNP word_NN vector_NN model_NN ._.
SVM-based_JJ spam_NN detection_NN models_NNS -LRB-_-LRB- 21_CD ,_, 24_CD -RRB-_-RRB- and_CC boosting_VBG spam_NN models_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- were_VBD compared_VBN in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC genetic_JJ algorithms_NNS versus_CC Naïve_JJ Bayes_NNS were_VBD introduced_VBN and_CC evaluated_VBN in_IN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Text_NN distance_NN models_NNS -LRB-_-LRB- 39_CD ,_, 40_CD -RRB-_-RRB- and_CC pattern_NN extraction_NN versus_CC Naïve_JJ Bayes_NNS were_VBD compared_VBN in_IN -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
Further_JJ work_NN has_VBZ been_VBN done_VBN using_VBG cost-sensitive_JJ based_JJ learning_NN -LRB-_-LRB- 1_CD ,_, 2_CD ,_, 17_CD -RRB-_-RRB- ,_, extensions_NNS to_TO Naïve_FW Bayes_FW ba_FW
studies_NNS have_VBP shown_VBN that_IN combining_VBG classifiers_NNS yields_NNS better_JJR results_NNS than_IN achievable_JJ with_IN an_DT individual_JJ classifier_NN -LRB-_-LRB- 9_CD ,_, 25_CD -RRB-_-RRB- ._.
2_CD Some_DT propose_VBP combining_VBG very_RB strong_JJ classifiers_NNS -LRB-_-LRB- i.e._FW with_IN low_JJ error_NN rates_NNS -RRB-_-RRB- =_JJ -_: =[_NN 32_CD ,_, 43_CD -RRB-_-RRB- -_: =_SYM -_: assuming_VBG that_IN weak_JJ classifiers_NNS -LRB-_-LRB- high_JJ false_JJ positives_NNS -RRB-_-RRB- will_MD not_RB combine_VB as_RB well_RB ,_, or_CC will_MD require_VB too_RB many_JJ rounds_NNS of_IN training_NN to_TO achieve_VB low_JJ error_NN rates_NNS ._.
Measuring_VBG the_DT ``_`` competence_NN ''_'' of_IN each_DT classifier_NN b_NN
-LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
Further_JJ work_NN has_VBZ been_VBN done_VBN using_VBG cost-sensitive_JJ based_JJ learning_NN -LRB-_-LRB- 1_CD ,_, 2_CD ,_, 17_CD -RRB-_-RRB- ,_, extensions_NNS to_TO Naïve_NNP Bayes_NNP bag-of-words_JJ modeling_NN -LRB-_-LRB- 30_CD ,_, 34_CD -RRB-_-RRB- and_CC a_DT comparative_JJ evaluations_NNS of_IN different_JJ Naïve_NNP Bayes_NNP models_NNS =_JJ -_: =[_NN 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
An_DT excellent_JJ overview_NN of_IN these_DT methods_NNS and_CC techniques_NNS is_VBZ provided_VBN by_IN -LRB-_-LRB- 13_CD ,_, 28_CD -RRB-_-RRB- ._.
Recently_RB even_RB DNA_NN pattern_NN analysis_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- have_VBP also_RB made_VBN it_PRP to_TO the_DT spam_NN classification_NN domain_NN ._.
To_TO be_VB sure_JJ ,_, machine_NN learni_NNS
odel_NN ._.
SVM-based_JJ spam_NN detection_NN models_NNS -LRB-_-LRB- 21_CD ,_, 24_CD -RRB-_-RRB- and_CC boosting_VBG spam_NN models_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- were_VBD compared_VBN in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC genetic_JJ algorithms_NNS versus_CC Naïve_JJ Bayes_NNS were_VBD introduced_VBN and_CC evaluated_VBN in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Text_NN distance_NN models_NNS =_JJ -_: =[_NN 39_CD ,_, 40_CD -RRB-_-RRB- -_: =_JJ -_: and_CC pattern_NN extraction_NN versus_CC Naïve_JJ Bayes_NNS were_VBD compared_VBN in_IN -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
Further_JJ work_NN has_VBZ been_VBN done_VBN using_VBG cost-sensitive_JJ based_JJ learning_NN -LRB-_-LRB- 1_CD ,_, 2_CD ,_, 17_CD -RRB-_-RRB- ,_, extensions_NNS to_TO Naïve_NNP Bayes_NNP bag-of-words_JJ modeling_NN -LRB-_-LRB- 30_CD ,_, 34_CD -RRB-_-RRB- an_DT
ocument_NN classification_NN ,_, handwriting_NN analysis_NN and_CC other_JJ fields_NNS ._.
Various_JJ approaches_NNS combine_VBP models_NNS using_VBG different_JJ feature_NN sets_NNS ,_, other_JJ works_NNS correlate_VBP model_NN outputs_NNS ._.
An_DT overview_NN of_IN the_DT topic_NN appears_VBZ in_IN =_JJ -_: =[_NN 6_CD ,_, 22_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Numerous_JJ studies_NNS have_VBP shown_VBN that_IN combining_VBG classifiers_NNS yields_NNS better_JJR results_NNS than_IN achievable_JJ with_IN an_DT individual_JJ classifier_NN -LRB-_-LRB- 9_CD ,_, 25_CD -RRB-_-RRB- ._.
2_CD Some_DT propose_VBP combining_VBG very_RB strong_JJ classifiers_NNS -LRB-_-LRB- i.e._FW with_IN low_JJ er_NN
ocument_NN classification_NN ,_, handwriting_NN analysis_NN and_CC other_JJ fields_NNS ._.
Various_JJ approaches_NNS combine_VBP models_NNS using_VBG different_JJ feature_NN sets_NNS ,_, other_JJ works_NNS correlate_VBP model_NN outputs_NNS ._.
An_DT overview_NN of_IN the_DT topic_NN appears_VBZ in_IN =_JJ -_: =[_NN 6_CD ,_, 22_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Numerous_JJ studies_NNS have_VBP shown_VBN that_IN combining_VBG classifiers_NNS yields_NNS better_JJR results_NNS than_IN achievable_JJ with_IN an_DT individual_JJ classifier_NN -LRB-_-LRB- 9_CD ,_, 25_CD -RRB-_-RRB- ._.
2_CD Some_DT propose_VBP combining_VBG very_RB strong_JJ classifiers_NNS -LRB-_-LRB- i.e._FW with_IN low_JJ er_NN
f_LS the_DT most_RBS studied_VBN machine_NN learning_NN algorithms_NNS for_IN the_DT task_NN of_IN spam_NN detection_NN has_VBZ been_VBN applying_VBG Bayesian_JJ classification_NN to_TO modeling_NN the_DT content_NN of_IN email_NN ._.
Bayes_NNP classifiers_NNS are_VBP based_VBN on_IN early_JJ works_NNS by_IN =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: in_IN the_DT field_NN of_IN pattern_NN recognition_NN ._.
Given_VBN an_DT unlabeled_JJ example_NN ,_, the_DT classifier_NN will_MD calculate_VB the_DT most_RBS likely_JJ classification_NN with_IN some_DT degree_NN of_IN probability_NN ._.
Bayes_FW theorem_FW is_VBZ a_DT way_NN of_IN calculating_VBG th_DT
message_NN ,_, number_NN of_IN recipients_NNS ,_, number_NN of_IN attachments_NNS ,_, and_CC the_DT MIME-type_NN of_IN the_DT email_NN are_VBP used_VBN ._.
For_IN continuous_JJ value_NN features_NNS we_PRP use_VBP a_DT multiple_JJ Gaussian_JJ estimate_NN to_TO estimate_VB a_DT probability_NN value_NN as_IN in_IN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
More_RBR detailed_JJ information_NN about_IN our_PRP$ classifier_NN can_MD be_VB found_VBN in_IN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
4.2_CD N-Gram_NN Classifier_NN When_WRB analyzing_NN text_NN ,_, one_CD alternative_NN to_TO using_VBG words_NNS as_IN tokens_NNS is_VBZ to_TO take_VB subsequences_NNS of_IN the_DT data_NNS and_CC use_VB t_NN
ks_NNS correlate_VBP model_NN outputs_NNS ._.
An_DT overview_NN of_IN the_DT topic_NN appears_VBZ in_IN -LRB-_-LRB- 6_CD ,_, 22_CD ,_, 23_CD -RRB-_-RRB- ._.
Numerous_JJ studies_NNS have_VBP shown_VBN that_IN combining_VBG classifiers_NNS yields_NNS better_JJR results_NNS than_IN achievable_JJ with_IN an_DT individual_JJ classifier_NN =_JJ -_: =[_NN 9_CD ,_, 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
2_CD Some_DT propose_VBP combining_VBG very_RB strong_JJ classifiers_NNS -LRB-_-LRB- i.e._FW with_IN low_JJ error_NN rates_NNS -RRB-_-RRB- -LRB-_-LRB- 32_CD ,_, 43_CD -RRB-_-RRB- assuming_VBG that_IN weak_JJ classifiers_NNS -LRB-_-LRB- high_JJ false_JJ positives_NNS -RRB-_-RRB- will_MD not_RB combine_VB as_RB well_RB ,_, or_CC will_MD require_VB too_RB many_JJ rounds_NNS
,_, 31_CD -RRB-_-RRB- ._.
A_DT great_JJ deal_NN of_IN the_DT published_VBN work_NN follows_VBZ the_DT same_JJ paradigm_NN of_IN training_NN a_DT Spam_NNP classifier_NN given_VBN examples_NNS of_IN Spam_NNP emails_NNS ._.
For_IN example_NN ,_, Naïve_NNP Bayes_NNP models_NNS to_TO detect_VB Spam_NNP was_VBD first_RB introduced_VBN by_IN =_JJ -_: =[_NN 36_CD -RRB-_-RRB- -_: =_SYM -_: with_IN a_DT Bernoulli_NNP word_NN vector_NN model_NN ._.
SVM-based_JJ spam_NN detection_NN models_NNS -LRB-_-LRB- 21_CD ,_, 24_CD -RRB-_-RRB- and_CC boosting_VBG spam_NN models_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- were_VBD compared_VBN in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC genetic_JJ algorithms_NNS versus_CC Naïve_JJ Bayes_NNS were_VBD introduced_VBN and_CC evaluated_VBN
wed_VBN as_IN a_DT document_NN vector_NN ._.
Given_VBN a_DT set_NN of_IN training_NN emails_NNS ,_, we_PRP use_VBP the_DT arithmetic_NN average_NN of_IN the_DT document_NN vectors_NNS as_IN the_DT centroid_NN for_IN that_DT set_NN ._.
For_IN an_DT unknown_JJ test_NN email_NN ,_, we_PRP compute_VBP the_DT cosine_NN distance_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: against_IN the_DT centroid_NN created_VBN for_IN the_DT training_NN set_NN ._.
If_IN the_DT cosine_NN distance_NN is_VBZ 1_CD ,_, then_RB the_DT two_CD documents_NNS are_VBP deemed_VBN identical_JJ ._.
The_DT smaller_JJR the_DT value_NN of_IN the_DT cosine_NN distance_NN ,_, the_DT more_RBR different_JJ the_DT two_CD d_NN
a_DT ,_, as_IN it_PRP computes_VBZ a_DT final_JJ combined_JJ model_NN output_NN from_IN the_DT raw_JJ scores_NNS produced_VBN by_IN each_DT component_NN classifier_NN ._.
5.2_CD Learned_JJ Weights_NNS -_: Weighted_NNP Majority_NNP The_DT weighted_JJ majority_NN function_NN is_VBZ an_DT adaptation_NN from_IN =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Each_DT of_IN the_DT individual_JJ classifiers_NNS is_VBZ initially_RB assigned_VBN an_DT equal_JJ weight_NN vote_NN ._.
During_IN training_NN ,_, a_DT threshold_NN is_VBZ chosen_VBN for_IN binary_JJ classification_NN -LRB-_-LRB- correct_JJ or_CC not_RB -RRB-_-RRB- and_CC a_DT tally_NN of_IN scores_NNS is_VBZ computed_JJ wit_NN
studies_NNS have_VBP shown_VBN that_IN combining_VBG classifiers_NNS yields_NNS better_JJR results_NNS than_IN achievable_JJ with_IN an_DT individual_JJ classifier_NN -LRB-_-LRB- 9_CD ,_, 25_CD -RRB-_-RRB- ._.
2_CD Some_DT propose_VBP combining_VBG very_RB strong_JJ classifiers_NNS -LRB-_-LRB- i.e._FW with_IN low_JJ error_NN rates_NNS -RRB-_-RRB- =_JJ -_: =[_NN 32_CD ,_, 43_CD -RRB-_-RRB- -_: =_SYM -_: assuming_VBG that_IN weak_JJ classifiers_NNS -LRB-_-LRB- high_JJ false_JJ positives_NNS -RRB-_-RRB- will_MD not_RB combine_VB as_RB well_RB ,_, or_CC will_MD require_VB too_RB many_JJ rounds_NNS of_IN training_NN to_TO achieve_VB low_JJ error_NN rates_NNS ._.
Measuring_VBG the_DT ``_`` competence_NN ''_'' of_IN each_DT classifier_NN b_NN
rmula_NN and_CC assign_VB a_DT confidence_NN score_NN of_IN the_DT predicted_VBN class_NN ._.
P_NN -LRB-_-LRB- Spam_NN -RRB-_-RRB- ∏_NN P_NN -LRB-_-LRB- wordi_FW |_FW Spam_NN -RRB-_-RRB- class_NN ,_, score_NN =_JJ max_NN P_NN -LRB-_-LRB- NotSpam_NN -RRB-_-RRB- ∏_NN P_NN -LRB-_-LRB- word_NN |_FW NotSpam_FW -RRB-_-RRB- 4.4_CD Content-based_JJ Naïve_NNP Bayes_NNP -LRB-_-LRB- PGRAM_NNP -RRB-_-RRB- Recent_JJ work_NN by_IN Graham_NNP =_SYM -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: on_IN the_DT task_NN of_IN spam_NN detection_NN has_VBZ floated_VBN the_DT idea_NN of_IN a_DT partial_JJ Naive_JJ Bayes_NNP approach_NN ,_, biased_VBN towards_IN low_JJ false_JJ positive_JJ rates_NNS ._.
It_PRP also_RB uses_VBZ word_NN tokens_NNS ,_, but_CC filters_VBZ out_RP predefined_JJ common_JJ tokens_NNS ._.
We_PRP i_LS
ocument_NN classification_NN ,_, handwriting_NN analysis_NN and_CC other_JJ fields_NNS ._.
Various_JJ approaches_NNS combine_VBP models_NNS using_VBG different_JJ feature_NN sets_NNS ,_, other_JJ works_NNS correlate_VBP model_NN outputs_NNS ._.
An_DT overview_NN of_IN the_DT topic_NN appears_VBZ in_IN =_JJ -_: =[_NN 6_CD ,_, 22_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Numerous_JJ studies_NNS have_VBP shown_VBN that_IN combining_VBG classifiers_NNS yields_NNS better_JJR results_NNS than_IN achievable_JJ with_IN an_DT individual_JJ classifier_NN -LRB-_-LRB- 9_CD ,_, 25_CD -RRB-_-RRB- ._.
2_CD Some_DT propose_VBP combining_VBG very_RB strong_JJ classifiers_NNS -LRB-_-LRB- i.e._FW with_IN low_JJ er_NN
17_CD -RRB-_-RRB- ,_, extensions_NNS to_TO Naïve_NNP Bayes_NNP bag-of-words_JJ modeling_NN -LRB-_-LRB- 30_CD ,_, 34_CD -RRB-_-RRB- and_CC a_DT comparative_JJ evaluations_NNS of_IN different_JJ Naïve_NNP Bayes_NNP models_NNS -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
An_DT excellent_JJ overview_NN of_IN these_DT methods_NNS and_CC techniques_NNS is_VBZ provided_VBN by_IN =_JJ -_: =[_NN 13_CD ,_, 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Recently_RB even_RB DNA_NN pattern_NN analysis_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- have_VBP also_RB made_VBN it_PRP to_TO the_DT spam_NN classification_NN domain_NN ._.
To_TO be_VB sure_JJ ,_, machine_NN learning_NN applied_VBN to_TO Spam_NNP detection_NN has_VBZ received_VBN intense_JJ study_NN over_IN the_DT last_JJ few_JJ years_NNS
y_NN cluster_NN in_IN any_DT class_NN ._.
This_DT is_VBZ similar_JJ to_TO a_DT K-nearest_JJ neighbor_NN algorithm_NN ._.
This_DT distance_NN is_VBZ then_RB converted_VBN into_IN a_DT confidence_NN score_NN and_CC outputted_VBD as_IN a_DT predicted_VBN score_NN ._.
For_IN more_JJR details_NNS please_VBP refer_VB to_TO =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT end_NN result_NN is_VBZ a_DT measure_NN of_IN how_WRB unusual_JJ or_CC familiar_JJ a_DT URL_NN may_MD be_VB in_IN an_DT email_JJ message_NN given_VBN the_DT user_NN 's_POS prior_JJ history_NN of_IN emails_NNS with_IN embedded_JJ URL_NN 's_POS ._.
5_CD ._.
Combining_VBG Classifiers_NNS The_DT goal_NN of_IN Model_NNP combi_NNS
fidence_NN factors_NNS is_VBZ able_JJ to_TO achieve_VB better_JJR results_NNS than_IN a_DT combination_NN of_IN binary_JJ classifiers_NNS ._.
3_LS ._.
An_DT Overview_NNP of_IN EMT_NNP The_NNP Email_NNP Mining_NNP Toolkit_NNP developed_VBD at_IN Columbia_NNP University_NNP has_VBZ been_VBN reported_VBN elsewhere_RB =_JJ -_: =[_NN 15_CD ,_, 16_CD ,_, 41_CD ,_, 42_CD -RRB-_-RRB- -_: =_SYM -_: ._.
EMT_NN contains_VBZ behavior_NN modeling_NN features_NNS revealing_VBG much_JJ information_NN about_IN individual_JJ users_NNS as_RB well_RB as_IN the_DT behavior_NN of_IN groups_NNS of_IN users_NNS in_IN an_DT organization_NN ,_, and_CC the_DT behavior_NN of_IN file_NN attachments_NNS in_IN an_DT em_NN
fidence_NN factors_NNS is_VBZ able_JJ to_TO achieve_VB better_JJR results_NNS than_IN a_DT combination_NN of_IN binary_JJ classifiers_NNS ._.
3_LS ._.
An_DT Overview_NNP of_IN EMT_NNP The_NNP Email_NNP Mining_NNP Toolkit_NNP developed_VBD at_IN Columbia_NNP University_NNP has_VBZ been_VBN reported_VBN elsewhere_RB =_JJ -_: =[_NN 15_CD ,_, 16_CD ,_, 41_CD ,_, 42_CD -RRB-_-RRB- -_: =_SYM -_: ._.
EMT_NN contains_VBZ behavior_NN modeling_NN features_NNS revealing_VBG much_JJ information_NN about_IN individual_JJ users_NNS as_RB well_RB as_IN the_DT behavior_NN of_IN groups_NNS of_IN users_NNS in_IN an_DT organization_NN ,_, and_CC the_DT behavior_NN of_IN file_NN attachments_NNS in_IN an_DT em_NN
ature_NN to_TO improve_VB the_DT accuracy_NN of_IN Spam_NNP filters_NNS ._.
The_DT prior_JJ generation_NN of_IN rule-based_JJ Spam_NNP filters_NNS have_VBP failed_VBN for_IN many_JJ reasons_NNS not_RB least_JJS of_IN which_WDT is_VBZ the_DT error_NN prone_JJ methods_NNS of_IN string_NN matching_NN algorithms_VBZ =_JJ -_: =[_NN 7_CD ,_, 18_CD ,_, 31_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT great_JJ deal_NN of_IN the_DT published_VBN work_NN follows_VBZ the_DT same_JJ paradigm_NN of_IN training_NN a_DT Spam_NNP classifier_NN given_VBN examples_NNS of_IN Spam_NNP emails_NNS ._.
For_IN example_NN ,_, Naïve_NNP Bayes_NNP models_NNS to_TO detect_VB Spam_NNP was_VBD first_RB introduced_VBN by_IN -LRB-_-LRB- 36_CD -RRB-_-RRB-
ls_NNS -LRB-_-LRB- 39_CD ,_, 40_CD -RRB-_-RRB- and_CC pattern_NN extraction_NN versus_CC Naïve_JJ Bayes_NNS were_VBD compared_VBN in_IN -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
Further_JJ work_NN has_VBZ been_VBN done_VBN using_VBG cost-sensitive_JJ based_JJ learning_NN -LRB-_-LRB- 1_CD ,_, 2_CD ,_, 17_CD -RRB-_-RRB- ,_, extensions_NNS to_TO Naïve_NNP Bayes_NNP bag-of-words_NNS modeling_NN =_JJ -_: =[_NN 30_CD ,_, 34_CD -RRB-_-RRB- -_: =_JJ -_: and_CC a_DT comparative_JJ evaluations_NNS of_IN different_JJ Naïve_NNP Bayes_NNP models_NNS -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
An_DT excellent_JJ overview_NN of_IN these_DT methods_NNS and_CC techniques_NNS is_VBZ provided_VBN by_IN -LRB-_-LRB- 13_CD ,_, 28_CD -RRB-_-RRB- ._.
Recently_RB even_RB DNA_NN pattern_NN analysis_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- have_VBP also_RB ma_FW
17_CD -RRB-_-RRB- ,_, extensions_NNS to_TO Naïve_NNP Bayes_NNP bag-of-words_JJ modeling_NN -LRB-_-LRB- 30_CD ,_, 34_CD -RRB-_-RRB- and_CC a_DT comparative_JJ evaluations_NNS of_IN different_JJ Naïve_NNP Bayes_NNP models_NNS -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
An_DT excellent_JJ overview_NN of_IN these_DT methods_NNS and_CC techniques_NNS is_VBZ provided_VBN by_IN =_JJ -_: =[_NN 13_CD ,_, 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Recently_RB even_RB DNA_NN pattern_NN analysis_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- have_VBP also_RB made_VBN it_PRP to_TO the_DT spam_NN classification_NN domain_NN ._.
To_TO be_VB sure_JJ ,_, machine_NN learning_NN applied_VBN to_TO Spam_NNP detection_NN has_VBZ received_VBN intense_JJ study_NN over_IN the_DT last_JJ few_JJ years_NNS
tives_NNS -RRB-_-RRB- will_MD not_RB combine_VB as_RB well_RB ,_, or_CC will_MD require_VB too_RB many_JJ rounds_NNS of_IN training_NN to_TO achieve_VB low_JJ error_NN rates_NNS ._.
Measuring_VBG the_DT ``_`` competence_NN ''_'' of_IN each_DT classifier_NN before_IN combining_VBG them_PRP is_VBZ a_DT common_JJ approach_NN as_IN in_IN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN -LRB-_-LRB- 37_CD -RRB-_-RRB- a_DT combination_NN of_IN spam_NN classifiers_NNS is_VBZ proposed_VBN ._.
That_DT work_NN was_VBD limited_VBN to_TO training_VBG a_DT committee_NN of_IN classifiers_NNS on_IN a_DT subset_NN of_IN labeled_JJ data_NNS ,_, and_CC then_RB training_VBG a_DT `_`` president_NN '_'' classifier_NN using_VBG the_DT
modeling_NN -LRB-_-LRB- 30_CD ,_, 34_CD -RRB-_-RRB- and_CC a_DT comparative_JJ evaluations_NNS of_IN different_JJ Naïve_NNP Bayes_NNP models_NNS -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
An_DT excellent_JJ overview_NN of_IN these_DT methods_NNS and_CC techniques_NNS is_VBZ provided_VBN by_IN -LRB-_-LRB- 13_CD ,_, 28_CD -RRB-_-RRB- ._.
Recently_RB even_RB DNA_NN pattern_NN analysis_NN =_JJ -_: =[_NN 35_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP also_RB made_VBN it_PRP to_TO the_DT spam_NN classification_NN domain_NN ._.
To_TO be_VB sure_JJ ,_, machine_NN learning_NN applied_VBN to_TO Spam_NNP detection_NN has_VBZ received_VBN intense_JJ study_NN over_IN the_DT last_JJ few_JJ years_NNS ._.
In_IN this_DT work_NN ,_, we_PRP evaluate_VBP methods_NNS that_IN
odel_NN ._.
SVM-based_JJ spam_NN detection_NN models_NNS -LRB-_-LRB- 21_CD ,_, 24_CD -RRB-_-RRB- and_CC boosting_VBG spam_NN models_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- were_VBD compared_VBN in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC genetic_JJ algorithms_NNS versus_CC Naïve_JJ Bayes_NNS were_VBD introduced_VBN and_CC evaluated_VBN in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Text_NN distance_NN models_NNS =_JJ -_: =[_NN 39_CD ,_, 40_CD -RRB-_-RRB- -_: =_JJ -_: and_CC pattern_NN extraction_NN versus_CC Naïve_JJ Bayes_NNS were_VBD compared_VBN in_IN -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
Further_JJ work_NN has_VBZ been_VBN done_VBN using_VBG cost-sensitive_JJ based_JJ learning_NN -LRB-_-LRB- 1_CD ,_, 2_CD ,_, 17_CD -RRB-_-RRB- ,_, extensions_NNS to_TO Naïve_NNP Bayes_NNP bag-of-words_JJ modeling_NN -LRB-_-LRB- 30_CD ,_, 34_CD -RRB-_-RRB- an_DT
ks_NNS correlate_VBP model_NN outputs_NNS ._.
An_DT overview_NN of_IN the_DT topic_NN appears_VBZ in_IN -LRB-_-LRB- 6_CD ,_, 22_CD ,_, 23_CD -RRB-_-RRB- ._.
Numerous_JJ studies_NNS have_VBP shown_VBN that_IN combining_VBG classifiers_NNS yields_NNS better_JJR results_NNS than_IN achievable_JJ with_IN an_DT individual_JJ classifier_NN =_JJ -_: =[_NN 9_CD ,_, 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
2_CD Some_DT propose_VBP combining_VBG very_RB strong_JJ classifiers_NNS -LRB-_-LRB- i.e._FW with_IN low_JJ error_NN rates_NNS -RRB-_-RRB- -LRB-_-LRB- 32_CD ,_, 43_CD -RRB-_-RRB- assuming_VBG that_IN weak_JJ classifiers_NNS -LRB-_-LRB- high_JJ false_JJ positives_NNS -RRB-_-RRB- will_MD not_RB combine_VB as_RB well_RB ,_, or_CC will_MD require_VB too_RB many_JJ rounds_NNS
ature_NN to_TO improve_VB the_DT accuracy_NN of_IN Spam_NNP filters_NNS ._.
The_DT prior_JJ generation_NN of_IN rule-based_JJ Spam_NNP filters_NNS have_VBP failed_VBN for_IN many_JJ reasons_NNS not_RB least_JJS of_IN which_WDT is_VBZ the_DT error_NN prone_JJ methods_NNS of_IN string_NN matching_NN algorithms_VBZ =_JJ -_: =[_NN 7_CD ,_, 18_CD ,_, 31_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT great_JJ deal_NN of_IN the_DT published_VBN work_NN follows_VBZ the_DT same_JJ paradigm_NN of_IN training_NN a_DT Spam_NNP classifier_NN given_VBN examples_NNS of_IN Spam_NNP emails_NNS ._.
For_IN example_NN ,_, Naïve_NNP Bayes_NNP models_NNS to_TO detect_VB Spam_NNP was_VBD first_RB introduced_VBN by_IN -LRB-_-LRB- 36_CD -RRB-_-RRB-
es_NNS were_VBD introduced_VBN and_CC evaluated_VBN in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Text_NN distance_NN models_NNS -LRB-_-LRB- 39_CD ,_, 40_CD -RRB-_-RRB- and_CC pattern_NN extraction_NN versus_CC Naïve_JJ Bayes_NNS were_VBD compared_VBN in_IN -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
Further_JJ work_NN has_VBZ been_VBN done_VBN using_VBG cost-sensitive_JJ based_JJ learning_NN =_JJ -_: =[_NN 1_CD ,_, 2_CD ,_, 17_CD -RRB-_-RRB- -_: =_JJ -_: ,_, extensions_NNS to_TO Naïve_NNP Bayes_NNP bag-of-words_JJ modeling_NN -LRB-_-LRB- 30_CD ,_, 34_CD -RRB-_-RRB- and_CC a_DT comparative_JJ evaluations_NNS of_IN different_JJ Naïve_NNP Bayes_NNP models_NNS -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
An_DT excellent_JJ overview_NN of_IN these_DT methods_NNS and_CC techniques_NNS is_VBZ provided_VBN by_IN -LRB-_-LRB- 13_CD ,_,
ature_NN to_TO improve_VB the_DT accuracy_NN of_IN Spam_NNP filters_NNS ._.
The_DT prior_JJ generation_NN of_IN rule-based_JJ Spam_NNP filters_NNS have_VBP failed_VBN for_IN many_JJ reasons_NNS not_RB least_JJS of_IN which_WDT is_VBZ the_DT error_NN prone_JJ methods_NNS of_IN string_NN matching_NN algorithms_VBZ =_JJ -_: =[_NN 7_CD ,_, 18_CD ,_, 31_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT great_JJ deal_NN of_IN the_DT published_VBN work_NN follows_VBZ the_DT same_JJ paradigm_NN of_IN training_NN a_DT Spam_NNP classifier_NN given_VBN examples_NNS of_IN Spam_NNP emails_NNS ._.
For_IN example_NN ,_, Naïve_NNP Bayes_NNP models_NNS to_TO detect_VB Spam_NNP was_VBD first_RB introduced_VBN by_IN -LRB-_-LRB- 36_CD -RRB-_-RRB-
For_IN example_NN ,_, Naïve_NNP Bayes_NNP models_NNS to_TO detect_VB Spam_NNP was_VBD first_RB introduced_VBN by_IN -LRB-_-LRB- 36_CD -RRB-_-RRB- with_IN a_DT Bernoulli_NNP word_NN vector_NN model_NN ._.
SVM-based_JJ spam_NN detection_NN models_NNS -LRB-_-LRB- 21_CD ,_, 24_CD -RRB-_-RRB- and_CC boosting_VBG spam_NN models_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- were_VBD compared_VBN in_IN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_JJ -_: and_CC genetic_JJ algorithms_NNS versus_CC Naïve_JJ Bayes_NNS were_VBD introduced_VBN and_CC evaluated_VBN in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Text_NN distance_NN models_NNS -LRB-_-LRB- 39_CD ,_, 40_CD -RRB-_-RRB- and_CC pattern_NN extraction_NN versus_CC Naïve_JJ Bayes_NNS were_VBD compared_VBN in_IN -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
Further_JJ work_NN has_VBZ been_VBN d_NN
aining_VBG a_DT Spam_NNP classifier_NN given_VBN examples_NNS of_IN Spam_NNP emails_NNS ._.
For_IN example_NN ,_, Naïve_NNP Bayes_NNP models_NNS to_TO detect_VB Spam_NNP was_VBD first_RB introduced_VBN by_IN -LRB-_-LRB- 36_CD -RRB-_-RRB- with_IN a_DT Bernoulli_NNP word_NN vector_NN model_NN ._.
SVM-based_JJ spam_NN detection_NN models_NNS =_JJ -_: =[_NN 21_CD ,_, 24_CD -RRB-_-RRB- -_: =_JJ -_: and_CC boosting_VBG spam_NN models_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- were_VBD compared_VBN in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC genetic_JJ algorithms_NNS versus_CC Naïve_JJ Bayes_NNS were_VBD introduced_VBN and_CC evaluated_VBN in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Text_NN distance_NN models_NNS -LRB-_-LRB- 39_CD ,_, 40_CD -RRB-_-RRB- and_CC pattern_NN extraction_NN versus_CC Naïve_JJ B_NN
aining_VBG a_DT Spam_NNP classifier_NN given_VBN examples_NNS of_IN Spam_NNP emails_NNS ._.
For_IN example_NN ,_, Naïve_NNP Bayes_NNP models_NNS to_TO detect_VB Spam_NNP was_VBD first_RB introduced_VBN by_IN -LRB-_-LRB- 36_CD -RRB-_-RRB- with_IN a_DT Bernoulli_NNP word_NN vector_NN model_NN ._.
SVM-based_JJ spam_NN detection_NN models_NNS =_JJ -_: =[_NN 21_CD ,_, 24_CD -RRB-_-RRB- -_: =_JJ -_: and_CC boosting_VBG spam_NN models_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- were_VBD compared_VBN in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC genetic_JJ algorithms_NNS versus_CC Naïve_JJ Bayes_NNS were_VBD introduced_VBN and_CC evaluated_VBN in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Text_NN distance_NN models_NNS -LRB-_-LRB- 39_CD ,_, 40_CD -RRB-_-RRB- and_CC pattern_NN extraction_NN versus_CC Naïve_JJ B_NN
fidence_NN factors_NNS is_VBZ able_JJ to_TO achieve_VB better_JJR results_NNS than_IN a_DT combination_NN of_IN binary_JJ classifiers_NNS ._.
3_LS ._.
An_DT Overview_NNP of_IN EMT_NNP The_NNP Email_NNP Mining_NNP Toolkit_NNP developed_VBD at_IN Columbia_NNP University_NNP has_VBZ been_VBN reported_VBN elsewhere_RB =_JJ -_: =[_NN 15_CD ,_, 16_CD ,_, 41_CD ,_, 42_CD -RRB-_-RRB- -_: =_SYM -_: ._.
EMT_NN contains_VBZ behavior_NN modeling_NN features_NNS revealing_VBG much_JJ information_NN about_IN individual_JJ users_NNS as_RB well_RB as_IN the_DT behavior_NN of_IN groups_NNS of_IN users_NNS in_IN an_DT organization_NN ,_, and_CC the_DT behavior_NN of_IN file_NN attachments_NNS in_IN an_DT em_NN
fidence_NN factors_NNS is_VBZ able_JJ to_TO achieve_VB better_JJR results_NNS than_IN a_DT combination_NN of_IN binary_JJ classifiers_NNS ._.
3_LS ._.
An_DT Overview_NNP of_IN EMT_NNP The_NNP Email_NNP Mining_NNP Toolkit_NNP developed_VBD at_IN Columbia_NNP University_NNP has_VBZ been_VBN reported_VBN elsewhere_RB =_JJ -_: =[_NN 15_CD ,_, 16_CD ,_, 41_CD ,_, 42_CD -RRB-_-RRB- -_: =_SYM -_: ._.
EMT_NN contains_VBZ behavior_NN modeling_NN features_NNS revealing_VBG much_JJ information_NN about_IN individual_JJ users_NNS as_RB well_RB as_IN the_DT behavior_NN of_IN groups_NNS of_IN users_NNS in_IN an_DT organization_NN ,_, and_CC the_DT behavior_NN of_IN file_NN attachments_NNS in_IN an_DT em_NN
ill_RB not_RB combine_VB as_RB well_RB ,_, or_CC will_MD require_VB too_RB many_JJ rounds_NNS of_IN training_NN to_TO achieve_VB low_JJ error_NN rates_NNS ._.
Measuring_VBG the_DT ``_`` competence_NN ''_'' of_IN each_DT classifier_NN before_IN combining_VBG them_PRP is_VBZ a_DT common_JJ approach_NN as_IN in_IN -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
In_IN =_JJ -_: =[_NN 37_CD -RRB-_-RRB- -_: =_SYM -_: a_DT combination_NN of_IN spam_NN classifiers_NNS is_VBZ proposed_VBN ._.
That_DT work_NN was_VBD limited_VBN to_TO training_VBG a_DT committee_NN of_IN classifiers_NNS on_IN a_DT subset_NN of_IN labeled_JJ data_NNS ,_, and_CC then_RB training_VBG a_DT `_`` president_NN '_'' classifier_NN using_VBG the_DT labeled_JJ d_NN
es_NNS were_VBD introduced_VBN and_CC evaluated_VBN in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Text_NN distance_NN models_NNS -LRB-_-LRB- 39_CD ,_, 40_CD -RRB-_-RRB- and_CC pattern_NN extraction_NN versus_CC Naïve_JJ Bayes_NNS were_VBD compared_VBN in_IN -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
Further_JJ work_NN has_VBZ been_VBN done_VBN using_VBG cost-sensitive_JJ based_JJ learning_NN =_JJ -_: =[_NN 1_CD ,_, 2_CD ,_, 17_CD -RRB-_-RRB- -_: =_JJ -_: ,_, extensions_NNS to_TO Naïve_NNP Bayes_NNP bag-of-words_JJ modeling_NN -LRB-_-LRB- 30_CD ,_, 34_CD -RRB-_-RRB- and_CC a_DT comparative_JJ evaluations_NNS of_IN different_JJ Naïve_NNP Bayes_NNP models_NNS -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
An_DT excellent_JJ overview_NN of_IN these_DT methods_NNS and_CC techniques_NNS is_VBZ provided_VBN by_IN -LRB-_-LRB- 13_CD ,_,
els_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- were_VBD compared_VBN in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC genetic_JJ algorithms_NNS versus_CC Naïve_JJ Bayes_NNS were_VBD introduced_VBN and_CC evaluated_VBN in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Text_NN distance_NN models_NNS -LRB-_-LRB- 39_CD ,_, 40_CD -RRB-_-RRB- and_CC pattern_NN extraction_NN versus_CC Naïve_JJ Bayes_NNS were_VBD compared_VBN in_IN =_JJ -_: =[_NN 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Further_JJ work_NN has_VBZ been_VBN done_VBN using_VBG cost-sensitive_JJ based_JJ learning_NN -LRB-_-LRB- 1_CD ,_, 2_CD ,_, 17_CD -RRB-_-RRB- ,_, extensions_NNS to_TO Naïve_NNP Bayes_NNP bag-of-words_JJ modeling_NN -LRB-_-LRB- 30_CD ,_, 34_CD -RRB-_-RRB- and_CC a_DT comparative_JJ evaluations_NNS of_IN different_JJ Naïve_NNP Bayes_NNP models_NNS -LRB-_-LRB- 38_CD -RRB-_-RRB-
ls_NNS -LRB-_-LRB- 39_CD ,_, 40_CD -RRB-_-RRB- and_CC pattern_NN extraction_NN versus_CC Naïve_JJ Bayes_NNS were_VBD compared_VBN in_IN -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
Further_JJ work_NN has_VBZ been_VBN done_VBN using_VBG cost-sensitive_JJ based_JJ learning_NN -LRB-_-LRB- 1_CD ,_, 2_CD ,_, 17_CD -RRB-_-RRB- ,_, extensions_NNS to_TO Naïve_NNP Bayes_NNP bag-of-words_NNS modeling_NN =_JJ -_: =[_NN 30_CD ,_, 34_CD -RRB-_-RRB- -_: =_JJ -_: and_CC a_DT comparative_JJ evaluations_NNS of_IN different_JJ Naïve_NNP Bayes_NNP models_NNS -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
An_DT excellent_JJ overview_NN of_IN these_DT methods_NNS and_CC techniques_NNS is_VBZ provided_VBN by_IN -LRB-_-LRB- 13_CD ,_, 28_CD -RRB-_-RRB- ._.
Recently_RB even_RB DNA_NN pattern_NN analysis_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- have_VBP also_RB ma_FW
nalysis_NN on_IN each_DT attachment_NN in_IN the_DT database_NN to_TO calculate_VB a_DT number_NN of_IN metrics_NNS ._.
These_DT include_VBP birth_NN rate_NN ,_, lifespan_NN ,_, incident_NN rate_NN ,_, prevalence_NN ,_, threat_NN ,_, spread_NN ,_, and_CC death_NN rate_NN ._.
They_PRP are_VBP explained_VBN fully_RB in_IN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_JJ -_: and_CC are_VBP used_VBN to_TO detect_VB unusual_JJ attachment_NN communication_NN indicating_VBG security_NN breaches_NNS or_CC virus_NN propagations_NNS ._.
Similar_JJ Users_NNS -_: User_NN accounts_NNS that_WDT may_MD behave_VB similarly_RB may_MD be_VB identified_VBN by_IN computing_VBG the_DT
es_NNS were_VBD introduced_VBN and_CC evaluated_VBN in_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Text_NN distance_NN models_NNS -LRB-_-LRB- 39_CD ,_, 40_CD -RRB-_-RRB- and_CC pattern_NN extraction_NN versus_CC Naïve_JJ Bayes_NNS were_VBD compared_VBN in_IN -LRB-_-LRB- 33_CD -RRB-_-RRB- ._.
Further_JJ work_NN has_VBZ been_VBN done_VBN using_VBG cost-sensitive_JJ based_JJ learning_NN =_JJ -_: =[_NN 1_CD ,_, 2_CD ,_, 17_CD -RRB-_-RRB- -_: =_JJ -_: ,_, extensions_NNS to_TO Naïve_NNP Bayes_NNP bag-of-words_JJ modeling_NN -LRB-_-LRB- 30_CD ,_, 34_CD -RRB-_-RRB- and_CC a_DT comparative_JJ evaluations_NNS of_IN different_JJ Naïve_NNP Bayes_NNP models_NNS -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
An_DT excellent_JJ overview_NN of_IN these_DT methods_NNS and_CC techniques_NNS is_VBZ provided_VBN by_IN -LRB-_-LRB- 13_CD ,_,
