A_DT sequential_JJ sampling_NN algorithm_NN for_IN a_DT general_JJ class_NN of_IN utility_NN criteria_NNS
which_WDT require_VBP a_DT number_NN of_IN examples_NNS that_WDT can_MD be_VB guaranteed_VBN to_TO suce_VB forsnding_VBG a_DT nearly_RB optimal_JJ hypothesis_NN even_RB in_IN the_DT worst_JJS case_NN have_VBP early_RB on_IN been_VBN criticized_VBN as_IN being_VBG impractical_JJ ._.
Maron_NNP ,_, Moore_NNP ,_, &_CC Lee_NNP =_SYM -_: =[_NN 14_CD ,_, 15_CD -RRB-_-RRB- ha_SYM -_: =_JJ -_: ve_RB introduced_VBN sequential_JJ sampling_NN techniques_NNS -LRB-_-LRB- 4_CD ,_, 19_CD -RRB-_-RRB- into_IN the_DT machine_NN learning_NN context_NN by_IN proposing_VBG the_DT \_NN Hoe_VB ding_JJ Race_NN ''_'' algorithm_NN that_WDT combines_VBZ loop-reversal_JJ with_IN adaptive_JJ Hoeding_NN bounds_NNS ._.
A_DT gener_NN
;_: e.g._FW ,_, Gini_NNP diversity_NN index_NN ,_, twoing_JJ criterion_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ,_, and_CC the_DT chi-square_JJ test_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- ._.
The_DT order_NN which_WDT this_DT criterion_NN imposes_VBZ on_IN hypotheses_NNS is_VBZ also_RB equal_JJ to_TO the_DT order_NN imposed_VBN by_IN the_DT criterion_NN of_IN Inferrule_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Unfortunately_RB ,_, this_DT utility_NN function_NN is_VBZ not_RB bounded_VBN and_CC a_DT few_JJ examples_NNS that_WDT have_VBP not_RB been_VBN included_VBN in_IN the_DT sample_NN can_MD impose_VB dramatic_JJ changes_NNS on_IN the_DT values_NNS of_IN this_DT function_NN ._.
Theorem_NN 2_CD ._.
There_EX is_VBZ no_DT al_FW
aging_VBG utility_NN function_NN ._.
This_DT is_VBZ the_DT case_NN ,_, e.g._FW ,_, for_IN all_DT functions_NNS that_WDT combine_VBP coverage_NN and_CC distributional_JJ properties_NNS of_IN a_DT hypothesis_NN ,_, as_IN popular_JJ in_IN subgroup_NN discovery_NN ._.
The_DT task_NN of_IN subgroup_NN discovery_NN =_JJ -_: =[_NN 12_CD -_: =-]_CD is_VBZ tosnd_VBN maximally_RB general_JJ subsets_NNS of_IN database_NN transactions_NNS within_IN which_WDT the_DT distribution_NN of_IN a_DT focused_JJ feature_NN diers_NNS maximally_RB from_IN the_DT default_NN probability_NN of_IN that_DT feature_NN in_IN the_DT whole_JJ database_NN ._.
As_IN
ative_JJ Result_NN Several_JJ independent_JJ impurity_NN criteria_NNS have_VBP led_VBN to_TO utility_NN functions_NNS which_WDT are_VBP equivalent_JJ -LRB-_-LRB- up_RB to_TO a_DT constant_JJ factor_NN -RRB-_-RRB- to_TO f_FW -LRB-_-LRB- h_NN -RRB-_-RRB- =_JJ g_NN 1_CD g_NN -LRB-_-LRB- p_NN p0_NN -RRB-_-RRB- 2_CD ;_: e.g._FW ,_, Gini_NNP diversity_NN index_NN ,_, twoing_VBG criterion_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC the_DT chi-square_JJ test_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- ._.
The_DT order_NN which_WDT this_DT criterion_NN imposes_VBZ on_IN hypotheses_NNS is_VBZ also_RB equal_JJ to_TO the_DT order_NN imposed_VBN by_IN the_DT criterion_NN of_IN Inferrule_NNP -LRB-_-LRB- 2_CD -RRB-_-RRB- ._.
Unfortunately_RB ,_, this_DT utility_NN function_NN is_VBZ not_RB b_NN
H_NN one_CD of_IN the_DT elements_NNS with_IN maximal_JJ value_NN of_IN an_DT instance-averaging_JJ utility_NN function_NN f_SYM ,_, or_CC all_DT elements_NNS with_IN an_DT f-value_NN above_IN a_DT user-given_JJ threshold_NN -LRB-_-LRB- e.g._FW ,_, all_DT association_NN rules_NNS with_IN sucient_JJ support_NN -RRB-_-RRB- =_JJ -_: =[_NN 5_CD ,_, 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
With_IN instance-averaging_JJ utility_NN functions_NNS ,_, the_DT quality_NN of_IN a_DT hypothesis_NN h_NN is_VBZ the_DT average_NN across_IN all_DT instances_NNS in_IN a_DT dataset_NN D_NN of_IN an_DT instance_NN utility_NN function_NN finst_NN ._.
Many_JJ discovery_NN problems_NNS ,_, however_RB ,_,
te_IN error_NN probability_NN bound_VBD to_TO determine_VB the_DT required_JJ number_NN of_IN examples_NNS for_IN a_DT desired_VBN level_NN of_IN condence_NN and_CC accuracy_NN ._.
When_WRB estimating_VBG a_DT single_JJ probability_NN ,_, Cherno_NNP bounds_NNS that_WDT are_VBP used_VBN in_IN PAC_NN theory_NN -LRB-_-LRB- 1_CD =_JJ -_: =_JJ 0_CD ,_, 18_CD -_: =-]_CD and_CC many_JJ other_JJ areas_NNS of_IN statistics_NNS and_CC computer_NN science_NN can_MD be_VB used_VBN to_TO determine_VB appropriate_JJ sample_NN bounds_NNS -LRB-_-LRB- 17_CD -RRB-_-RRB- ._.
When_WRB such_JJ algorithms_NNS are_VBP implemented_VBN ,_, the_DT Cherno_NNP bounds_NNS can_MD be_VB replaced_VBN by_IN tighter_JJR no_DT
pping_NN database_NN items_NNS to_TO class_NN labels_NNS -RRB-_-RRB- ,_, accuracy_NN is_VBZ often_RB used_VBN as_IN utility_NN criterion_NN ._.
For_IN the_DT discovery_NN of_IN association_NN rules_NNS ,_, by_IN contrast_NN ,_, one_NN usually_RB relies_VBZ on_IN generality_NN as_IN primary_JJ utility_NN criterion_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Finally_RB ,_, for_IN subgroup_NN discovery_NN ,_, it_PRP is_VBZ commonplace_JJ to_TO combine_VB both_CC generality_NN and_CC distributional_JJ unusualness_NN ,_, resulting_VBG in_IN relatively_RB complex_JJ evaluation_NN functions_NNS -LRB-_-LRB- see_VB ,_, e.g._FW ,_, -LRB-_-LRB- 13_CD -RRB-_-RRB- for_IN an_DT overview_NN -RRB-_-RRB- ._.
d_NN of_IN these_DT utility_NN functions_NNS ._.
One_CD class_NN of_IN utility_NN functions_NNS weights_NNS the_DT generality_NN g_NN of_IN a_DT subgroup_NN and_CC the_DT deviation_NN of_IN the_DT probability_NN p_NN of_IN a_DT certain_JJ feature_NN from_IN the_DT default_NN probability_NN p0_NN equally_RB =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Hence_RB ,_, these_DT functions_NNS multiply_VBP generality_NN and_CC distributional_JJ unusualness_NN of_IN subgroups_NNS ._.
Alternatively_RB ,_, we_PRP can_MD use_VB the_DT absolute_JJ distance_NN jp_FW p0_FW j_NN between_IN probability_NN p_NN and_CC default_NN probability_NN p0_NN ._.
The_DT
owever_RB ,_, can_MD not_RB easily_RB be_VB cast_VBN in_IN this_DT framework_NN ._.
Firstly_RB ,_, it_PRP is_VBZ often_RB more_RBR natural_JJ for_IN a_DT user_NN to_TO ask_VB for_IN the_DT n_NN best_JJS solutions_NNS instead_RB of_IN the_DT single_JJ best_JJS or_CC all_DT hypotheses_NNS above_IN a_DT threshold_NN -LRB-_-LRB- see_VB e.g._FW ,_, =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Secondly_RB ,_, many_JJ popular_JJ utility_NN measures_NNS can_MD not_RB be_VB expressed_VBN as_IN an_DT averaging_NN utility_NN function_NN ._.
This_DT is_VBZ the_DT case_NN ,_, e.g._FW ,_, for_IN all_DT functions_NNS that_WDT combine_VBP coverage_NN and_CC distributional_JJ properties_NNS of_IN a_DT hypo_NN
y_NN utility_NN criterion_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ._.
Finally_RB ,_, for_IN subgroup_NN discovery_NN ,_, it_PRP is_VBZ commonplace_JJ to_TO combine_VB both_CC generality_NN and_CC distributional_JJ unusualness_NN ,_, resulting_VBG in_IN relatively_RB complex_JJ evaluation_NN functions_NNS -LRB-_-LRB- see_VB ,_, e.g._FW ,_, =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: for_IN an_DT overview_NN -RRB-_-RRB- ._.
In_IN light_NN of_IN the_DT large_JJ range_NN of_IN existing_JJ and_CC possible_JJ future_JJ utility_NN functions_NNS ,_, in_IN order_NN to_TO avoid_VB unduly_RB restricting_VBG our_PRP$ algorithm_NN ,_, we_PRP will_MD not_RB make_VB syntactic_JJ assumptions_NNS about_IN f_FW ._.
I_PRP
wesrst_FW dene_FW the_DT n-best_NN hypotheses_NNS problem_NN more_RBR precisely_RB and_CC identify_VB appropriate_JJ quality_NN guarantees_NNS ._.
Section_NN 3_CD then_RB presents_VBZ the_DT generic_JJ algorithm_NN ._.
Our_PRP$ algorithm_NN is_VBZ a_DT sequential_JJ sampling_NN algorithm_NN -LRB-_-LRB- =_JJ -_: =_JJ 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, in_IN the_DT sense_NN that_IN it_PRP does_VBZ not_RB wait_VB for_IN asxed_JJ number_NN of_IN examples_NNS that_WDT can_MD be_VB guaranteed_VBN to_TO suce_VB even_RB in_IN the_DT worst_JJS case_NN before_IN starting_VBG the_DT analysis_NN ._.
It_PRP starts_VBZ to_TO return_VB -LRB-_-LRB- or_CC discard_VB -RRB-_-RRB- hypotheses_NNS that_IN a_DT
y._NN When_WRB estimating_VBG a_DT single_JJ probability_NN ,_, Cherno_NNP bounds_NNS that_WDT are_VBP used_VBN in_IN PAC_NN theory_NN -LRB-_-LRB- 10_CD ,_, 18_CD -RRB-_-RRB- and_CC many_JJ other_JJ areas_NNS of_IN statistics_NNS and_CC computer_NN science_NN can_MD be_VB used_VBN to_TO determine_VB appropriate_JJ sample_NN bounds_NNS -LRB-_-LRB- =_JJ -_: =_JJ 17_CD -_: =-]_CD ._.
When_WRB such_JJ algorithms_NNS are_VBP implemented_VBN ,_, the_DT Cherno_NNP bounds_NNS can_MD be_VB replaced_VBN by_IN tighter_JJR normal_JJ or_CC Student_NNP 's_POS t-distribution_NN tables_NNS ._.
Unfortunately_RB ,_, the_DT straightforward_JJ extension_NN of_IN such_JJ approaches_NNS to_TO sele_VB
range_NN of_IN possible_JJ values_NNS of_IN measured_JJ performance_NN dierences_NNS ._.
^_FW f_FW -LRB-_-LRB- h1_NN ;_: Q_NNP i_LS -RRB-_-RRB- ^_FW f_FW -LRB-_-LRB- h2_NN ;_: Q_NNP i_LS -RRB-_-RRB- is_VBZ a_DT random_JJ variable_NN with_IN mean_NN value_NN f_SYM -LRB-_-LRB- h1_NN -RRB-_-RRB- f_LS -LRB-_-LRB- h2_NN -RRB-_-RRB- and_CC bounded_VBD range_NN ._.
We_PRP can_MD use_VB the_DT Hoe_VB ding_JJ inequality_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- to_TO bound_VBD the_DT chance_NN that_IN an_DT arbitrary_JJ -LRB-_-LRB- bounded_VBN -RRB-_-RRB- random_JJ variable_NN takes_VBZ a_DT value_NN which_WDT is_VBZ far_RB away_RB from_IN its_PRP$ mean_NN value_NN ._.
When_WRB X_NN is_VBZ a_DT random_JJ variable_NN with_IN expectation_NN E_NN -LRB-_-LRB- X_NN -RRB-_-RRB- and_CC range_NN at_IN most_JJS and_CC the_DT samp_NN
te_IN error_NN probability_NN bound_VBD to_TO determine_VB the_DT required_JJ number_NN of_IN examples_NNS for_IN a_DT desired_VBN level_NN of_IN condence_NN and_CC accuracy_NN ._.
When_WRB estimating_VBG a_DT single_JJ probability_NN ,_, Cherno_NNP bounds_NNS that_WDT are_VBP used_VBN in_IN PAC_NN theory_NN -LRB-_-LRB- 1_CD =_JJ -_: =_JJ 0_CD ,_, 18_CD -_: =-]_CD and_CC many_JJ other_JJ areas_NNS of_IN statistics_NNS and_CC computer_NN science_NN can_MD be_VB used_VBN to_TO determine_VB appropriate_JJ sample_NN bounds_NNS -LRB-_-LRB- 17_CD -RRB-_-RRB- ._.
When_WRB such_JJ algorithms_NNS are_VBP implemented_VBN ,_, the_DT Cherno_NNP bounds_NNS can_MD be_VB replaced_VBN by_IN tighter_JJR no_DT
ecied_VBN by_IN the_DT Cherno_NNP bound_VBD ,_, which_WDT we_PRP have_VBP to_TO when_WRB the_DT frequencies_NNS are_VBP similar_JJ ._.
Sequential_JJ sampling_NN methods_NNS have_VBP been_VBN reported_VBN to_TO reduce_VB the_DT required_JJ sample_NN size_NN by_IN several_JJ orders_NNS of_IN magnitudes_NNS -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 7_CD =_JJ -_: =]_NN -RRB-_-RRB- ._.
In_IN -_: =_SYM -_: our_PRP$ algorithm_NN -LRB-_-LRB- Table_NNP 1_CD -RRB-_-RRB- ,_, we_PRP combine_VBP sequential_JJ sampling_NN with_IN the_DT popular_JJ \_CD loop_NN reversal_NN ''_'' technique_NN found_VBN in_IN many_JJ KDD_NNP algorithms_NNS ._.
Instead_RB of_IN processing_VBG hypotheses_NNS one_CD after_IN another_DT ,_, and_CC obtaining_VBG
which_WDT require_VBP a_DT number_NN of_IN examples_NNS that_WDT can_MD be_VB guaranteed_VBN to_TO suce_VB forsnding_VBG a_DT nearly_RB optimal_JJ hypothesis_NN even_RB in_IN the_DT worst_JJS case_NN have_VBP early_RB on_IN been_VBN criticized_VBN as_IN being_VBG impractical_JJ ._.
Maron_NNP ,_, Moore_NNP ,_, &_CC Lee_NNP =_SYM -_: =[_NN 14_CD ,_, 15_CD -RRB-_-RRB- ha_SYM -_: =_JJ -_: ve_RB introduced_VBN sequential_JJ sampling_NN techniques_NNS -LRB-_-LRB- 4_CD ,_, 19_CD -RRB-_-RRB- into_IN the_DT machine_NN learning_NN context_NN by_IN proposing_VBG the_DT \_NN Hoe_VB ding_JJ Race_NN ''_'' algorithm_NN that_WDT combines_VBZ loop-reversal_JJ with_IN adaptive_JJ Hoeding_NN bounds_NNS ._.
A_DT gener_NN
e_LS very_RB large_JJ samples_NNS to_TO recognize_VB small_JJ dierences_NNS in_IN utility_NN ,_, even_RB if_IN the_DT actual_JJ dierences_NNS between_IN hypotheses_NNS to_TO be_VB compared_VBN are_VBP very_RB large_JJ ._.
This_DT problem_NN is_VBZ addressed_VBN by_IN sequential_JJ sampling_NN methods_NNS -LRB-_-LRB- 4_CD =_JJ -_: =_JJ ,_, 19_CD -_: =-]_CD -LRB-_-LRB- that_WDT have_VBP also_RB been_VBN referred_VBN to_TO as_IN adaptive_JJ sampling_NN methods_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- -RRB-_-RRB- ._.
The_DT idea_NN of_IN sequential_JJ sampling_NN is_VBZ that_IN when_WRB a_DT dierence_NN between_IN two_CD frequencies_NNS is_VBZ very_RB large_JJ after_IN only_RB a_DT few_JJ examples_NNS ,_, then_RB we_PRP c_SYM
non-sequential_JJ sampling_NN algorithm_NN for_IN KDD_NNP has_VBZ been_VBN presented_VBN by_IN Toivonen_NNP -LRB-_-LRB- 17_CD -RRB-_-RRB- ;_: a_DT sequential_JJ algorithm_NN -LRB-_-LRB- that_WDT imposes_VBZ further_JJ restrictions_NNS on_IN f_FW and_CC possesses_VBZ an_DT additional_JJ parameter_NN -RRB-_-RRB- by_IN Domingo_NNP et_FW al._FW =_SYM -_: =[_NN 5_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
So_RB far_RB ,_, all_DT sampling_NN algorithms_NNS have_VBP been_VBN restricted_JJ to_TO instance-averaging_JJ utility_NN functions_NNS -LRB-_-LRB- such_JJ as_IN error_NN probabilities_NNS -RRB-_-RRB- ,_, and_CC tosnding_VBG a_DT single_JJ approximately_RB best_JJS hypothesis_NN ._.
For_IN the_DT subgroup_NN dis_NN
H_NN one_CD of_IN the_DT elements_NNS with_IN maximal_JJ value_NN of_IN an_DT instance-averaging_JJ utility_NN function_NN f_SYM ,_, or_CC all_DT elements_NNS with_IN an_DT f-value_NN above_IN a_DT user-given_JJ threshold_NN -LRB-_-LRB- e.g._FW ,_, all_DT association_NN rules_NNS with_IN sucient_JJ support_NN -RRB-_-RRB- =_JJ -_: =[_NN 5_CD ,_, 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
With_IN instance-averaging_JJ utility_NN functions_NNS ,_, the_DT quality_NN of_IN a_DT hypothesis_NN h_NN is_VBZ the_DT average_NN across_IN all_DT instances_NNS in_IN a_DT dataset_NN D_NN of_IN an_DT instance_NN utility_NN function_NN finst_NN ._.
Many_JJ discovery_NN problems_NNS ,_, however_RB ,_,
the_DT support_NN of_IN a_DT hypothesis_NN -LRB-_-LRB- i.e._FW ,_, the_DT hypothesis_NN applies_VBZ to_TO the_DT transaction_NN -RRB-_-RRB- ._.
A_DT number_NN of_IN utility_NN functions_NNS have_VBP been_VBN proposed_VBN that_IN measure_NN these_DT two_CD properties_NNS of_IN hypotheses_NNS ._.
We_PRP refer_VBP the_DT reader_NN to_TO =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: for_IN a_DT discussion_NN on_IN the_DT background_NN of_IN these_DT utility_NN functions_NNS ._.
One_CD class_NN of_IN utility_NN functions_NNS weights_NNS the_DT generality_NN g_NN of_IN a_DT subgroup_NN and_CC the_DT deviation_NN of_IN the_DT probability_NN p_NN of_IN a_DT certain_JJ feature_NN from_IN t_NN
