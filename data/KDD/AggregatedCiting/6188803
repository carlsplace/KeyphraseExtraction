Active_JJ exploration_NN for_IN learning_VBG rankings_NNS from_IN clickthrough_JJ data_NNS
We_PRP address_VBP the_DT task_NN of_IN learning_VBG rankings_NNS of_IN documents_NNS from_IN search_NN enginelogs_NNS of_IN user_NN behavior_NN ._.
Previous_JJ work_NN on_IN this_DT problem_NN has_VBZ relied_VBN onpassively_RB collected_VBN clickthrough_JJ data_NNS ._.
In_IN contrast_NN ,_, we_PRP show_VBP that_IN anactive_JJ exploration_NN strategy_NN can_MD provide_VB data_NNS that_WDT leads_VBZ to_TO much_JJ fasterlearning_NN ._.
Specifically_RB ,_, we_PRP develop_VBP a_DT Bayesian_JJ approach_NN for_IN selectingrankings_NNS to_TO present_JJ users_NNS so_IN that_IN interactions_NNS result_VBP in_IN more_JJR informativetraining_NN data_NNS ._.
Our_PRP$ results_NNS using_VBG the_DT TREC-10_NN Web_NN corpus_NN ,_, as_RB well_RB assynthetic_JJ data_NNS ,_, demonstrate_VBP that_IN a_DT directed_JJ exploration_NN strategy_NN quicklyleads_NNS to_TO users_NNS being_VBG presented_VBN improved_JJ rankings_NNS in_IN an_DT online_JJ learningsetting_NN ._.
We_PRP find_VBP that_IN active_JJ exploration_NN substantially_RB outperformspassive_JJ observation_NN and_CC random_JJ exploration_NN ._.
document_NN corpus_NN ._.
This_DT subset_NN of_IN the_DT corpus_NN includes_VBZ 50_CD topics_NNS and_CC topic_NN descriptions_NNS ,_, run_VBP as_IN queries_NNS on_IN documents_NNS that_WDT are_VBP part_NN of_IN the_DT corpus_NN ._.
As_IN part_NN of_IN the_DT 10th_JJ Text_NN REtrieval_NN Conference_NN -LRB-_-LRB- TREC-10_NN -RRB-_-RRB- =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_JJ -_: ,_, 18_CD teams_NNS submitted_VBD a_DT ranking_NN of_IN documents_NNS for_IN each_DT topic_NN ._.
Then_RB ,_, for_IN each_DT topic_NN ,_, documents_NNS ranked_VBD highly_RB by_IN the_DT teams_NNS were_VBD manually_RB judged_VBN to_TO be_VB either_CC highly_RB relevant_JJ -LRB-_-LRB- relevance_NN score_NN of_IN 2_CD -RRB-_-RRB- ,_, relevan_NN
ska_FW et_FW al._FW in_IN the_DT context_NN of_IN utility_NN estimation_NN where_WRB they_PRP found_VBD that_IN the_DT true_JJ utility_NN of_IN many_JJ different_JJ outcomes_NNS can_MD be_VB quickly_RB discovered_VBN by_IN maximizing_VBG the_DT reduction_NN in_IN expected_JJ loss_NN given_VBN new_JJ data_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Largest_NNP Expected_NNP Loss_NN Documents_NNS -LRB-_-LRB- LELdoc_NN -RRB-_-RRB- ._.
For_IN each_DT document_NN di_FW ,_, compute_VB the_DT total_JJ contribution_NN of_IN all_DT pairs_NNS including_VBG di_FW to_TO the_DT expected_VBN loss_NN of_IN the_DT ranking_NN ._.
Present_JJ the_DT two_CD documents_NNS with_IN highest_JJS t_NN
-LRB-_-LRB- where_WRB si_NN is_VBZ 1_CD if_IN di_FW wins_NNS and_CC 0_CD otherwise_RB -RRB-_-RRB- is_VBZ presented_VBN in_IN Table_NNP 1_CD ._.
While_IN it_PRP would_MD also_RB be_VB interesting_JJ to_TO compare_VB alternative_JJ ways_NNS of_IN maintaining_VBG P_NN -LRB-_-LRB- M_NN |_NN D_NN -RRB-_-RRB- -LRB-_-LRB- e.g._FW -LRB-_-LRB- 17_CD -RRB-_-RRB- -RRB-_-RRB- ,_, or_CC using_VBG a_DT batch_NN algorithm_NN -LRB-_-LRB- see_VB =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: for_IN a_DT discussion_NN of_IN alternatives_NNS -RRB-_-RRB- ,_, the_DT simplicity_NN and_CC online_NN aspects_NNS of_IN the_DT glicko_NN system_NN are_VBP appealing_JJ ._.
In_IN particular_JJ ,_, in_IN real_JJ world_NN settings_NNS where_WRB large_JJ amounts_NNS of_IN data_NNS are_VBP collected_VBN for_IN large_JJ docu_NN
14_CD ,_, 15_CD -RRB-_-RRB- ._.
The_DT feedback_NN -LRB-_-LRB- clicks_NNS -RRB-_-RRB- on_IN these_DT results_NNS is_VBZ recorded_VBN and_CC used_VBN to_TO infer_VB relevance_NN judgments_NNS ._.
These_DT judgments_NNS are_VBP then_RB used_VBN to_TO train_VB a_DT learning_NN algorithm_NN such_JJ as_IN a_DT ranking_JJ support_NN vector_NN machine_NN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN particular_JJ ,_, users_NNS very_RB rarely_RB evaluate_VB results_NNS beyond_IN the_DT first_JJ page_NN ,_, so_IN the_DT data_NNS obtained_VBN is_VBZ strongly_RB biased_VBN toward_IN documents_NNS already_RB ranked_VBD highly_RB ._.
Highly_RB relevant_JJ results_NNS that_WDT are_VBP not_RB initiall_NN
timate_VB This_DT model_NN is_VBZ motivated_VBN by_IN ability_NN estimates_NNS maintained_VBN for_IN chess_NN players_NNS -LRB-_-LRB- 11_CD -RRB-_-RRB- ._.
In_IN the_DT most_RBS closely_RB related_JJ previous_JJ work_NN ,_, Chu_NNP and_CC Ghahramani_NNP address_VBP a_DT similar_JJ problem_NN using_VBG Gaussian_JJ Processes_NNS =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, instead_RB maintaining_VBG the_DT distribution_NN P_NN -LRB-_-LRB- M_NN |_NN D_NN -RRB-_-RRB- ,_, they_PRP directly_RB estimate_VBP M_NN ∗_NN given_VBN D._NNP This_NNP is_VBZ also_RB true_JJ of_IN other_JJ related_JJ prior_JJ work_NN -LRB-_-LRB- 9_CD ,_, 10_CD ,_, 22_CD -RRB-_-RRB- ._.
The_DT key_JJ difference_NN in_IN our_PRP$ approach_NN is_VBZ that_IN we_PRP ar_VBP
the_DT limitations_NNS of_IN passively_RB collected_VBN data_NNS ,_, consider_VB the_DT typical_JJ interactions_NNS of_IN search_NN engine_NN users_NNS ._.
Usually_RB ,_, a_DT user_NN executes_VBZ a_DT query_NN then_RB perhaps_RB considers_VBZ the_DT first_JJ two_CD or_CC three_CD results_NNS presented_VBD =_JJ -_: =[_NN 14_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT feedback_NN -LRB-_-LRB- clicks_NNS -RRB-_-RRB- on_IN these_DT results_NNS is_VBZ recorded_VBN and_CC used_VBN to_TO infer_VB relevance_NN judgments_NNS ._.
These_DT judgments_NNS are_VBP then_RB used_VBN to_TO train_VB a_DT learning_NN algorithm_NN such_JJ as_IN a_DT ranking_JJ support_NN vector_NN machine_NN -LRB-_-LRB- 18_CD -RRB-_-RRB- ._.
I_PRP
ing_VBG the_DT uncertainty_NN in_IN their_PRP$ relevances_NNS ,_, we_PRP are_VBP likely_JJ to_TO reduce_VB the_DT contributions_NNS to_TO the_DT risk_NN of_IN all_DT pairs_NNS including_VBG the_DT documents_NNS ._.
An_DT alternative_JJ selection_NN algorithm_NN proposed_VBN in_IN previous_JJ work_NN -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 13_CD ,_, 7_CD -RRB-_-RRB- -_: =--RRB-_NN is_VBZ to_TO compare_VB pairs_NNS of_IN items_NNS such_JJ that_IN the_DT probability_NN distribution_NN over_IN models_NNS changes_NNS most_JJS in_IN terms_NNS of_IN KL-divergence_NN or_CC entropy_NN ._.
We_PRP do_VBP not_RB pursue_VB this_DT alternative_NN as_IN it_PRP does_VBZ not_RB take_VB into_IN account_NN
ach_NN ._.
There_EX has_VBZ also_RB recently_RB been_VBN interest_NN in_IN minimizing_VBG the_DT number_NN of_IN documents_NNS that_WDT need_VBP to_TO be_VB evaluated_VBN by_IN human_JJ judges_NNS to_TO evaluate_VB performance_NN of_IN ranking_JJ algorithms_NNS on_IN a_DT document_NN collection_NN -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 5_CD ,_, 28_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
While_IN such_JJ human_JJ judgments_NNS are_VBP absolute_JJ ,_, i.e._FW a_DT human_JJ is_VBZ asked_VBN to_TO rate_VB each_DT document_NN on_IN a_DT fixed_JJ scale_NN ,_, it_PRP would_MD be_VB interesting_JJ to_TO adapt_VB our_PRP$ approach_NN to_TO a_DT setting_NN that_WDT minimizes_VBZ the_DT number_NN of_IN human_JJ
ramani_NNS address_VBP a_DT similar_JJ problem_NN using_VBG Gaussian_JJ Processes_NNS -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
However_RB ,_, instead_RB maintaining_VBG the_DT distribution_NN P_NN -LRB-_-LRB- M_NN |_NN D_NN -RRB-_-RRB- ,_, they_PRP directly_RB estimate_VBP M_NN ∗_NN given_VBN D._NNP This_NNP is_VBZ also_RB true_JJ of_IN other_JJ related_JJ prior_JJ work_NN =_JJ -_: =[_NN 9_CD ,_, 10_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT key_JJ difference_NN in_IN our_PRP$ approach_NN is_VBZ that_IN we_PRP are_VBP not_RB simply_RB finding_VBG the_DT optimizing_VBG ranking_NN ._.
Rather_RB ,_, maintaining_VBG P_NN -LRB-_-LRB- M_NN |_NN D_NN -RRB-_-RRB- is_VBZ key_JJ as_IN it_PRP allows_VBZ us_PRP to_TO optimize_VB for_IN collected_VBN training_NN data_NNS ._.
3.2_CD Inference_NN
M_NN |_NN D_NN -RRB-_-RRB- as_IN a_DT set_NN of_IN Gaussians_NNS centered_VBN at_IN νi_NN with_IN variance_NN σ_NN 2_CD i_LS ._.
For_IN example_NN :_: ν1_FW ν4_FW ν5_FW Research_NNP Track_NNP Paper_NNP Relevance_NNP estimate_VBP This_DT model_NN is_VBZ motivated_VBN by_IN ability_NN estimates_NNS maintained_VBN for_IN chess_NN players_NNS =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN the_DT most_RBS closely_RB related_JJ previous_JJ work_NN ,_, Chu_NNP and_CC Ghahramani_NNP address_VBP a_DT similar_JJ problem_NN using_VBG Gaussian_JJ Processes_NNS -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
However_RB ,_, instead_RB maintaining_VBG the_DT distribution_NN P_NN -LRB-_-LRB- M_NN |_NN D_NN -RRB-_-RRB- ,_, they_PRP directly_RB estimate_VBP M_NN
significant_JJ probability_NN of_IN being_VBG incorrect_JJ ._.
However_RB ,_, previous_JJ work_NN has_VBZ shown_VBN that_IN if_IN the_DT difference_NN in_IN relevance_NN between_IN documents_NNS is_VBZ larger_JJR ,_, relative_JJ relevance_NN judgments_NNS are_VBP less_RBR likely_JJ to_TO be_VB noisy_JJ =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT work_NN also_RB showed_VBD that_IN if_IN adjacent_JJ pairs_NNS of_IN documents_NNS in_IN the_DT ranking_NN shown_VBN to_TO users_NNS are_VBP randomly_RB swapped_VBN to_TO compensate_VB for_IN presentation_NN bias_NN ,_, provably_RB reliable_JJ pairwise_JJ relevance_NN judgments_NNS about_IN
we_PRP ignore_VBP the_DT effect_NN of_IN rank_NN in_IN the_DT loss_NN function_NN ,_, this_DT approach_NN is_VBZ similar_JJ to_TO previous_JJ work_NN in_IN active_JJ learning_NN where_WRB users_NNS are_VBP asked_VBN to_TO label_VB items_NNS where_WRB the_DT predicted_VBN label_NN is_VBZ most_RBS uncertain_JJ -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 3_CD ,_, 27_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
In_IN our_PRP$ setting_NN ,_, document_NN pairs_NNS with_IN high_JJ pairwise_JJ contribution_NN tend_VBP to_TO be_VB those_DT with_IN large_JJ estimated_VBN error_NN in_IN relevance_NN ._.
One_CD Step_NN Lookahead_NN -LRB-_-LRB- OSL_NN -RRB-_-RRB- ._.
For_IN each_DT pair_NN of_IN documents_NNS ,_, compute_VB the_DT expected_VBN p_NN
Keywords_NNP Clickthrough_NNP data_NNS ,_, Web_NN search_NN ,_, Active_JJ exploration_NN ,_, Learning_NNP to_TO rank_VB 1_CD ._.
INTRODUCTION_NN There_EX has_VBZ recently_RB been_VBN an_DT interest_NN in_IN training_NN search_NN engines_NNS automatically_RB using_VBG machine_NN learning_NN -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 20_CD ,_, 4_CD ,_, 24_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
The_DT ideal_JJ training_NN data_NNS would_MD be_VB rankings_NNS of_IN documents_NNS ordered_VBN by_IN relevance_NN for_IN some_DT set_NN of_IN queries_NNS ._.
In_IN some_DT cases_NNS it_PRP is_VBZ practical_JJ to_TO hire_VB experts_NNS to_TO manually_RB provide_VB relevance_NN information_NN for_IN part_NN
aments_NNS ._.
However_RB ,_, there_EX are_VBP two_CD key_JJ differences_NNS ._.
First_RB ,_, a_DT tournament_NN has_VBZ a_DT different_JJ concept_NN of_IN loss_NN ._.
A_DT criterion_NN often_RB optimized_VBN is_VBZ the_DT probability_NN of_IN the_DT true_JJ best_JJS player_NN winning_VBG the_DT final_JJ game_NN -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 12_CD ,_, 26_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Second_JJ ,_, pairwise_JJ comparisons_NNS in_IN a_DT tournament_NN have_VBP no_DT cost_NN ._.
In_IN most_JJS sports_NNS ,_, a_DT common_JJ constraint_NN is_VBZ that_IN all_DT teams_NNS or_CC players_NNS must_MD compete_VB for_IN at_IN least_JJS n_NN rounds_NNS ._.
This_DT means_VBZ that_IN each_DT ``_`` item_NN ''_'' must_MD be_VB c_NN
di_FW following_VBG a_DT single_JJ comparison_NN to_TO dj_NN -LRB-_-LRB- where_WRB si_NN is_VBZ 1_CD if_IN di_FW wins_NNS and_CC 0_CD otherwise_RB -RRB-_-RRB- is_VBZ presented_VBN in_IN Table_NNP 1_CD ._.
While_IN it_PRP would_MD also_RB be_VB interesting_JJ to_TO compare_VB alternative_JJ ways_NNS of_IN maintaining_VBG P_NN -LRB-_-LRB- M_NN |_NN D_NN -RRB-_-RRB- -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =--RRB-_NN ,_, or_CC using_VBG a_DT batch_NN algorithm_NN -LRB-_-LRB- see_VB -LRB-_-LRB- 19_CD -RRB-_-RRB- for_IN a_DT discussion_NN of_IN alternatives_NNS -RRB-_-RRB- ,_, the_DT simplicity_NN and_CC online_NN aspects_NNS of_IN the_DT glicko_NN system_NN are_VBP appealing_JJ ._.
In_IN particular_JJ ,_, in_IN real_JJ world_NN settings_NNS where_WRB large_JJ amoun_NN
aments_NNS ._.
However_RB ,_, there_EX are_VBP two_CD key_JJ differences_NNS ._.
First_RB ,_, a_DT tournament_NN has_VBZ a_DT different_JJ concept_NN of_IN loss_NN ._.
A_DT criterion_NN often_RB optimized_VBN is_VBZ the_DT probability_NN of_IN the_DT true_JJ best_JJS player_NN winning_VBG the_DT final_JJ game_NN -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 12_CD ,_, 26_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Second_JJ ,_, pairwise_JJ comparisons_NNS in_IN a_DT tournament_NN have_VBP no_DT cost_NN ._.
In_IN most_JJS sports_NNS ,_, a_DT common_JJ constraint_NN is_VBZ that_IN all_DT teams_NNS or_CC players_NNS must_MD compete_VB for_IN at_IN least_JJS n_NN rounds_NNS ._.
This_DT means_VBZ that_IN each_DT ``_`` item_NN ''_'' must_MD be_VB c_NN
we_PRP ignore_VBP the_DT effect_NN of_IN rank_NN in_IN the_DT loss_NN function_NN ,_, this_DT approach_NN is_VBZ similar_JJ to_TO previous_JJ work_NN in_IN active_JJ learning_NN where_WRB users_NNS are_VBP asked_VBN to_TO label_VB items_NNS where_WRB the_DT predicted_VBN label_NN is_VBZ most_RBS uncertain_JJ -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 3_CD ,_, 27_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
In_IN our_PRP$ setting_NN ,_, document_NN pairs_NNS with_IN high_JJ pairwise_JJ contribution_NN tend_VBP to_TO be_VB those_DT with_IN large_JJ estimated_VBN error_NN in_IN relevance_NN ._.
One_CD Step_NN Lookahead_NN -LRB-_-LRB- OSL_NN -RRB-_-RRB- ._.
For_IN each_DT pair_NN of_IN documents_NNS ,_, compute_VB the_DT expected_VBN p_NN
learning_VBG task_NN ._.
A_DT number_NN of_IN studies_NNS have_VBP shown_VBN that_IN users_NNS tend_VBP to_TO click_VB on_IN results_NNS ranked_VBN highly_RB by_IN search_NN engines_NNS much_RB more_RBR often_RB than_IN those_DT ranked_VBD lower_JJR ._.
For_IN example_NN ,_, in_IN recent_JJ work_NN Agichtein_NNP et_FW al._FW =_SYM -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: present_VB a_DT summary_NN distribution_NN of_IN the_DT relative_NN click_VBP frequency_NN on_IN web_NN search_NN results_VBZ for_IN a_DT large_JJ search_NN engine_NN as_IN a_DT function_NN of_IN rank_NN for_IN 120,000_CD searches_NNS for_IN 3,500_CD queries_NNS ._.
They_PRP show_VBP that_IN the_DT relativ_NN
ramani_NNS address_VBP a_DT similar_JJ problem_NN using_VBG Gaussian_JJ Processes_NNS -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
However_RB ,_, instead_RB maintaining_VBG the_DT distribution_NN P_NN -LRB-_-LRB- M_NN |_NN D_NN -RRB-_-RRB- ,_, they_PRP directly_RB estimate_VBP M_NN ∗_NN given_VBN D._NNP This_NNP is_VBZ also_RB true_JJ of_IN other_JJ related_JJ prior_JJ work_NN =_JJ -_: =[_NN 9_CD ,_, 10_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT key_JJ difference_NN in_IN our_PRP$ approach_NN is_VBZ that_IN we_PRP are_VBP not_RB simply_RB finding_VBG the_DT optimizing_VBG ranking_NN ._.
Rather_RB ,_, maintaining_VBG P_NN -LRB-_-LRB- M_NN |_NN D_NN -RRB-_-RRB- is_VBZ key_JJ as_IN it_PRP allows_VBZ us_PRP to_TO optimize_VB for_IN collected_VBN training_NN data_NNS ._.
3.2_CD Inference_NN
the_DT limitations_NNS of_IN passively_RB collected_VBN data_NNS ,_, consider_VB the_DT typical_JJ interactions_NNS of_IN search_NN engine_NN users_NNS ._.
Usually_RB ,_, a_DT user_NN executes_VBZ a_DT query_NN then_RB perhaps_RB considers_VBZ the_DT first_JJ two_CD or_CC three_CD results_NNS presented_VBD =_JJ -_: =[_NN 14_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT feedback_NN -LRB-_-LRB- clicks_NNS -RRB-_-RRB- on_IN these_DT results_NNS is_VBZ recorded_VBN and_CC used_VBN to_TO infer_VB relevance_NN judgments_NNS ._.
These_DT judgments_NNS are_VBP then_RB used_VBN to_TO train_VB a_DT learning_NN algorithm_NN such_JJ as_IN a_DT ranking_JJ support_NN vector_NN machine_NN -LRB-_-LRB- 18_CD -RRB-_-RRB- ._.
I_PRP
e_LS second_JJ result_NN ,_, 50_CD %_NN as_IN many_JJ clicks_NNS on_IN the_DT third_JJ ,_, and_CC 30_CD %_NN as_IN many_JJ clicks_NNS on_IN the_DT fourth_JJ ._.
While_IN we_PRP may_MD hypothesize_VB that_IN this_DT is_VBZ simply_RB because_IN better_JJR results_NNS tend_VBP to_TO be_VB presented_VBN higher_JJR ,_, Joachims_NNP et_FW al._FW =_SYM -_: =[_NN 21_CD -RRB-_-RRB- -_: =_JJ -_: showed_VBD that_IN there_EX is_VBZ an_DT inherent_JJ bias_NN to_TO rank_VB in_IN user_NN behavior_NN ._.
They_PRP showed_VBD that_IN users_NNS still_RB click_VBP more_RBR often_RB on_IN higher_JJR ranked_VBD results_NNS even_RB if_IN presented_VBN with_IN rankings_NNS reversing_VBG the_DT top_JJ ten_CD results_NNS ._.
I_PRP
Keywords_NNP Clickthrough_NNP data_NNS ,_, Web_NN search_NN ,_, Active_JJ exploration_NN ,_, Learning_NNP to_TO rank_VB 1_CD ._.
INTRODUCTION_NN There_EX has_VBZ recently_RB been_VBN an_DT interest_NN in_IN training_NN search_NN engines_NNS automatically_RB using_VBG machine_NN learning_NN -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 20_CD ,_, 4_CD ,_, 24_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
The_DT ideal_JJ training_NN data_NNS would_MD be_VB rankings_NNS of_IN documents_NNS ordered_VBN by_IN relevance_NN for_IN some_DT set_NN of_IN queries_NNS ._.
In_IN some_DT cases_NNS it_PRP is_VBZ practical_JJ to_TO hire_VB experts_NNS to_TO manually_RB provide_VB relevance_NN information_NN for_IN part_NN
ach_NN ._.
There_EX has_VBZ also_RB recently_RB been_VBN interest_NN in_IN minimizing_VBG the_DT number_NN of_IN documents_NNS that_WDT need_VBP to_TO be_VB evaluated_VBN by_IN human_JJ judges_NNS to_TO evaluate_VB performance_NN of_IN ranking_JJ algorithms_NNS on_IN a_DT document_NN collection_NN -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 5_CD ,_, 28_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
While_IN such_JJ human_JJ judgments_NNS are_VBP absolute_JJ ,_, i.e._FW a_DT human_JJ is_VBZ asked_VBN to_TO rate_VB each_DT document_NN on_IN a_DT fixed_JJ scale_NN ,_, it_PRP would_MD be_VB interesting_JJ to_TO adapt_VB our_PRP$ approach_NN to_TO a_DT setting_NN that_WDT minimizes_VBZ the_DT number_NN of_IN human_JJ
poorer_JJR results_NNS ._.
However_RB ,_, it_PRP benefits_VBZ from_IN the_DT potential_NN for_IN feedback_NN on_IN all_DT documents_NNS regardless_RB of_IN rank_NN ,_, even_RB in_IN the_DT presence_NN of_IN significant_JJ user_NN bias_NN ._.
A_DT similar_JJ method_NN was_VBD proposed_VBN by_IN Pandey_NNP et_FW al._FW =_SYM -_: =[_NN 23_CD -RRB-_-RRB- -_: =_SYM -_: in_IN the_DT context_NN of_IN identifying_VBG new_JJ web_NN pages_NNS that_WDT would_MD soon_RB become_VB popular_JJ ,_, suggesting_VBG to_TO randomly_RB insert_VB new_JJ documents_NNS into_IN web_NN search_NN results_NNS ._.
Largest_FW Expected_FW Loss_NN Pair_NN -LRB-_-LRB- LELpair_NN -RRB-_-RRB- ._.
Select_NNP the_DT pair_NN
Keywords_NNP Clickthrough_NNP data_NNS ,_, Web_NN search_NN ,_, Active_JJ exploration_NN ,_, Learning_NNP to_TO rank_VB 1_CD ._.
INTRODUCTION_NN There_EX has_VBZ recently_RB been_VBN an_DT interest_NN in_IN training_NN search_NN engines_NNS automatically_RB using_VBG machine_NN learning_NN -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 20_CD ,_, 4_CD ,_, 24_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
The_DT ideal_JJ training_NN data_NNS would_MD be_VB rankings_NNS of_IN documents_NNS ordered_VBN by_IN relevance_NN for_IN some_DT set_NN of_IN queries_NNS ._.
In_IN some_DT cases_NNS it_PRP is_VBZ practical_JJ to_TO hire_VB experts_NNS to_TO manually_RB provide_VB relevance_NN information_NN for_IN part_NN
ramani_NNS address_VBP a_DT similar_JJ problem_NN using_VBG Gaussian_JJ Processes_NNS -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
However_RB ,_, instead_RB maintaining_VBG the_DT distribution_NN P_NN -LRB-_-LRB- M_NN |_NN D_NN -RRB-_-RRB- ,_, they_PRP directly_RB estimate_VBP M_NN ∗_NN given_VBN D._NNP This_NNP is_VBZ also_RB true_JJ of_IN other_JJ related_JJ prior_JJ work_NN =_JJ -_: =[_NN 9_CD ,_, 10_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT key_JJ difference_NN in_IN our_PRP$ approach_NN is_VBZ that_IN we_PRP are_VBP not_RB simply_RB finding_VBG the_DT optimizing_VBG ranking_NN ._.
Rather_RB ,_, maintaining_VBG P_NN -LRB-_-LRB- M_NN |_NN D_NN -RRB-_-RRB- is_VBZ key_JJ as_IN it_PRP allows_VBZ us_PRP to_TO optimize_VB for_IN collected_VBN training_NN data_NNS ._.
3.2_CD Inference_NN
cating_VBG that_DT di_FW was_VBD judged_VBN more_RBR relevant_JJ that_IN dj_NN ._.
A_DT standard_JJ approach_NN to_TO modeling_NN noise_NN in_IN pairwise_JJ comparisons_NNS is_VBZ to_TO assume_VB that_IN the_DT probability_NN of_IN an_DT outcome_NN is_VBZ determined_VBN by_IN the_DT Bradley-Terry_NNP model_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: :_: P_NN -LRB-_-LRB- di_FW ≻_FW dj_FW -RRB-_-RRB- =_JJ rel_NN -LRB-_-LRB- di_FW -RRB-_-RRB- ,_, -LRB-_-LRB- 6_CD -RRB-_-RRB- rel_NN -LRB-_-LRB- di_FW -RRB-_-RRB- +_CC rel_NN -LRB-_-LRB- dj_NN -RRB-_-RRB- where_WRB rel_NN -LRB-_-LRB- di_FW -RRB-_-RRB- is_VBZ the_DT relevance_NN of_IN di_FW ._.
The_DT Bradley-Terry_NNP model_NN can_MD be_VB reparameterized_VBN setting_VBG rel_NN -LRB-_-LRB- di_FW -RRB-_-RRB- =_JJ 10_CD µ_FW i_FW \/_: σ_NN where_WRB σ_NN is_VBZ a_DT known_JJ ,_, global_JJ and_CC fixed_JJ par_NN
ing_VBG the_DT uncertainty_NN in_IN their_PRP$ relevances_NNS ,_, we_PRP are_VBP likely_JJ to_TO reduce_VB the_DT contributions_NNS to_TO the_DT risk_NN of_IN all_DT pairs_NNS including_VBG the_DT documents_NNS ._.
An_DT alternative_JJ selection_NN algorithm_NN proposed_VBN in_IN previous_JJ work_NN -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 13_CD ,_, 7_CD -RRB-_-RRB- -_: =--RRB-_NN is_VBZ to_TO compare_VB pairs_NNS of_IN items_NNS such_JJ that_IN the_DT probability_NN distribution_NN over_IN models_NNS changes_NNS most_JJS in_IN terms_NNS of_IN KL-divergence_NN or_CC entropy_NN ._.
We_PRP do_VBP not_RB pursue_VB this_DT alternative_NN as_IN it_PRP does_VBZ not_RB take_VB into_IN account_NN
