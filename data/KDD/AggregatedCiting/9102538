A_DT sequential_JJ dual_JJ method_NN for_IN large_JJ scale_NN multi-class_JJ linear_NN svms_NNS
Efficient_JJ training_NN of_IN direct_JJ multi-class_JJ formulations_NNS of_IN linear_JJ Support_NN Vector_NNP Machines_NNP is_VBZ very_RB useful_JJ in_IN applications_NNS such_JJ as_IN text_NN classification_NN with_IN a_DT huge_JJ number_NN examples_NNS as_RB well_RB as_IN features_NNS ._.
This_DT paper_NN presents_VBZ a_DT fast_JJ dual_JJ method_NN for_IN this_DT training_NN ._.
The_DT main_JJ idea_NN is_VBZ to_TO sequentially_RB traverse_VB through_IN the_DT training_NN set_NN and_CC optimize_VB the_DT dual_JJ variables_NNS associated_VBN with_IN one_CD example_NN at_IN a_DT time_NN ._.
The_DT speed_NN of_IN training_NN is_VBZ enhanced_VBN further_RB by_IN shrinking_VBG and_CC cooling_VBG heuristics_NNS ._.
Experiments_NNS indicate_VBP that_IN our_PRP$ method_NN is_VBZ much_RB faster_RBR than_IN state_NN of_IN the_DT art_NN solvers_VBZ such_JJ as_IN bundle_NN ,_, cutting_VBG plane_NN and_CC exponentiated_JJ gradient_NN methods_NNS ._.
om_IN the_DT context_NN ._.
Superscript_JJ T_NN will_MD denote_VB transpose_NN for_IN vectors_NNS ._.
The_DT following_VBG multi-class_JJ datasets_NNS are_VBP used_VBN in_IN the_DT paper_NN for_IN doing_VBG various_JJ experiments_NNS :_: NEWS20_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ,_, SECTOR_NN -LRB-_-LRB- 20_CD ,_, 19_CD -RRB-_-RRB- ,_, MNIST_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, RCV1_NN =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_JJ -_: and_CC COVER_NN -LRB-_-LRB- 13_CD -RRB-_-RRB- ._.
RCV1_NN is_VBZ a_DT taxonomy_NN based_VBN multi-label_JJ dataset_NN and_CC so_RB we_PRP modified_VBD it_PRP to_TO a_DT multi-class_JJ dataset_NN by_IN removing_VBG all_DT examples_NNS which_WDT had_VBD mismatched_VBN labels_NNS in_IN the_DT taxonomy_NN tree_NN ;_: in_IN the_DT process_NN o_NN
ass_NN inference_NN ,_, is_VBZ one_CD of_IN the_DT popular_JJ schemes_NNS to_TO solve_VB a_DT multi-class_JJ problem_NN ._.
OVR_NNP is_VBZ easy_JJ and_CC efficient_JJ to_TO design_NN and_CC also_RB gives_VBZ good_JJ performance_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ._.
Crammer_NNP and_CC Singer_NNP -LRB-_-LRB- 5_CD ,_, 6_CD -RRB-_-RRB- and_CC Weston_NNP and_CC Watkins_NNP =_SYM -_: =[_NN 25_CD -RRB-_-RRB- -_: =_SYM -_: gave_VBD direct_JJ multi-class_JJ SVM_NN formulations_NNS ._.
With_IN nonlinear_JJ kernels_NNS in_IN mind_NN ,_, Crammer_NNP and_CC Singer_NNP -LRB-_-LRB- 5_CD ,_, 6_CD -RRB-_-RRB- and_CC Hsu_NNP and_CC Lin_NNP -LRB-_-LRB- 10_CD -RRB-_-RRB- gave_VBD efficient_JJ decomposition_NN methods_NNS for_IN these_DT formulations_NNS ._.
Recently_RB ,_, some_DT go_VBP
g_NN the_DT classifiers_NNS for_IN multi-class_JJ inference_NN ,_, is_VBZ one_CD of_IN the_DT popular_JJ schemes_NNS to_TO solve_VB a_DT multi-class_JJ problem_NN ._.
OVR_NNP is_VBZ easy_JJ and_CC efficient_JJ to_TO design_NN and_CC also_RB gives_VBZ good_JJ performance_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ._.
Crammer_NNP and_CC Singer_NNP =_SYM -_: =[_NN 5_CD ,_, 6_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Weston_NNP and_CC Watkins_NNP -LRB-_-LRB- 25_CD -RRB-_-RRB- gave_VBD direct_JJ multi-class_JJ SVM_NN formulations_NNS ._.
With_IN nonlinear_JJ kernels_NNS in_IN mind_NN ,_, Crammer_NNP and_CC Singer_NNP -LRB-_-LRB- 5_CD ,_, 6_CD -RRB-_-RRB- and_CC Hsu_NNP and_CC Lin_NNP -LRB-_-LRB- 10_CD -RRB-_-RRB- gave_VBD efficient_JJ decomposition_NN methods_NNS for_IN these_DT for_IN
be_VB clear_JJ from_IN the_DT context_NN ._.
Superscript_JJ T_NN will_MD denote_VB transpose_NN for_IN vectors_NNS ._.
The_DT following_VBG multi-class_JJ datasets_NNS are_VBP used_VBN in_IN the_DT paper_NN for_IN doing_VBG various_JJ experiments_NNS :_: NEWS20_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ,_, SECTOR_NN -LRB-_-LRB- 20_CD ,_, 19_CD -RRB-_-RRB- ,_, MNIST_NN =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_JJ -_: ,_, RCV1_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- and_CC COVER_NN -LRB-_-LRB- 13_CD -RRB-_-RRB- ._.
RCV1_NN is_VBZ a_DT taxonomy_NN based_VBN multi-label_JJ dataset_NN and_CC so_RB we_PRP modified_VBD it_PRP to_TO a_DT multi-class_JJ dataset_NN by_IN removing_VBG all_DT examples_NNS which_WDT had_VBD mismatched_VBN labels_NNS in_IN the_DT taxonomy_NN tree_NN ;_: in_IN th_DT
be_VB extended_VBN to_TO more_RBR general_JJ SVM_NN problems_NNS with_IN structured_JJ outputs_NNS ,_, such_JJ as_IN taxonomy_NN ,_, multilabel_NN and_CC sequence_NN labeling_NN problems_NNS ._.
We_PRP note_VBP that_IN ,_, for_IN the_DT structured_JJ outputs_NNS setting_VBG ,_, Tsochantaridis_NNP et_FW al._FW =_SYM -_: =[_NN 24_CD -RRB-_-RRB- -_: =_SYM -_: mentioned_VBD the_DT sequential_JJ dual_JJ method_NN as_IN a_DT possibility_NN -LRB-_-LRB- see_VB Variant_JJ -LRB-_-LRB- b_NN -RRB-_-RRB- in_IN Algorithm_NN 1_CD of_IN that_DT paper_NN -RRB-_-RRB- ,_, but_CC did_VBD not_RB pursue_VB it_PRP as_IN a_DT potentially_RB fast_JJ method_NN ._.
In_IN such_JJ extensions_NNS the_DT quadratic_JJ programming_NN
lasses_NNS ,_, and_CC then_RB combining_VBG the_DT classifiers_NNS for_IN multi-class_JJ inference_NN ,_, is_VBZ one_CD of_IN the_DT popular_JJ schemes_NNS to_TO solve_VB a_DT multi-class_JJ problem_NN ._.
OVR_NNP is_VBZ easy_JJ and_CC efficient_JJ to_TO design_NN and_CC also_RB gives_VBZ good_JJ performance_NN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Crammer_NNP and_CC Singer_NNP -LRB-_-LRB- 5_CD ,_, 6_CD -RRB-_-RRB- and_CC Weston_NNP and_CC Watkins_NNP -LRB-_-LRB- 25_CD -RRB-_-RRB- gave_VBD direct_JJ multi-class_JJ SVM_NN formulations_NNS ._.
With_IN nonlinear_JJ kernels_NNS in_IN mind_NN ,_, Crammer_NNP and_CC Singer_NNP -LRB-_-LRB- 5_CD ,_, 6_CD -RRB-_-RRB- and_CC Hsu_NNP and_CC Lin_NNP -LRB-_-LRB- 10_CD -RRB-_-RRB- gave_VBD efficient_JJ decompos_NNS
dimension_NN will_MD be_VB clear_JJ from_IN the_DT context_NN ._.
Superscript_JJ T_NN will_MD denote_VB transpose_NN for_IN vectors_NNS ._.
The_DT following_VBG multi-class_JJ datasets_NNS are_VBP used_VBN in_IN the_DT paper_NN for_IN doing_VBG various_JJ experiments_NNS :_: NEWS20_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ,_, SECTOR_NN =_JJ -_: =[_NN 20_CD ,_, 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, MNIST_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, RCV1_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- and_CC COVER_NN -LRB-_-LRB- 13_CD -RRB-_-RRB- ._.
RCV1_NN is_VBZ a_DT taxonomy_NN based_VBN multi-label_JJ dataset_NN and_CC so_RB we_PRP modified_VBD it_PRP to_TO a_DT multi-class_JJ dataset_NN by_IN removing_VBG all_DT examples_NNS which_WDT had_VBD mismatched_VBN labels_NNS in_IN the_DT taxonomy_NN
VMs_NNS ._.
Teo_NNP et_FW al._FW -LRB-_-LRB- 23_CD -RRB-_-RRB- suggested_VBD a_DT bundle_NN method_NN and_CC Joachims_NNPS et_FW al._FW -LRB-_-LRB- 13_CD -RRB-_-RRB- gave_VBD a_DT cutting_VBG plane_NN method_NN that_WDT is_VBZ very_RB close_JJ to_TO it_PRP ;_: these_DT methods_NNS can_MD be_VB viewed_VBN as_IN extensions_NNS of_IN the_DT method_NN given_VBN by_IN Joachims_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: for_IN binary_JJ linear_JJ SVMs_NNS ._.
Collins_NNP et_FW al._FW -LRB-_-LRB- 4_CD -RRB-_-RRB- gave_VBD the_DT exponentiated_JJ gradient_NN method_NN ._.
In_IN this_DT paper_NN we_PRP present_VBP fast_RB dual_JJ methods_NNS for_IN CrammerSinger_NNP and_CC Weston-Watkins_NNP formulations_NNS ._.
Like_IN the_DT methods_NNS of_IN Cr_NN
o_NN α_NN m_NN i_LS ,_, it_PRP is_VBZ prudent_JJ to_TO use_VB a_DT linked_VBN list_NN data_NNS structure_NN and_CC store_NN only_RB those_DT α_JJ m_NN i_FW which_WDT are_VBP non-zero_JJ ._.
The_DT following_VBG convergence_NN theorem_NN can_MD be_VB proved_VBN for_IN SDM_NNP ,_, employing_VBG ideas_NNS similar_JJ to_TO those_DT in_IN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Theorem_NNP 2.1_CD Let_NNP α_NN t_NN denote_VBP the_DT α_NN at_IN the_DT end_NN of_IN the_DT t-th_NN loop_NN of_IN Algorithm_NN 2.1_CD ._.
Any_DT limit_NN point_NN of_IN a_DT convergent_JJ subsequence_NN of_IN -LCB-_-LRB- α_NN t_NN -RCB-_-RRB- is_VBZ a_DT global_JJ minimum_NN of_IN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
Because_IN of_IN space_NN limitation_NN we_PRP omit_VBP t_NN
od_NN and_CC Joachims_NNPS et_FW al._FW -LRB-_-LRB- 13_CD -RRB-_-RRB- gave_VBD a_DT cutting_VBG plane_NN method_NN that_WDT is_VBZ very_RB close_JJ to_TO it_PRP ;_: these_DT methods_NNS can_MD be_VB viewed_VBN as_IN extensions_NNS of_IN the_DT method_NN given_VBN by_IN Joachims_NNP -LRB-_-LRB- 12_CD -RRB-_-RRB- for_IN binary_JJ linear_JJ SVMs_NNS ._.
Collins_NNP et_FW al._FW =_SYM -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: gave_VBD the_DT exponentiated_JJ gradient_NN method_NN ._.
In_IN this_DT paper_NN we_PRP present_VBP fast_RB dual_JJ methods_NNS for_IN CrammerSinger_NNP and_CC Weston-Watkins_NNP formulations_NNS ._.
Like_IN the_DT methods_NNS of_IN Crammer_NNP and_CC Singer_NNP -LRB-_-LRB- 5_CD ,_, 6_CD -RRB-_-RRB- and_CC Hsu_NNP and_CC Lin_NNP -LRB-_-LRB- 10_CD
rresponding_VBG quantities_NNS of_IN the_DT algorithm_NN for_IN the_DT next_JJ C_NN value_NN ._.
This_DT is_VBZ a_DT standard_JJ seeding_NN technique_NN that_WDT improves_VBZ efficiency_NN ,_, and_CC is_VBZ also_RB used_VBN in_IN the_DT EG_NN method_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
Stochastic_JJ gradient_NN descent_NN methods_NNS =_JJ -_: =[_NN 22_CD ,_, 3_CD -RRB-_-RRB- -_: =_SYM -_: can_MD be_VB applied_VBN to_TO the_DT online_JJ version_NN of_IN -LRB-_-LRB- 1_LS -RRB-_-RRB- and_CC they_PRP are_VBP known_VBN to_TO achieve_VB steady_JJ state_NN test_NN performance_NN quite_RB fast_RB ._.
We_PRP have_VBP not_RB evaluated_VBN SDM_NN against_IN these_DT methods_NNS ._.
However_RB ,_, our_PRP$ evaluation_NN in_IN -LRB-_-LRB- 9_CD -RRB-_-RRB- sho_NN
ion_NN methods_NNS for_IN these_DT formulations_NNS ._.
Recently_RB ,_, some_DT good_JJ methods_NNS have_VBP been_VBN proposed_VBN for_IN SVMs_NNS with_IN structured_JJ outputs_NNS ,_, that_WDT also_RB specialize_VBP nicely_RB for_IN Crammer-Singer_NNP multi-class_JJ linear_JJ SVMs_NNS ._.
Teo_NNP et_FW al._FW =_SYM -_: =[_NN 23_CD -RRB-_-RRB- -_: =_SYM -_: suggested_VBD a_DT bundle_NN method_NN and_CC Joachims_NNPS et_FW al._FW -LRB-_-LRB- 13_CD -RRB-_-RRB- gave_VBD a_DT cutting_VBG plane_NN method_NN that_WDT is_VBZ very_RB close_JJ to_TO it_PRP ;_: these_DT methods_NNS can_MD be_VB viewed_VBN as_IN extensions_NNS of_IN the_DT method_NN given_VBN by_IN Joachims_NNP -LRB-_-LRB- 12_CD -RRB-_-RRB- for_IN binary_JJ line_NN
tics_NNS for_IN improving_VBG efficiency_NN Crammer_NNP and_CC Singer_NNP -LRB-_-LRB- 6_CD -RRB-_-RRB- employed_VBN two_CD heuristics_NNS to_TO speed_VB up_RP their_PRP$ algorithm_NN ._.
We_PRP employ_VBP these_DT heuristics_NNS for_IN SDM_NNP too_RB ._.
We_PRP now_RB discuss_VBP these_DT heuristics_NNS ._.
Shrinking_VBG ._.
Shrinking_VBG =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT technique_NN for_IN removing_VBG variables_NNS that_WDT are_VBP not_RB expected_VBN to_TO change_VB ,_, is_VBZ known_VBN to_TO be_VB a_DT very_RB good_JJ way_NN to_TO speed_VB up_RP decomposition_NN methods_NNS for_IN binary_JJ SVMs_NNS ._.
In_IN the_DT multi-class_JJ case_NN ,_, it_PRP may_MD turn_VB out_RP that_DT fo_NN
n_NN 6.2_CD of_IN -LRB-_-LRB- 5_CD -RRB-_-RRB- -RRB-_-RRB- and_CC -LRB-_-LRB- ii_LS -RRB-_-RRB- an_DT approximate_JJ iterative_JJ fixed-point_JJ algorithm_NN -LRB-_-LRB- see_VB section_NN 6_CD of_IN -LRB-_-LRB- 6_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Alternatively_RB ,_, one_PRP could_MD also_RB employ_VB an_DT active_JJ set_NN method_NN meant_VBN for_IN convex_NN quadratic_JJ programming_NN problems_NNS =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, starting_VBG from_IN δαi_NN =_JJ 0_CD as_IN the_DT initial_JJ point_NN ._.
Since_IN the_DT Hessian_NN of_IN the_DT objective_JJ function_NN in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- is_VBZ Ai_NN times_NNS the_DT identity_NN matrix_NN and_CC the_DT constraints_NNS of_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- are_VBP in_IN a_DT simple_JJ form_NN ,_, various_JJ linear_JJ equat_NN
r_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- has_VBZ some_DT similarities_NNS with_IN our_PRP$ sequential_JJ dual_JJ method_NN ,_, but_CC it_PRP is_VBZ given_VBN in_IN an_DT online_JJ setting_NN and_CC does_VBZ not_RB solve_VB the_DT batch_NN problem_NN ._.
Also_RB ,_, ideas_NNS such_JJ as_IN shrinking_NN do_VBP not_RB apply_VB to_TO it_PRP ._.
Bordes_NNP et_FW al._FW =_SYM -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: apply_VB a_DT coordinate_JJ descent_NN method_NN for_IN multi-class_JJ SVM_NN ,_, but_CC they_PRP focus_VBP on_IN nonlinear_JJ kernels_NNS ._.
10_CD 3_CD 10_CD 3s3_NN ._.
SDM_NN FOR_IN WESTON-WATKINS_NNP FORMULATION_NNP Let_NNP e_LS m_NN i_FW and_CC δ_NN m_NN i_FW be_VB as_IN defined_VBN in_IN section_NN 2_CD ._.
In_IN -LRB-_-LRB- 25_CD -RRB-_-RRB- ,_, We_PRP
for_IN binary_JJ classification_NN SDM_NN is_VBZ faster_RBR than_IN stochastic_JJ gradient_NN methods_NNS ._.
So_RB we_PRP expect_VBP the_DT same_JJ result_NN to_TO hold_VB for_IN the_DT multi-class_JJ case_NN too_RB ._.
The_DT modified_VBN MIRA_NN algorithm_NN proposed_VBN by_IN Crammer_NNP and_CC Singer_NNP =_SYM -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: has_VBZ some_DT similarities_NNS with_IN our_PRP$ sequential_JJ dual_JJ method_NN ,_, but_CC it_PRP is_VBZ given_VBN in_IN an_DT online_JJ setting_NN and_CC does_VBZ not_RB solve_VB the_DT batch_NN problem_NN ._.
Also_RB ,_, ideas_NNS such_JJ as_IN shrinking_NN do_VBP not_RB apply_VB to_TO it_PRP ._.
Bordes_NNP et_FW al._FW -LRB-_-LRB- 1_LS -RRB-_-RRB- a_DT
vergence_NN for_IN Algorithm_NNP 2.1_CD ._.
As_IN we_PRP remarked_VBD earlier_RBR ,_, for_IN binary_JJ classification_NN SDM_NN becomes_VBZ coordinate_JJ descent_NN ,_, a_DT standard_JJ method_NN for_IN which_WDT good_JJ convergence_NN results_NNS exist_VBP in_IN the_DT optimization_NN literature_NN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT presence_NN of_IN the_DT equality_NN constraint_NN in_IN -LRB-_-LRB- 4_CD -RRB-_-RRB- makes_VBZ the_DT multi-class_JJ version_NN somewhat_RB non-standard_JJ ._.
It_PRP is_VBZ an_DT interesting_JJ open_JJ problem_NN to_TO establish_VB linear_JJ convergence_NN for_IN Algorithm_NNP 2.1_CD ._.
Let_VB us_PRP now_RB di_FW
bject_VB Descriptors_NNP I._NNP 5.2_CD -LRB-_-LRB- Pattern_NN Recognition_NN -RRB-_-RRB- :_: Design_NN Methodology_NN --_: Classifier_NN design_NN and_CC evaluation_NN General_JJ Terms_NNS Algorithms_NNPS ,_, Performance_NNP ,_, Experimentation_NN 1_CD ._.
INTRODUCTION_NN Support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: are_VBP popular_JJ methods_NNS for_IN solving_VBG classification_NN problems_NNS ._.
An_DT SVM_NN employing_VBG a_DT nonlinear_JJ kernel_NN maps_VBZ the_DT input_NN x_NN to_TO a_DT high_JJ dimensional_JJ feature_NN space_NN via_IN a_DT nonlinear_JJ function_NN φ_NN -LRB-_-LRB- x_NN -RRB-_-RRB- and_CC forms_VBZ a_DT linear_JJ clas_NN
plane_NN ,_, bundle_NN and_CC exponentiated_JJ gradient_NN methods_NNS ._.
For_IN the_DT special_JJ case_NN of_IN binary_JJ classification_NN our_PRP$ methods_NNS turn_VBP out_RP to_TO be_VB equivalent_JJ to_TO doing_VBG coordinate_JJ descent_NN ._.
We_PRP covered_VBD this_DT method_NN in_IN detail_NN in_IN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
sTable_JJ 1.1_CD :_: Properties_NNPS of_IN datasets_NNS Dataset_NNP l_NN ltest_NN n_NN k_NN #_# nonzeros_NNS in_IN whole_JJ data_NNS NEWS20_NN 15,935_CD 3,993_CD 62,061_CD 20_CD 1,593,692_CD SECTOR_NN 6,412_CD 3,207_CD 55,197_CD 105_CD 1,569,904_CD MNIST_NNP 60,000_CD 10,000_CD 779_CD 10_CD 10,505,375_CD R_NN
rresponding_VBG quantities_NNS of_IN the_DT algorithm_NN for_IN the_DT next_JJ C_NN value_NN ._.
This_DT is_VBZ a_DT standard_JJ seeding_NN technique_NN that_WDT improves_VBZ efficiency_NN ,_, and_CC is_VBZ also_RB used_VBN in_IN the_DT EG_NN method_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
Stochastic_JJ gradient_NN descent_NN methods_NNS =_JJ -_: =[_NN 22_CD ,_, 3_CD -RRB-_-RRB- -_: =_SYM -_: can_MD be_VB applied_VBN to_TO the_DT online_JJ version_NN of_IN -LRB-_-LRB- 1_LS -RRB-_-RRB- and_CC they_PRP are_VBP known_VBN to_TO achieve_VB steady_JJ state_NN test_NN performance_NN quite_RB fast_RB ._.
We_PRP have_VBP not_RB evaluated_VBN SDM_NN against_IN these_DT methods_NNS ._.
However_RB ,_, our_PRP$ evaluation_NN in_IN -LRB-_-LRB- 9_CD -RRB-_-RRB- sho_NN
inactive_JJ variables_NNS per_IN example_NN is_VBZ quite_RB small_JJ †_NN -LRB-_-LRB- even_RB when_WRB the_DT number_NN of_IN classes_NNS is_VBZ large_JJ -RRB-_-RRB- and_CC so_RB we_PRP use_VBP this_DT method_NN in_IN our_PRP$ implementation_NN ._.
2.1_CD Heuristics_NNS for_IN improving_VBG efficiency_NN Crammer_NNP and_CC Singer_NNP =_SYM -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: employed_VBN two_CD heuristics_NNS to_TO speed_VB up_RP their_PRP$ algorithm_NN ._.
We_PRP employ_VBP these_DT heuristics_NNS for_IN SDM_NNP too_RB ._.
We_PRP now_RB discuss_VBP these_DT heuristics_NNS ._.
Shrinking_VBG ._.
Shrinking_VBG -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, a_DT technique_NN for_IN removing_VBG variables_NNS that_WDT are_VBP no_DT
literature_NN -LRB-_-LRB- see_VB -LRB-_-LRB- 18_CD -RRB-_-RRB- and_CC in_IN particular_JJ section_NN 6_CD there_EX -RRB-_-RRB- can_MD be_VB applied_VBN to_TO show_VB that_IN Algorithm_NN 3.1_CD has_VBZ linear_JJ convergence_NN ._.
Finally_RB ,_, similar_JJ to_TO section_NN 2.2_CD we_PRP can_MD argue_VB that_IN ,_, the_DT method_NN of_IN Hsu_NNP and_CC Lin_NNP =_SYM -_: =[_NN 10_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ suited_VBN for_IN nonlinear_JJ kernels_NNS ,_, but_CC SDM_NNP is_VBZ better_JJR for_IN the_DT linear_JJ SVM_NN case_NN ._.
For_IN efficiency_NN ,_, -LRB-_-LRB- 21_CD -RRB-_-RRB- can_MD be_VB solved_VBN only_RB for_IN some_DT restricted_JJ variables_NNS ,_, say_VBP only_RB the_DT δα_NN m_NN i_LS for_IN which_WDT v_LS m_NN i_LS -RRB-_-RRB- 0_CD ._.
The_DT heurist_NN
dimension_NN will_MD be_VB clear_JJ from_IN the_DT context_NN ._.
Superscript_JJ T_NN will_MD denote_VB transpose_NN for_IN vectors_NNS ._.
The_DT following_VBG multi-class_JJ datasets_NNS are_VBP used_VBN in_IN the_DT paper_NN for_IN doing_VBG various_JJ experiments_NNS :_: NEWS20_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ,_, SECTOR_NN =_JJ -_: =[_NN 20_CD ,_, 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, MNIST_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, RCV1_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- and_CC COVER_NN -LRB-_-LRB- 13_CD -RRB-_-RRB- ._.
RCV1_NN is_VBZ a_DT taxonomy_NN based_VBN multi-label_JJ dataset_NN and_CC so_RB we_PRP modified_VBD it_PRP to_TO a_DT multi-class_JJ dataset_NN by_IN removing_VBG all_DT examples_NNS which_WDT had_VBD mismatched_VBN labels_NNS in_IN the_DT taxonomy_NN
good_JJ methods_NNS have_VBP been_VBN proposed_VBN for_IN SVMs_NNS with_IN structured_JJ outputs_NNS ,_, that_WDT also_RB specialize_VBP nicely_RB for_IN Crammer-Singer_NNP multi-class_JJ linear_JJ SVMs_NNS ._.
Teo_NNP et_FW al._FW -LRB-_-LRB- 23_CD -RRB-_-RRB- suggested_VBD a_DT bundle_NN method_NN and_CC Joachims_NNPS et_FW al._FW =_SYM -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: gave_VBD a_DT cutting_VBG plane_NN method_NN that_WDT is_VBZ very_RB close_JJ to_TO it_PRP ;_: these_DT methods_NNS can_MD be_VB viewed_VBN as_IN extensions_NNS of_IN the_DT method_NN given_VBN by_IN Joachims_NNP -LRB-_-LRB- 12_CD -RRB-_-RRB- for_IN binary_JJ linear_JJ SVMs_NNS ._.
Collins_NNP et_FW al._FW -LRB-_-LRB- 4_CD -RRB-_-RRB- gave_VBD the_DT exponentiated_VBN
