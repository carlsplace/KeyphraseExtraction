Automating_VBG exploratory_JJ data_NNS analysis_NN for_IN efficient_JJ data_NNS mining_NN
iterative_JJ ,_, interactive_JJ endeavor_NN is_VBZ advocated_VBN in_IN -LRB-_-LRB- 27_CD -RRB-_-RRB- ._.
While_IN we_PRP agree_VBP with_IN this_DT philosophy_NN in_IN some_DT aspect_NN ,_, our_PRP$ primary_JJ focus_NN is_VBZ on_IN automatic_JJ process_NN ._.
Visualization_NN environment_NN for_IN EDA_NNP is_VBZ discussed_VBN in_IN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN attribute_NN selection_NN in_IN unsupervised_JJ learning_NN see_VB -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
Two_CD models_NNS ,_, filter_NN and_CC wrapper_NN ,_, exist_VBP for_IN attribute_NN selection_NN and_CC both_DT are_VBP described_VBN in_IN -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
For_IN an_DT earlier_JJR work_NN on_IN attribute_NN selection_NN see_VBP
near_IN statistical_JJ modeling_NN ,_, many_JJ similar_JJ approaches_NNS have_VBP been_VBN used_VBN ;_: most_RBS notably_RB ,_, principal_JJ component_NN analysis_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
The_DT idea_NN that_IN EDA_NNP is_VBZ inherently_RB an_DT iterative_JJ ,_, interactive_JJ endeavor_NN is_VBZ advocated_VBN in_IN =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
While_IN we_PRP agree_VBP with_IN this_DT philosophy_NN in_IN some_DT aspect_NN ,_, our_PRP$ primary_JJ focus_NN is_VBZ on_IN automatic_JJ process_NN ._.
Visualization_NN environment_NN for_IN EDA_NNP is_VBZ discussed_VBN in_IN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
For_IN attribute_NN selection_NN in_IN unsupervised_JJ learning_NN
e_LS and_CC descriptive_JJ engines_NNS ,_, much_RB of_IN our_PRP$ focus_NN has_VBZ been_VBN on_IN the_DT efficient_JJ building_NN of_IN models_NNS using_VBG standard_JJ predictive_JJ techniques_NNS :_: neural_JJ networks_NNS -LRB-_-LRB- 12,11_CD -RRB-_-RRB- ,_, classification_NN and_CC regression_NN decision_NN trees_NNS =_JJ -_: =[_NN 2_CD ,_, 25_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC Bayesian_JJ learning_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
Due_JJ to_TO the_DT practical_JJ limitations_NNS of_IN commercial_JJ mining_NN ,_, we_PRP have_VBP tried_VBN to_TO achieve_VB a_DT balance_NN between_IN the_DT time_NN spent_VBN on_IN data_NNS exploration_NN and_CC the_DT gains_NNS we_PRP get_VBP in_IN this_DT process_NN ._.
mber_NN of_IN groups_NNS or_CC thresholds_NNS and_CC their_PRP$ location_NN ._.
For_IN a_DT continuous_JJ attribute_NN and_CC a_DT fixed_JJ number_NN of_IN thresholding_JJ intervals_NNS ,_, the_DT corresponding_JJ cut_NN points_NNS are_VBP optimized_VBN by_IN means_NNS of_IN an_DT annealing_NN algorithm_NN =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN practice_NN ,_, we_PRP also_RB impose_VBP a_DT lower_JJR bound_VBN on_IN the_DT number_NN of_IN cases_NNS per_IN thresholding_NN interval_NN to_TO ensure_VB that_IN the_DT ranges_NNS are_VBP relevant_JJ ._.
For_IN a_DT categorical_JJ attribute_NN and_CC a_DT fixed_JJ number_NN of_IN groups_NNS -LRB-_-LRB- less_JJR than_IN
e_LS and_CC descriptive_JJ engines_NNS ,_, much_RB of_IN our_PRP$ focus_NN has_VBZ been_VBN on_IN the_DT efficient_JJ building_NN of_IN models_NNS using_VBG standard_JJ predictive_JJ techniques_NNS :_: neural_JJ networks_NNS -LRB-_-LRB- 12,11_CD -RRB-_-RRB- ,_, classification_NN and_CC regression_NN decision_NN trees_NNS =_JJ -_: =[_NN 2_CD ,_, 25_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC Bayesian_JJ learning_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
Due_JJ to_TO the_DT practical_JJ limitations_NNS of_IN commercial_JJ mining_NN ,_, we_PRP have_VBP tried_VBN to_TO achieve_VB a_DT balance_NN between_IN the_DT time_NN spent_VBN on_IN data_NNS exploration_NN and_CC the_DT gains_NNS we_PRP get_VBP in_IN this_DT process_NN ._.
le_DT we_PRP agree_VBP with_IN this_DT philosophy_NN in_IN some_DT aspect_NN ,_, our_PRP$ primary_JJ focus_NN is_VBZ on_IN automatic_JJ process_NN ._.
Visualization_NN environment_NN for_IN EDA_NNP is_VBZ discussed_VBN in_IN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
For_IN attribute_NN selection_NN in_IN unsupervised_JJ learning_NN see_VBP =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Two_CD models_NNS ,_, filter_NN and_CC wrapper_NN ,_, exist_VBP for_IN attribute_NN selection_NN and_CC both_DT are_VBP described_VBN in_IN -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
For_IN an_DT earlier_JJR work_NN on_IN attribute_NN selection_NN see_VBP -LRB-_-LRB- 16_CD -RRB-_-RRB- ._.
The_DT Markov_NNP Blanket_NNP attribute_NN selection_NN algorithm_NN i_FW
of_IN our_PRP$ focus_NN has_VBZ been_VBN on_IN the_DT efficient_JJ building_NN of_IN models_NNS using_VBG standard_JJ predictive_JJ techniques_NNS :_: neural_JJ networks_NNS -LRB-_-LRB- 12,11_CD -RRB-_-RRB- ,_, classification_NN and_CC regression_NN decision_NN trees_NNS -LRB-_-LRB- 2_CD ,_, 25_CD -RRB-_-RRB- ,_, and_CC Bayesian_JJ learning_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Due_JJ to_TO the_DT practical_JJ limitations_NNS of_IN commercial_JJ mining_NN ,_, we_PRP have_VBP tried_VBN to_TO achieve_VB a_DT balance_NN between_IN the_DT time_NN spent_VBN on_IN data_NNS exploration_NN and_CC the_DT gains_NNS we_PRP get_VBP in_IN this_DT process_NN ._.
In_IN this_DT paper_NN ,_, we_PRP assume_VBP th_DT
e_LS measures_NNS was_VBD significant_JJ ,_, we_PRP ran_VBD multiple_JJ models_NNS with_IN different_JJ training_NN and_CC verification_NN sets_NNS ._.
We_PRP calculated_VBD from_IN formulas_NNS that_IN the_DT top_JJ 5_CD %_NN lift_NN had_VBD a_DT standard_JJ deviation_NN of_IN 0.11_CD and_CC the_DT ROC_NN metrics_NNS =_JJ -_: =[_NN 20_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: had_VBD a_DT standard_JJ deviation_NN of_IN 0.0037_CD ._.
Second_JJ ,_, these_DT results_NNS were_VBD obtained_VBN using_VBG a_DT boosted_VBN naYve_NN bayesian_JJ classifier_NN ;_: a_DT classification_NN tree_NN induction_NN technique_NN produced_VBD analogous_JJ results_NNS ._.
8_CD Related_JJ Work_NN
chniques_NNS are_VBP well-described_JJ in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
Grouping_NN of_IN categorical_JJ values_NNS as_IN it_PRP relates_VBZ to_TO tree_NN induction_NN techniques_NNS is_VBZ discussed_VBN in_IN -LRB-_-LRB- 25_CD -RRB-_-RRB- while_IN thresholding_NN of_IN continuous_JJ variables_NNS is_VBZ discussed_VBN in_IN -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
in_IN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: information_NN based_JJ thresholding_NN of_IN continuous_JJ attributes_NNS is_VBZ augmented_VBN by_IN the_DT use_NN of_IN the_DT minimal_JJ description_NN length_NN principal_NN ._.
A_DT comprehensive_JJ introduction_NN to_TO information_NN theory_NN is_VBZ contained_VBN in_IN -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
Fo_NN
isualization_NN environment_NN for_IN EDA_NNP is_VBZ discussed_VBN in_IN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
For_IN attribute_NN selection_NN in_IN unsupervised_JJ learning_NN see_VB -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
Two_CD models_NNS ,_, filter_NN and_CC wrapper_NN ,_, exist_VBP for_IN attribute_NN selection_NN and_CC both_DT are_VBP described_VBN in_IN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN an_DT earlier_JJR work_NN on_IN attribute_NN selection_NN see_VBP -LRB-_-LRB- 16_CD -RRB-_-RRB- ._.
The_DT Markov_NNP Blanket_NNP attribute_NN selection_NN algorithm_NN is_VBZ a_DT modification_NN of_IN the_DT algorithm_NN introduced_VBN in_IN -LRB-_-LRB- 18_CD -RRB-_-RRB- ._.
inconsistency_NN Rate_NNP ,_, utilized_VBN in_IN iR_NN attr_NN
e_LS measures_NNS was_VBD significant_JJ ,_, we_PRP ran_VBD multiple_JJ models_NNS with_IN different_JJ training_NN and_CC verification_NN sets_NNS ._.
We_PRP calculated_VBD from_IN formulas_NNS that_IN the_DT top_JJ 5_CD %_NN lift_NN had_VBD a_DT standard_JJ deviation_NN of_IN 0.11_CD and_CC the_DT ROC_NN metrics_NNS =_JJ -_: =[_NN 20_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: had_VBD a_DT standard_JJ deviation_NN of_IN 0.0037_CD ._.
Second_JJ ,_, these_DT results_NNS were_VBD obtained_VBN using_VBG a_DT boosted_VBN naYve_NN bayesian_JJ classifier_NN ;_: a_DT classification_NN tree_NN induction_NN technique_NN produced_VBD analogous_JJ results_NNS ._.
8_CD Related_JJ Work_NN
e_LS and_CC multivariate_JJ transformations_NNS ._.
When_WRB all_DT original_JJ and_CC new_JJ derived_VBN attributes_NNS are_VBP cleansed_VBN ,_, confirmed_VBN to_TO be_VB appropriate_JJ ,_, and_CC discretized_VBN ,_, EDA_NNP uses_VBZ two_CD independent_JJ approaches_NNS to_TO attribute_VB selection_NN =_JJ -_: =[_NN 18_CD ,_, 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, both_DT of_IN which_WDT are_VBP based_VBN on_IN filter_NN 4_CD model_NN selection_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
Using_VBG two_CD algorithms_NNS provides_VBZ additional_JJ flexibility_NN and_CC increases_VBZ our_PRP$ confidence_NN in_IN the_DT results_NNS ._.
3_CD Inappropriate_JJ and_CC Suspicious_JJ Attributes_NNS
rget_NN beyond_IN a_DT specified_JJ threshold_NN ,_, that_IN transformation_NN is_VBZ retained_VBN for_IN further_JJ processing_NN ._.
EDA_NNP relies_VBZ on_IN the_DT fact_NN that_IN the_DT concept_NN of_IN correlation_NN can_MD be_VB generalized_VBN to_TO a_DT continuous-categorical_JJ couple_NN =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_SYM -_: so_IN that_IN these_DT transforms_VBZ can_MD be_VB used_VBN regardless_RB of_IN whether_IN the_DT target_NN is_VBZ continuous_JJ or_CC categorical_JJ ._.
EDA_NNP also_RB supports_VBZ exploring_VBG functions_NNS of_IN several_JJ continuous_JJ attributes_NNS ,_, including_VBG linear_JJ combinatio_NN
butes_NNS are_VBP processed_VBN to_TO determine_VB the_DT most_RBS appropriate_JJ representation_NN ._.
This_DT step_NN handles_VBZ outliers_NNS ,_, missing_VBG values_NNS ,_, and_CC encoding_NN ._.
Continuous_JJ attributes_NNS are_VBP encoded_VBN by_IN thresholding_NN -LRB-_-LRB- a.k.a._NN discretizing_NN -RRB-_-RRB- =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: the_DT original_JJ values_NNS into_IN a_DT small_JJ number_NN of_IN value_NN ranges_NNS ._.
For_IN categorical_JJ attributes_NNS ,_, encoding_NN merges_VBZ several_JJ values_NNS -LRB-_-LRB- categories_NNS -RRB-_-RRB- together_RB ._.
This_DT grouping_NN is_VBZ similar_JJ to_TO a_DT subset_NN option_NN in_IN C4_NN .5_CD -LRB-_-LRB- 25_CD -RRB-_-RRB- ._.
As_IN
s_NNS were_VBD obtained_VBN using_VBG a_DT boosted_VBN naYve_NN bayesian_JJ classifier_NN ;_: a_DT classification_NN tree_NN induction_NN technique_NN produced_VBD analogous_JJ results_NNS ._.
8_CD Related_NNP Work_NNP Data_NNP preprocessing_NN is_VBZ a_DT standard_JJ practice_NN in_IN statistics_NNS =_JJ -_: =[_NN 28_CD -RRB-_-RRB- -_: =_JJ -_: ,_, pattern_NN recognition_NN and_CC data_NN mining_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ._.
Generic_JJ data_NNS cleansing_VBG techniques_NNS are_VBP well-described_JJ in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
Grouping_NN of_IN categorical_JJ values_NNS as_IN it_PRP relates_VBZ to_TO tree_NN induction_NN techniques_NNS is_VBZ discussed_VBN in_IN -LRB-_-LRB- 25_CD
econd_JJ association_NN measure_NN based_VBN on_IN chi-squared_JJ statistic_NN z2_NN -LRB-_-LRB- X_NN ,_, Y_NN -RRB-_-RRB- =_JJ N_NNP F._NNP jq_NN -LRB-_-LRB- Pjq_NN -_: pj_NN ._.
p._NN q_NN -RRB-_-RRB- 2_CD \/_: -LRB-_-LRB- pj_NN ._.
p._NN q_NN -RRB-_-RRB- ._.
where_WRB N_NN is_VBZ total_JJ number_NN of_IN cases_NNS ._.
A_DT well_RB known_VBN normalization_NN of_IN chi-squared_JJ statistic_NN scaled_VBN to_TO =_JJ -_: =[_NN 0,1_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT represents_VBZ the_DT strength_NN of_IN association_NN is_VBZ Cramer_NNP 's_POS V_NN -LRB-_-LRB- 24_CD -RRB-_-RRB- V_NN -LRB-_-LRB- X_NN ,_, Y_NN -RRB-_-RRB- =_JJ z2_NN -LRB-_-LRB- X_NN ,_, Y_NN -RRB-_-RRB- \/_: -LRB-_-LRB- N_NN rain_NN -LRB-_-LRB- Q_NNP ,_, J_NNP -RRB-_-RRB- -_: l_NN -RRB-_-RRB- ._.
The_DT third_JJ measure_NN of_IN association_NN used_VBN in_IN EDA_NNP is_VBZ a_DT Goodman-Kruskal_JJ association_NN index_NN ._.
Consider_VB a_DT
q_RB ,_, mutual_JJ information_NN I_CD -LRB-_-LRB- x_NN ,_, -RRB-_-RRB- is_VBZ defined_VBN as_IN I_NN -LRB-_-LRB- X_NN ,_, Y_NN -RRB-_-RRB- =_JJ F._NNP jq_NN Pjq_NN log_NN -LRB-_-LRB- Pjq_NN \/_: Pj_NN ._.
P._FW q_FW -RRB-_-RRB- ._.
where_WRB we_PRP use_VBP base_NN two_CD logarithm_NN if_IN the_DT information_NN units_NNS are_VBP bits_NNS ._.
This_DT measure_NN is_VBZ widely_RB used_VBN in_IN information_NN theory_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: and_CC machine_NN learning_NN -LRB-_-LRB- 25_CD -RRB-_-RRB- ._.
It_PRP is_VBZ sometimes_RB referred_VBN to_TO as_IN information_NN gain_NN ,_, due_JJ to_TO a_DT property_NN that_IN it_PRP is_VBZ equal_JJ to_TO a_DT decrease_NN in_IN entropy_NN H_NN -LRB-_-LRB- -RRB-_-RRB- -_: H_NN -LRB-_-LRB- I_NN X_NN -RRB-_-RRB- caused_VBN by_IN knowing_VBG x_NN ,_, where_WRB H_NN -LRB-_-LRB- X_NN -RRB-_-RRB- =_JJ -_: ._.
q_FW P._FW q_FW 1_CD
e_LS and_CC multivariate_JJ transformations_NNS ._.
When_WRB all_DT original_JJ and_CC new_JJ derived_VBN attributes_NNS are_VBP cleansed_VBN ,_, confirmed_VBN to_TO be_VB appropriate_JJ ,_, and_CC discretized_VBN ,_, EDA_NNP uses_VBZ two_CD independent_JJ approaches_NNS to_TO attribute_VB selection_NN =_JJ -_: =[_NN 18_CD ,_, 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, both_DT of_IN which_WDT are_VBP based_VBN on_IN filter_NN 4_CD model_NN selection_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
Using_VBG two_CD algorithms_NNS provides_VBZ additional_JJ flexibility_NN and_CC increases_VBZ our_PRP$ confidence_NN in_IN the_DT results_NNS ._.
3_CD Inappropriate_JJ and_CC Suspicious_JJ Attributes_NNS
