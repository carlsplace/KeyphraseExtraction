Experimental_JJ comparisons_NNS of_IN online_NN and_CC batch_NN versions_NNS of_IN bagging_VBG and_CC boosting_VBG
Bagging_VBG and_CC boosting_VBG are_VBP well-known_JJ ensemble_NN learning_NN methods_NNS ._.
They_PRP combine_VBP multiple_JJ learned_VBN base_NN models_NNS with_IN the_DT aim_NN of_IN improving_VBG generalization_NN performance_NN ._.
To_TO date_NN ,_, they_PRP have_VBP been_VBN used_VBN primarily_RB in_IN batch_NN mode_NN ,_, i.e._FW ,_, they_PRP require_VBP multiple_JJ passes_NNS through_IN the_DT training_NN data_NNS ._.
In_IN previous_JJ work_NN ,_, we_PRP presented_VBD online_NN bagging_VBG and_CC boosting_VBG algorithms_NNS that_WDT only_RB require_VBP one_CD pass_NN through_IN the_DT training_NN data_NNS and_CC presented_VBN experimental_JJ results_NNS on_IN some_DT relatively_RB small_JJ datasets_NNS ._.
Through_IN additional_JJ experiments_NNS on_IN a_DT variety_NN of_IN larger_JJR synthetic_JJ and_CC real_JJ datasets_NNS ,_, this_DT paper_NN demonstrates_VBZ that_IN our_PRP$ online_JJ versions_NNS perform_VBP comparably_RB to_TO their_PRP$ batch_NN counterparts_NNS in_IN terms_NNS of_IN classification_NN accuracy_NN ._.
We_PRP also_RB demonstrate_VBP the_DT substantial_JJ reduction_NN in_IN running_VBG time_NN we_PRP obtain_VBP with_IN our_PRP$ online_JJ algorithms_NNS because_IN they_PRP require_VBP fewer_JJR passes_NNS through_IN the_DT training_NN data_NNS ._.
zes_NNS of_IN the_DT training_NN and_CC test_NN sets_NNS in_IN oursve-fold_JJ crossvalidation_NN runs_NNS ._.
Data_NNP Set_NNP Training_NNP Test_NNP Inputs_NNP Classes_NNS Set_FW Set_FW Promoters_NNS 84_CD 22_CD 57_CD 2_CD Balance_NN 500_CD 125_CD 4_CD 3_CD Soybean-Large_NN 307_CD 376_CD 35_CD 19_CD Breast_NN Cancer_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: 559_CD 140_CD 9_CD 2_CD German_NNP Credit_NNP 800_CD 200_CD 20_CD 2_CD Car_NN Evaluation_NN 1382_CD 346_CD 6_CD 4_CD Chess_NNP 2556_CD 640_CD 36_CD 2_CD Mushroom_NN 6499_CD 1625_CD 22_CD 2_CD Nursery_NN 10368_CD 2592_CD 8_CD 5_CD Connect4_NN 54045_CD 13512_CD 42_CD 3_CD Synthetic-1_NN 80000_CD 20000_CD 20_CD 2_CD Synthetic_JJ -_:
twork_VB and_CC use_VB it_PRP to_TO classify_VB examples_NNS ._.
1_CD Ensemble_NN learning_NN algorithms_NNS combine_VBP the_DT predictions_NNS of_IN multiple_JJ base_NN models_NNS ,_, each_DT of_IN which_WDT is_VBZ learned_VBN using_VBG a_DT traditional_JJ algorithm_NN ._.
Bagging_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- and_CC Boosting_VBG =_JJ -_: =[_NN 4_CD -_: =-]_CD are_VBP well-known_JJ ensemble_NN learning_NN algorithms_NNS that_WDT have_VBP been_VBN shown_VBN to_TO be_VB very_RB eective_JJ in_IN improving_VBG generalization_NN performance_NN compared_VBN to_TO the_DT individual_JJ base_NN models_NNS ._.
Theoretical_JJ analysis_NN of_IN boosting_VBG 's_POS
tree_NN or_CC neural_JJ network_NN and_CC use_VB it_PRP to_TO classify_VB examples_NNS ._.
1_CD Ensemble_NN learning_NN algorithms_NNS combine_VBP the_DT predictions_NNS of_IN multiple_JJ base_NN models_NNS ,_, each_DT of_IN which_WDT is_VBZ learned_VBN using_VBG a_DT traditional_JJ algorithm_NN ._.
Bagging_VBG =_JJ -_: =[_NN 3_CD -_: =-]_NN and_CC Boosting_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- are_VBP well-known_JJ ensemble_NN learning_NN algorithms_NNS that_WDT have_VBP been_VBN shown_VBN to_TO be_VB very_RB eective_JJ in_IN improving_VBG generalization_NN performance_NN compared_VBN to_TO the_DT individual_JJ base_NN models_NNS ._.
Theoretical_JJ analy_NN
s_NNS having_VBG 600MHz_NNP Pentium_NNP III_NNP processors_NNS and_CC 2GB_NN of_IN memory_NN ._.
4.1_CD The_DT Data_NN We_PRP tested_VBD our_PRP$ algorithms_NNS on_IN several_JJ UCI_NN datasets_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, two_CD datasets_NNS -LRB-_-LRB- Census_NNP Income_NNP and_CC Forest_NNP Covertype_NNP -RRB-_-RRB- from_IN the_DT UCI_NNP KDD_NNP archive_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC three_CD synthetic_JJ datasets_NNS ._.
We_PRP give_VBP their_PRP$ sizes_NNS and_CC numbers_NNS of_IN attributes_NNS and_CC classes_NNS in_IN Table_NNP 1_CD ._.
All_DT three_CD of_IN our_PRP$ synthetic_JJ datasets_NNS have_VBP two_CD classes_NNS ._.
The_DT prior_JJ probability_NN of_IN each_DT class_NN is_VBZ 0.5_CD ,_,
rithms_NNS are_VBP essentially_RB identical_JJ ._.
We_PRP ran_VBD these_DT experiments_NNS on_IN Dell_NNP 6350_CD computers_NNS having_VBG 600MHz_NNP Pentium_NNP III_NNP processors_NNS and_CC 2GB_NN of_IN memory_NN ._.
4.1_CD The_DT Data_NN We_PRP tested_VBD our_PRP$ algorithms_NNS on_IN several_JJ UCI_NN datasets_NNS =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: ,_, two_CD datasets_NNS -LRB-_-LRB- Census_NNP Income_NNP and_CC Forest_NNP Covertype_NNP -RRB-_-RRB- from_IN the_DT UCI_NNP KDD_NNP archive_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ,_, and_CC three_CD synthetic_JJ datasets_NNS ._.
We_PRP give_VBP their_PRP$ sizes_NNS and_CC numbers_NNS of_IN attributes_NNS and_CC classes_NNS in_IN Table_NNP 1_CD ._.
All_DT three_CD of_IN our_PRP$ s_NN
we_PRP discuss_VBP some_DT experiments_NNS that_WDT demonstrate_VBP the_DT performance_NN of_IN our_PRP$ online_JJ algorithms_NNS relative_JJ to_TO their_PRP$ batch_NN counterparts_NNS ._.
For_IN decision_NN trees_NNS ,_, we_PRP have_VBP reimplemented_VBN the_DT lossless_JJ ITI_NNP online_NN algorithm_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: in_IN C_NN +_CC +_CC ;_: batch_NN and_CC online_NN Naive_JJ Bayes_NNP algorithms_NNS are_VBP essentially_RB identical_JJ ._.
We_PRP ran_VBD these_DT experiments_NNS on_IN Dell_NNP 6350_CD computers_NNS having_VBG 600MHz_NNP Pentium_NNP III_NNP processors_NNS and_CC 2GB_NN of_IN memory_NN ._.
4.1_CD The_DT Data_NN We_PRP test_VBP
n_NN shown_VBN to_TO be_VB very_RB eective_JJ in_IN improving_VBG generalization_NN performance_NN compared_VBN to_TO the_DT individual_JJ base_NN models_NNS ._.
Theoretical_JJ analysis_NN of_IN boosting_VBG 's_POS performance_NN supports_VBZ these_DT results_NNS -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
In_IN previous_JJ work_NN -LRB-_-LRB- =_JJ -_: =_JJ 7_CD -RRB-_-RRB- ,_, we_PRP -_: =_SYM -_: developed_VBD online_JJ versions_NNS of_IN these_DT algorithms_NNS ._.
Online_JJ learning_NN algorithms_NNS process_VBP each_DT training_NN instance_NN once_IN \_NN on_IN arrival_NN ''_'' without_IN the_DT need_NN for_IN storage_NN and_CC reprocessing_NN ,_, and_CC maintain_VB a_DT current_JJ hy_NN
