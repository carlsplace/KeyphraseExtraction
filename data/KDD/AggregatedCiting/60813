A_DT probabilistic_JJ framework_NN for_IN semi-supervised_JJ clustering_NN
Unsupervised_JJ clustering_NN can_MD be_VB significantly_RB improved_VBN using_VBG supervision_NN in_IN the_DT form_NN of_IN pairwise_JJ constraints_NNS ,_, i.e._FW ,_, pairs_NNS of_IN instances_NNS labeled_VBN as_IN belonging_VBG to_TO same_JJ or_CC different_JJ clusters_NNS ._.
In_IN recent_JJ years_NNS ,_, a_DT number_NN of_IN algorithms_NNS have_VBP been_VBN proposed_VBN for_IN enhancing_VBG clustering_NN quality_NN by_IN employing_VBG such_JJ supervision_NN ._.
Such_JJ methods_NNS use_VBP the_DT constraints_NNS to_TO either_RB modify_VB the_DT objective_JJ function_NN ,_, or_CC to_TO learn_VB the_DT distance_NN measure_NN ._.
We_PRP propose_VBP a_DT probabilistic_JJ model_NN for_IN semi-supervised_JJ clustering_NN based_VBN on_IN Hidden_NNP Markov_NNP Random_NNP Fields_NNP -LRB-_-LRB- HMRFs_NNS -RRB-_-RRB- that_WDT provides_VBZ a_DT principled_JJ framework_NN for_IN incorporating_VBG supervision_NN into_IN prototype-based_JJ clustering_NN ._.
The_DT model_NN generalizes_VBZ a_DT previous_JJ approach_NN that_WDT combines_VBZ constraints_NNS and_CC Euclidean_JJ distance_NN learning_NN ,_, and_CC allows_VBZ the_DT use_NN of_IN a_DT broad_JJ range_NN of_IN clustering_NN distortion_NN measures_NNS ,_, including_VBG Bregman_NNP divergences_NNS -LRB-_-LRB- e.g._FW ,_, Euclidean_JJ distance_NN and_CC I-divergence_NN -RRB-_-RRB- and_CC directional_JJ similarity_NN measures_NNS -LRB-_-LRB- e.g._FW ,_, cosine_NN similarity_NN -RRB-_-RRB- ._.
We_PRP present_VBP an_DT algorithm_NN that_WDT performs_VBZ partitional_JJ semi-supervised_JJ clustering_NN of_IN data_NNS by_IN minimizing_VBG an_DT objective_JJ function_NN derived_VBN from_IN the_DT posterior_JJ energy_NN of_IN the_DT HMRF_NN model_NN ._.
Experimental_JJ results_NNS on_IN several_JJ text_NN data_NNS sets_NNS demonstrate_VBP the_DT advantages_NNS of_IN the_DT proposed_VBN framework_NN ._.
t_NN kinds_NNS of_IN gene_NN representations_NNS ,_, for_IN which_WDT different_JJ clustering_NN distance_NN measures_NNS would_MD be_VB appropriate_JJ ,_, e.g._FW ,_, Pearson_NNP 's_POS correlation_NN would_MD be_VB an_DT appropriate_JJ distortion_NN measure_NN for_IN gene_NN microarray_NN data_NN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: ,_, I-divergence_NN would_MD be_VB useful_JJ for_IN the_DT phylogenetic_JJ profile_NN representation_NN of_IN genes_NNS -LRB-_-LRB- 30_CD -RRB-_-RRB- ,_, etc._NN ._.
We_PRP plan_VBP to_TO run_VB experiments_NNS for_IN clustering_VBG these_DT datasets_NNS using_VBG the_DT HMRF-KMEANS_NN algorithm_NN ,_, where_WRB the_DT const_NN
measure_NN based_VBN on_IN the_DT angle_NN between_IN vectors_NNS is_VBZ more_RBR appropriate_JJ -LRB-_-LRB- 1_LS -RRB-_-RRB- ._.
Consequently_RB ,_, clustering_NN algorithms_NNS that_WDT utilize_VBP distortion_NN measures_NNS appropriate_JJ for_IN directional_JJ data_NNS have_VBP recently_RB been_VBN developed_VBN =_JJ -_: =[_NN 18_CD ,_, 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Our_PRP$ unified_JJ semi-supervised_JJ clustering_NN framework_NN based_VBN on_IN HMRFs_NNS is_VBZ also_RB applicable_JJ to_TO such_JJ directional_JJ similarity_NN measures_NNS ._.
To_TO summarize_VB ,_, the_DT proposed_VBN approach_NN aids_VBZ unsupervised_JJ clustering_NN by_IN incorp_NN
r_NN ,_, we_PRP focus_VBP on_IN semi-supervised_JJ clustering_NN ,_, where_WRB the_DT performance_NN of_IN unsupervised_JJ clustering_NN algorithms_NNS is_VBZ improved_VBN with_IN limited_JJ amounts_NNS of_IN supervision_NN in_IN the_DT form_NN of_IN labels_NNS on_IN the_DT data_NNS or_CC constraints_NNS =_JJ -_: =[_NN 38_CD ,_, 6_CD ,_, 27_CD ,_, 39_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Existing_VBG methods_NNS for_IN semi-supervised_JJ clustering_NN fall_NN into_IN two_CD general_JJ categories_NNS which_WDT we_PRP call_VBP constraint-based_JJ and_CC distancebased_JJ ._.
Constraint-based_JJ methods_NNS rely_VBP on_IN user-provided_JJ labels_NNS or_CC constraint_NN
is_VBZ objective_JJ function_NN ._.
Previously_RB ,_, we_PRP proposed_VBD a_DT unified_JJ approach_NN to_TO semi-supervised_JJ clustering_NN that_WDT was_VBD experimentally_RB shown_VBN to_TO produce_VB more_RBR accurate_JJ clusters_NNS than_IN other_JJ methods_NNS on_IN several_JJ data_NNS sets_VBZ =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, this_DT approach_NN is_VBZ restricted_JJ to_TO using_VBG Euclidean_JJ distance_NN as_IN the_DT clustering_NN distortion_NN measure_NN ._.
In_IN this_DT paper_NN ,_, we_PRP show_VBP how_WRB to_TO generalize_VB that_DT model_NN to_TO handle_VB non-Euclidean_JJ measures_NNS ._.
Our_PRP$ gener_NN
ality_NN of_IN the_DT clustering_NN with_IN respect_NN to_TO a_DT given_JJ underlying_JJ class_NN labeling_NN of_IN the_DT data_NNS :_: it_PRP measures_VBZ how_WRB closely_RB the_DT clustering_NN algorithm_NN could_MD reconstruct_VB the_DT underlying_JJ label_NN distribution_NN in_IN the_DT data_NN =_JJ -_: =[_NN 37_CD ,_, 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
If_IN C_NN is_VBZ the_DT random_JJ variable_NN denoting_VBG the_DT cluster_NN assignments_NNS of_IN the_DT points_NNS and_CC K_NN is_VBZ the_DT random_JJ variable_NN denoting_VBG the_DT underlying_VBG class_NN labels_NNS on_IN the_DT points_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, then_RB the_DT NMI_NNP measure_NN is_VBZ defined_VBN as_IN :_: NM_NN
borhoods_NNS are_VBP selected_VBN as_IN initial_JJ clusters_NNS using_VBG the_DT clustering_NN distortion_NN measure_NN ._.
Farthest-first_JJ traversal_NN is_VBZ a_DT good_JJ heuristic_NN for_IN initialization_NN in_IN prototype-based_JJ partitional_JJ clustering_NN algorithms_NNS =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT goal_NN in_IN farthest-first_JJ traversal_NN is_VBZ to_TO find_VB K_NN points_NNS that_WDT are_VBP maximally_RB separated_VBN from_IN each_DT other_JJ in_IN terms_NNS of_IN a_DT given_VBN distance_NN function_NN ._.
In_IN our_PRP$ case_NN ,_, we_PRP apply_VBP a_DT weighted_JJ variant_NN of_IN farthest-firs_NNS
an_DT ``_`` incomplete-data_JJ problem_NN ''_'' ,_, for_IN which_WDT a_DT popular_JJ solution_NN method_NN is_VBZ Expectation_NN Maximization_NN -LRB-_-LRB- EM_NN -RRB-_-RRB- -LRB-_-LRB- 16_CD -RRB-_-RRB- ._.
It_PRP is_VBZ well-known_JJ that_IN KMeans_NN is_VBZ equivalent_JJ to_TO an_DT EM_NN algorithm_NN with_IN hard_JJ clustering_NN assignments_NNS =_JJ -_: =[_NN 26_CD ,_, 6_CD ,_, 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Section_NN 3.2_CD describes_VBZ a_DT K-Means-type_JJ hard_JJ partitional_JJ clustering_NN algorithm_NN ,_, HMRF-KMEANS_NN ,_, that_WDT finds_VBZ a_DT -LRB-_-LRB- local_JJ -RRB-_-RRB- maximum_NN of_IN the_DT above_JJ function_NN ._.
The_DT posterior_JJ probability_NN Pr_NN -LRB-_-LRB- L_NN |_NN X_NN -RRB-_-RRB- in_IN Eqn_NN ._.
-LRB-_-LRB- 5_CD -RRB-_-RRB- has_VBZ 2_CD compo_NN
be_VB appropriate_JJ ,_, e.g._FW ,_, Pearson_NNP 's_POS correlation_NN would_MD be_VB an_DT appropriate_JJ distortion_NN measure_NN for_IN gene_NN microarray_NN data_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, I-divergence_NN would_MD be_VB useful_JJ for_IN the_DT phylogenetic_JJ profile_NN representation_NN of_IN genes_NNS =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_JJ -_: ,_, etc._NN ._.
We_PRP plan_VBP to_TO run_VB experiments_NNS for_IN clustering_VBG these_DT datasets_NNS using_VBG the_DT HMRF-KMEANS_NN algorithm_NN ,_, where_WRB the_DT constraints_NNS will_MD be_VB inferred_VBN from_IN protein_NN interaction_NN databases_NNS as_RB well_RB as_IN from_IN function_NN path_NN
ality_NN of_IN the_DT clustering_NN with_IN respect_NN to_TO a_DT given_JJ underlying_JJ class_NN labeling_NN of_IN the_DT data_NNS :_: it_PRP measures_VBZ how_WRB closely_RB the_DT clustering_NN algorithm_NN could_MD reconstruct_VB the_DT underlying_JJ label_NN distribution_NN in_IN the_DT data_NN =_JJ -_: =[_NN 37_CD ,_, 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
If_IN C_NN is_VBZ the_DT random_JJ variable_NN denoting_VBG the_DT cluster_NN assignments_NNS of_IN the_DT points_NNS and_CC K_NN is_VBZ the_DT random_JJ variable_NN denoting_VBG the_DT underlying_VBG class_NN labels_NNS on_IN the_DT points_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, then_RB the_DT NMI_NNP measure_NN is_VBZ defined_VBN as_IN :_: NM_NN
work_NN on_IN distance-based_JJ semi-supervised_JJ clustering_NN with_IN pairwise_JJ constraints_NNS ,_, Cohn_NNP et_FW al._FW -LRB-_-LRB- 13_CD -RRB-_-RRB- used_VBD gradient_NN descent_NN for_IN weighted_JJ Jensen-Shannon_NNP divergence_NN in_IN the_DT context_NN of_IN EM_NN clustering_NN ._.
Xing_NNP et_FW al._FW =_SYM -_: =[_NN 39_CD -RRB-_-RRB- -_: =_SYM -_: utilized_VBD a_DT combination_NN of_IN gradient_NN descent_NN and_CC iterative_JJ projections_NNS to_TO learn_VB a_DT Mahalanobis_NNP distance_NN for_IN K-Means_NN clustering_NN ._.
The_DT Redundant_JJ Component_NN Analysis_NN -LRB-_-LRB- RCA_NN -RRB-_-RRB- algorithm_NN used_VBD only_RB must-link_JJ const_NN
e_LS to_TO generate_VB ,_, since_IN labeling_NN typically_RB requires_VBZ human_JJ expertise_NN ._.
Consequently_RB ,_, semi-supervised_JJ learning_NN ,_, which_WDT uses_VBZ both_DT labeled_JJ and_CC unlabeled_JJ data_NNS ,_, has_VBZ become_VBN a_DT topic_NN of_IN significant_JJ recent_JJ interest_NN =_JJ -_: =[_NN 11_CD ,_, 24_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, we_PRP focus_VBP on_IN semi-supervised_JJ clustering_NN ,_, where_WRB the_DT performance_NN of_IN unsupervised_JJ clustering_NN algorithms_NNS is_VBZ improved_VBN with_IN limited_JJ amounts_NNS of_IN supervision_NN in_IN the_DT form_NN of_IN labels_NNS on_IN the_DT data_NNS o_NN
e_LS to_TO generate_VB ,_, since_IN labeling_NN typically_RB requires_VBZ human_JJ expertise_NN ._.
Consequently_RB ,_, semi-supervised_JJ learning_NN ,_, which_WDT uses_VBZ both_DT labeled_JJ and_CC unlabeled_JJ data_NNS ,_, has_VBZ become_VBN a_DT topic_NN of_IN significant_JJ recent_JJ interest_NN =_JJ -_: =[_NN 11_CD ,_, 24_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, we_PRP focus_VBP on_IN semi-supervised_JJ clustering_NN ,_, where_WRB the_DT performance_NN of_IN unsupervised_JJ clustering_NN algorithms_NNS is_VBZ improved_VBN with_IN limited_JJ amounts_NNS of_IN supervision_NN in_IN the_DT form_NN of_IN labels_NNS on_IN the_DT data_NNS o_NN
bels_NNS or_CC constraints_NNS in_IN the_DT supervised_JJ data_NNS ._.
Several_JJ adaptive_JJ distance_NN measures_NNS have_VBP been_VBN used_VBN for_IN semisupervised_JJ clustering_NN ,_, including_VBG string-edit_JJ distance_NN trained_VBN using_VBG Expectation_NN Maximization_NN -LRB-_-LRB- EM_NN -RRB-_-RRB- =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_JJ -_: ,_, KL_NN divergence_NN trained_VBN using_VBG gradient_NN descent_NN -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, Euclidean_JJ distance_NN modified_VBN by_IN a_DT shortestpath_NN algorithm_NN -LRB-_-LRB- 27_CD -RRB-_-RRB- ,_, or_CC Mahalanobis_NNP distances_NNS trained_VBD using_VBG convex_NN optimization_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- ._.
We_PRP propose_VBP a_DT princip_NN
potential_JJ function_NN V_NN in_IN the_DT first_JJ term_NN of_IN Eqn_NN ._.
-LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
In_IN previous_JJ work_NN ,_, only_RB must-linked_JJ points_NNS were_VBD considered_VBN in_IN the_DT neighborhood_NN of_IN a_DT Markov_NNP Random_NNP Field_NNP with_IN the_DT generalized_JJ Potts_NNP potential_JJ function_NN =_JJ -_: =[_NN 12_CD ,_, 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT potential_JJ function_NN ,_, the_DT must-link_JJ penalty_NN is_VBZ fM_NN -LRB-_-LRB- xi_NN ,_, xj_NN -RRB-_-RRB- =_JJ wi_NN j_NN -LRB-_-LRB- li_NN =_JJ l_NN j_NN -RRB-_-RRB- ,_, where_WRB wi_FW j_FW is_VBZ the_DT cost_NN for_IN violating_VBG the_DT must-link_JJ constraint_NN -LRB-_-LRB- i_FW ,_, j_NN -RRB-_-RRB- ,_, ands_NNS -LRB-_-LRB- 6_CD -RRB-_-RRB- is_VBZ the_DT indicator_NN function_NN -LRB-_-LRB- s_NN -LRB-_-LRB- true_JJ -RRB-_-RRB- =_JJ
e_LS to_TO generate_VB ,_, since_IN labeling_NN typically_RB requires_VBZ human_JJ expertise_NN ._.
Consequently_RB ,_, semi-supervised_JJ learning_NN ,_, which_WDT uses_VBZ both_DT labeled_JJ and_CC unlabeled_JJ data_NNS ,_, has_VBZ become_VBN a_DT topic_NN of_IN significant_JJ recent_JJ interest_NN =_JJ -_: =[_NN 11_CD ,_, 24_CD ,_, 33_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, we_PRP focus_VBP on_IN semi-supervised_JJ clustering_NN ,_, where_WRB the_DT performance_NN of_IN unsupervised_JJ clustering_NN algorithms_NNS is_VBZ improved_VBN with_IN limited_JJ amounts_NNS of_IN supervision_NN in_IN the_DT form_NN of_IN labels_NNS on_IN the_DT data_NNS o_NN
ilenko@cs.utexas.edu_NNP Raymond_NNP J._NNP Mooney_NNP Dept._NNP of_IN Computer_NNP Sciences_NNPS University_NNP of_IN Texas_NNP at_IN Austin_NNP Austin_NNP ,_, TX_NNP 78712_CD mooney@cs.utexas.edu_NN evaluating_VBG clusterings_NNS so_IN that_IN it_PRP includes_VBZ satisfying_JJ constraints_NNS =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_JJ -_: ,_, enforcing_VBG constraints_NNS during_IN the_DT clustering_NN process_NN -LRB-_-LRB- 38_CD -RRB-_-RRB- ,_, or_CC initializing_VBG and_CC constraining_VBG the_DT clustering_NN based_VBN on_IN labeled_JJ examples_NNS -LRB-_-LRB- 6_CD -RRB-_-RRB- ._.
In_IN distance-based_JJ approaches_NNS ,_, an_DT existing_VBG clustering_NN algorith_NN
labels_NNS of_IN the_DT points_NNS that_WDT are_VBP must-linked_JJ or_CC cannot-linked_JJ to_TO xi_VB ._.
Let_VB us_PRP consider_VB a_DT particular_JJ cluster_NN label_NN configuration_NN L_NN to_TO be_VB the_DT joint_JJ event_NN L_NN =_JJ -LCB-_-LRB- li_NN -RCB-_-RRB- N_NN i_LS =_JJ 1_CD ._.
By_IN the_DT Hammersley-Clifford_JJ theorem_NN =_JJ -_: =[_NN 22_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT probability_NN of_IN a_DT label_NN configuration_NN can_MD be_VB expressed_VBN as_IN a_DT Gibbs_NNP distribution_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ,_, so_IN that_IN Pr_NN -LRB-_-LRB- L_NN -RRB-_-RRB- =_JJ 1_CD exp_NN Z1_NN −_NN V_NN -LRB-_-LRB- L_NN -RRB-_-RRB- =_JJ 1_CD Z1_NN exp_FW −_FW ∑_FW VN_FW i_FW N_NN i_FW ∈_FW N_NN -LRB-_-LRB- L_NN -RRB-_-RRB- where_WRB N_NN is_VBZ the_DT set_NN of_IN all_DT neighborhoods_NNS ,_,
ticular_JJ cluster_NN label_NN configuration_NN L_NN to_TO be_VB the_DT joint_JJ event_NN L_NN =_JJ -LCB-_-LRB- li_NN -RCB-_-RRB- N_NN i_LS =_JJ 1_CD ._.
By_IN the_DT Hammersley-Clifford_JJ theorem_NN -LRB-_-LRB- 22_CD -RRB-_-RRB- ,_, the_DT probability_NN of_IN a_DT label_NN configuration_NN can_MD be_VB expressed_VBN as_IN a_DT Gibbs_NNP distribution_NN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_JJ -_: ,_, so_IN that_IN Pr_NN -LRB-_-LRB- L_NN -RRB-_-RRB- =_JJ 1_CD exp_NN Z1_NN −_NN V_NN -LRB-_-LRB- L_NN -RRB-_-RRB- =_JJ 1_CD Z1_NN exp_FW −_FW ∑_FW VN_FW i_FW N_NN i_FW ∈_FW N_NN -LRB-_-LRB- L_NN -RRB-_-RRB- where_WRB N_NN is_VBZ the_DT set_NN of_IN all_DT neighborhoods_NNS ,_, Z1_NN is_VBZ a_DT normalizing_VBG constant_NN ,_, and_CC V_NN -LRB-_-LRB- L_NN -RRB-_-RRB- is_VBZ the_DT overall_JJ label_NN configuration_NN potential_JJ fun_NN
odel_NN -LRB-_-LRB- 36_CD -RRB-_-RRB- ._.
There_EX exist_VBP several_JJ techniques_NNS for_IN computing_NN cluster_NN assignments_NNS that_IN approximate_JJ the_DT optimal_JJ solution_NN in_IN this_DT framework_NN ,_, e.g._FW ,_, iterated_JJ conditional_JJ modes_NNS -LRB-_-LRB- ICM_NNP -RRB-_-RRB- -LRB-_-LRB- 9_CD ,_, 40_CD -RRB-_-RRB- ,_, belief_NN propagation_NN =_JJ -_: =[_NN 34_CD ,_, 36_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC linear_JJ programming_NN relaxation_NN -LRB-_-LRB- 28_CD -RRB-_-RRB- ._.
We_PRP follow_VBP the_DT ICM_NNP approach_NN ,_, which_WDT is_VBZ a_DT greedy_JJ strategy_NN to_TO sequentially_RB update_VB the_DT cluster_NN assignment_NN of_IN each_DT point_NN ,_, keeping_VBG the_DT assignments_NNS for_IN the_DT other_JJ poin_NN
potential_JJ function_NN V_NN in_IN the_DT first_JJ term_NN of_IN Eqn_NN ._.
-LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
In_IN previous_JJ work_NN ,_, only_RB must-linked_JJ points_NNS were_VBD considered_VBN in_IN the_DT neighborhood_NN of_IN a_DT Markov_NNP Random_NNP Field_NNP with_IN the_DT generalized_JJ Potts_NNP potential_JJ function_NN =_JJ -_: =[_NN 12_CD ,_, 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT potential_JJ function_NN ,_, the_DT must-link_JJ penalty_NN is_VBZ fM_NN -LRB-_-LRB- xi_NN ,_, xj_NN -RRB-_-RRB- =_JJ wi_NN j_NN -LRB-_-LRB- li_NN =_JJ l_NN j_NN -RRB-_-RRB- ,_, where_WRB wi_FW j_FW is_VBZ the_DT cost_NN for_IN violating_VBG the_DT must-link_JJ constraint_NN -LRB-_-LRB- i_FW ,_, j_NN -RRB-_-RRB- ,_, ands_NNS -LRB-_-LRB- 6_CD -RRB-_-RRB- is_VBZ the_DT indicator_NN function_NN -LRB-_-LRB- s_NN -LRB-_-LRB- true_JJ -RRB-_-RRB- =_JJ
minimized_VBN ._.
A_DT popular_JJ clustering_NN algorithm_NN in_IN this_DT category_NN is_VBZ K-Means_NN -LRB-_-LRB- 29_CD -RRB-_-RRB- ._.
Earlier_JJR research_NN on_IN semi-supervised_JJ clustering_NN has_VBZ considered_VBN supervision_NN in_IN the_DT form_NN of_IN labeled_JJ points_NNS -LRB-_-LRB- 6_CD -RRB-_-RRB- or_CC constraints_NNS =_JJ -_: =[_NN 38_CD ,_, 39_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, we_PRP will_MD be_VB considering_VBG the_DT model_NN where_WRB supervision_NN is_VBZ provided_VBN in_IN the_DT form_NN of_IN must-link_JJ and_CC cannot-link_JJ constraints_NNS ,_, indicating_VBG respectively_RB that_IN a_DT pair_NN of_IN points_NNS should_MD be_VB or_CC should_MD
s_NNS known_VBN as_IN Bregman_NNP divergences_NNS -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
Another_DT popular_JJ class_NN of_IN distortion_NN measures_NNS includes_VBZ directional_JJ similarity_NN functions_NNS such_JJ as_IN normalized_VBN dot_NN product_NN -LRB-_-LRB- cosine_NN similarity_NN -RRB-_-RRB- and_CC Pearson_NNP 's_POS correlation_NN =_JJ -_: =[_NN 31_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Selection_NN of_IN the_DT most_RBS appropriate_JJ distortion_NN measure_NN for_IN a_DT clustering_NN task_NN should_MD take_VB into_IN account_NN intrinsic_JJ properties_NNS of_IN the_DT dataset_NN ._.
For_IN example_NN ,_, Euclidean_JJ distance_NN is_VBZ most_RBS appropriate_JJ for_IN low-d_NN
well_RB as_IN the_DT cluster_NN labels_NNS for_IN the_DT points_NNS are_VBP unknown_JJ in_IN a_DT clustering_NN setting_NN ,_, maximizing_VBG Eqn_NN ._.
-LRB-_-LRB- 5_CD -RRB-_-RRB- is_VBZ an_DT ``_`` incomplete-data_JJ problem_NN ''_'' ,_, for_IN which_WDT a_DT popular_JJ solution_NN method_NN is_VBZ Expectation_NN Maximization_NN -LRB-_-LRB- EM_NN -RRB-_-RRB- =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
It_PRP is_VBZ well-known_JJ that_IN KMeans_NN is_VBZ equivalent_JJ to_TO an_DT EM_NN algorithm_NN with_IN hard_JJ clustering_NN assignments_NNS -LRB-_-LRB- 26_CD ,_, 6_CD ,_, 3_CD -RRB-_-RRB- ._.
Section_NN 3.2_CD describes_VBZ a_DT K-Means-type_JJ hard_JJ partitional_JJ clustering_NN algorithm_NN ,_, HMRF-KMEANS_NN ,_, th_DT
erized_VBN I-Divergence_NN In_IN certain_JJ domains_NNS ,_, data_NNS is_VBZ described_VBN by_IN probability_NN distributions_NNS ,_, e.g._FW text_NN documents_NNS can_MD be_VB represented_VBN as_IN probability_NN distributions_NNS over_IN words_NNS generated_VBN by_IN a_DT multinomial_JJ model_NN =_JJ -_: =[_NN 35_CD -RRB-_-RRB- -_: =_SYM -_: ._.
KL-divergence_NN is_VBZ a_DT widely_RB used_VBN distance_NN measure_NN for_IN such_JJ data_NNS :_: DKL_NN -LRB-_-LRB- xi_NN ,_, xj_NN -RRB-_-RRB- =_JJ ∑_FW d_FW m_NN =_JJ 1_CD xim_NN log_NN xim_NN x_NN jm_NN ,_, where_WRB xi_NN and_CC x_NN j_NN are_VBP probability_NN distributions_NNS over_IN d_NN events_NNS :_: ∑_FW d_FW m_NN =_JJ 1_CD xim_NN =_JJ ∑_FW d_FW m_NN =_JJ 1_CD x_NN jm_NN =_JJ 1_CD ._.
I_PRP
to_TO learn_VB a_DT Mahalanobis_NNP distance_NN using_VBG convex_NN optimization_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
Spectral_JJ learning_NN is_VBZ another_DT recent_JJ method_NN that_WDT utilizes_VBZ supervision_NN to_TO transform_VB the_DT clustering_NN distance_NN measure_NN using_VBG spectral_JJ methods_NNS =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
All_DT these_DT distance_NN learning_NN techniques_NNS for_IN clustering_NN train_NN the_DT distance_NN measure_NN first_RB using_VBG only_JJ supervised_JJ data_NNS ,_, and_CC then_RB perform_VB clustering_NN on_IN the_DT unsupervised_JJ data_NNS ._.
In_IN contrast_NN ,_, our_PRP$ method_NN integ_NN
ster_NN conditional_JJ probability_NN is_VBZ a_DT unit_NN variance_NN Gaussian_JJ -LRB-_-LRB- 26_CD -RRB-_-RRB- ;_: •_FW xi_FW and_CC µli_NN are_VBP probability_NN distributions_NNS and_CC D_NN is_VBZ the_DT KL-divergence_NN :_: the_DT cluster_NN conditional_JJ probability_NN is_VBZ a_DT multinomial_JJ distribution_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_JJ -_: ;_: •_FW xi_FW and_CC µli_NN are_VBP vectors_NNS of_IN unit_NN length_NN -LRB-_-LRB- according_VBG to_TO the_DT L2_NN norm_NN -RRB-_-RRB- and_CC D_NN is_VBZ one_CD minus_NN the_DT dot-product_NN :_: the_DT cluster_NN conditional_JJ probability_NN is_VBZ a_DT von-Mises_NNP Fisher_NNP -LRB-_-LRB- vMF_NN -RRB-_-RRB- distribution_NN with_IN unit_NN concentr_NN
ustering_VBG algorithm_NN that_WDT has_VBZ a_DT heuristically_RB motivated_JJ objective_NN function_NN -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
Our_PRP$ method_NN ,_, on_IN the_DT other_JJ hand_NN ,_, has_VBZ an_DT underlying_JJ probabilistic_JJ model_NN based_VBN on_IN Hidden_NNP Markov_NNP Random_NNP Fields_NNP ._.
Bansal_NNP et_FW al._FW =_SYM -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: also_RB proposed_VBD a_DT framework_NN for_IN pairwise_JJ constrained_VBN clustering_NN ,_, but_CC their_PRP$ model_NN performs_VBZ clustering_NN using_VBG only_RB the_DT constraints_NNS ,_, whereas_IN our_PRP$ formulation_NN uses_VBZ both_DT constraints_NNS and_CC an_DT underlying_JJ distorti_NN
adaptive_JJ distance_NN measures_NNS have_VBP been_VBN used_VBN for_IN semisupervised_JJ clustering_NN ,_, including_VBG string-edit_JJ distance_NN trained_VBN using_VBG Expectation_NN Maximization_NN -LRB-_-LRB- EM_NN -RRB-_-RRB- -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, KL_NN divergence_NN trained_VBN using_VBG gradient_NN descent_NN =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Euclidean_JJ distance_NN modified_VBN by_IN a_DT shortestpath_NN algorithm_NN -LRB-_-LRB- 27_CD -RRB-_-RRB- ,_, or_CC Mahalanobis_NNP distances_NNS trained_VBD using_VBG convex_NN optimization_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- ._.
We_PRP propose_VBP a_DT principled_JJ probabilistic_JJ framework_NN based_VBN on_IN Hidden_NNP Markov_NNP
r_NN ,_, we_PRP focus_VBP on_IN semi-supervised_JJ clustering_NN ,_, where_WRB the_DT performance_NN of_IN unsupervised_JJ clustering_NN algorithms_NNS is_VBZ improved_VBN with_IN limited_JJ amounts_NNS of_IN supervision_NN in_IN the_DT form_NN of_IN labels_NNS on_IN the_DT data_NNS or_CC constraints_NNS =_JJ -_: =[_NN 38_CD ,_, 6_CD ,_, 27_CD ,_, 39_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Existing_VBG methods_NNS for_IN semi-supervised_JJ clustering_NN fall_NN into_IN two_CD general_JJ categories_NNS which_WDT we_PRP call_VBP constraint-based_JJ and_CC distancebased_JJ ._.
Constraint-based_JJ methods_NNS rely_VBP on_IN user-provided_JJ labels_NNS or_CC constraint_NN
r_NN the_DT hidden_JJ variables_NNS ._.
As_IN a_DT result_NN ,_, computing_VBG the_DT assignment_NN of_IN data_NNS points_NNS to_TO cluster_VB representatives_NNS to_TO minimize_VB the_DT objective_JJ function_NN is_VBZ computationally_RB intractable_JJ in_IN any_DT non-trivial_JJ HMRF_NN model_NN =_JJ -_: =[_NN 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
There_EX exist_VBP several_JJ techniques_NNS for_IN computing_NN cluster_NN assignments_NNS that_IN approximate_JJ the_DT optimal_JJ solution_NN in_IN this_DT framework_NN ,_, e.g._FW ,_, iterated_JJ conditional_JJ modes_NNS -LRB-_-LRB- ICM_NNP -RRB-_-RRB- -LRB-_-LRB- 9_CD ,_, 40_CD -RRB-_-RRB- ,_, belief_NN propagation_NN -LRB-_-LRB- 34_CD ,_, 36_CD -RRB-_-RRB- ,_,
r_NN ,_, we_PRP focus_VBP on_IN semi-supervised_JJ clustering_NN ,_, where_WRB the_DT performance_NN of_IN unsupervised_JJ clustering_NN algorithms_NNS is_VBZ improved_VBN with_IN limited_JJ amounts_NNS of_IN supervision_NN in_IN the_DT form_NN of_IN labels_NNS on_IN the_DT data_NNS or_CC constraints_NNS =_JJ -_: =[_NN 38_CD ,_, 6_CD ,_, 27_CD ,_, 39_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Existing_VBG methods_NNS for_IN semi-supervised_JJ clustering_NN fall_NN into_IN two_CD general_JJ categories_NNS which_WDT we_PRP call_VBP constraint-based_JJ and_CC distancebased_JJ ._.
Constraint-based_JJ methods_NNS rely_VBP on_IN user-provided_JJ labels_NNS or_CC constraint_NN
le_DT in_IN any_DT non-trivial_JJ HMRF_NN model_NN -LRB-_-LRB- 36_CD -RRB-_-RRB- ._.
There_EX exist_VBP several_JJ techniques_NNS for_IN computing_NN cluster_NN assignments_NNS that_IN approximate_JJ the_DT optimal_JJ solution_NN in_IN this_DT framework_NN ,_, e.g._FW ,_, iterated_JJ conditional_JJ modes_NNS -LRB-_-LRB- ICM_NNP -RRB-_-RRB- =_JJ -_: =[_NN 9_CD ,_, 40_CD -RRB-_-RRB- -_: =_JJ -_: ,_, belief_NN propagation_NN -LRB-_-LRB- 34_CD ,_, 36_CD -RRB-_-RRB- ,_, and_CC linear_JJ programming_NN relaxation_NN -LRB-_-LRB- 28_CD -RRB-_-RRB- ._.
We_PRP follow_VBP the_DT ICM_NNP approach_NN ,_, which_WDT is_VBZ a_DT greedy_JJ strategy_NN to_TO sequentially_RB update_VB the_DT cluster_NN assignment_NN of_IN each_DT point_NN ,_, keeping_VBG the_DT a_DT
le_DT in_IN any_DT non-trivial_JJ HMRF_NN model_NN -LRB-_-LRB- 36_CD -RRB-_-RRB- ._.
There_EX exist_VBP several_JJ techniques_NNS for_IN computing_NN cluster_NN assignments_NNS that_IN approximate_JJ the_DT optimal_JJ solution_NN in_IN this_DT framework_NN ,_, e.g._FW ,_, iterated_JJ conditional_JJ modes_NNS -LRB-_-LRB- ICM_NNP -RRB-_-RRB- =_JJ -_: =[_NN 9_CD ,_, 40_CD -RRB-_-RRB- -_: =_JJ -_: ,_, belief_NN propagation_NN -LRB-_-LRB- 34_CD ,_, 36_CD -RRB-_-RRB- ,_, and_CC linear_JJ programming_NN relaxation_NN -LRB-_-LRB- 28_CD -RRB-_-RRB- ._.
We_PRP follow_VBP the_DT ICM_NNP approach_NN ,_, which_WDT is_VBZ a_DT greedy_JJ strategy_NN to_TO sequentially_RB update_VB the_DT cluster_NN assignment_NN of_IN each_DT point_NN ,_, keeping_VBG the_DT a_DT
distortion_NN measure_NN D_NN is_VBZ updated_VBN in_IN the_DT M-step_NN to_TO reduce_VB the_DT objective_JJ function_NN simultaneously_RB by_IN transforming_VBG the_DT space_NN in_IN which_WDT data_NN lies_VBZ ._.
Note_VB that_IN this_DT corresponds_VBZ to_TO the_DT generalized_JJ EM_NN algorithm_NN =_JJ -_: =[_NN 32_CD ,_, 16_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB the_DT objective_JJ function_NN is_VBZ reduced_VBN but_CC not_RB necessarily_RB minimized_VBN in_IN the_DT M-step_NN ._.
Effectively_RB ,_, the_DT E-step_NN minimizes_VBZ Jobj_NNP over_IN cluster_NN assignments_NNS L_NN ,_, the_DT M-step_NN -LRB-_-LRB- A_NN -RRB-_-RRB- minimizes_VBZ Jobj_NNP over_IN cluster_NN rep_NN
type_NN -RRB-_-RRB- so_IN that_IN a_DT well-defined_JJ cost_NN function_NN ,_, involving_VBG a_DT distortion_NN measure_NN between_IN the_DT points_NNS and_CC the_DT cluster_NN representatives_NNS ,_, is_VBZ minimized_VBN ._.
A_DT popular_JJ clustering_NN algorithm_NN in_IN this_DT category_NN is_VBZ K-Means_NN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Earlier_JJR research_NN on_IN semi-supervised_JJ clustering_NN has_VBZ considered_VBN supervision_NN in_IN the_DT form_NN of_IN labeled_JJ points_NNS -LRB-_-LRB- 6_CD -RRB-_-RRB- or_CC constraints_NNS -LRB-_-LRB- 38_CD ,_, 39_CD ,_, 5_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP will_MD be_VB considering_VBG the_DT model_NN where_WRB supervis_NN
istances_NNS ,_, e.g._FW ,_, KL_NN divergence_NN ._.
In_IN a_DT number_NN of_IN applications_NNS ,_, such_JJ as_IN text-clustering_NN using_VBG a_DT vector-space_JJ model_NN ,_, a_DT directional_JJ similarity_NN measure_NN based_VBN on_IN the_DT angle_NN between_IN vectors_NNS is_VBZ more_RBR appropriate_JJ =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Consequently_RB ,_, clustering_NN algorithms_NNS that_WDT utilize_VBP distortion_NN measures_NNS appropriate_JJ for_IN directional_JJ data_NNS have_VBP recently_RB been_VBN developed_VBN -LRB-_-LRB- 18_CD ,_, 2_CD -RRB-_-RRB- ._.
Our_PRP$ unified_JJ semi-supervised_JJ clustering_NN framework_NN based_VBN on_IN
divergences_NNS each_DT cluster_NN representative_NN calculated_VBN in_IN the_DT M-step_NN of_IN the_DT EM_NN algorithm_NN is_VBZ equivalent_JJ to_TO the_DT expectation_NN value_NN over_IN the_DT points_NNS in_IN that_DT cluster_NN ,_, which_WDT is_VBZ essentially_RB their_PRP$ arithmetic_NN mean_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Additionally_RB ,_, it_PRP has_VBZ been_VBN experimentally_RB demonstrated_VBN that_IN for_IN distribution-based_JJ clustering_NN ,_, smoothing_VBG cluster_NN representatives_NNS by_IN a_DT prior_RB using_VBG a_DT deterministic_JJ annealing_NN schedule_NN leads_VBZ to_TO considera_VB
measure_NN based_VBN on_IN the_DT angle_NN between_IN vectors_NNS is_VBZ more_RBR appropriate_JJ -LRB-_-LRB- 1_LS -RRB-_-RRB- ._.
Consequently_RB ,_, clustering_NN algorithms_NNS that_WDT utilize_VBP distortion_NN measures_NNS appropriate_JJ for_IN directional_JJ data_NNS have_VBP recently_RB been_VBN developed_VBN =_JJ -_: =[_NN 18_CD ,_, 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Our_PRP$ unified_JJ semi-supervised_JJ clustering_NN framework_NN based_VBN on_IN HMRFs_NNS is_VBZ also_RB applicable_JJ to_TO such_JJ directional_JJ similarity_NN measures_NNS ._.
To_TO summarize_VB ,_, the_DT proposed_VBN approach_NN aids_VBZ unsupervised_JJ clustering_NN by_IN incorp_NN
