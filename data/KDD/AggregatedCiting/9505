Information-theoretic_JJ co-clustering_NN
Two-dimensional_JJ contingency_NN or_CC co-occurrence_NN tables_NNS arise_VBP frequently_RB in_IN important_JJ applications_NNS such_JJ as_IN text_NN ,_, web-log_JJ and_CC market-basket_JJ data_NN analysis_NN ._.
A_DT basic_JJ problem_NN in_IN contingency_NN table_NN analysis_NN is_VBZ co-clustering_JJ :_: simultaneous_JJ clustering_NN of_IN the_DT rows_NNS and_CC columns_NNS ._.
A_DT novel_JJ theoretical_JJ formulation_NN views_VBZ the_DT contingency_NN table_NN as_IN an_DT empirical_JJ joint_JJ probability_NN distribution_NN of_IN two_CD discrete_JJ random_JJ variables_NNS and_CC poses_VBZ the_DT co-clustering_JJ problem_NN as_IN an_DT optimization_NN problem_NN in_IN information_NN theory_NN --_: the_DT optimal_JJ co-clustering_NN maximizes_VBZ the_DT mutual_JJ information_NN between_IN the_DT clustered_VBN random_JJ variables_NNS subject_JJ to_TO constraints_NNS on_IN the_DT number_NN of_IN row_NN and_CC column_NN clusters_NNS ._.
We_PRP present_VBP an_DT innovative_JJ co-clustering_JJ algorithm_NN that_WDT monotonically_RB increases_VBZ the_DT preserved_JJ mutual_JJ information_NN by_IN intertwining_VBG both_CC the_DT row_NN and_CC column_NN clusterings_NNS at_IN all_DT stages_NNS ._.
Using_VBG the_DT practical_JJ example_NN of_IN simultaneous_JJ word-document_JJ clustering_NN ,_, we_PRP demonstrate_VBP that_IN our_PRP$ algorithm_NN works_VBZ well_RB in_IN practice_NN ,_, especially_RB in_IN the_DT presence_NN of_IN sparsity_NN and_CC high-dimensionality_NN ._.
atrix_NN approximation_NN q_NN -LRB-_-LRB- X_NN ;_: Y_NN -RRB-_-RRB- ._.
A_DT soft_JJ version_NN of_IN our_PRP$ procedure_NN is_VBZ related_JJ to_TO the_DT PLSI_NN scheme_NN of_IN -LRB-_-LRB- 12_CD -RRB-_-RRB- ;_: however_RB the_DT latter_JJ uses_VBZ a_DT single_JJ latent_JJ variable_JJ model_NN ._.
A_DT twocluster_NN abstraction_NN model_NN is_VBZ given_VBN in_IN =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: that_WDT uses_VBZ maximum_NN likelihood_NN in_IN a_DT model-based_JJ generative_JJ framework_NN ._.
4_LS ._.
CO-CLUSTERING_NNP ALGORITHM_NNP We_PRP now_RB describe_VBP a_DT novel_JJ algorithm_NN that_WDT monotonically_RB decreases_VBZ the_DT objective_JJ function_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ._.
To_TO describe_VB t_NN
higher_JJR classication_NN accuracies_NNS than_IN -LRB-_-LRB- 1_CD ,_, 19_CD -RRB-_-RRB- ._.
All_DT these_DT algorithms_NNS were_VBD proposed_VBN for_IN one-sided_JJ clustering_NN ._.
An_DT agglomerative_JJ hard_JJ clustering_NN version_NN of_IN the_DT Information_NNP Bottleneck_NNP algorithm_NN was_VBD used_VBN in_IN -LRB-_-LRB- =_JJ -_: =_JJ 18_CD -RRB-_-RRB- -_: =_SYM -_: to_TO cluster_VB documents_NNS after_IN clustering_NN words_NNS ._.
The_DT work_NN in_IN -LRB-_-LRB- 8_CD -RRB-_-RRB- extended_VBD the_DT above_JJ work_NN to_TO repetitively_RB cluster_VB documents_NNS and_CC then_RB words_NNS ._.
However_RB ,_, both_DT these_DT papers_NNS use_VBP heuristic_NN procedures_NNS and_CC cluster_NN
ng_NN to_TO denote_VB document_NN clustering_NN without_IN any_DT word_NN clustering_NN i._NN e_SYM ,_, clustering_VBG along_IN a_DT single_JJ dimension_NN ._.
5.1_CD Data_NN Sets_VBZ For_IN our_PRP$ experimental_JJ results_NNS we_PRP use_VBP various_JJ subsets_NNS of_IN the_DT 20-Newsgroup_NN data_NNS -LRB-_-LRB- NG20_NN -RRB-_-RRB- =_JJ -_: =[_NN 13_CD -_: =-]_NN and_CC the_DT SMART_JJ collection_NN from_IN Cornell_NNP -LRB-_-LRB- ftp_NN :_: \/_: \/_: ftp.cs.cornell.edu\/pub\/smart_NN -RRB-_-RRB- ._.
The_DT NG20_NN data_NN set_NN consists_VBZ of_IN approximately_RB 20_CD ;_: 000_CD newsgroup_NN articles_NNS collected_VBN evenly_RB from_IN 20_CD dierent_JJ usenet_NN news-groups_NNS
rue_FW co-clustering_FW procedure_NN ._.
By_IN Lemma_NNP 2.1_CD ,_, our_PRP$ co-clustering_JJ procedure_NN is_VBZ intimately_RB related_VBN tosnding_VBG a_DT matrix_NN approximation_NN q_NN -LRB-_-LRB- X_NN ;_: Y_NN -RRB-_-RRB- ._.
A_DT soft_JJ version_NN of_IN our_PRP$ procedure_NN is_VBZ related_JJ to_TO the_DT PLSI_NN scheme_NN of_IN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_JJ -_: ;_: however_RB the_DT latter_JJ uses_VBZ a_DT single_JJ latent_JJ variable_JJ model_NN ._.
A_DT twocluster_NN abstraction_NN model_NN is_VBZ given_VBN in_IN -LRB-_-LRB- 13_CD -RRB-_-RRB- that_WDT uses_VBZ maximum_NN likelihood_NN in_IN a_DT model-based_JJ generative_JJ framework_NN ._.
4_LS ._.
CO-CLUSTERING_NNP ALGORITHM_NNP
en_IN compression_NN and_CC preservation_NN of_IN mutual_JJ information_NN ._.
The_DT Information_NNP Bottleneck_NNP algorithm_NN yields_VBZ a_DT \_CD soft_JJ ''_'' clustering_NN of_IN the_DT data_NNS using_VBG a_DT procedure_NN similar_JJ to_TO the_DT deterministic_JJ annealing_NN approac_NN =_JJ -_: =_JJ h_NN of_IN -LRB-_-LRB- 16_CD -_: =-]_CD ._.
A_DT greedy_JJ agglomerative_JJ hard_JJ clustering_NN version_NN of_IN the_DT Information_NNP Bottleneck_NNP algorithm_NN was_VBD used_VBN in_IN -LRB-_-LRB- 1_CD ,_, 19_CD -RRB-_-RRB- to_TO cluster_VB words_NNS in_IN order_NN to_TO reduce_VB feature_NN size_NN for_IN supervised_JJ text_NN classication_NN ._.
For_IN thi_NN
thms_NNS were_VBD proposed_VBN for_IN one-sided_JJ clustering_NN ._.
An_DT agglomerative_JJ hard_JJ clustering_NN version_NN of_IN the_DT Information_NNP Bottleneck_NNP algorithm_NN was_VBD used_VBN in_IN -LRB-_-LRB- 18_CD -RRB-_-RRB- to_TO cluster_VB documents_NNS after_IN clustering_NN words_NNS ._.
The_DT work_NN in_IN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: extended_VBD the_DT above_JJ work_NN to_TO repetitively_RB cluster_VB documents_NNS and_CC then_RB words_NNS ._.
However_RB ,_, both_DT these_DT papers_NNS use_VBP heuristic_NN procedures_NNS and_CC cluster_NN documents_NNS and_CC words_NNS independently_RB using_VBG an_DT agglomerative_JJ algo_NN
a_DT strong_JJ theoretical_JJ foundation_NN and_CC monotonically_RB reduces_VBZ this_DT loss_NN function_NN ,_, converging_VBG to_TO a_DT local_JJ minimum_NN ._.
Recently_RB ,_, when_WRB considering_VBG a_DT general_JJ clustering_NN framework_NN using_VBG Bayesian_JJ belief_NN networks_NNS ,_, =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: proposed_VBD an_DT iterative_JJ optimization_NN method_NN that_WDT amounts_VBZ to_TO a_DT multivariate_JJ generalization_NN of_IN -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, and_CC ,_, once_RB again_RB ,_, uses_VBZ deterministic_JJ annealing_NN ._.
A_DT later_JJ paper_NN -LRB-_-LRB- 17_CD -RRB-_-RRB- presented_VBD an_DT agglomerative_JJ algorithm_NN
ich_NN used_VBD a_DT local_JJ greedy_JJ splitting_NN procedure_NN to_TO identify_VB hierarchical_JJ row_NN and_CC column_NN clusters_NNS in_IN matrices_NNS of_IN small_JJ size_NN ._.
Co-clustering_NN has_VBZ also_RB been_VBN called_VBN biclustering_VBG and_CC block_VB clustering_NN in_IN -LRB-_-LRB- 2_CD -RRB-_-RRB- and_CC =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: respectively_RB ._.
Recently_RB -LRB-_-LRB- 4_CD -RRB-_-RRB- used_VBD a_DT graph_NN formulation_NN and_CC a_DT spectral_JJ heuristic_NN that_WDT uses_VBZ eigenvectors_NNS to_TO co-cluster_JJ documents_NNS and_CC words_NNS ;_: however_RB ,_, a_DT restriction_NN in_IN -LRB-_-LRB- 4_CD -RRB-_-RRB- was_VBD that_IN each_DT word_NN cluster_NN was_VBD ass_NN
neous_JJ word-document_NN clustering_NN ,_, we_PRP demonstrate_VBP that_IN our_PRP$ algorithm_NN works_VBZ well_RB in_IN practice_NN ,_, especially_RB in_IN the_DT presence_NN of_IN sparsity_NN ._.
1_CD Introduction_NN Clustering_NN is_VBZ the_DT grouping_VBG together_RB of_IN similar_JJ objects_NNS =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC has_VBZ practical_JJ importance_NN in_IN a_DT wide_JJ variety_NN of_IN applications_NNS such_JJ as_IN text_NN ,_, web-log_JJ and_CC market-basket_JJ data_NN analysis_NN ._.
Typically_RB ,_, the_DT data_NNS that_WDT arises_VBZ in_IN these_DT applications_NNS is_VBZ arranged_VBN as_IN a_DT contingen_NN
some_DT early_JJ work_NN on_IN co-clustering_NN ,_, such_JJ as_IN -LRB-_-LRB- 11_CD -RRB-_-RRB- which_WDT was_VBD limited_VBN to_TO problems_NNS of_IN small_JJ sizes_NNS and_CC used_VBD a_DT local_JJ greedy_JJ splitting_NN procedure_NN to_TO identify_VB hierarchical_JJ row_NN and_CC column_NN clusters_NNS ._.
More_RBR recently_RB =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: used_VBD a_DT bipartite_JJ graph_NN formulation_NN and_CC a_DT spectral_JJ heuristic_NN that_WDT uses_VBZ eigenvectors_NNS to_TO co-cluster_JJ documents_NNS and_CC words_NNS ;_: however_RB ,_, a_DT restriction_NN in_IN -LRB-_-LRB- 4_CD -RRB-_-RRB- was_VBD that_IN each_DT word_NN 4_CD cluster_NN was_VBD associated_VBN with_IN a_DT
data_NN set_NN consists_VBZ of_IN approximately_RB 20_CD ;_: 000_CD newsgroup_NN articles_NNS collected_VBN evenly_RB from_IN 20_CD dierent_JJ usenet_NN news-groups_NNS ._.
This_DT data_NNS set_NN has_VBZ been_VBN used_VBN for_IN testing_VBG several_JJ supervised_JJ text_NN classication_NN tasks_NNS -LRB-_-LRB- 1_CD =_JJ -_: =_JJ ,_, 19_CD ,_, 14_CD ,_, 6_CD -RRB-_-RRB- -_: =_JJ -_: and_CC un-supervised_JJ document_NN clustering_NN tasks_NNS -LRB-_-LRB- 18_CD ,_, 8_CD -RRB-_-RRB- ._.
Many_JJ of_IN the_DT news-groups_NNS share_VBP similar_JJ topics_NNS and_CC about_IN 4:5_CD %_NN of_IN the_DT documents_NNS are_VBP cross_JJ posted_VBD making_VBG the_DT boundaries_NNS between_IN some_DT news-groups_NNS rathe_VBP
umber_NN of_IN word_NN clusters_NNS ._.
A_DT note_NN about_IN our_PRP$ initialization_NN :_: we_PRP use_VBP deterministic_JJ initialization_NN of_IN word_NN clusters_NNS by_IN choosing_VBG initial_JJ word_NN cluster_NN distributions_NNS to_TO be_VB \_CD maximally_RB ''_'' far_RB apart_RB from_IN each_DT =_JJ -_: =_JJ other_JJ -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, and_CC -_: =_JJ -_: use_VB a_DT random_JJ perturbation_NN of_IN the_DT \_JJ mean_NN ''_'' document_NN to_TO initialize_VB document_NN clusters_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
Since_IN this_DT initialization_NN has_VBZ a_DT random_JJ component_NN all_DT our_PRP$ results_NNS are_VBP averages_NNS ofsve_VBP trials_NNS unless_IN stated_VBN oth_NN
n_NN fact_NN ,_, see_VBP Section_NNP 5_CD for_IN examples_NNS of_IN dierent_JJ types_NNS of_IN row_NN and_CC column_NN clusters_NNS ._.
Our_PRP$ information-theoretic_JJ formulation_NN of_IN preserving_VBG mutual_JJ information_NN is_VBZ similar_JJ to_TO the_DT Information_NNP Bottleneck_NN method_NN -LRB-_-LRB- =_JJ -_: =_JJ 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT Information_NNP Bottleneck_NNP method_NN was_VBD introduced_VBN for_IN one-sided_JJ clustering_NN ,_, say_VBP X_NN to_TO ^_NNP X_NNP ,_, and_CC tries_VBZ to_TO minimize_VB the_DT quantity_NN I_NN -LRB-_-LRB- X_NN ;_: ^_CD X_NN -RRB-_-RRB- in_IN order_NN to_TO gain_VB compression_NN in_IN addition_NN to_TO maximizing_VBG the_DT mutua_NN
moving_VBG stop_NN words_NNS and_CC numeric_JJ characters_NNS we_PRP selected_VBD the_DT top_JJ 2000_CD words_NNS by_IN mutual_JJ information_NN as_IN part_NN of_IN our_PRP$ pre-processing_NN ._.
We_PRP will_MD refer_VB to_TO this_DT data_NNS set_VBN as_IN CLASSIC3_NN ._.
5.2_CD Implementation_NNP Details_NNP Bow_NN =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ a_DT library_NN of_IN C_NN code_NN useful_JJ for_IN writing_VBG text_NN analysis_NN ,_, language_NN modeling_NN and_CC information_NN retrieval_NN programs_NNS ._.
We_PRP extended_VBD Bow_NNP to_TO implement_VB co-clustering_NN and_CC document_NN clustering_NN and_CC used_VBD MATLAB_NNP to_TO gi_VB
on_IN of_IN word_NN clusters_NNS by_IN choosing_VBG initial_JJ word_NN cluster_NN distributions_NNS to_TO be_VB \_CD maximally_RB ''_'' far_RB apart_RB from_IN each_DT other_JJ -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, and_CC use_VB a_DT random_JJ perturbation_NN of_IN the_DT \_JJ mean_NN ''_'' document_NN to_TO initialize_VB document_NN =_JJ -_: =_JJ clusters_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Since_IN this_DT initialization_NN has_VBZ a_DT random_JJ component_NN all_DT our_PRP$ results_NNS are_VBP averages_NNS ofsve_VBP trials_NNS unless_IN stated_VBN otherwise_RB ._.
Figure_NN 2_CD shows_VBZ two_CD confusion_NN matrices_NNS obtained_VBN on_IN the_DT CLASSIC3_NN data_NNS set_VBN using_VBG algo_NN
ks_NNS ._.
We_PRP refer_VBP to_TO each_DT such_JJ block_NN as_IN a_DT co-cluster_NN ._.
A_DT fundamental_JJ quantity_NN that_WDT measures_VBZ the_DT amount_NN of_IN information_NN random_JJ variable_NN X_NN contains_VBZ about_IN Y_NN -LRB-_-LRB- and_CC vice_NN versa_RB -RRB-_-RRB- is_VBZ the_DT mutual_JJ information_NN I_CD -LRB-_-LRB- X_NN ;_: Y_NN -RRB-_-RRB- =_JJ -_: =[_NN 3_CD -_: =-]_CD ._.
We_PRP will_MD judge_VB the_DT quality_NN of_IN a_DT co-clustering_NN by_IN the_DT resulting_VBG loss_NN in_IN mutual_JJ information_NN ,_, I_NN -LRB-_-LRB- X_NN ;_: Y_NN -RRB-_-RRB- I_NN -LRB-_-LRB- ^_NN X_NN ;_: ^_CD Y_NN -RRB-_-RRB- -LRB-_-LRB- any_DT non-trivial_JJ coclustering_NN lowers_VBZ mutual_JJ information_NN ,_, see_VBP Lemma_NNP 2.1_CD below_IN -RRB-_-RRB- ._.
Den_NNP
t_NN ''_'' clustering_NN of_IN the_DT data_NNS using_VBG a_DT procedure_NN similar_JJ to_TO the_DT deterministic_JJ annealing_NN approach_NN of_IN -LRB-_-LRB- 16_CD -RRB-_-RRB- ._.
A_DT greedy_JJ agglomerative_JJ hard_JJ clustering_NN version_NN of_IN the_DT Information_NNP Bottleneck_NNP algorithm_NN was_VBD use_NN =_JJ -_: =d_NN in_IN -LRB-_-LRB- 1_CD ,_, 19_CD -_: =-]_CD to_TO cluster_VB words_NNS in_IN order_NN to_TO reduce_VB feature_NN size_NN for_IN supervised_JJ text_NN classication_NN ._.
For_IN this_DT same_JJ task_NN ,_, recently_RB -LRB-_-LRB- 6_CD -RRB-_-RRB- proposed_VBD a_DT divisive_JJ hard_JJ clustering_NN algorithm_NN that_WDT directly_RB minimizes_VBZ the_DT loss_NN in_IN
ve_IN hard_JJ clustering_NN version_NN of_IN the_DT Information_NNP Bottleneck_NNP algorithm_NN was_VBD used_VBN in_IN -LRB-_-LRB- 1_CD ,_, 19_CD -RRB-_-RRB- to_TO cluster_VB words_NNS in_IN order_NN to_TO reduce_VB feature_NN size_NN for_IN supervised_JJ text_NN classication_NN ._.
For_IN this_DT same_JJ task_NN ,_, recently_RB -LRB-_-LRB- =_JJ -_: =_JJ 6_CD -_: =-]_CD proposed_VBD a_DT divisive_JJ hard_JJ clustering_NN algorithm_NN that_WDT directly_RB minimizes_VBZ the_DT loss_NN in_IN mutual_JJ information_NN and_CC was_VBD found_VBN to_TO result_VB in_IN higher_JJR classication_NN accuracies_NNS than_IN -LRB-_-LRB- 1_CD ,_, 19_CD -RRB-_-RRB- ._.
All_DT these_DT algorithms_NNS were_VBD
-LRB-_-LRB- 11_CD -RRB-_-RRB- which_WDT used_VBD a_DT local_JJ greedy_JJ splitting_NN procedure_NN to_TO identify_VB hierarchical_JJ row_NN and_CC column_NN clusters_NNS in_IN matrices_NNS of_IN small_JJ size_NN ._.
Co-clustering_NN has_VBZ also_RB been_VBN called_VBN biclustering_VBG and_CC block_VB clustering_NN in_IN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: and_CC -LRB-_-LRB- 17_CD -RRB-_-RRB- respectively_RB ._.
Recently_RB -LRB-_-LRB- 4_CD -RRB-_-RRB- used_VBD a_DT graph_NN formulation_NN and_CC a_DT spectral_JJ heuristic_NN that_WDT uses_VBZ eigenvectors_NNS to_TO co-cluster_JJ documents_NNS and_CC words_NNS ;_: however_RB ,_, a_DT restriction_NN in_IN -LRB-_-LRB- 4_CD -RRB-_-RRB- was_VBD that_IN each_DT word_NN cluste_NN
o-clustering_NN ._.
3_CD Related_JJ work_NN Most_NNP of_IN the_DT clustering_NN literature_NN has_VBZ focused_VBN on_IN one-sided_JJ clustering_NN algorithms_NNS ,_, see_VB -LRB-_-LRB- 12_CD -RRB-_-RRB- for_IN a_DT comprehensive_JJ survey_NN ._.
There_EX was_VBD some_DT early_JJ work_NN on_IN co-clustering_NN ,_, such_JJ as_IN =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: which_WDT was_VBD limited_VBN to_TO problems_NNS of_IN small_JJ sizes_NNS and_CC used_VBD a_DT local_JJ greedy_JJ splitting_NN procedure_NN to_TO identify_VB hierarchical_JJ row_NN and_CC column_NN clusters_NNS ._.
More_RBR recently_RB -LRB-_-LRB- 4_CD -RRB-_-RRB- used_VBD a_DT bipartite_JJ graph_NN formulation_NN and_CC a_DT s_NN
e_LS presented_VBN examples_NNS to_TO motivate_VB the_DT new_JJ concepts_NNS and_CC to_TO illustrate_VB the_DT ecacy_NN of_IN our_PRP$ algorithm_NN ._.
In_IN particular_JJ ,_, word-document_JJ matrices_NNS that_WDT arise_VBP in_IN information_NN retrieval_NN are_VBP known_VBN to_TO be_VB highly_RB sparse_JJ =_JJ -_: =[_NN 7_CD -_: =-]_CD ._.
For_IN such_JJ sparse_JJ data_NNS ,_, even_RB if_IN one_CD were_VBD only_RB interested_JJ in_IN document_NN clustering_NN ,_, we_PRP believe_VBP that_DT co-clustering_NN will_MD be_VB more_RBR eective_JJ than_IN a_DT plain_JJ clustering_NN of_IN just_JJ documents_NNS ._.
The_DT reason_NN is_VBZ that_IN when_WRB
