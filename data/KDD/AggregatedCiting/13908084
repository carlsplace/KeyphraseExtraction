Mining_NNP and_CC summarizing_VBG customer_NN reviews_NNS
Merchants_NNS selling_VBG products_NNS on_IN the_DT Web_NN often_RB ask_VBP their_PRP$ customers_NNS to_TO review_VB the_DT products_NNS that_IN they_PRP have_VBP purchased_VBN and_CC the_DT associated_VBN services_NNS ._.
As_IN e-commerce_NN is_VBZ becoming_VBG more_RBR and_CC more_RBR popular_JJ ,_, the_DT number_NN of_IN customer_NN reviews_NNS that_IN a_DT product_NN receives_VBZ grows_VBZ rapidly_RB ._.
For_IN a_DT popular_JJ product_NN ,_, the_DT number_NN of_IN reviews_NNS can_MD be_VB in_IN hundreds_NNS or_CC even_RB thousands_NNS ._.
This_DT makes_VBZ it_PRP difficult_JJ for_IN a_DT potential_JJ customer_NN to_TO read_VB them_PRP to_TO make_VB an_DT informed_JJ decision_NN on_IN whether_IN to_TO purchase_VB the_DT product_NN ._.
It_PRP also_RB makes_VBZ it_PRP difficult_JJ for_IN the_DT manufacturer_NN of_IN the_DT product_NN to_TO keep_VB track_NN and_CC to_TO manage_VB customer_NN opinions_NNS ._.
For_IN the_DT manufacturer_NN ,_, there_EX are_VBP additional_JJ difficulties_NNS because_IN many_JJ merchant_NN sites_NNS may_MD sell_VB the_DT same_JJ product_NN and_CC the_DT manufacturer_NN normally_RB produces_VBZ many_JJ kinds_NNS of_IN products_NNS ._.
In_IN this_DT research_NN ,_, we_PRP aim_VBP to_TO mine_VB and_CC to_TO summarize_VB all_PDT the_DT customer_NN reviews_NNS of_IN a_DT product_NN ._.
This_DT summarization_NN task_NN is_VBZ different_JJ from_IN traditional_JJ text_NN summarization_NN because_IN we_PRP only_RB mine_VBP the_DT features_NNS of_IN the_DT product_NN on_IN which_WDT the_DT customers_NNS have_VBP expressed_VBN their_PRP$ opinions_NNS and_CC whether_IN the_DT opinions_NNS are_VBP positive_JJ or_CC negative_JJ ._.
We_PRP do_VBP not_RB summarize_VB the_DT reviews_NNS by_IN selecting_VBG a_DT subset_NN or_CC rewrite_VB some_DT of_IN the_DT original_JJ sentences_NNS from_IN the_DT reviews_NNS to_TO capture_VB the_DT main_JJ points_NNS as_IN in_IN the_DT classic_JJ text_NN summarization_NN ._.
Our_PRP$ task_NN is_VBZ performed_VBN in_IN three_CD steps_NNS :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- mining_NN product_NN features_NNS that_WDT have_VBP been_VBN commented_VBN on_RP by_IN customers_NNS ;_: -LRB-_-LRB- 2_LS -RRB-_-RRB- identifying_VBG opinion_NN sentences_NNS in_IN each_DT review_NN and_CC deciding_VBG whether_IN each_DT opinion_NN sentence_NN is_VBZ positive_JJ or_CC negative_JJ ;_: -LRB-_-LRB- 3_LS -RRB-_-RRB- summarizing_VBG the_DT results_NNS ._.
This_DT paper_NN proposes_VBZ several_JJ novel_JJ techniques_NNS to_TO perform_VB these_DT tasks_NNS ._.
Our_PRP$ experimental_JJ results_NNS using_VBG reviews_NNS of_IN a_DT number_NN of_IN products_NNS sold_VBD online_NN demonstrate_VBP the_DT effectiveness_NN of_IN the_DT techniques_NNS ._.
nt_NN 's_POS content_NN ._.
Our_PRP$ work_NN is_VBZ different_JJ in_IN that_IN we_PRP do_VBP not_RB extract_VB representative_JJ sentences_NNS ,_, but_CC identify_VB and_CC extract_VB those_DT specific_JJ product_NN features_NNS and_CC the_DT opinions_NNS related_VBN to_TO them_PRP ._.
Boguraev_NNP and_CC Kennedy_NNP =_SYM -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: propose_VBP to_TO find_VB a_DT few_JJ very_RB prominent_JJ expressions_NNS ,_, objects_NNS or_CC events_NNS in_IN a_DT document_NN and_CC use_VB them_PRP to_TO help_VB summarize_VB the_DT document_NN ._.
Our_PRP$ work_NN is_VBZ again_RB different_JJ as_IN we_PRP find_VBP all_DT product_NN features_NNS in_IN a_DT set_NN of_IN
ut_NN ._.
For_IN a_DT manufacturer_NN ,_, it_PRP is_VBZ possible_JJ to_TO combine_VB summaries_NNS from_IN multiple_JJ merchant_NN sites_NNS to_TO produce_VB a_DT single_JJ report_NN for_IN each_DT of_IN its_PRP$ products_NNS ._.
Our_PRP$ task_NN is_VBZ different_JJ from_IN traditional_JJ text_NN summarization_NN =_JJ -_: =[_NN 15_CD ,_, 39_CD ,_, 36_CD -RRB-_-RRB- -_: =_SYM -_: in_IN a_DT number_NN of_IN ways_NNS ._.
First_RB of_IN all_DT ,_, a_DT summary_NN in_IN our_PRP$ case_NN is_VBZ structured_VBN rather_RB than_IN another_DT -LRB-_-LRB- but_CC shorter_JJR -RRB-_-RRB- free_JJ text_NN document_NN as_IN produced_VBN by_IN most_JJS text_NN summarization_NN systems_NNS ._.
Second_RB ,_, we_PRP are_VBP only_JJ interes_NNS
classification_NN classifies_VBZ texts_NNS into_IN different_JJ styles_NNS ,_, e.g._FW ,_, ``_`` editorial_NN ''_'' ,_, ``_`` novel_JJ ''_'' ,_, ``_`` news_NN ''_'' ,_, ``_`` poem_NN ''_'' etc._NN ._.
Although_IN some_DT techniques_NNS for_IN genre_NN classification_NN can_MD recognize_VB documents_NNS that_WDT express_VBP opinions_NNS =_JJ -_: =[_NN 23_CD ,_, 24_CD ,_, 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, they_PRP do_VBP not_RB tell_VB whether_IN the_DT opinions_NNS are_VBP positive_JJ or_CC negative_JJ ._.
In_IN our_PRP$ work_NN ,_, we_PRP need_VBP to_TO determine_VB whether_IN an_DT opinion_NN is_VBZ positive_JJ or_CC negative_JJ and_CC to_TO perform_VB opinion_NN classification_NN at_IN the_DT sentence_NN lev_NN
ut_NN ._.
For_IN a_DT manufacturer_NN ,_, it_PRP is_VBZ possible_JJ to_TO combine_VB summaries_NNS from_IN multiple_JJ merchant_NN sites_NNS to_TO produce_VB a_DT single_JJ report_NN for_IN each_DT of_IN its_PRP$ products_NNS ._.
Our_PRP$ task_NN is_VBZ different_JJ from_IN traditional_JJ text_NN summarization_NN =_JJ -_: =[_NN 15_CD ,_, 39_CD ,_, 36_CD -RRB-_-RRB- -_: =_SYM -_: in_IN a_DT number_NN of_IN ways_NNS ._.
First_RB of_IN all_DT ,_, a_DT summary_NN in_IN our_PRP$ case_NN is_VBZ structured_VBN rather_RB than_IN another_DT -LRB-_-LRB- but_CC shorter_JJR -RRB-_-RRB- free_JJ text_NN document_NN as_IN produced_VBN by_IN most_JJS text_NN summarization_NN systems_NNS ._.
Second_RB ,_, we_PRP are_VBP only_JJ interes_NNS
ressed_VBD their_PRP$ opinions_NNS ._.
Although_IN they_PRP do_VBP find_VB some_DT frequent_JJ phrases_NNS indicating_VBG reputations_NNS ,_, these_DT phrases_NNS may_MD not_RB be_VB product_NN features_NNS -LRB-_-LRB- e.g._FW ,_, ``_`` does_VBZ n't_RB work_VB ''_'' ,_, ``_`` benchmark_JJ result_NN ''_'' and_CC ``_`` no_DT problem_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- ''_'' -RRB-_-RRB- ._.
In_IN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Cardie_NNP et_FW al_FW discuss_VB opinion-oriented_JJ information_NN extraction_NN ._.
They_PRP aim_VBP to_TO create_VB summary_NN representations_NNS of_IN opinions_NNS to_TO perform_VB question_NN answering_NN ._.
They_PRP propose_VBP to_TO use_VB opinion-oriented_JJ ``_`` scenario_NN tem_NN
we_PRP focus_VBP on_IN finding_VBG frequent_JJ features_NNS ,_, i.e._FW ,_, those_DT features_NNS that_WDT are_VBP talked_VBN about_IN by_IN many_JJ customers_NNS -LRB-_-LRB- finding_VBG infrequent_JJ features_NNS will_MD be_VB discussed_VBN later_RB -RRB-_-RRB- ._.
For_IN this_DT purpose_NN ,_, we_PRP use_VBP association_NN mining_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: to_TO find_VB all_DT frequent_JJ itemsets_NNS ._.
In_IN our_PRP$ context_NN ,_, an_DT itemset_NN is_VBZ simply_RB a_DT set_NN of_IN words_NNS or_CC a_DT phrase_NN that_WDT occurs_VBZ together_RB in_IN some_DT sentences_NNS ._.
The_DT main_JJ reason_NN for_IN using_VBG association_NN mining_NN is_VBZ because_IN of_IN the_DT f_FW
classification_NN classifies_VBZ texts_NNS into_IN different_JJ styles_NNS ,_, e.g._FW ,_, ``_`` editorial_NN ''_'' ,_, ``_`` novel_JJ ''_'' ,_, ``_`` news_NN ''_'' ,_, ``_`` poem_NN ''_'' etc._NN ._.
Although_IN some_DT techniques_NNS for_IN genre_NN classification_NN can_MD recognize_VB documents_NNS that_WDT express_VBP opinions_NNS =_JJ -_: =[_NN 23_CD ,_, 24_CD ,_, 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, they_PRP do_VBP not_RB tell_VB whether_IN the_DT opinions_NNS are_VBP positive_JJ or_CC negative_JJ ._.
In_IN our_PRP$ work_NN ,_, we_PRP need_VBP to_TO determine_VB whether_IN an_DT opinion_NN is_VBZ positive_JJ or_CC negative_JJ and_CC to_TO perform_VB opinion_NN classification_NN at_IN the_DT sentence_NN lev_NN
guistics_NNS ._.
Das_NNP and_CC Chen_NNP -LRB-_-LRB- 8_CD -RRB-_-RRB- use_VBP a_DT manually_RB crafted_VBN lexicon_NN in_IN conjunction_NN with_IN several_JJ scoring_VBG methods_NNS to_TO classify_VB 169Research_NNP Track_NNP Paper_NNP stock_NN postings_NNS on_IN an_DT investor_NN bulletin_NN ._.
Huettner_NNP and_CC Subasic_NNP =_SYM -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: also_RB manually_RB construct_VB a_DT discriminant-word_JJ lexicon_NN and_CC use_VB fuzzy_JJ logic_NN to_TO classify_VB sentiments_NNS ._.
Tong_NNP -LRB-_-LRB- 41_CD -RRB-_-RRB- generates_VBZ sentiment_NN timelines_NNS ._.
It_PRP tracks_VBZ online_JJ discussions_NNS about_IN movies_NNS and_CC displays_VBZ a_DT plot_NN
nly_RB positive_JJ and_CC negative_JJ orientations_NNS ._.
Unfortunately_RB ,_, dictionaries_NNS and_CC similar_JJ sources_NNS ,_, i.e._FW ,_, WordNet_NNP -LRB-_-LRB- 29_CD -RRB-_-RRB- do_VBP not_RB include_VB semantic_JJ orientation_NN information_NN for_IN each_DT word_NN ._.
Hatzivassiloglou_NNP and_CC McKeown_NNP =_SYM -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: use_VB a_DT supervised_JJ learning_NN algorithm_NN to_TO infer_VB the_DT semantic_JJ orientation_NN of_IN adjectives_NNS from_IN constraints_NNS on_IN conjunctions_NNS ._.
Although_IN their_PRP$ method_NN achieves_VBZ high_JJ precision_NN ,_, it_PRP relies_VBZ on_IN a_DT large_JJ corpus_NN ,_, and_CC n_NN
st_NN of_IN seed_NN adjectives_NNS tagged_VBN with_IN positive_JJ or_CC negative_JJ labels_NNS ._.
Our_PRP$ seed_NN adjective_JJ list_NN is_VBZ also_RB domain_NN independent_JJ ._.
An_DT effective_JJ technique_NN is_VBZ proposed_VBN to_TO grow_VB this_DT list_NN using_VBG WordNet_NNP ._.
Turney_NNP 's_POS work_NN in_IN =_JJ -_: =[_NN 42_CD -RRB-_-RRB- -_: =_SYM -_: applies_VBZ a_DT specific_JJ unsupervised_JJ learning_NN technique_NN based_VBN on_IN the_DT mutual_JJ information_NN between_IN document_NN phrases_NNS and_CC the_DT words_NNS ``_`` excellent_JJ ''_'' and_CC ``_`` poor_JJ ''_'' ,_, where_WRB the_DT mutual_JJ information_NN is_VBZ computed_VBN using_VBG statis_NN
opinion_NN words_NNS in_IN this_DT paper_NN ._.
Second_JJ ,_, for_IN each_DT opinion_NN word_NN ,_, we_PRP determine_VBD its_PRP$ semantic_JJ orientation_NN ,_, e.g._FW ,_, positive_JJ or_CC negative_JJ ._.
A_DT bootstrapping_NN technique_NN is_VBZ proposed_VBN to_TO perform_VB this_DT task_NN using_VBG WordNet_NN =_JJ -_: =[_NN 29_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Finally_RB ,_, we_PRP decide_VBP the_DT opinion_NN orientation_NN of_IN each_DT sentence_NN ._.
An_DT effective_JJ algorithm_NN is_VBZ also_RB given_VBN for_IN this_DT purpose_NN ._.
-LRB-_-LRB- 3_LS -RRB-_-RRB- Summarizing_VBG the_DT results_NNS ._.
This_DT step_NN aggregates_NNS the_DT results_NNS of_IN previous_JJ steps_NNS an_DT
nique_NN based_VBN on_IN the_DT mutual_JJ information_NN between_IN document_NN phrases_NNS and_CC the_DT words_NNS ``_`` excellent_JJ ''_'' and_CC ``_`` poor_JJ ''_'' ,_, where_WRB the_DT mutual_JJ information_NN is_VBZ computed_VBN using_VBG statistics_NNS gathered_VBN by_IN a_DT search_NN engine_NN ._.
Pang_NNP et_FW al._FW =_SYM -_: =[_NN 33_CD -RRB-_-RRB- -_: =_SYM -_: examine_VB several_JJ supervised_JJ machine_NN learning_NN methods_NNS for_IN sentiment_NN classification_NN of_IN movie_NN reviews_NNS and_CC conclude_VBP that_IN machine_NN learning_NN techniques_NNS outperform_VBP the_DT method_NN that_WDT is_VBZ based_VBN on_IN human-tagged_JJ fea_NN
ut_NN ._.
For_IN a_DT manufacturer_NN ,_, it_PRP is_VBZ possible_JJ to_TO combine_VB summaries_NNS from_IN multiple_JJ merchant_NN sites_NNS to_TO produce_VB a_DT single_JJ report_NN for_IN each_DT of_IN its_PRP$ products_NNS ._.
Our_PRP$ task_NN is_VBZ different_JJ from_IN traditional_JJ text_NN summarization_NN =_JJ -_: =[_NN 15_CD ,_, 39_CD ,_, 36_CD -RRB-_-RRB- -_: =_SYM -_: in_IN a_DT number_NN of_IN ways_NNS ._.
First_RB of_IN all_DT ,_, a_DT summary_NN in_IN our_PRP$ case_NN is_VBZ structured_VBN rather_RB than_IN another_DT -LRB-_-LRB- but_CC shorter_JJR -RRB-_-RRB- free_JJ text_NN document_NN as_IN produced_VBN by_IN most_JJS text_NN summarization_NN systems_NNS ._.
Second_RB ,_, we_PRP are_VBP only_JJ interes_NNS
rge_NN number_NN of_IN customer_NN reviews_NNS of_IN 5_CD products_NNS sold_VBD online_JJ show_NN that_IN FBS_NN and_CC its_PRP$ techniques_NNS are_VBP highly_RB effectiveness_NN ._.
2_CD ._.
RELATED_NNS WORK_VBP Our_PRP$ work_NN is_VBZ closely_RB related_JJ to_TO Dave_NNP ,_, Lawrence_NNP and_CC Pennock_NNP 's_POS work_NN in_IN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: on_IN semantic_JJ classification_NN of_IN reviews_NNS ._.
Using_VBG available_JJ training_NN corpus_NN from_IN some_DT Web_NN sites_NNS ,_, where_WRB each_DT review_NN already_RB has_VBZ a_DT class_NN -LRB-_-LRB- e.g._FW ,_, thumbs-up_NN and_CC thumbs-downs_NNS ,_, or_CC some_DT other_JJ quantitative_JJ or_CC bina_NN
product_NN features_NNS that_WDT have_VBP been_VBN commented_VBN on_RP by_IN customers_NNS ._.
We_PRP make_VBP use_NN of_IN both_DT data_NNS mining_NN and_CC natural_JJ language_NN processing_NN techniques_NNS to_TO perform_VB this_DT task_NN ._.
This_DT part_NN of_IN the_DT study_NN has_VBZ been_VBN reported_VBN in_IN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, for_IN completeness_NN ,_, we_PRP will_MD summarize_VB its_PRP$ techniques_NNS in_IN this_DT paper_NN and_CC also_RB present_VBP a_DT comparative_JJ evaluation_NN ._.
-LRB-_-LRB- 2_LS -RRB-_-RRB- Identifying_VBG opinion_NN sentences_NNS in_IN each_DT review_NN and_CC deciding_VBG whether_IN each_DT opinio_NN
work_NN on_IN distinguishing_VBG sentences_NNS used_VBN to_TO express_VB subjective_JJ opinions_NNS from_IN sentences_NNS used_VBN to_TO objectively_RB 171Research_NNP Track_NNP Paper_NNP describe_VBP some_DT factual_JJ information_NN -LRB-_-LRB- 43_CD -RRB-_-RRB- ._.
Previous_JJ work_NN on_IN subjectivity_NN =_JJ -_: =[_NN 44_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: has_VBZ established_VBN a_DT positive_JJ statistically_RB significant_JJ correlation_NN with_IN the_DT presence_NN of_IN adjectives_NNS ._.
Thus_RB the_DT presence_NN of_IN adjectives_NNS is_VBZ useful_JJ for_IN predicting_VBG whether_IN a_DT sentence_NN is_VBZ subjective_JJ ,_, i.e._FW ,_, expr_NN
work_NN on_IN distinguishing_VBG sentences_NNS used_VBN to_TO express_VB subjective_JJ opinions_NNS from_IN sentences_NNS used_VBN to_TO objectively_RB 171Research_NNP Track_NNP Paper_NNP describe_VBP some_DT factual_JJ information_NN -LRB-_-LRB- 43_CD -RRB-_-RRB- ._.
Previous_JJ work_NN on_IN subjectivity_NN =_JJ -_: =[_NN 44_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: has_VBZ established_VBN a_DT positive_JJ statistically_RB significant_JJ correlation_NN with_IN the_DT presence_NN of_IN adjectives_NNS ._.
Thus_RB the_DT presence_NN of_IN adjectives_NNS is_VBZ useful_JJ for_IN predicting_VBG whether_IN a_DT sentence_NN is_VBZ subjective_JJ ,_, i.e._FW ,_, expr_NN
s_NNS have_VBP been_VBN expressed_VBN ._.
2.2_CD Sentiment_NN Classification_NN Works_NNP of_IN Hearst_NNP -LRB-_-LRB- 18_CD -RRB-_-RRB- and_CC Sack_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- on_IN sentiment-based_JJ classification_NN of_IN entire_JJ documents_NNS use_VBP models_NNS inspired_VBN by_IN cognitive_JJ linguistics_NNS ._.
Das_NNP and_CC Chen_NNP =_SYM -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: use_VB a_DT manually_RB crafted_VBN lexicon_NN in_IN conjunction_NN with_IN several_JJ scoring_VBG methods_NNS to_TO classify_VB 169Research_NNP Track_NNP Paper_NNP stock_NN postings_NNS on_IN an_DT investor_NN bulletin_NN ._.
Huettner_NNP and_CC Subasic_NNP -LRB-_-LRB- 20_CD -RRB-_-RRB- also_RB manually_RB constru_VB
specific_JJ task_NN of_IN determining_VBG the_DT semantic_JJ orientations_NNS of_IN those_DT subjective_JJ sentences_NNS ._.
Neither_DT do_VBP they_PRP find_VB features_NNS on_IN which_WDT opinions_NNS have_VBP been_VBN expressed_VBN ._.
2.2_CD Sentiment_NN Classification_NN Works_NNP of_IN Hearst_NNP =_SYM -_: =[_NN 18_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Sack_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- on_IN sentiment-based_JJ classification_NN of_IN entire_JJ documents_NNS use_VBP models_NNS inspired_VBN by_IN cognitive_JJ linguistics_NNS ._.
Das_NNP and_CC Chen_NNP -LRB-_-LRB- 8_CD -RRB-_-RRB- use_VBP a_DT manually_RB crafted_VBN lexicon_NN in_IN conjunction_NN with_IN several_JJ scoring_VBG m_NN
lassify_JJ 169Research_NN Track_NNP Paper_NNP stock_NN postings_NNS on_IN an_DT investor_NN bulletin_NN ._.
Huettner_NNP and_CC Subasic_NNP -LRB-_-LRB- 20_CD -RRB-_-RRB- also_RB manually_RB construct_VB a_DT discriminant-word_JJ lexicon_NN and_CC use_VB fuzzy_JJ logic_NN to_TO classify_VB sentiments_NNS ._.
Tong_NNP =_SYM -_: =[_NN 41_CD -RRB-_-RRB- -_: =_SYM -_: generates_VBZ sentiment_NN timelines_NNS ._.
It_PRP tracks_VBZ online_JJ discussions_NNS about_IN movies_NNS and_CC displays_VBZ a_DT plot_NN of_IN the_DT number_NN of_IN positive_JJ and_CC negative_JJ sentiment_NN messages_NNS over_IN time_NN ._.
Messages_NNS are_VBP classified_VBN by_IN looking_VBG fo_NN
s_NN is_VBZ appropriate_JJ because_IN those_DT frequent_JJ itemsets_NNS are_VBP likely_JJ to_TO be_VB product_NN features_NNS ._.
Those_DT noun\/noun_JJ phrases_NNS that_WDT are_VBP infrequent_JJ are_VBP likely_JJ to_TO be_VB non-product_JJ features_NNS ._.
We_PRP run_VBP the_DT association_NN miner_NN CBA_NN =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT is_VBZ based_VBN on_IN the_DT Apriori_NNP algorithm_NN in_IN -LRB-_-LRB- 1_LS -RRB-_-RRB- on_IN the_DT transaction_NN set_NN of_IN noun\/noun_JJ phrases_NNS produced_VBN in_IN the_DT previous_JJ step_NN ._.
Each_DT resulting_VBG frequent_JJ itemset_NN is_VBZ a_DT possible_JJ feature_NN ._.
In_IN our_PRP$ work_NN ,_, we_PRP defin_VBP
practice_NN ._.
2.3_CD Text_NN Summarization_NN Existing_VBG text_NN summarization_NN techniques_NNS mainly_RB fall_VBP in_IN one_CD of_IN the_DT two_CD categories_NNS :_: template_NN instantiation_NN and_CC passage_NN extraction_NN ._.
Work_NN in_IN the_DT former_JJ framework_NN includes_VBZ =_JJ -_: =[_NN 10_CD ,_, 39_CD -RRB-_-RRB- -_: =_SYM -_: ._.
They_PRP emphasize_VBP on_IN identification_NN and_CC extraction_NN of_IN certain_JJ core_NN entities_NNS and_CC facts_NNS in_IN a_DT document_NN ,_, which_WDT are_VBP packaged_VBN in_IN a_DT template_NN ._.
This_DT framework_NN requires_VBZ background_NN knowledge_NN in_IN order_NN to_TO instantia_NN
that_WDT rely_VBP on_IN syntactic_JJ description_NN of_IN terms_NNS ,_, namely_RB noun_NN phrases_NNS ,_, and_CC statistical_JJ approaches_NNS that_WDT exploit_VBP the_DT fact_NN that_IN the_DT words_NNS composing_VBG a_DT term_NN tend_VB to_TO be_VB found_VBN close_RB to_TO each_DT other_JJ and_CC reoccurring_VBG =_JJ -_: =[_NN 21_CD ,_, 22_CD ,_, 7_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, using_VBG noun_NN phrases_NNS tends_VBZ to_TO produce_VB too_RB many_JJ non-terms_NNS -LRB-_-LRB- low_JJ precision_NN -RRB-_-RRB- ,_, while_IN using_VBG reoccurring_VBG phrases_NNS misses_VBZ many_JJ low_JJ frequency_NN terms_NNS ,_, terms_NNS with_IN variations_NNS ,_, and_CC terms_NNS with_IN only_RB one_CD word_NN ._.
of_IN determining_VBG the_DT semantic_JJ orientations_NNS of_IN those_DT subjective_JJ sentences_NNS ._.
Neither_DT do_VBP they_PRP find_VB features_NNS on_IN which_WDT opinions_NNS have_VBP been_VBN expressed_VBN ._.
2.2_CD Sentiment_NN Classification_NN Works_NNP of_IN Hearst_NNP -LRB-_-LRB- 18_CD -RRB-_-RRB- and_CC Sack_NN =_JJ -_: =[_NN 35_CD -RRB-_-RRB- -_: =_SYM -_: on_IN sentiment-based_JJ classification_NN of_IN entire_JJ documents_NNS use_VBP models_NNS inspired_VBN by_IN cognitive_JJ linguistics_NNS ._.
Das_NNP and_CC Chen_NNP -LRB-_-LRB- 8_CD -RRB-_-RRB- use_VBP a_DT manually_RB crafted_VBN lexicon_NN in_IN conjunction_NN with_IN several_JJ scoring_VBG methods_NNS to_TO clas_NNS
ment_NN ,_, which_WDT are_VBP packaged_VBN in_IN a_DT template_NN ._.
This_DT framework_NN requires_VBZ background_NN knowledge_NN in_IN order_NN to_TO instantiate_VB a_DT template_NN to_TO a_DT suitable_JJ level_NN of_IN detail_NN ._.
Therefore_RB ,_, it_PRP is_VBZ not_RB domain_NN or_CC genre_NN independent_NN =_JJ -_: =[_NN 37_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ different_JJ from_IN our_PRP$ work_NN as_IN our_PRP$ techniques_NNS do_VBP not_RB fill_VB any_DT template_NN and_CC are_VBP domain_NN independent_JJ ._.
The_DT passage_NN extraction_NN framework_NN -LRB-_-LRB- e.g._FW ,_, 32_CD ,_, 25_CD ,_, 36_CD -RRB-_-RRB- identifies_VBZ certain_JJ segments_NNS of_IN the_DT text_NN -LRB-_-LRB- ty_NN
ment_NN ,_, which_WDT are_VBP packaged_VBN in_IN a_DT template_NN ._.
This_DT framework_NN requires_VBZ background_NN knowledge_NN in_IN order_NN to_TO instantiate_VB a_DT template_NN to_TO a_DT suitable_JJ level_NN of_IN detail_NN ._.
Therefore_RB ,_, it_PRP is_VBZ not_RB domain_NN or_CC genre_NN independent_NN =_JJ -_: =[_NN 37_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ different_JJ from_IN our_PRP$ work_NN as_IN our_PRP$ techniques_NNS do_VBP not_RB fill_VB any_DT template_NN and_CC are_VBP domain_NN independent_JJ ._.
The_DT passage_NN extraction_NN framework_NN -LRB-_-LRB- e.g._FW ,_, 32_CD ,_, 25_CD ,_, 36_CD -RRB-_-RRB- identifies_VBZ certain_JJ segments_NNS of_IN the_DT text_NN -LRB-_-LRB- ty_NN
Clearly_RB ,_, this_DT is_VBZ related_JJ to_TO existing_VBG work_NN on_IN distinguishing_VBG sentences_NNS used_VBN to_TO express_VB subjective_JJ opinions_NNS from_IN sentences_NNS used_VBN to_TO objectively_RB 171Research_NNP Track_NNP Paper_NNP describe_VBP some_DT factual_JJ information_NN =_JJ -_: =[_NN 43_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Previous_JJ work_NN on_IN subjectivity_NN -LRB-_-LRB- 44_CD ,_, 4_CD -RRB-_-RRB- has_VBZ established_VBN a_DT positive_JJ statistically_RB significant_JJ correlation_NN with_IN the_DT presence_NN of_IN adjectives_NNS ._.
Thus_RB the_DT presence_NN of_IN adjectives_NNS is_VBZ useful_JJ for_IN predicting_VBG wheth_NN
that_WDT rely_VBP on_IN syntactic_JJ description_NN of_IN terms_NNS ,_, namely_RB noun_NN phrases_NNS ,_, and_CC statistical_JJ approaches_NNS that_WDT exploit_VBP the_DT fact_NN that_IN the_DT words_NNS composing_VBG a_DT term_NN tend_VB to_TO be_VB found_VBN close_RB to_TO each_DT other_JJ and_CC reoccurring_VBG =_JJ -_: =[_NN 21_CD ,_, 22_CD ,_, 7_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, using_VBG noun_NN phrases_NNS tends_VBZ to_TO produce_VB too_RB many_JJ non-terms_NNS -LRB-_-LRB- low_JJ precision_NN -RRB-_-RRB- ,_, while_IN using_VBG reoccurring_VBG phrases_NNS misses_VBZ many_JJ low_JJ frequency_NN terms_NNS ,_, terms_NNS with_IN variations_NNS ,_, and_CC terms_NNS with_IN only_RB one_CD word_NN ._.
opinion_NN words_NNS in_IN this_DT paper_NN ._.
Second_JJ ,_, for_IN each_DT opinion_NN word_NN ,_, we_PRP determine_VBD its_PRP$ semantic_JJ orientation_NN ,_, e.g._FW ,_, positive_JJ or_CC negative_JJ ._.
A_DT bootstrapping_NN technique_NN is_VBZ proposed_VBN to_TO perform_VB this_DT task_NN using_VBG WordNet_NN =_JJ -_: =[_NN 29_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Finally_RB ,_, we_PRP decide_VBP the_DT opinion_NN orientation_NN of_IN each_DT sentence_NN ._.
An_DT effective_JJ algorithm_NN is_VBZ also_RB given_VBN for_IN this_DT purpose_NN ._.
-LRB-_-LRB- 3_LS -RRB-_-RRB- Summarizing_VBG the_DT results_NNS ._.
This_DT step_NN aggregates_NNS the_DT results_NNS of_IN previous_JJ steps_NNS an_DT
classification_NN classifies_VBZ texts_NNS into_IN different_JJ styles_NNS ,_, e.g._FW ,_, ``_`` editorial_NN ''_'' ,_, ``_`` novel_JJ ''_'' ,_, ``_`` news_NN ''_'' ,_, ``_`` poem_NN ''_'' etc._NN ._.
Although_IN some_DT techniques_NNS for_IN genre_NN classification_NN can_MD recognize_VB documents_NNS that_WDT express_VBP opinions_NNS =_JJ -_: =[_NN 23_CD ,_, 24_CD ,_, 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, they_PRP do_VBP not_RB tell_VB whether_IN the_DT opinions_NNS are_VBP positive_JJ or_CC negative_JJ ._.
In_IN our_PRP$ work_NN ,_, we_PRP need_VBP to_TO determine_VB whether_IN an_DT opinion_NN is_VBZ positive_JJ or_CC negative_JJ and_CC to_TO perform_VB opinion_NN classification_NN at_IN the_DT sentence_NN lev_NN
that_WDT rely_VBP on_IN syntactic_JJ description_NN of_IN terms_NNS ,_, namely_RB noun_NN phrases_NNS ,_, and_CC statistical_JJ approaches_NNS that_WDT exploit_VBP the_DT fact_NN that_IN the_DT words_NNS composing_VBG a_DT term_NN tend_VB to_TO be_VB found_VBN close_RB to_TO each_DT other_JJ and_CC reoccurring_VBG =_JJ -_: =[_NN 21_CD ,_, 22_CD ,_, 7_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, using_VBG noun_NN phrases_NNS tends_VBZ to_TO produce_VB too_RB many_JJ non-terms_NNS -LRB-_-LRB- low_JJ precision_NN -RRB-_-RRB- ,_, while_IN using_VBG reoccurring_VBG phrases_NNS misses_VBZ many_JJ low_JJ frequency_NN terms_NNS ,_, terms_NNS with_IN variations_NNS ,_, and_CC terms_NNS with_IN only_RB one_CD word_NN ._.
tation_NN prediction_NN ._.
We_PRP believe_VBP that_IN they_PRP may_MD be_VB used_VBN in_IN practical_JJ settings_NNS ._.
We_PRP also_RB note_VBP three_CD main_JJ limitations_NNS of_IN our_PRP$ system_NN :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- We_PRP have_VBP not_RB dealt_VBN with_IN opinion_NN sentences_NNS that_WDT need_VBP pronoun_NN resolution_NN =_JJ -_: =[_NN 40_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN instance_NN ,_, ``_`` it_PRP is_VBZ quiet_JJ but_CC powerful_JJ ''_'' ._.
To_TO understand_VB what_WP it_PRP represents_VBZ ,_, pronoun_NN resolution_NN needs_VBZ to_TO be_VB performed_VBN ._.
Pronoun_NN resolution_NN is_VBZ a_DT complex_JJ and_CC computational_JJ expensive_JJ problem_NN in_IN natural_JJ l_NN
