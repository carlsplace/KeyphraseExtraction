Effective_JJ label_NN acquisition_NN for_IN collective_JJ classification_NN
Information_NN diffusion_NN ,_, viral_JJ marketing_NN ,_, and_CC collective_JJ classification_NN all_DT attempt_NN to_TO model_VB and_CC exploit_VB the_DT relationships_NNS in_IN a_DT network_NN to_TO make_VB inferences_NNS about_IN the_DT labels_NNS of_IN nodes_NNS ._.
A_DT variety_NN of_IN techniques_NNS have_VBP been_VBN introduced_VBN and_CC methods_NNS that_WDT combine_VBP attribute_NN information_NN and_CC neighboring_JJ label_NN information_NN have_VBP been_VBN shown_VBN to_TO be_VB effective_JJ for_IN collective_JJ labeling_NN of_IN the_DT nodes_NNS in_IN a_DT network_NN ._.
However_RB ,_, in_IN part_NN because_IN of_IN the_DT correlation_NN between_IN node_NN labels_NNS that_IN the_DT techniques_NNS exploit_VBP ,_, it_PRP is_VBZ easy_JJ to_TO find_VB cases_NNS in_IN which_WDT ,_, once_RB a_DT misclassification_NN is_VBZ made_VBN ,_, incorrect_JJ information_NN propagates_VBZ throughout_IN the_DT network_NN ._.
This_DT problem_NN can_MD be_VB mitigated_VBN if_IN the_DT system_NN is_VBZ allowed_VBN to_TO judiciously_RB acquire_VB the_DT labels_NNS for_IN a_DT small_JJ number_NN of_IN nodes_NNS ._.
Unfortunately_RB ,_, under_IN relatively_RB general_JJ assumptions_NNS ,_, determining_VBG the_DT optimal_JJ set_NN of_IN labels_NNS to_TO acquire_VB is_VBZ intractable_JJ ._.
Here_RB we_PRP propose_VBP an_DT acquisition_NN method_NN that_WDT learns_VBZ the_DT cases_NNS when_WRB a_DT given_VBN collective_JJ classification_NN algorithm_NN makes_VBZ mistakes_NNS ,_, and_CC suggests_VBZ acquisitions_NNS to_TO correct_VB those_DT mistakes_NNS ._.
We_PRP empirically_RB show_VBP on_IN both_CC real_JJ and_CC synthetic_JJ datasets_NNS that_IN this_DT method_NN significantly_RB outperforms_VBZ a_DT greedy_JJ approximate_JJ inference_NN approach_NN ,_, a_DT viral_JJ marketing_NN approach_NN ,_, and_CC approaches_NNS based_VBN on_IN network_NN structural_JJ measures_NNS such_JJ as_IN node_NN degree_NN and_CC network_NN clustering_NN ._.
In_IN addition_NN to_TO significantly_RB improving_VBG accuracy_NN with_IN just_RB a_DT small_JJ amount_NN of_IN labeled_JJ data_NNS ,_, our_PRP$ method_NN is_VBZ tractable_JJ on_IN large_JJ networks_NNS ._.
erence_NN technique_NN is_VBZ expensive_JJ ,_, this_DT acquisition_NN method_NN can_MD be_VB very_RB slow_JJ ._.
4_LS ._.
VIRAL_NNP MARKETING_NNP ACQUISITION_NNP -LRB-_-LRB- VMA_NNP -RRB-_-RRB- Another_DT ,_, simpler_JJR ,_, approach_NN to_TO label_NN acquisition_NN is_VBZ based_VBN on_IN an_DT analogy_NN to_TO viral_JJ marketing_NN =_JJ -_: =[_NN 9_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN the_DT viral_JJ marketing_NN setting_NN ,_, we_PRP have_VBP customers_NNS that_WDT are_VBP potential_JJ buyers_NNS of_IN a_DT product_NN and_CC the_DT customers_NNS have_VBP relationships_NNS between_IN each_DT other_JJ ,_, such_JJ as_IN family_NN ,_, friendship_NN ,_, co-worker_NN ,_, etc._NN ._.
When_WRB a_DT c_NN
e_LS differences_NNS between_IN the_DT other_JJ methods_NNS were_VBD not_RB statistically_RB significant_JJ ._.
6.2_CD Experiments_NNS on_IN Real_NNP Data_NNP We_PRP experimented_VBD on_IN two_CD real_JJ publication_NN datasets_NNS that_WDT are_VBP publicly_RB available_JJ ,_, the_DT Cora_NNP dataset_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_JJ -_: and_CC the_DT CiteSeer_NNP dataset_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
The_DT Cora_NNP dataset_NN contains_VBZ a_DT 2708_CD machine_NN learning_NN papers_NNS that_WDT are_VBP divided_VBN into_IN 7_CD classes_NNS ,_, while_IN CiteSeer_FW dataset_FW has_VBZ 3312_CD documents_NNS that_WDT are_VBP divided_VBN into_IN 6_CD classes_NNS ._.
Our_PRP$
ady_RB trained_VBN model_NN of_IN the_DT domain_NN ,_, and_CC thus_RB the_DT learning_NN has_VBZ been_VBN done_VBN offline_JJ ,_, but_CC we_PRP have_VBP the_DT option_NN to_TO acquire_VB labels_NNS to_TO seed_NN the_DT classification_NN during_IN inference_NN ._.
This_DT is_VBZ the_DT setting_VBG Rattigan_NNP et_FW al._FW =_SYM -_: =[_NN 22_CD -RRB-_-RRB- -_: =_SYM -_: introduced_VBN and_CC referred_VBN to_TO as_IN ``_`` active_JJ inference_NN ._. ''_''
They_PRP looked_VBD at_IN the_DT relational_JJ network_NN classifier_NN ,_, introduced_VBN by_IN Macskassy_NNP and_CC Provost_NNP -LRB-_-LRB- 14_CD -RRB-_-RRB- in_IN which_WDT there_EX are_VBP no_DT node_NN attributes_VBZ ;_: only_RB labels_NNS are_VBP pro_JJ
it_PRP has_VBZ been_VBN shown_VBN that_IN methods_NNS such_JJ as_IN collective_JJ classification_NN ,_, i.e._FW ,_, classifying_VBG the_DT nodes_NNS of_IN a_DT network_NN simultaneously_RB ,_, can_MD significantly_RB outperform_VB the_DT traditional_JJ independent_JJ labeling_NN approaches_VBZ =_JJ -_: =[_NN 2_CD ,_, 7_CD ,_, 13_CD ,_, 15_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, sometimes_RB ,_, the_DT advantage_NN of_IN exploiting_VBG the_DT relationships_NNS can_MD become_VB a_DT disadvantage_NN ._.
An_DT incorrect_JJ prediction_NN about_IN a_DT particular_JJ node_NN -LRB-_-LRB- due_JJ to_TO an_DT approximate_JJ inference_NN procedure_NN ,_, noise_NN in_IN the_DT
ing_NN model_NN is_VBZ an_DT undirected_JJ graphical_JJ model_NN ,_, such_JJ as_IN Markov_NNP random_JJ field_NN ,_, there_EX are_VBP many_JJ approximate_JJ inference_NN techniques_NNS we_PRP can_MD make_VB use_NN of_IN ,_, such_JJ as_IN loopy_JJ belief_NN propagation_NN -LRB-_-LRB- 28_CD -RRB-_-RRB- ,_, variational_JJ methods_NNS =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Gibbs_NNP sampling_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, etc._NN ._.
If_IN the_DT underlying_JJ model_NN is_VBZ a_DT collection_NN of_IN local_JJ conditional_JJ models_NNS ,_, then_RB one_PRP can_MD use_VB iterative_JJ approaches_NNS to_TO compute_VB the_DT probabilities_NNS -LRB-_-LRB- 19_CD ,_, 13_CD -RRB-_-RRB- ._.
Moreover_RB ,_, instead_RB of_IN consid_NN
instance_NN ,_, when_WRB the_DT underlying_VBG model_NN is_VBZ an_DT undirected_JJ graphical_JJ model_NN ,_, such_JJ as_IN Markov_NNP random_JJ field_NN ,_, there_EX are_VBP many_JJ approximate_JJ inference_NN techniques_NNS we_PRP can_MD make_VB use_NN of_IN ,_, such_JJ as_IN loopy_JJ belief_NN propagation_NN =_JJ -_: =[_NN 28_CD -RRB-_-RRB- -_: =_JJ -_: ,_, variational_JJ methods_NNS -LRB-_-LRB- 8_CD -RRB-_-RRB- ,_, Gibbs_NN sampling_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, etc._NN ._.
If_IN the_DT underlying_JJ model_NN is_VBZ a_DT collection_NN of_IN local_JJ conditional_JJ models_NNS ,_, then_RB one_PRP can_MD use_VB iterative_JJ approaches_NNS to_TO compute_VB the_DT probabilities_NNS -LRB-_-LRB- 19_CD ,_, 13_CD -RRB-_-RRB- ._.
Mo_NN
hod_NN we_PRP propose_VBP significantly_RB outperforms_VBZ all_DT of_IN the_DT other_JJ methods_NNS on_IN both_CC real_JJ and_CC synthetic_JJ datasets_NNS ._.
The_DT label_NN acquisition_NN problem_NN has_VBZ received_VBN ample_JJ attention_NN within_IN the_DT context_NN of_IN active_JJ learning_NN =_JJ -_: =[_NN 3_CD ,_, 16_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
There_EX are_VBP two_CD main_JJ differences_NNS between_IN the_DT scenario_NN we_PRP address_VBP and_CC the_DT active_JJ learning_NN scenario_NN ._.
First_JJ ,_, active_JJ learning_NN has_VBZ traditionally_RB been_VBN concerned_VBN with_IN flat_JJ data_NNS ;_: here_RB ,_, we_PRP are_VBP interested_JJ in_IN ne_NN
butes_NNS of_IN other_JJ nodes_NNS in_IN the_DT graph_NN ._.
There_EX are_VBP many_JJ collective_JJ classification_NN models_NNS proposed_VBN to_TO date_NN that_WDT make_VBP different_JJ modeling_NN assumptions_NNS about_IN these_DT dependencies_NNS ._.
For_IN instance_NN ,_, Neville_NNP and_CC Jensen_NNP =_SYM -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Lu_NNP and_CC Getoor_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, Macskassy_NNP and_CC Provost_NNP -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, and_CC McDowell_NNP et_FW al._FW -LRB-_-LRB- 18_CD -RRB-_-RRB- make_VBP use_NN of_IN local_JJ models_NNS ,_, such_JJ as_IN Naive_JJ Bayes_NNS ,_, Logistic_JJ Regression_NN ,_, etc._NN ,_, as_IN a_DT function_NN of_IN the_DT local_JJ attributes_NNS Xi_NN and_CC aggreg_NN
ition_NN during_IN inference_NN ,_, the_DT aim_NN for_IN active_JJ learning_NN is_VBZ to_TO acquire_VB labels_NNS to_TO learn_VB a_DT good_JJ model_NN ._.
We_PRP are_VBP instead_RB acquiring_VBG labels_NNS during_IN inference_NN ._.
Another_DT related_JJ area_NN is_VBZ viral_JJ -LRB-_-LRB- or_CC targeted_VBN -RRB-_-RRB- marketing_NN =_JJ -_: =[_NN 9_CD ,_, 11_CD ,_, 21_CD ,_, 23_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB a_DT subset_NN of_IN customers_NNS need_VBP to_TO be_VB selected_VBN for_IN targeted_VBN advertisement_NN so_RB as_IN to_TO maximize_VB the_DT product_NN sales_NNS ._.
We_PRP showed_VBD how_WRB viral_JJ marketing_NN is_VBZ related_JJ to_TO label_NN acquisition_NN and_CC used_VBD Richardson_NNP &_CC Do_NNP
ition_NN during_IN inference_NN ,_, the_DT aim_NN for_IN active_JJ learning_NN is_VBZ to_TO acquire_VB labels_NNS to_TO learn_VB a_DT good_JJ model_NN ._.
We_PRP are_VBP instead_RB acquiring_VBG labels_NNS during_IN inference_NN ._.
Another_DT related_JJ area_NN is_VBZ viral_JJ -LRB-_-LRB- or_CC targeted_VBN -RRB-_-RRB- marketing_NN =_JJ -_: =[_NN 9_CD ,_, 11_CD ,_, 21_CD ,_, 23_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB a_DT subset_NN of_IN customers_NNS need_VBP to_TO be_VB selected_VBN for_IN targeted_VBN advertisement_NN so_RB as_IN to_TO maximize_VB the_DT product_NN sales_NNS ._.
We_PRP showed_VBD how_WRB viral_JJ marketing_NN is_VBZ related_JJ to_TO label_NN acquisition_NN and_CC used_VBD Richardson_NNP &_CC Do_NNP
ess_VB very_RB restrictive_JJ assumptions_NNS about_IN the_DT structure_NN of_IN the_DT underlying_VBG collective_JJ model_NN are_VBP made_VBN ,_, such_JJ as_IN linear_JJ dependence_NN on_IN the_DT neighborhood_NN and_CC attributes_NNS ,_, the_DT problem_NN is_VBZ at_IN least_JJS NP_NN PP_NN -_: complete_JJ =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC this_DT is_VBZ the_DT case_NN for_IN our_PRP$ model_NN CM_NN ._.
Since_IN finding_VBG the_DT optimal_JJ solution_NN to_TO the_DT label_NN acquisition_NN problem_NN is_VBZ intractable_JJ in_IN a_DT general_JJ setting_NN ,_, we_PRP must_MD resort_VB to_TO approximate_JJ techniques_NNS ._.
In_IN the_DT next_JJ
eric_JJ and_CC logistic_JJ regression_NN was_VBD able_JJ to_TO handle_VB them_PRP better_RBR than_IN Naive_JJ Bayes_NNPS with_IN Gaussians_NNP ._.
6.1_CD Experiments_NNS on_IN Synthetic_NNP Data_NNP We_PRP generated_VBD synthetic_JJ data_NNS using_VBG the_DT forest-fire_JJ graph_NN generation_NN model_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT forest_NN fire_NN model_NN is_VBZ shown_VBN to_TO exhibit_VB many_JJ real-world_JJ phenomenon_NN such_JJ as_IN power_NN law_NN degree_NN distribution_NN ,_, small_JJ world_NN effect_NN ,_, and_CC shrinking_NN diameters_NNS ._.
However_RB ,_, the_DT forest-fire_JJ method_NN ,_, like_IN most_JJS ra_NN
it_PRP has_VBZ been_VBN shown_VBN that_IN methods_NNS such_JJ as_IN collective_JJ classification_NN ,_, i.e._FW ,_, classifying_VBG the_DT nodes_NNS of_IN a_DT network_NN simultaneously_RB ,_, can_MD significantly_RB outperform_VB the_DT traditional_JJ independent_JJ labeling_NN approaches_VBZ =_JJ -_: =[_NN 2_CD ,_, 7_CD ,_, 13_CD ,_, 15_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, sometimes_RB ,_, the_DT advantage_NN of_IN exploiting_VBG the_DT relationships_NNS can_MD become_VB a_DT disadvantage_NN ._.
An_DT incorrect_JJ prediction_NN about_IN a_DT particular_JJ node_NN -LRB-_-LRB- due_JJ to_TO an_DT approximate_JJ inference_NN procedure_NN ,_, noise_NN in_IN the_DT
r_NN methods_NNS were_VBD not_RB statistically_RB significant_JJ ._.
6.2_CD Experiments_NNS on_IN Real_NNP Data_NNP We_PRP experimented_VBD on_IN two_CD real_JJ publication_NN datasets_NNS that_WDT are_VBP publicly_RB available_JJ ,_, the_DT Cora_NNP dataset_NN -LRB-_-LRB- 17_CD -RRB-_-RRB- and_CC the_DT CiteSeer_NNP dataset_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT Cora_NNP dataset_NN contains_VBZ a_DT 2708_CD machine_NN learning_NN papers_NNS that_WDT are_VBP divided_VBN into_IN 7_CD classes_NNS ,_, while_IN CiteSeer_FW dataset_FW has_VBZ 3312_CD documents_NNS that_WDT are_VBP divided_VBN into_IN 6_CD classes_NNS ._.
Our_PRP$ evaluation_NN methodology_NN is_VBZ sli_NN
st._NNP Other_NNP models_NNS could_MD very_RB well_RB be_VB used_VBN and_CC compared_VBN against_IN ;_: one_CD of_IN the_DT reasons_NNS we_PRP chose_VBD -LRB-_-LRB- 23_CD -RRB-_-RRB- is_VBZ the_DT fact_NN that_IN the_DT exact_JJ solution_NN was_VBD tractable_JJ ._.
The_DT work_NN in_IN feature-value_JJ acquisition_NN during_IN testing_NN =_JJ -_: =[_NN 1_CD ,_, 25_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ very_RB related_JJ to_TO the_DT label_NN acquisition_NN problem_NN ;_: however_RB ,_, the_DT focus_NN has_VBZ been_VBN on_IN acquiring_VBG feature_NN values_NNS ,_, not_RB labels_NNS ,_, and_CC also_RB they_PRP considered_VBD acquisition_NN for_IN non-graph_JJ data_NNS ._.
The_DT most_RBS related_JJ work_NN i_FW
st._NNP Other_NNP models_NNS could_MD very_RB well_RB be_VB used_VBN and_CC compared_VBN against_IN ;_: one_CD of_IN the_DT reasons_NNS we_PRP chose_VBD -LRB-_-LRB- 23_CD -RRB-_-RRB- is_VBZ the_DT fact_NN that_IN the_DT exact_JJ solution_NN was_VBD tractable_JJ ._.
The_DT work_NN in_IN feature-value_JJ acquisition_NN during_IN testing_NN =_JJ -_: =[_NN 1_CD ,_, 25_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ very_RB related_JJ to_TO the_DT label_NN acquisition_NN problem_NN ;_: however_RB ,_, the_DT focus_NN has_VBZ been_VBN on_IN acquiring_VBG feature_NN values_NNS ,_, not_RB labels_NNS ,_, and_CC also_RB they_PRP considered_VBD acquisition_NN for_IN non-graph_JJ data_NNS ._.
The_DT most_RBS related_JJ work_NN i_FW
hod_NN we_PRP propose_VBP significantly_RB outperforms_VBZ all_DT of_IN the_DT other_JJ methods_NNS on_IN both_CC real_JJ and_CC synthetic_JJ datasets_NNS ._.
The_DT label_NN acquisition_NN problem_NN has_VBZ received_VBN ample_JJ attention_NN within_IN the_DT context_NN of_IN active_JJ learning_NN =_JJ -_: =[_NN 3_CD ,_, 16_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
There_EX are_VBP two_CD main_JJ differences_NNS between_IN the_DT scenario_NN we_PRP address_VBP and_CC the_DT active_JJ learning_NN scenario_NN ._.
First_JJ ,_, active_JJ learning_NN has_VBZ traditionally_RB been_VBN concerned_VBN with_IN flat_JJ data_NNS ;_: here_RB ,_, we_PRP are_VBP interested_JJ in_IN ne_NN
it_PRP has_VBZ been_VBN shown_VBN that_IN methods_NNS such_JJ as_IN collective_JJ classification_NN ,_, i.e._FW ,_, classifying_VBG the_DT nodes_NNS of_IN a_DT network_NN simultaneously_RB ,_, can_MD significantly_RB outperform_VB the_DT traditional_JJ independent_JJ labeling_NN approaches_VBZ =_JJ -_: =[_NN 2_CD ,_, 7_CD ,_, 13_CD ,_, 15_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, sometimes_RB ,_, the_DT advantage_NN of_IN exploiting_VBG the_DT relationships_NNS can_MD become_VB a_DT disadvantage_NN ._.
An_DT incorrect_JJ prediction_NN about_IN a_DT particular_JJ node_NN -LRB-_-LRB- due_JJ to_TO an_DT approximate_JJ inference_NN procedure_NN ,_, noise_NN in_IN the_DT
tion_NN during_IN inference_NN ._.
This_DT is_VBZ the_DT setting_VBG Rattigan_NNP et_FW al._FW -LRB-_-LRB- 22_CD -RRB-_-RRB- introduced_VBN and_CC referred_VBN to_TO as_IN ``_`` active_JJ inference_NN ._. ''_''
They_PRP looked_VBD at_IN the_DT relational_JJ network_NN classifier_NN ,_, introduced_VBN by_IN Macskassy_NNP and_CC Provost_NNP =_SYM -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: in_IN which_WDT there_EX are_VBP no_DT node_NN attributes_VBZ ;_: only_RB labels_NNS are_VBP propagated_VBN ._.
Here_RB ,_, we_PRP build_VBP on_IN this_DT ,_, and_CC look_VB at_IN networks_NNS in_IN which_WDT the_DT nodes_NNS have_VBP attribute_NN information_NN and_CC compare_VB to_TO the_DT structural_JJ strategy_NN th_DT
hods_NNS including_VBG AIGA_NN on_IN small_JJ graphs_NNS ,_, graphs_NNS of_IN 100_CD nodes_NNS ,_, and_CC then_RB compare_VB the_DT remaining_VBG methods_NNS on_IN larger_JJR graphs_NNS of_IN 2000_CD nodes_NNS ._.
For_IN each_DT experiment_NN ,_, we_PRP first_RB report_VBP the_DT average_JJ degree_NN ,_, assortativity_NN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: ,_, how_WRB well_RB the_DT local_JJ model_NN LM_NN does_VBZ on_IN average_NN ,_, and_CC the_DT average_JJ perfect_JJ information_NN P_NN I_CD accuracies_NNS ._.
The_DT first_JJ set_NN of_IN graphs_NNS of_IN 100_CD nodes_NNS had_VBD an_DT average_JJ degree_NN of_IN 3.36_CD and_CC an_DT assortativity_NN of_IN 0.62_CD ._.
LM_NN h_NN
hod_NN we_PRP propose_VBP significantly_RB outperforms_VBZ all_DT of_IN the_DT other_JJ methods_NNS on_IN both_CC real_JJ and_CC synthetic_JJ datasets_NNS ._.
The_DT label_NN acquisition_NN problem_NN has_VBZ received_VBN ample_JJ attention_NN within_IN the_DT context_NN of_IN active_JJ learning_NN =_JJ -_: =[_NN 3_CD ,_, 16_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
There_EX are_VBP two_CD main_JJ differences_NNS between_IN the_DT scenario_NN we_PRP address_VBP and_CC the_DT active_JJ learning_NN scenario_NN ._.
First_JJ ,_, active_JJ learning_NN has_VBZ traditionally_RB been_VBN concerned_VBN with_IN flat_JJ data_NNS ;_: here_RB ,_, we_PRP are_VBP interested_JJ in_IN ne_NN
of_IN this_DT method_NN depends_VBZ heavily_RB on_IN theprecision_NN of_IN the_DT estimated_VBN probability_NN values_NNS ._.
If_IN the_DT probability_NN estimates_NNS are_VBP not_RB well-calibrated_JJ ,_, then_RB the_DT expected_VBN misclassification_NN costs_NNS will_MD be_VB incorrect_JJ =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_JJ -_: ,_, making_VBG the_DT valueaiga_NN calculations_NNS meaningless_JJ ._.
Second_RB ,_, the_DT time_NN this_DT acquisition_NN method_NN takes_VBZ to_TO run_VB depends_VBZ on_IN the_DT time_NN complexity_NN of_IN the_DT approximate_JJ inference_NN technique_NN ;_: we_PRP need_VBP to_TO calculate_VB the_DT v_LS
n_NN models_NNS proposed_VBN to_TO date_NN that_WDT make_VBP different_JJ modeling_NN assumptions_NNS about_IN these_DT dependencies_NNS ._.
For_IN instance_NN ,_, Neville_NNP and_CC Jensen_NNP -LRB-_-LRB- 19_CD -RRB-_-RRB- ,_, Lu_NNP and_CC Getoor_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, Macskassy_NNP and_CC Provost_NNP -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, and_CC McDowell_NNP et_FW al._FW =_SYM -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: make_VB use_NN of_IN local_JJ models_NNS ,_, such_JJ as_IN Naive_JJ Bayes_NNS ,_, Logistic_JJ Regression_NN ,_, etc._NN ,_, as_IN a_DT function_NN of_IN the_DT local_JJ attributes_NNS Xi_NN and_CC aggregation_NN of_IN the_DT neighbor_NN labels_NNS ._.
Chakrabarti_NNP et_FW al._FW -LRB-_-LRB- 2_CD -RRB-_-RRB- considered_VBN using_VBG the_DT
ition_NN during_IN inference_NN ,_, the_DT aim_NN for_IN active_JJ learning_NN is_VBZ to_TO acquire_VB labels_NNS to_TO learn_VB a_DT good_JJ model_NN ._.
We_PRP are_VBP instead_RB acquiring_VBG labels_NNS during_IN inference_NN ._.
Another_DT related_JJ area_NN is_VBZ viral_JJ -LRB-_-LRB- or_CC targeted_VBN -RRB-_-RRB- marketing_NN =_JJ -_: =[_NN 9_CD ,_, 11_CD ,_, 21_CD ,_, 23_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB a_DT subset_NN of_IN customers_NNS need_VBP to_TO be_VB selected_VBN for_IN targeted_VBN advertisement_NN so_RB as_IN to_TO maximize_VB the_DT product_NN sales_NNS ._.
We_PRP showed_VBD how_WRB viral_JJ marketing_NN is_VBZ related_JJ to_TO label_NN acquisition_NN and_CC used_VBD Richardson_NNP &_CC Do_NNP
it_PRP has_VBZ been_VBN shown_VBN that_IN methods_NNS such_JJ as_IN collective_JJ classification_NN ,_, i.e._FW ,_, classifying_VBG the_DT nodes_NNS of_IN a_DT network_NN simultaneously_RB ,_, can_MD significantly_RB outperform_VB the_DT traditional_JJ independent_JJ labeling_NN approaches_VBZ =_JJ -_: =[_NN 2_CD ,_, 7_CD ,_, 13_CD ,_, 15_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, sometimes_RB ,_, the_DT advantage_NN of_IN exploiting_VBG the_DT relationships_NNS can_MD become_VB a_DT disadvantage_NN ._.
An_DT incorrect_JJ prediction_NN about_IN a_DT particular_JJ node_NN -LRB-_-LRB- due_JJ to_TO an_DT approximate_JJ inference_NN procedure_NN ,_, noise_NN in_IN the_DT
it_PRP has_VBZ been_VBN shown_VBN that_IN methods_NNS such_JJ as_IN collective_JJ classification_NN ,_, i.e._FW ,_, classifying_VBG the_DT nodes_NNS of_IN a_DT network_NN simultaneously_RB ,_, can_MD significantly_RB outperform_VB the_DT traditional_JJ independent_JJ labeling_NN approaches_VBZ =_JJ -_: =[_NN 2_CD ,_, 7_CD ,_, 13_CD ,_, 15_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, sometimes_RB ,_, the_DT advantage_NN of_IN exploiting_VBG the_DT relationships_NNS can_MD become_VB a_DT disadvantage_NN ._.
An_DT incorrect_JJ prediction_NN about_IN a_DT particular_JJ node_NN -LRB-_-LRB- due_JJ to_TO an_DT approximate_JJ inference_NN procedure_NN ,_, noise_NN in_IN the_DT
it_PRP has_VBZ been_VBN shown_VBN that_IN methods_NNS such_JJ as_IN collective_JJ classification_NN ,_, i.e._FW ,_, classifying_VBG the_DT nodes_NNS of_IN a_DT network_NN simultaneously_RB ,_, can_MD significantly_RB outperform_VB the_DT traditional_JJ independent_JJ labeling_NN approaches_VBZ =_JJ -_: =[_NN 2_CD ,_, 7_CD ,_, 13_CD ,_, 15_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, sometimes_RB ,_, the_DT advantage_NN of_IN exploiting_VBG the_DT relationships_NNS can_MD become_VB a_DT disadvantage_NN ._.
An_DT incorrect_JJ prediction_NN about_IN a_DT particular_JJ node_NN -LRB-_-LRB- due_JJ to_TO an_DT approximate_JJ inference_NN procedure_NN ,_, noise_NN in_IN the_DT
et_CC ,_, acquire_VBP the_DT value_NN for_IN it_PRP ,_, and_CC repeat_VB the_DT process_NN until_IN the_DT budget_NN is_VBZ exhausted_VBN -LRB-_-LRB- Algorithm_NN 1_CD -RRB-_-RRB- ._.
Note_VB that_IN the_DT value_NN calculation_NN at_IN step_NN 7_CD is_VBZ essentially_RB an_DT expected_JJ value_NN of_IN information_NN calculation_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: and_CC it_PRP requires_VBZ running_VBG the_DT inference_NN procedure_NN for_IN each_DT possible_JJ label_NN ._.
Algorithm_NN 1_CD :_: Approximate_JJ inference_NN and_CC greedy_JJ acquisition_NN -LRB-_-LRB- AIGA_NN -RRB-_-RRB- algorithm_NN ._.
Input_NN :_: G_NN --_: the_DT test_NN graph_NN ,_, CM_NN --_: the_DT learned_VBN collec_NN
