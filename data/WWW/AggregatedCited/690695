User-centric_JJ Web_NN crawling_VBG
Search_VB engines_NNS are_VBP the_DT primary_JJ gateways_NNS of_IN information_NN access_NN on_IN the_DT Web_NN today_NN ._.
Behind_IN the_DT scenes_NNS ,_, search_NN engines_NNS crawl_VBP the_DT Web_NN to_TO populate_VB a_DT local_JJ indexed_VBN repository_NN of_IN Web_NN pages_NNS ,_, used_VBN to_TO answer_VB user_NN search_NN queries_NNS ._.
In_IN an_DT aggregate_JJ sense_NN ,_, the_DT Web_NN is_VBZ very_RB dynamic_JJ ,_, causing_VBG any_DT repository_NN of_IN Web_NN pages_NNS to_TO become_VB out_IN of_IN date_NN over_IN time_NN ,_, which_WDT in_IN turn_NN causes_VBZ query_JJ answer_NN quality_NN to_TO degrade_VB ._.
Given_VBN the_DT considerable_JJ size_NN ,_, dynamicity_NN ,_, and_CC degree_NN of_IN autonomy_NN of_IN the_DT Web_NN as_IN a_DT whole_NN ,_, it_PRP is_VBZ not_RB feasible_JJ for_IN a_DT search_NN engine_NN to_TO maintain_VB its_PRP$ repository_NN exactly_RB synchronized_VBN with_IN the_DT Web_NN ._.
In_IN this_DT paper_NN we_PRP study_VBD how_WRB to_TO schedule_VB Web_NN pages_NNS for_IN selective_JJ -LRB-_-LRB- re_NN -RRB-_-RRB- downloading_VBG into_IN a_DT search_NN engine_NN repository_NN ._.
The_DT scheduling_NN objective_NN is_VBZ to_TO maximize_VB the_DT quality_NN of_IN the_DT user_NN experience_NN for_IN those_DT who_WP query_VBP the_DT search_NN engine_NN ._.
We_PRP begin_VBP with_IN a_DT quantitative_JJ characterization_NN of_IN the_DT way_NN in_IN which_WDT the_DT discrepancy_NN between_IN the_DT content_NN of_IN the_DT repository_NN and_CC the_DT current_JJ content_NN of_IN the_DT live_JJ Web_NN impacts_VBZ the_DT quality_NN of_IN the_DT user_NN experience_NN ._.
This_DT characterization_NN leads_VBZ to_TO a_DT user-centric_JJ metric_NN of_IN the_DT quality_NN of_IN a_DT search_NN engine_NN 's_POS local_JJ repository_NN ._.
We_PRP use_VBP this_DT metric_NN to_TO derive_VB a_DT policy_NN for_IN scheduling_NN Web_NN page_NN -LRB-_-LRB- re_NN -RRB-_-RRB- downloading_NN that_WDT is_VBZ driven_VBN by_IN search_NN engine_NN usage_NN and_CC free_JJ of_IN exterior_NN tuning_NN parameters_NNS ._.
We_PRP then_RB focus_VB on_IN the_DT important_JJ subproblem_NN of_IN scheduling_NN refreshing_VBG of_IN Web_NN pages_NNS already_RB present_JJ in_IN the_DT repository_NN ,_, and_CC show_VB how_WRB to_TO compute_VB the_DT priorities_NNS efficiently_RB ._.
We_PRP provide_VBP extensive_JJ empirical_JJ comparisons_NNS of_IN our_PRP$ user-centric_JJ method_NN against_IN prior_JJ Web_NN page_NN refresh_NN strategies_NNS ,_, using_VBG real_JJ Web_NN data_NNS ._.
Our_PRP$ results_NNS demonstrate_VBP that_IN our_PRP$ method_NN requires_VBZ far_RB fewer_JJR resources_NNS to_TO maintain_VB same_JJ search_NN engine_NN quality_NN level_NN for_IN users_NNS ,_, leaving_VBG substantially_RB more_JJR resources_NNS available_JJ for_IN incorporating_VBG new_JJ Web_NN pages_NNS into_IN the_DT search_NN repository_NN ._.
eve_NN hidden_JJ pages_NNS ;_: while_IN a_DT forum_NN crawler_NN is_VBZ interested_JJ in_IN how_WRB to_TO identify_VB valuable_JJ links_NNS to_TO follow_VB ,_, given_VBN that_IN most_JJS forum_NN pages_NNS have_VBP explicit_JJ in-links_NNS ._.
The_DT most_RBS related_JJ work_NN is_VBZ focused_VBN crawling_VBG -LRB-_-LRB- 8_CD -RRB-_-RRB- -LRB-_-LRB- 12_CD -RRB-_-RRB- =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =-[_NN 15_CD -RRB-_-RRB- ,_, which_WDT attempts_VBZ to_TO retrieve_VB Web_NN pages_NNS that_WDT are_VBP relevant_JJ to_TO some_DT predefined_VBN topics_NNS or_CC labeled_JJ examples_NNS ._.
The_DT target_NN descriptions_NNS in_IN focused_JJ crawling_NN are_VBP quite_RB different_JJ in_IN various_JJ applications_NNS ._.
In_IN
orm_NN of_IN keywords_NNS ._.
Then_RB ,_, it_PRP searches_VBZ its_PRP$ database_NN and_CC retrieves_VBZ the_DT pages_NNS relevant_JJ to_TO the_DT submitted_VBN query_NN ._.
Finally_RB ,_, query_NN result_NN is_VBZ introduced_VBN to_TO the_DT user_NN in_IN the_DT form_NN of_IN a_DT ranked_VBN list_NN of_IN relevant_JJ pages_NNS =_JJ -_: =[_NN 4_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_JJS search_NN engines_NNS rely_VBP on_IN crawlers_NNS to_TO traverse_VB the_DT web_NN to_TO collect_VB pages_NNS ,_, pass_VB them_PRP to_TO the_DT indexer_NN ,_, and_CC then_RB follow_VB links_NNS from_IN one_CD page_NN to_TO another_DT web_NN crawlers_NNS have_VBP the_DT ability_NN to_TO index_NN thousands_NNS o_NN
t_NN page_NN ._.
Some_DT related_JJ works_NNS have_VBP been_VBN reported_VBN in_IN recent_JJ literature_NN ._.
Focused_VBN crawling_NN ,_, which_WDT attempts_VBZ to_TO download_VB only_JJ Web_NN pages_NNS that_WDT are_VBP relevant_JJ to_TO some_DT pre-defined_JJ topics_NNS ,_, has_VBZ been_VBN studied_VBN in_IN -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC -LRB-_-LRB- 25_CD -RRB-_-RRB- ._.
And_CC in_IN -LRB-_-LRB- 18_CD -RRB-_-RRB- and_CC -LRB-_-LRB- 21_CD -RRB-_-RRB- ,_, the_DT problem_NN of_IN deep_JJ Webh_NNP tp_NN :_: \/_: w_NN w_NN w_NN ._.
tripadvisor.com_NN \/_: S_NN how_WRB F_NN orum_NN -_: g28926-i29-C_NN alifornia_NN ._.
htm_NN l_NN h_NN tp_NN :_: \/_: w_NN w_NN w_NN ._.
tripadvisor.com_NN \/_: S_NN how_WRB F_NN orum_NN -_: g32655-i61-Los_A_NN ngeles_C_NN
utilize_VB a_DT web_NN servers_NNS knowledge_NN ,_, nor_CC offer_VBP provable_JJ guarantees_NNS on_IN coverage_NN ,_, freshness_NN or_CC efficiency_NN ._.
Extensive_JJ research_NN has_VBZ been_VBN done_VBN on_IN the_DT problem_NN of_IN approximating_VBG the_DT rate_NN of_IN change_NN of_IN web_NN content_NN =_JJ -_: =[_NN 10_CD ,_, 11_CD ,_, 9_CD ,_, 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC developing_VBG crawling_VBG algorithms_NNS that_WDT improve_VBP the_DT freshness_NN of_IN documents_NNS ._.
In_IN -LRB-_-LRB- 24_CD -RRB-_-RRB- it_PRP was_VBD shown_VBN that_IN approximating_VBG the_DT rate_NN of_IN change_NN is_VBZ not_RB always_RB possible_JJ ._.
On_IN the_DT other_JJ hand_NN ,_, if_IN the_DT rate_NN of_IN chang_NN
are_VBP three_CD major_JJ factors_NNS that_WDT have_VBP been_VBN considered_VBN to_TO learn_VB how_WRB often_RB each_DT page_NN should_MD be_VB revisited_VBN :_: -LRB-_-LRB- i_LS -RRB-_-RRB- the_DT importance\/relevance_NN of_IN pages_NNS -LRB-_-LRB- e.g._FW PageRank_FW ,_, similarity_NN of_IN keywords_NNS to_TO user_NN queries_NNS ,_, etc._NN -RRB-_-RRB- =_JJ -_: =[_NN 14_CD ,_, 24_CD ,_, 35_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- ii_LS -RRB-_-RRB- the_DT longevity_NN 4_CD of_IN information_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- and_CC -LRB-_-LRB- iii_LS -RRB-_-RRB- the_DT frequency_NN of_IN changes_NNS -LRB-_-LRB- 11_CD ,_, 12_CD ,_, 15_CD ,_, 16_CD -RRB-_-RRB- ._.
Another_DT factor_NN that_WDT has_VBZ been_VBN ignored_VBN so_RB far_RB is_VBZ the_DT importance_NN of_IN changes_NNS between_IN pages_NNS 2_CD http:\/\/www.arch_NN
acteristics_NNS of_IN the_DT Webpages_NNPS or_CC the_DT collective_JJ behavior_NN of_IN search_NN engine_NN users_NNS ._.
There_EX are_VBP some_DT web_NN crawling_VBG algorithms_NNS that_WDT take_VBP the_DT collective_JJ user_NN behavior_NN into_IN account_NN ._.
In_IN user-centric_JJ web_NN crawling_VBG =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Webpages_NNS are_VBP refreshed_VBN by_IN considering_VBG their_PRP$ positions_NNS in_IN the_DT result_NN list_NN and_CC the_DT query_JJ frequency_NN of_IN their_PRP$ related_JJ keywords_NNS made_VBN by_IN the_DT users_NNS ._.
Focused_VBN crawling_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- concentrates_VBZ on_IN how_WRB to_TO obtain_VB an_DT i_FW
reshold_FW τ_FW =_JJ 0.5_CD ,_, C_NNP -LRB-_-LRB- Di_NNP -RRB-_-RRB- at_IN week_NN 2_CD is_VBZ not_RB substantially_RB different_JJ from_IN 12_CD As_IN we_PRP discuss_VBP in_IN Section_NN 7_CD ,_, a_DT number_NN of_IN update_VB scheduling_NN policies_NNS have_VBP been_VBN developed_VBN specifically_RB for_IN search_NN engines_NNS ,_, such_JJ as_IN =_JJ -_: =_JJ -LRB-_-LRB- PO05_NN -RRB-_-RRB- -_: =_JJ -_: and_CC -LRB-_-LRB- WSY_NN +_CC 02_CD -RRB-_-RRB- ._.
While_IN these_DT policies_NNS show_VBP further_JJ improvement_NN compared_VBN to_TO -LRB-_-LRB- CN02_NN -RRB-_-RRB- ,_, they_PRP exploit_VBP specific_JJ properties_NNS of_IN the_DT ranking_JJ functions_NNS used_VBN by_IN the_DT search_NN engines_NNS ._.
As_IN a_DT result_NN ,_, these_DT optimization_NN
,_, and_CC the_DT change_NN rates_NNS of_IN individual_JJ pages_NNS -LRB-_-LRB- 3_CD ,_, 5_CD ,_, 14_CD ,_, 22_CD -RRB-_-RRB- ._.
Parallel_JJ to_TO this_DT line_NN of_IN work_NN ,_, there_EX has_VBZ been_VBN a_DT significant_JJ body_NN of_IN work_NN on_IN refreshing_JJ already-discovered_JJ content_NN ,_, which_WDT has_VBZ been_VBN studied_VBN in_IN =_JJ -_: =[_NN 6_CD ,_, 9_CD ,_, 10_CD ,_, 21_CD ,_, 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Already-discovered_JJ pages_NNS are_VBP recrawled_VBN to_TO keep_VB the_DT search_NN engine_NN local_JJ repository_NN fresh_JJ so_IN that_IN the_DT search_NN queries_NNS are_VBP not_RB answered_VBN incorrectly_RB due_JJ to_TO stale_JJ information_NN ,_, while_IN the_DT discovery_NN of_IN new_JJ p_NN
p-based_JJ aggregation_NN ,_, in_IN this_DT paper_NN we_PRP primarily_RB focus_VB on_IN the_DT server-based_JJ aggregation_NN scenario_NN ._.
This_DT problem_NN is_VBZ similar_JJ to_TO the_DT index_NN refresh_NN problem_NN for_IN Web-search_JJ engines_NNS -LRB-_-LRB- 7_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 9_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 13_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 31_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 40_CD -RRB-_-RRB- ,_, but_CC two_CD important_JJ properties_NNS of_IN the_DT information_NN in_IN the_DT RSS_NN domain_NN make_VBP this_DT problem_NN unique_JJ and_CC interesting_JJ :_: •_CD The_DT information_NN in_IN the_DT RSS_NN domain_NN is_VBZ often_RB time_NN sensitive_JJ ._.
Most_JJS new_JJ RSS_NNS cont_VBP
,_, and_CC the_DT change_NN rates_NNS of_IN individual_JJ pages_NNS -LRB-_-LRB- 3_CD ,_, 5_CD ,_, 14_CD ,_, 22_CD -RRB-_-RRB- ._.
Parallel_JJ to_TO this_DT line_NN of_IN work_NN ,_, there_EX has_VBZ been_VBN a_DT significant_JJ body_NN of_IN work_NN on_IN refreshing_JJ already-discovered_JJ content_NN ,_, which_WDT has_VBZ been_VBN studied_VBN in_IN =_JJ -_: =[_NN 6_CD ,_, 9_CD ,_, 10_CD ,_, 21_CD ,_, 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Already-discovered_JJ pages_NNS are_VBP recrawled_VBN to_TO keep_VB the_DT search_NN engine_NN local_JJ repository_NN fresh_JJ so_IN that_IN the_DT search_NN queries_NNS are_VBP not_RB answered_VBN incorrectly_RB due_JJ to_TO stale_JJ information_NN ,_, while_IN the_DT discovery_NN of_IN new_JJ p_NN
nt_NN 1_CD ._.
INTRODUCTION_NN Web_NN crawling_VBG is_VBZ an_DT integral_JJ piece_NN of_IN infrastructure_NN for_IN search_NN engines_NNS ._.
Generic_JJ crawlers_NNS -LRB-_-LRB- 1_CD ,_, 9_CD -RRB-_-RRB- crawl_VBP documents_NNS and_CC links_NNS belonging_VBG to_TO a_DT variety_NN of_IN topics_NNS ,_, whereas_IN focused_JJ crawlers_NNS =_JJ -_: =[_NN 27_CD ,_, 43_CD ,_, 46_CD -RRB-_-RRB- -_: =_SYM -_: use_VB some_DT specialized_JJ knowledge_NN to_TO limit_VB the_DT crawl_NN to_TO pages_NNS pertaining_VBG to_TO specific_JJ topics_NNS ._.
For_IN web_NN crawling_NN ,_, issues_NNS like_IN freshness_NN and_CC efficient_JJ resource_NN usage_NN have_VBP previously_RB been_VBN addressed_VBN -LRB-_-LRB- 15_CD ,_, 16_CD ,_,
ple_NN algorithm_NN performs_VBZ well_RB in_IN practice_NN and_CC is_VBZ able_JJ to_TO achieve_VB high_JJ RankMass_NNP coverage_NN early_RB during_IN a_DT crawl_NN ._.
There_EX exist_VBP a_DT large_JJ body_NN of_IN related_JJ work_NN in_IN the_DT literature_NN that_WDT investigates_VBZ related_JJ issues_NNS =_JJ -_: =[_NN 24_CD ,_, 4_CD ,_, 14_CD ,_, 10_CD ,_, 13_CD -RRB-_-RRB- -_: =_JJ -_: and_CC in_IN particular_JJ instances_NNS of_IN the_DT family_NN of_IN algorithms_NNS we_PRP present_JJ in_IN this_DT paper_NN have_VBP been_VBN described_VBN before_IN -LRB-_-LRB- 23_CD ,_, 2_CD ,_, 11_CD -RRB-_-RRB- ._.
However_RB ,_, due_JJ to_TO the_DT fundamental_JJ difficulty_NN of_IN computing_VBG exact_JJ PageRank_NN values_NNS
and_CC the_DT change_NN probabilities_NNS of_IN the_DT data_NNS items_NNS ._.
Secondly_RB ,_, the_DT data_NNS items_NNS being_VBG monitored_VBN ,_, which_WDT contribute_VBP to_TO the_DT incoherency_NN ,_, and_CC eventually_RB get_VB polled_VBN for_IN again_RB ,_, are_VBP numeric_JJ values_NNS ._.
Pandey_NNP et_NNP ._.
al._FW =_SYM -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: propose_VBP User_NN Centric_JJ Web_NN Crawling_NN ,_, a_DT method_NN where_WRB crawl_NN strategy_NN is_VBZ directed_VBN towards_IN maximizing_VBG repository_JJ quality_NN ._.
Informally_RB ,_, quality_NN of_IN a_DT repository_NN is_VBZ proportional_JJ to_TO the_DT expected_VBN average_JJ usefuln_NN
f_LS the_DT search_NN engine_NN 's_POS index_NN by_IN removing_VBG documents_NNS that_WDT are_VBP unlikely_JJ to_TO be_VB returned_VBN by_IN a_DT search_NN query_NN ._.
The_DT pruning_NN is_VBZ typically_RB done_VBN based_VBN on_IN the_DT frequency_NN of_IN query_NN terms_NNS ._.
Similarly_RB ,_, Pandey_NN and_CC Olston_NN =_JJ -_: =[_NN 28_CD -RRB-_-RRB- -_: =_JJ -_: suggest_VBP crawling_VBG pages_NNS frequently_RB if_IN they_PRP are_VBP likely_JJ to_TO incorrectly_RB appear_VB -LRB-_-LRB- or_CC not_RB appear_VB -RRB-_-RRB- as_IN a_DT result_NN of_IN a_DT search_NN ._.
Similar_JJ methods_NNS could_MD be_VB incorporated_VBN into_IN the_DT static_JJ rank_NN -LRB-_-LRB- e.g._FW ,_, how_WRB many_JJ frequent_JJ
However_RB ,_, as_RB far_RB as_IN we_PRP know_VBP ,_, no_DT work_NN has_VBZ considered_VBN a_DT unified_JJ algorithm_NN to_TO incorporate_VB different_JJ levels_NNS of_IN collaboration_NN between_IN the_DT search_NN engines_NNS and_CC the_DT web_NN servers_NNS being_VBG crawled_VBN ._.
Pandy_NN and_CC Olston_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: assume_VB no_DT feedback_NN from_IN content_NN providers_NNS ._.
Their_PRP$ scheduling_NN algorithm_NN aims_VBZ at_IN maximizing_VBG the_DT user-centric_JJ search_NN repository_JJ quality_NN ,_, which_WDT includes_VBZ addressing_VBG page_NN ranking_NN ,_, index_NN maintenance_NN and_CC repo_NN
most_RBS impactful_JJ newly_RB discovered_VBN pages_NNS ,_, and_CC -LRB-_-LRB- c_LS -RRB-_-RRB- synchronizing_VBG the_DT repository_NN with_IN known_JJ live_JJ pages_NNS that_WDT have_VBP undergone_VBN impactful_JJ updates_NNS ._.
I_PRP have_VBP had_VBN the_DT opportunity_NN of_IN working_VBG on_IN each_DT of_IN these_DT aspects_NNS =_JJ -_: =[_NN 2_CD ,_, 4_CD ,_, 8_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
s_NN •_CD Discovering_VBG links_NNS to_TO new_JJ pages_NNS :_: Search_VB engines_NNS typically_RB discover_VBP links_NNS to_TO new_JJ pages_NNS by_IN polling_NN known_JJ pages_NNS and_CC extracting_VBG their_PRP$ outgoing_JJ links_NNS ._.
Since_IN the_DT set_NN of_IN outgoing_JJ links_NNS from_IN different_JJ page_NN
n_NN by_IN users_NNS -LRB-_-LRB- 8_CD -RRB-_-RRB- ,_, even_RB if_IN the_DT overall_JJ freshness_NN is_VBZ maximized_VBN ,_, the_DT the_DT perceived_VBN quality_NN of_IN the_DT repository_NN may_MD be_VB low_JJ if_IN the_DT uniform_JJ refresh_NN policy_NN is_VBZ used_VBN ._.
To_TO address_VB this_DT limitation_NN ,_, Pandey_NN and_CC Olston_NN =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: proposed_VBD a_DT usercentric_JJ approach_NN to_TO guide_VB the_DT update_VBP process_NN ._.
During_IN the_DT update_VBP process_NN ,_, they_PRP prioritize_VBP pages_NNS that_IN if_IN updated_VBN ,_, maximize_VB the_DT expected_VBN improvement_NN in_IN repository_JJ quality_NN ._.
This_DT expectatio_NN
eve_NN hidden_JJ pages_NNS ;_: while_IN a_DT forum_NN crawler_NN is_VBZ interested_JJ in_IN how_WRB to_TO identify_VB valuable_JJ links_NNS to_TO follow_VB ,_, given_VBN that_IN most_JJS forum_NN pages_NNS have_VBP explicit_JJ in-links_NNS ._.
The_DT most_RBS related_JJ work_NN is_VBZ focused_VBN crawling_VBG -LRB-_-LRB- 8_CD -RRB-_-RRB- -LRB-_-LRB- 12_CD -RRB-_-RRB- =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =-[_NN 15_CD -RRB-_-RRB- ,_, which_WDT attempts_VBZ to_TO retrieve_VB Web_NN pages_NNS that_WDT are_VBP relevant_JJ to_TO some_DT predefined_VBN topics_NNS or_CC labeled_JJ examples_NNS ._.
The_DT target_NN descriptions_NNS in_IN focused_JJ crawling_NN are_VBP quite_RB different_JJ in_IN various_JJ applications_NNS ._.
In_IN
s_NN reputation_NN ,_, size_NN ,_, etc._NN ,_, ensure_VB the_DT scalability_NN and_CC efficiency_NN of_IN the_DT crawler_NN ._.
Other_JJ criterion_NN that_WDT have_VBP been_VBN considered_VBN when_WRB defining_VBG crawl_NN selection_NN methods_NNS are_VBP for_IN example_NN user-specific_JJ interests_NNS =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT avoidance_NN of_IN spam_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- and_CC wanting_VBG to_TO obtain_VB fresh_JJ versions_NNS of_IN frequently_RB changing_VBG pages_NNS -LRB-_-LRB- -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 9_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Breadth-first_JJ crawling_NN ,_, wherein_WRB pages_NNS are_VBP crawled_VBN in_IN the_DT order_NN they_PRP are_VBP discovered_VBN ,_, has_VBZ been_VBN
estimators_NNS in_IN order_NN to_TO improve_VB Web_NN crawlers_NNS and_CC Web_NN caches_NNS ._.
Edward_NNP et_FW al._FW -LRB-_-LRB- 13_CD -RRB-_-RRB- also_RB propose_VBP a_DT change_NN frequency-based_JJ adaptive_JJ model_NN to_TO optimize_VB performance_NN of_IN incremental_JJ crawlers_NNS ._.
Olston_NN and_CC Pandey_NN =_JJ -_: =[_NN 22_CD -RRB-_-RRB- -_: =_SYM -_: present_VB a_DT strategy_NN to_TO schedule_VB Web_NN pages_NNS for_IN selective_JJ -LRB-_-LRB- re_NN -RRB-_-RRB- downloading_VBG into_IN a_DT search_NN engine_NN repository_NN ._.
This_DT strategy_NN aims_VBZ to_TO maximize_VB the_DT quality_NN of_IN the_DT user_NN experience_NN for_IN those_DT who_WP query_VBP the_DT searc_NN
