A_DT contextual-bandit_JJ approach_NN to_TO personalized_JJ news_NN article_NN recommendation_NN
Personalized_VBN web_NN services_NNS strive_VBP to_TO adapt_VB their_PRP$ services_NNS -LRB-_-LRB- advertisements_NNS ,_, news_NN articles_NNS ,_, etc._NN -RRB-_-RRB- to_TO individual_JJ users_NNS by_IN making_VBG use_NN of_IN both_CC content_NN and_CC user_NN information_NN ._.
Despite_IN a_DT few_JJ recent_JJ advances_NNS ,_, this_DT problem_NN remains_VBZ challenging_JJ for_IN at_IN least_JJS two_CD reasons_NNS ._.
First_RB ,_, web_NN service_NN is_VBZ featured_VBN with_IN dynamically_RB changing_VBG pools_NNS of_IN content_NN ,_, rendering_VBG traditional_JJ collaborative_JJ filtering_VBG methods_NNS inapplicable_JJ ._.
Second_RB ,_, the_DT scale_NN of_IN most_JJS web_NN services_NNS of_IN practical_JJ interest_NN calls_VBZ for_IN solutions_NNS that_WDT are_VBP both_DT fast_JJ in_IN learning_NN and_CC computation_NN ._.
In_IN this_DT work_NN ,_, we_PRP model_VBP personalized_JJ recommendation_NN of_IN news_NN articles_NNS as_IN a_DT contextual_JJ bandit_NN problem_NN ,_, a_DT principled_JJ approach_NN in_IN which_WDT a_DT learning_NN algorithm_NN sequentially_RB selects_VBZ articles_NNS to_TO serve_VB users_NNS based_VBN on_IN contextual_JJ information_NN about_IN the_DT users_NNS and_CC articles_NNS ,_, while_IN simultaneously_RB adapting_VBG its_PRP$ article-selection_JJ strategy_NN based_VBN on_IN user-click_JJ feedback_NN to_TO maximize_VB total_JJ user_NN clicks_NNS ._.
The_DT contributions_NNS of_IN this_DT work_NN are_VBP three-fold_JJ ._.
First_RB ,_, we_PRP propose_VBP a_DT new_JJ ,_, general_JJ contextual_JJ bandit_NN algorithm_NN that_WDT is_VBZ computationally_RB efficient_JJ and_CC well_RB motivated_VBN from_IN learning_VBG theory_NN ._.
Second_RB ,_, we_PRP argue_VBP that_IN any_DT bandit_NN algorithm_NN can_MD be_VB reliably_RB evaluated_VBN offline_NN using_VBG previously_RB recorded_VBN random_JJ traffic_NN ._.
Finally_RB ,_, using_VBG this_DT offline_JJ evaluation_NN method_NN ,_, we_PRP successfully_RB applied_VBD our_PRP$ new_JJ algorithm_NN to_TO a_DT Yahoo_NNP !_.
Front_NN Page_NNP Today_NNP Module_NNP dataset_NN containing_VBG over_IN 33_CD million_CD events_NNS ._.
Results_NNS showed_VBD a_DT 12.5_CD %_NN click_VBP lift_NN compared_VBN to_TO a_DT standard_JJ context-free_JJ bandit_NN algorithm_NN ,_, and_CC the_DT advantage_NN becomes_VBZ even_RB greater_JJR when_WRB data_NNS gets_VBZ more_RBR scarce_JJ ._.
reinforcement_NN learning_NN algorithm_NN motivated_VBN by_IN the_DT KWIK_NNP algorithm_NN of_IN Walsh_NNP et_FW al._FW -LRB-_-LRB- 2009_CD -RRB-_-RRB- has_VBZ showed_VBN encouraging_JJ results_NNS in_IN a_DT challenging_JJ online_NN news_NN article_NN recommendation_NN problem_NN on_IN Yahoo_NNP !_.
Frontpage_NN -LRB-_-LRB- =_JJ -_: =_JJ Li_NNP et_FW al._FW 2010_CD -_: =--RRB-_NN ._.
The_DT study_NN in_IN the_DT present_JJ paper_NN raises_VBZ several_JJ important_JJ theoretical_JJ directions_NNS ._.
We_PRP list_VBP seven_CD of_IN them_PRP to_TO conclude_VB the_DT paper_NN ._.
First_RB ,_, we_PRP would_MD like_VB to_TO extend_VB the_DT KWIK_NNP framework_NN to_TO the_DT ``_`` unrealizable_JJ ''_''
roblem_NN ,_, and_CC also_RB illustrates_VBZ how_WRB the_DT algorithm_NN may_MD be_VB implemented_VBN efficiently_RB for_IN special_JJ classes_NNS of_IN experts_NNS ._.
The_DT problem_NN we_PRP study_VBP is_VBZ personalized_VBN news_NN article_NN recommendation_NN on_IN the_DT Yahoo_NNP !_.
front_JJ page_NN =_JJ -_: =[_NN 1_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Each_DT time_NN a_DT user_NN visits_VBZ the_DT front_JJ page_NN ,_, a_DT news_NN article_NN out_IN of_IN 24Alina_NNP Beygelzimer_NNP ,_, John_NNP Langford_NNP ,_, Lihong_NNP Li_NNP a_DT small_JJ pool_NN of_IN hand-picked_JJ candidates_NNS is_VBZ highlighted_VBN ._.
The_DT goal_NN is_VBZ to_TO highlight_VB the_DT most_JJS
o_NN predict_VBP the_DT probability_NN of_IN a_DT user_NN clicking_VBG on_IN a_DT given_VBN advertisement_NN ._.
This_DT setting_NN has_VBZ been_VBN used_VBN for_IN other_JJ applications_NNS including_VBG making_VBG article_NN recommendations_NNS on_IN web_NN portals_NNS -LRB-_-LRB- Agarwal_NNP et_FW al._FW ,_, 2009_CD ,_, =_JJ -_: =_JJ Li_NNP et_FW al._FW ,_, 2010_CD -_: =-]_CD ._.
In_IN this_DT paper_NN ,_, we_PRP give_VBP a_DT theoretical_JJ analysis_NN of_IN a_DT variant_NN of_IN LinUCB_NN ,_, a_DT natural_JJ upper_JJ confidence_NN bound_VBD algorithm_NN introduced_VBN and_CC experimentally_RB demonstrated_VBN to_TO be_VB effective_JJ by_IN Li_NNP et_FW al._FW -LRB-_-LRB- 2010_CD -RRB-_-RRB- ._.
We_PRP u_VBP
the_DT user_NN ._.
Furthermore_RB ,_, it_PRP is_VBZ typically_RB desirable_JJ to_TO learn_VB a_DT feature-based_JJ model_NN that_WDT can_MD generalize_VB to_TO new_JJ or_CC previously_RB unseen_JJ articles_NNS and_CC users_NNS ;_: this_DT is_VBZ often_RB called_VBN the_DT contextual_NN bandits_VBZ problem_NN =_JJ -_: =[_NN 13_CD ,_, 15_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Although_IN there_EX exist_VBP approaches_NNS that_WDT have_VBP addressed_VBN these_DT challenges_NNS individually_RB ,_, to_TO our_PRP$ knowledge_NN there_EX is_VBZ no_DT single_JJ approach_NN which_WDT solves_VBZ both_DT simultaneously_RB and_CC is_VBZ also_RB practical_JJ to_TO implement_VB ._.
F_NN
ot_IN independent_JJ of_IN the_DT actions_NNS taken_VBN in_IN the_DT past_NN -LRB-_-LRB- since_IN the_DT algorithm_NN 's_POS choices_NNS of_IN future_JJ actions_NNS depend_VBP on_IN the_DT random_JJ confidence_NN set_NN constructed_VBN from_IN past_JJ data_NNS -RRB-_-RRB- ._.
In_IN fact_NN ,_, several_JJ authors_NNS -LRB-_-LRB- Auer_NNP ,_, 2000_CD ,_, =_JJ -_: =_JJ Li_NNP et_FW al._FW ,_, 2010_CD -_: =_JJ -_: ,_, Walsh_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- fell_VBD victim_NN of_IN making_VBG a_DT mistake_NN because_IN they_PRP did_VBD not_RB recognize_VB this_DT issue_NN ._.
Correct_JJ solutions_NNS require_VBP new_JJ martingale_NN techniques_NNS which_WDT we_PRP provide_VBP here_RB ._.
The_DT smaller_JJR confidence_NN sets_NNS
action_NN is_VBZ given_VBN by_IN φ_NN -LRB-_-LRB- x_NN -RRB-_-RRB- ·_FW w_FW ,_, where_WRB w_NN is_VBZ an_DT unknown_JJ weight_NN vector_NN ._.
The_DT computational_JJ complexity_NN of_IN most_JJS existing_VBG algorithms_NNS is_VBZ nevertheless_RB linear_JJ in_IN the_DT number_NN of_IN actions_NNS -LRB-_-LRB- Abe_NN et_FW al._FW ,_, 2003_CD ;_: Auer_NNP ,_, 2002_CD ;_: =_JJ -_: =_JJ Li_NNP et_FW al._FW ,_, 2010_CD -_: =--RRB-_NN ._.
Furthermore_RB ,_, rather_RB than_IN being_VBG specified_VBN explicitly_RB ,_, the_DT linear_JJ space_NN in_IN which_WDT our_PRP$ parameterizations_NNS lie_VBP are_VBP given_VBN by_IN the_DT underlying_VBG graphical_NN or_CC locality_NN structure_NN of_IN the_DT model_NN ._.
More_RBR recent_JJ work_NN o_NN
blem_NN of_IN selecting_NN content_NN items_NNS to_TO present_VB to_TO a_DT user_NN who_WP is_VBZ intent_JJ on_IN browsing_VBG for_IN information_NN ._.
Examples_NNS of_IN content_NN optimization_NN are_VBP article_NN publishing_NN on_IN portal_JJ Websites_NNS -LRB-_-LRB- 2_CD ,_, 1_CD -RRB-_-RRB- ,_, news_NN personalization_NN =_JJ -_: =[_NN 16_CD ,_, 27_CD -RRB-_-RRB- -_: =_JJ -_: ,_, recommendation_NN of_IN dynamically_RB changing_VBG items_NNS -LRB-_-LRB- updates_NNS ,_, tweets_NNS ,_, etc_NN -RRB-_-RRB- ,_, and_CC computational_JJ advertising_NN -LRB-_-LRB- 11_CD ,_, 33_CD -RRB-_-RRB- ._.
This_DT work_NN will_MD address_VB the_DT variant_NN that_WDT displays_VBZ the_DT best_JJS set_NN of_IN trending_VBG queries_NNS from_IN th_DT
._.
Instead_RB it_PRP usually_RB arrives_VBZ in_IN batches_NNS over_IN a_DT certain_JJ period_NN of_IN time_NN ._.
We_PRP now_RB try_VBP to_TO quantify_VB the_DT impact_NN of_IN this_DT delay_NN by_IN doing_VBG some_DT simulations_NNS that_WDT mimic_VBP the_DT problem_NN of_IN news_NN articles_NNS recommendation_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: that_WDT will_MD be_VB described_VBN in_IN section_NN 5_CD ._.
4Regret_NN 4500 4000 3500 3000_CD 2500 2000 1500 1000_CD 500_CD α_NN =_JJ 2_CD α_NN =_JJ 1_CD α_NN =_JJ 0.5_CD α_NN =_JJ 0.25_CD Asymptotic_JJ lower_JJR bound_VBD Regret_NNP 7000 6000 5000 4000_CD 3000 2000 1000_CD 10_CD 2_CD 0_CD 10_CD 3_CD 10_CD 4_CD T_NN 10_CD 5_CD
ow_RB accurate_JJ the_DT offline_JJ evaluator_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- is_VBZ when_WRB non-random_JJ log_NN data_NNS are_VBP used_VBN instead_RB ._.
To_TO obtain_VB non-random_JJ log_NN data_NNS ,_, we_PRP ran_VBD the_DT LinUCB_NN algorithm_NN using_VBG the_DT offline_JJ bandit_NN simulation_NN procedure_NN ,_, both_DT from_IN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, on_IN our_PRP$ random_JJ log_NN data_NNS D0_NN and_CC recorded_JJ events_NNS -LRB-_-LRB- x_NN ,_, a_DT ,_, r_NN -RRB-_-RRB- for_IN which_WDT LinUCB_NN chose_VBD arm_NN a_DT for_IN context_NN x._NN Note_VBP that_IN π_NN is_VBZ a_DT deterministic_JJ learning_NN algorithm_NN ,_, and_CC may_MD choose_VB different_JJ arms_NNS for_IN the_DT same_JJ contex_NN
back_RB ._.
However_RB ,_, this_DT generality_NN comes_VBZ at_IN the_DT price_NN of_IN tractability_NN for_IN all_DT but_CC specific_JJ cases_NNS ,_, which_WDT do_VBP not_RB include_VB our_PRP$ model_NN ._.
Our_PRP$ work_NN is_VBZ also_RB somewhat_RB related_JJ to_TO the_DT contextual_JJ bandit_NN problem_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 9_CD ,_, 10_CD -RRB-_-RRB- -_: =--RRB-_NN ,_, where_WRB the_DT standard_JJ multi-armed_JJ bandits_NNS setting_VBG is_VBZ augmented_VBN with_IN some_DT side-information_NN provided_VBN in_IN each_DT round_NN ,_, which_WDT can_MD be_VB used_VBN to_TO determine_VB which_WDT action_NN to_TO pick_VB ._.
While_IN we_PRP also_RB consider_VBP additional_JJ
ncorporate_JJ various_JJ assumptions_NNS about_IN the_DT dependencies_NNS of_IN the_DT payoff_NN function_NN on_IN the_DT chosen_JJ actions_NNS and_CC observed_VBN contexts_NNS ._.
It_PRP also_RB allows_VBZ us_PRP to_TO generalize_VB several_JJ approaches_NNS proposed_VBN in_IN the_DT literature_NN =_JJ -_: =[_NN 3_CD ,_, 5_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN the_DT following_NN ,_, we_PRP will_MD prove_VB that_IN in_IN many_JJ practical_JJ applications_NNS ,_, CGP-UCB_NN attains_VBZ sublinear_JJ contextual_JJ regret_NN -LRB-_-LRB- i.e._FW ,_, is_VBZ able_JJ to_TO compete_VB with_IN the_DT optimal_JJ mapping_NN from_IN contexts_NNS to_TO actions_NNS -RRB-_-RRB- ._.
4_CD Bound_VBN
committing_VBG bandit_NN setup_NN ._.
There_EX are_VBP several_JJ extensions_NNS that_WDT call_VBP for_IN future_JJ research_NN which_WDT we_PRP outline_VBP below_IN ._.
First_RB ,_, an_DT extension_NN of_IN the_DT basic_JJ committing_VBG bandits_NNS setup_NN to_TO the_DT case_NN of_IN contextual_JJ bandits_NNS =_JJ -_: =[_NN 10_CD ,_, 11_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ natural_JJ ._.
In_IN this_DT setup_NN before_IN choosing_VBG an_DT arm_NN an_DT additional_JJ ``_`` context_NN ''_'' isprovidedtothedecision_NN maker_NN ._.
The_DT problem_NN is_VBZ to_TO choose_VB a_DT decision_NN rule_NN from_IN a_DT given_VBN class_NN that_WDT prescribes_VBZ what_WDT arm_NN to_TO choose_VB f_SYM
died_VBD in_IN reinforcement_NN learning_NN algorithms_NNS ._.
Multi-armed_JJ bandit_NN algorithms_NNS have_VBP been_VBN widely_RB studied_VBN in_IN the_DT Machine_NNP Learning_NNP community_NN and_CC recently_RB applied_VBN to_TO multiclass_JJ online_NN learning_NN -LRB-_-LRB- see_VB ,_, e.g._FW ,_, -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 6_CD -RRB-_-RRB- -RRB-_-RRB- ._.
In_IN multiclass_JJ bandit_NN algorithms_VBZ the_DT feature_NN vectors_NNS of_IN the_DT training_NN examples_NNS are_VBP considered_VBN as_IN side_JJ information_NN given_VBN to_TO the_DT gambler_NN to_TO help_VB him_PRP choose_VB the_DT next_JJ arm_NN to_TO pull_VB --_: these_DT b_NN
