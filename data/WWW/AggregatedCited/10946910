Exploring_VBG web_NN scale_NN language_NN models_NNS for_IN search_NN query_NN processing_NN
It_PRP has_VBZ been_VBN widely_RB observed_VBN that_IN search_NN queries_NNS are_VBP composed_VBN in_IN a_DT very_RB different_JJ style_NN from_IN that_DT of_IN the_DT body_NN or_CC the_DT title_NN of_IN a_DT document_NN ._.
Many_JJ techniques_NNS explicitly_RB accounting_VBG for_IN this_DT language_NN style_NN discrepancy_NN have_VBP shown_VBN promising_JJ results_NNS for_IN information_NN retrieval_NN ,_, yet_CC a_DT large_JJ scale_NN analysis_NN on_IN the_DT extent_NN of_IN the_DT language_NN differences_NNS has_VBZ been_VBN lacking_VBG ._.
In_IN this_DT paper_NN ,_, we_PRP present_VBP an_DT extensive_JJ study_NN on_IN this_DT issue_NN by_IN examining_VBG the_DT language_NN model_NN properties_NNS of_IN search_NN queries_NNS and_CC the_DT three_CD text_NN streams_NNS associated_VBN with_IN each_DT web_NN document_NN :_: the_DT body_NN ,_, the_DT title_NN ,_, and_CC the_DT anchor_NN text_NN ._.
Our_PRP$ information_NN theoretical_JJ analysis_NN shows_VBZ that_IN queries_NNS seem_VBP to_TO be_VB composed_VBN in_IN a_DT way_NN most_RBS similar_JJ to_TO how_WRB authors_NNS summarize_VBP documents_NNS in_IN anchor_NN texts_NNS or_CC titles_NNS ,_, offering_VBG a_DT quantitative_JJ explanation_NN to_TO the_DT observations_NNS in_IN past_JJ work_NN ._.
We_PRP apply_VBP these_DT web_NN scale_NN n-gram_NN language_NN models_NNS to_TO three_CD search_NN query_NN processing_NN -LRB-_-LRB- SQP_NN -RRB-_-RRB- tasks_NNS :_: query_JJ spelling_NN correction_NN ,_, query_NN bracketing_NN and_CC long_JJ query_NN segmentation_NN ._.
By_IN controlling_VBG the_DT size_NN and_CC the_DT order_NN of_IN different_JJ language_NN models_NNS ,_, we_PRP find_VBP that_IN the_DT perplexity_NN metric_NN to_TO be_VB a_DT good_JJ accuracy_NN indicator_NN for_IN these_DT query_JJ processing_NN tasks_NNS ._.
We_PRP show_VBP that_IN using_VBG smoothed_VBD language_NN models_NNS yields_VBZ significant_JJ accuracy_NN gains_NNS for_IN query_NN bracketing_VBG for_IN instance_NN ,_, compared_VBN to_TO using_VBG web_NN counts_NNS as_IN in_IN the_DT literature_NN ._.
We_PRP also_RB demonstrate_VBP that_IN applying_VBG web-scale_JJ language_NN models_NNS can_MD have_VB marked_JJ accuracy_NN advantage_NN over_IN smaller_JJR ones_NNS ._.
NTS_NN Language_NN differences_NNS between_IN search_NN queries_NNS and_CC Web_NN documents_NNS have_VBP often_RB been_VBN assumed_VBN in_IN previous_JJ studies_NNS without_IN a_DT quantitative_JJ evaluation_NN -LRB-_-LRB- e.g._FW ,_, 2_CD ,_, 16_CD ,_, 33_CD -RRB-_-RRB- ._.
Following_VBG and_CC extending_VBG the_DT study_NN in_IN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_JJ -_: ,_, we_PRP performed_VBD a_DT large_JJ scale_NN analysis_NN of_IN Web_NN and_CC query_NN collections_NNS for_IN the_DT sake_NN of_IN quantifying_VBG the_DT language_NN discrepancy_NN between_IN search_NN queries_NNS and_CC Web_NN documents_NNS ._.
Table_NNP 1_CD summarizes_VBZ the_DT Web_NN n-gram_NN mode_NN
s_NN prior_JJ specific_JJ permission_NN and\/or_CC a_DT fee_NN ._.
SIGIR_NN '_'' 10_CD ,_, July_NNP 19-23_CD ,_, 2010_CD ,_, Geneva_NNP ,_, Swizerland_NNP ._.
Copyright_NN 2010_CD ACM_NNP 978-1-60558-896-4_CD \/_: 10\/07_CD ..._: $_$ 10.00_CD ._.
1_CD An_DT earlier_JJR version_NN of_IN MWNLM_NN is_VBZ described_VBN in_IN Huang_NNP et_FW al._FW =_SYM -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT paper_NN provides_VBZ updated_VBN information_NN regarding_VBG the_DT most_RBS recent_JJ development_NN of_IN MWNLM_NN ._.
1_CD ._.
INTRODUCTION_NN The_DT goal_NN of_IN a_DT statistical_JJ language_NN model_NN -LRB-_-LRB- LM_NN -RRB-_-RRB- is_VBZ to_TO predict_VB the_DT probability_NN of_IN a_DT word_NN string_NN ._.
he_PRP titles_NNS of_IN the_DT documents_NNS ,_, or_CC the_DT anchor_NN text_NN from_IN all_DT hyperlinks_NNS ._.
As_IN the_DT Microsoft_NNP Web_NN N-gram_NN Service_NN is_VBZ particularly_RB new_JJ ,_, its_PRP$ use_NN in_IN literature_NN is_VBZ somewhat_RB sparse_JJ ._.
We_PRP note_VBP the_DT work_NN of_IN Huang_NNP et_FW al._FW =_SYM -_: =[_NN 11_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT examined_VBD how_WRB the_DT accuracy_NN of_IN some_DT related_JJ IR_NN tasks_NNS could_MD be_VB improved_VBN using_VBG the_DT n-gram_NN service_NN ,_, such_JJ as_IN spelling_NN correction_NN and_CC query_NN segmentation_NN ._.
Indeed_RB ,_, while_IN it_PRP is_VBZ plausible_JJ query_NN segmentat_NN
Web_NN documents_NNS have_VBP indicated_VBN that_IN various_JJ portions_NNS of_IN Web_NN documents_NNS often_RB exhibit_VBP unique_JJ language_NN styles_NNS that_IN their_PRP$ respective_JJ language_NN models_NNS have_VBP significantly_RB different_JJ statistics_NNS from_IN one_CD another_DT =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =-[_NN 25_CD -RRB-_-RRB- ._.
The_DT notion_NN is_VBZ indeed_RB quite_RB intuitive_JJ :_: the_DT body_NN of_IN the_DT document_NN tends_VBZ to_TO use_VB a_DT style_NN for_IN formal_JJ and_CC detail_NN descriptions_NNS ,_, whereas_IN the_DT title_NN of_IN a_DT document_NN is_VBZ more_JJR of_IN a_DT summary_NN style_NN ._.
The_DT anchor_NN tex_NN
nts_NNS by_IN literally_RB matching_VBG terms_NNS in_IN documents_NNS with_IN those_DT in_IN a_DT search_NN query_NN ._.
However_RB ,_, lexical_JJ matching_NN methods_NNS can_MD be_VB inaccurate_JJ due_JJ to_TO the_DT language_NN discrepancy_NN between_IN Web_NN documents_NNS and_CC search_NN queries_NNS =_JJ -_: =[_NN 20_CD ,_, 31_CD -RRB-_-RRB- -_: =_SYM -_: i.e._FW ,_, a_DT concept_NN is_VBZ often_RB expressed_VBN using_VBG different_JJ vocabularies_NNS and_CC language_NN styles_NNS in_IN documents_NNS and_CC queries_NNS ._.
In_IN the_DT last_JJ two_CD decades_NNS ,_, different_JJ latent_JJ semantic_JJ models_NNS have_VBP been_VBN proposed_VBN to_TO address_VB t_NN
tracks_VBZ the_DT current_JJ news_NN and_CC popular_JJ events_NNS ._.
For_IN these_DT reasons_NNS ,_, recent_JJ research_NN has_VBZ exploited_VBN the_DT textual_JJ content_NN of_IN the_DT Web_NN to_TO create_VB models_NNS for_IN natural_JJ language_NN tools_NNS ,_, in_IN particular_JJ ,_, language_NN models_NNS =_JJ -_: =[_NN 14_CD ,_, 21_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Typically_RB ,_, language_NN models_NNS are_VBP built_VBN on_IN a_DT training_NN corpus_NN of_IN sentences_NNS with_IN the_DT assumption_NN that_IN the_DT distribution_NN of_IN n-grams_NN in_IN the_DT training_NN set_NN is_VBZ the_DT same_JJ as_IN the_DT distribution_NN of_IN n-grams_NN in_IN the_DT task_NN
