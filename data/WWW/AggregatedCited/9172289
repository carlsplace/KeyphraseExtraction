Dynamic_NNP cost-per-action_JJ mechanisms_NNS and_CC applications_NNS to_TO online_JJ advertising_NN
We_PRP study_VBD the_DT Cost-Per-Action_NNP or_CC Cost-Per-Acquisition_NNP -LRB-_-LRB- CPA_NNP -RRB-_-RRB- charging_VBG scheme_NN in_IN online_NN advertising_NN ._.
In_IN this_DT scheme_NN ,_, instead_RB of_IN paying_VBG per_IN click_VBP ,_, the_DT advertisers_NNS pay_VBP only_RB when_WRB a_DT user_NN takes_VBZ a_DT specific_JJ action_NN -LRB-_-LRB- e.g._FW fills_VBZ out_RP a_DT form_NN -RRB-_-RRB- or_CC completes_VBZ a_DT transaction_NN on_IN their_PRP$ websites_NNS ._.
We_PRP focus_VBP on_IN designing_VBG efficient_JJ and_CC incentive_NN compatible_JJ mechanisms_NNS that_WDT use_VBP this_DT charging_VBG scheme_NN ._.
We_PRP describe_VBP a_DT mechanism_NN based_VBN on_IN a_DT sampling-based_JJ learning_NN algorithm_NN that_IN under_IN suitable_JJ assumptions_NNS is_VBZ asymptotically_RB individually_RB rational_JJ ,_, asymptotically_RB Bayesian_JJ incentive_NN compatible_JJ and_CC asymptotically_RB ex-ante_JJ efficient_JJ ._.
In_IN particular_JJ ,_, we_PRP demonstrate_VBP our_PRP$ mechanism_NN for_IN the_DT case_NN where_WRB the_DT utility_NN functions_NNS of_IN the_DT advertisers_NNS are_VBP independent_JJ and_CC identically-distributed_JJ random_JJ variables_NNS as_RB well_RB as_IN the_DT case_NN where_WRB they_PRP evolve_VBP like_IN independent_JJ reflected_VBN Brownian_JJ motions_NNS ._.
tting_NN and_CC prove_VB matching_JJ upper_JJ and_CC lower_JJR bounds_NNS on_IN the_DT regret_NN ,_, which_WDT in_IN their_PRP$ case_NN is_VBZ the_DT difference_NN in_IN the_DT social_JJ welfare_NN achieved_VBN by_IN the_DT mechanism_NN and_CC the_DT optimum_JJ social_JJ welfare_NN ._.
Nazerzadeh_NNP et_NNP ._.
al._FW =_SYM -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: consider_VB a_DT similar_JJ problem_NN ,_, where_WRB the_DT goal_NN is_VBZ to_TO design_VB a_DT truthful_JJ pay-per-acquisition_NN auction_NN --_: the_DT key_JJ difference_NN being_VBG that_IN the_DT bidders_NNS report_VBP whether_IN an_DT acquisition_NN happened_VBD or_CC not_RB ._.
Their_PRP$ auction_NN
from_IN large_JJ scale_NN data_NNS ,_, can_MD provide_VB effective_JJ solutions_NNS to_TO the_DT above_JJ problems_NNS in_IN different_JJ types_NNS of_IN online_NN advertising_NN ,_, including_VBG sponsored_VBN search_NN ,_, contextual_JJ advertising_NN ,_, behavior_NN targeting_NN and_CC so_RB on_IN =_JJ -_: =[_NN 6_CD ;_: 12_CD ;_: 13_CD ;_: 3_CD ;_: 14_CD ;_: 9_CD ;_: 4_LS -RRB-_-RRB- -_: =_SYM -_: ._.
âˆ—_FW Workshop_FW report_NN on_IN ADKDD_NN 2008_CD :_: the_DT 2nd_JJ International_NNP Workshop_NNP on_IN Data_NNP Mining_NNP and_CC Audience_NNP Intelligence_NNP for_IN Advertising_NNP ,_, held_VBN in_IN conjunction_NN with_IN KDD_NN 2008_CD ,_, The_DT 14th_JJ ACM_NNP SIGKDD_NNP International_NNP Confere_NNP
t_NN the_DT learning_VBG black_JJ box_NN is_VBZ optimal_JJ on_IN each_DT bandit_NN problem_NN ._.
The_DT large_JJ literature_NN on_IN multi-armed_JJ bandit_NN optimization_NN is_VBZ relevant_JJ here_RB -LRB-_-LRB- 10_CD ,_, 4_CD ,_, 3_CD ,_, 7_CD -RRB-_-RRB- ,_, including_VBG some_DT directly_RB applied_VBN to_TO sponsored_VBN search_NN =_JJ -_: =[_NN 8_CD ,_, 11_CD ,_, 14_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Thus_RB far_RB we_PRP have_VBP described_VBN a_DT standard_JJ bandits_NN framework_NN ;_: we_PRP now_RB introduce_VBP outsourcing_NN ._.
We_PRP assume_VBP that_IN at_IN every_DT observation_NN of_IN any_DT keyphrase_FW i_FW ,_, the_DT agent_NN can_MD choose_VB to_TO forgo_VB the_DT opportunity_NN to_TO learn_VB
t_NN the_DT learning_VBG black_JJ box_NN is_VBZ optimal_JJ on_IN each_DT bandit_NN problem_NN ._.
The_DT large_JJ literature_NN on_IN multi-armed_JJ bandit_NN optimization_NN is_VBZ relevant_JJ here_RB -LRB-_-LRB- 10_CD ,_, 4_CD ,_, 3_CD ,_, 7_CD -RRB-_-RRB- ,_, including_VBG some_DT directly_RB applied_VBN to_TO sponsored_VBN search_NN =_JJ -_: =[_NN 8_CD ,_, 11_CD ,_, 14_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Thus_RB far_RB we_PRP have_VBP described_VBN a_DT standard_JJ bandits_NN framework_NN ;_: we_PRP now_RB introduce_VBP outsourcing_NN ._.
We_PRP assume_VBP that_IN at_IN every_DT observation_NN of_IN any_DT keyphrase_FW i_FW ,_, the_DT agent_NN can_MD choose_VB to_TO forgo_VB the_DT opportunity_NN to_TO learn_VB
directly_RB ._.
The_DT PPA_NN scheme_NN is_VBZ a_DT relatively_RB new_JJ model_NN ,_, and_CC we_PRP are_VBP aware_JJ of_IN only_RB two_CD studies_NNS that_WDT deal_VBP with_IN it_PRP explicitly_RB ._.
-LRB-_-LRB- 8_CD -RRB-_-RRB- adopts_VBZ the_DT model_NN used_VBN for_IN the_DT PPC_NNP context_NN ,_, with_IN clicks_NNS replaced_VBN by_IN actions_NNS ._.
=_SYM -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: designs_VBZ a_DT mechanism_NN for_IN repeated_VBN single-item_JJ auction_NN with_IN stochastically_RB distributed_VBN agents_NNS '_POS valuations_NNS ,_, in_IN which_WDT only_RB the_DT winning_JJ agent_NN reports_VBZ his_PRP$ utility_NN ._.
While_IN their_PRP$ mechanism_NN has_VBZ many_JJ desirable_JJ
