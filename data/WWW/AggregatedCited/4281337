Large-scale_JJ text_NN categorization_NN by_IN batch_NN mode_NN active_JJ learning_NN
Large-scale_JJ text_NN categorization_NN is_VBZ an_DT important_JJ research_NN topic_NN for_IN Web_NN data_NNS mining_NN ._.
One_CD of_IN the_DT challenges_NNS in_IN large-scale_JJ text_NN categorization_NN is_VBZ how_WRB to_TO reduce_VB the_DT human_JJ efforts_NNS in_IN labeling_NN text_NN documents_NNS for_IN building_VBG reliable_JJ classification_NN models_NNS ._.
In_IN the_DT past_NN ,_, there_EX have_VBP been_VBN many_JJ studies_NNS on_IN applying_VBG active_JJ learning_VBG methods_NNS to_TO automatic_JJ text_NN categorization_NN ,_, which_WDT try_VBP to_TO select_VB the_DT most_RBS informative_JJ documents_NNS for_IN labeling_NN manually_RB ._.
Most_JJS of_IN these_DT studies_NNS focused_VBD on_IN selecting_VBG a_DT single_JJ unlabeled_JJ document_NN in_IN each_DT iteration_NN ._.
As_IN a_DT result_NN ,_, the_DT text_NN categorization_NN model_NN has_VBZ to_TO be_VB retrained_VBN after_IN each_DT labeled_VBN document_NN is_VBZ solicited_VBN ._.
In_IN this_DT paper_NN ,_, we_PRP present_VBP a_DT novel_JJ active_JJ learning_NN algorithm_NN that_WDT selects_VBZ a_DT batch_NN of_IN text_NN documents_NNS for_IN labeling_NN manually_RB in_IN each_DT iteration_NN ._.
The_DT key_NN of_IN the_DT batch_NN mode_NN active_JJ learning_NN is_VBZ how_WRB to_TO reduce_VB the_DT redundancy_NN among_IN the_DT selected_VBN examples_NNS such_JJ that_IN each_DT example_NN provides_VBZ unique_JJ information_NN for_IN model_NN updating_VBG ._.
To_TO this_DT end_NN ,_, we_PRP use_VBP the_DT Fisher_NNP information_NN matrix_NN as_IN the_DT measurement_NN of_IN model_NN uncertainty_NN and_CC choose_VB the_DT set_NN of_IN documents_NNS to_TO effectively_RB maximize_VB the_DT Fisher_NNP information_NN of_IN a_DT classification_NN model_NN ._.
Extensive_JJ experiments_NNS with_IN three_CD different_JJ datasets_NNS have_VBP shown_VBN that_IN our_PRP$ algorithm_NN is_VBZ more_RBR effective_JJ than_IN the_DT state-of-the-art_JJ active_JJ learning_NN techniques_NNS for_IN text_NN categorization_NN and_CC can_MD be_VB a_DT promising_JJ tool_NN toward_IN large-scale_JJ text_NN categorization_NN for_IN World_NN Wide_NN Web_NN documents_NNS ._.
nformation_NN for_IN model_NN updating_VBG ._.
To_TO this_DT end_NN ,_, we_PRP propose_VBP a_DT framework_NN of_IN batch_NN mode_NN active_JJ learning_NN that_WDT measures_VBZ the_DT overall_JJ information_NN for_IN a_DT set_NN of_IN unlabeled_JJ examples_NNS by_IN the_DT Fisher_NNP information_NN matrix_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP formulate_VBP the_DT batch_NN mode_NN active_JJ learning_NN framework_NN into_IN an_DT SDP_NN problem_NN ,_, and_CC present_VB an_DT effective_JJ optimization_NN algorithm_NN based_VBN on_IN the_DT bound_VBN optimization_NN technique_NN ._.
Further_RB ,_, we_PRP present_VBP the_DT kernel_NN v_LS
sifier_NN creation_NN and_CC data_NN annotation_NN ._.
Examples_NNS of_IN AL_NN used_VBN in_IN language_NN engineering_NN include_VBP named_VBN entity_NN recognition_NN -LRB-_-LRB- Shen_NNP et_FW al._FW ,_, 2004_CD ;_: Tomanek_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ,_, text_NN categorization_NN -LRB-_-LRB- Lewis_NNP and_CC Gale_NNP ,_, 1994_CD ;_: =_JJ -_: =_JJ Hoi_FW et_FW al._FW ,_, 2006_CD -_: =--RRB-_NN ,_, part-of-speech_JJ tagging_NN -LRB-_-LRB- Ringger_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ,_, and_CC parsing_NN -LRB-_-LRB- Thompson_NNP et_FW al._FW ,_, 1999_CD ;_: Becker_NNP and_CC Osborne_NNP ,_, 2005_CD -RRB-_-RRB- ._.
AL_NNP is_VBZ a_DT supervised_JJ machine_NN learning_NN technique_NN in_IN which_WDT the_DT learner_NN is_VBZ in_IN control_NN of_IN the_DT
erland_NN ._.
Copyright_NN 2010_CD ACM_NNP 978-1-60558-896-4_CD \/_: 10\/07_CD ..._: $_$ 10.00_CD ._.
number_NN of_IN unlabeled_JJ documents_NNS ,_, such_JJ as_IN web_NN pages_NNS ,_, newspapers_NNS and_CC journal_NN articles_NNS ._.
In_IN recent_JJ years_NNS ,_, a_DT new_JJ approach_NN called_VBN active_JJ learning_NN =_JJ -_: =[_NN 1_CD ,_, 3_CD ,_, 5_CD ,_, 6_CD ,_, 9_CD ,_, 11_CD ,_, 13_CD ,_, 14_CD ,_, 15_CD ,_, 16_CD ,_, 18_CD ,_, 20_CD ,_, 25_CD -RRB-_-RRB- -_: =_SYM -_: has_VBZ been_VBN developed_VBN in_IN the_DT machine_NN learning_NN community_NN with_IN the_DT goal_NN of_IN reducing_VBG the_DT labeling_NN cost_NN by_IN identifying_VBG and_CC presenting_VBG the_DT most_RBS informative_JJ examples_NNS from_IN the_DT unlabeled_JJ examples_NNS for_IN the_DT human_JJ
d_NN examples_NNS in_IN a_DT method_NN called_VBN `_`` batch_NN mode_NN active_JJ learning_NN '_'' by_IN measuring_VBG the_DT model_NN uncertainty_NN and_CC choosing_VBG a_DT batch_NN of_IN documents_NNS to_TO effectively_RB maximize_VB the_DT Fisher_NNP information_NN of_IN a_DT classification_NN model_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Fisher_NNP 's_POS methods_NNS are_VBP useful_JJ in_IN other_JJ classification_NN algorithms_NNS ._.
Support_NN vector_NN machines_NNS -LRB-_-LRB- SVMs_NNS -RRB-_-RRB- ,_, presented_VBN later_RB in_IN this_DT paper_NN ,_, have_VBP shown_VBN superb_JJ performance_NN for_IN text_NN classification_NN tasks_NNS ._.
They_PRP are_VBP a_DT
ve_IN sampling_NN approach_NN for_IN SVM_NNP active_JJ learning_NN ,_, which_WDT also_RB incorporates_VBZ a_DT diversity_NN measure_NN ._.
Specifically_RB ,_, they_PRP query_VBP cluster_NN centroids_NNS for_IN instances_NNS that_WDT lie_VBP close_RB to_TO the_DT decision_NN boundary_NN ._.
Hoi_FW et_FW al._FW =_SYM -_: =[_NN 7_CD ,_, 8_CD -RRB-_-RRB- -_: =_SYM -_: extend_VB the_DT Fisher_NNP information_NN framework_NN to_TO the_DT batch-mode_JJ setting_NN for_IN binary_JJ logistic_JJ regression_NN ._.
Hoi_FW et_FW al._FW -LRB-_-LRB- 9_CD -RRB-_-RRB- propose_VBP a_DT novel_JJ batch-mode_JJ active_JJ learning_NN scheme_NN on_IN SVMs_NNS that_WDT exploits_VBZ semi-supervise_JJ
ation_NN from_IN a_DT mixture_NN of_IN labeled_JJ and_CC unlabeled_JJ documents_NNS ._.
The_DT well-known_JJ examples_NNS within_IN this_DT category_NN include_VBP Transductive_JJ SVM_NN for_IN text_NN categorization_NN -LRB-_-LRB- 75_CD ,_, 148_CD -RRB-_-RRB- ._.
The_DT third_JJ approach_NN is_VBZ active_JJ learning_NN =_JJ -_: =[_NN 97_CD ,_, 58_CD ,_, 59_CD -RRB-_-RRB- -_: =_SYM -_: that_WDT aims_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ documents_NNS for_IN manually_RB labeling_VBG ._.
Finally_RB ,_, in_IN addition_NN to_TO semi-supervisedCHAPTER_NN 2_CD ._.
BACKGROUND_NN REVIEW_NNP :_: LEARNING_VBG WITH_IN UNLABELED_FW DATA36_FW learning_NN and_CC a_DT
r_NN et_FW al._FW ,_, 2001_CD -RRB-_-RRB- and_CC the_DT query-by-committee_NN -LRB-_-LRB- QBC_NN -RRB-_-RRB- algorithm_NN by_IN -LRB-_-LRB- Seung_NNP et_FW al._FW ,_, 1992_CD -RRB-_-RRB- ._.
In_IN addition_NN ,_, there_EX are_VBP algorithms_NNS designed_VBN for_IN reducing_VBG the_DT redundancy_NN in_IN queries_NNS which_WDT may_MD be_VB worth_JJ investigating_VBG -LRB-_-LRB- =_JJ -_: =_JJ Hoi_FW et_FW al._FW ,_, 2006_CD -_: =--RRB-_NN ._.
Also_RB ,_, -LRB-_-LRB- Hoi_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- shows_VBZ that_IN Logistic_JJ Regression_NN -LRB-_-LRB- LR_NN -RRB-_-RRB- outperforms_VBZ SVM_NNP when_WRB used_VBN with_IN active_JJ learning_NN ,_, yielding_VBG higher_JJR F-score_NN on_IN the_DT Reuters21578_NN data_NN set_NN -LRB-_-LRB- binary_JJ classification_NN ,_, 10,788_CD docu_NN
-LRB-_-LRB- 43_CD -RRB-_-RRB- ._.
Finally_RB ,_, to_TO minimize_VB the_DT human_JJ effort_NN of_IN labeling_NN training_NN data_NNS ,_, we_PRP can_MD study_VB active_JJ learning_NN techniques_NNS to_TO provide_VB users_NNS the_DT most_RBS informative_JJ examples_NNS for_IN labeling_NN during_IN the_DT annotation_NN tasks_NNS =_JJ -_: =[_NN 45_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 46_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 47_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 48_CD -RRB-_-RRB- ._.
VI_NNP ._.
CONCLUSION_NN In_IN this_DT paper_NN we_PRP proposed_VBD a_DT novel_JJ transductive_JJ learning_NN algorithm_NN for_IN face_NN annotation_NN ._.
In_IN contrast_NN to_TO traditional_JJ approaches_NNS using_VBG supervised_JJ learning_NN methods_NNS ,_, we_PRP pr_VBP
1_CD ._.
INTRODUCTION_NN With_IN the_DT rapid_JJ growth_NN of_IN text_NN information_NN on_IN the_DT World_NNP Wide_NN Web_NN -LRB-_-LRB- WWW_NN -RRB-_-RRB- ,_, text_NN classification_NN has_VBZ become_VBN one_CD of_IN the_DT most_RBS important_JJ topic_NN in_IN both_CC the_DT community_NN of_IN research_NN and_CC engineering_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB there_EX are_VBP two_CD major_JJ problems_NNS with_IN current_JJ algorithms_NNS involving_VBG in_IN text_NN classification_NN task_NN ._.
One_CD key_JJ challenge_NN is_VBZ that_IN almost_RB all_PDT the_DT algorithms_NNS treat_VBP the_DT problem_NN as_IN a_DT balanced_JJ classification_NN
-LRB-_-LRB- 43_CD -RRB-_-RRB- ._.
Finally_RB ,_, to_TO minimize_VB the_DT human_JJ effort_NN of_IN labeling_NN training_NN data_NNS ,_, we_PRP can_MD study_VB active_JJ learning_NN techniques_NNS to_TO provide_VB users_NNS the_DT most_RBS informative_JJ examples_NNS for_IN labeling_NN during_IN the_DT annotation_NN tasks_NNS =_JJ -_: =[_NN 45_CD -RRB-_-RRB- -_: =_SYM -_: --_: -LRB-_-LRB- 48_CD -RRB-_-RRB- ._.
VI_NNP ._.
CONCLUSION_NN In_IN this_DT paper_NN ,_, we_PRP proposed_VBD a_DT novel_JJ transductive_JJ learning_NN algorithm_NN for_IN face_NN annotation_NN ._.
In_IN contrast_NN to_TO traditional_JJ approaches_NNS using_VBG supervised_JJ learning_NN methods_NNS ,_, we_PRP proposed_VBD the_DT T_NN
as_IN interactive_JJ video_NN retrieval_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- and_CC image\/video_NN annotation_NN -LRB-_-LRB- 40_CD -RRB-_-RRB- ._.
To_TO these_DT problems_NNS ,_, we_PRP will_MD explore_VB the_DT proposed_VBN multimodal_JJ and_CC multilevel_JJ framework_NN together_RB with_IN active_JJ learning_NN techniques_NNS -LRB-_-LRB- 41_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 42_CD -RRB-_-RRB- -_: =_SYM -_: to_TO overcome_VB these_DT open_JJ challenges_NNS ._.
We_PRP may_MD also_RB study_VB more_RBR effective_JJ kernel_NN learning_NN methods_NNS ,_, such_JJ as_IN the_DT nonparametric_JJ kernel_NN learning_NN for_IN improving_VBG the_DT retrieval_NN performance_NN -LRB-_-LRB- 43_CD -RRB-_-RRB- ._.
Lastly_RB ,_, we_PRP may_MD stu_VB
c_NN approaches_NNS ,_, we_PRP learn_VBP a_DT sampling_NN distribution_NN by_IN formally_RB formulating_VBG the_DT batch_NN mode_NN active_JJ learning_NN problem_NN ._.
Finally_RB ,_, our_PRP$ work_NN is_VBZ different_JJ from_IN some_DT other_JJ recent_JJ work_NN on_IN batch_NN mode_NN active_JJ learning_NN =_JJ -_: =[_NN 8_CD ,_, 6_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
These_DT studies_NNS were_VBD mainly_RB based_VBN on_IN kernel_NN logistic_JJ regressions_NNS ,_, which_WDT may_MD not_RB be_VB able_JJ to_TO applicable_JJ to_TO SVM_NNP models_NNS directly_RB ._.
5_CD ._.
Conclusion_NN We_PRP proposed_VBD a_DT novel_JJ semi-supervised_JJ SVM_NN batch_NN mode_NN active_JJ le_FW
