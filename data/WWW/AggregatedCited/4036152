The_DT discoverability_NN of_IN the_DT web_NN
Previous_JJ studies_NNS have_VBP highlighted_VBN the_DT high_JJ arrival_NN rate_NN of_IN new_JJ contenton_NN the_DT web_NN ._.
We_PRP study_VBD the_DT extent_NN to_TO which_WDT this_DT new_JJ content_NN can_MD beefficiently_RB discovered_VBN by_IN a_DT crawler_NN ._.
Our_PRP$ study_NN has_VBZ two_CD parts_NNS ._.
First_RB ,_, we_PRP study_VBD the_DT inherent_JJ difficulty_NN of_IN the_DT discovery_NN problem_NN using_VBG amaximum_NN cover_NN formulation_NN ,_, under_IN an_DT assumption_NN of_IN perfect_JJ estimates_NNS oflikely_RB sources_NNS of_IN links_NNS to_TO new_JJ content_NN ._.
Second_RB ,_, we_PRP relax_VBP thisassumption_NN and_CC study_VB a_DT more_RBR realistic_JJ setting_NN in_IN which_WDT algorithms_NNS mustuse_VBP historical_JJ statistics_NNS to_TO estimate_VB which_WDT pages_NNS are_VBP most_RBS likely_JJ toyield_NN links_NNS to_TO new_JJ content_NN ._.
We_PRP recommend_VBP a_DT simple_JJ algorithm_NN thatperforms_NNS comparably_RB to_TO all_DT approaches_NNS we_PRP consider_VBP ._.
We_PRP measure_VBP the_DT emphoverhead_NN of_IN discovering_VBG new_JJ content_NN ,_, defined_VBN asthe_JJ average_JJ number_NN of_IN fetches_VBZ required_VBN to_TO discover_VB one_CD new_JJ page_NN ._.
Weshow_NNP first_RB that_IN with_IN perfect_JJ foreknowledge_NN of_IN where_WRB to_TO explore_VB forlinks_NNS to_TO new_JJ content_NN ,_, it_PRP is_VBZ possible_JJ to_TO discover_VB 90_CD %_NN of_IN all_DT newcontent_NN with_IN under_IN 3_CD %_NN overhead_NN ,_, and_CC 100_CD %_NN of_IN new_JJ content_NN with_IN 9_CD %_NN overhead_NN ._.
But_CC actual_JJ algorithms_NNS ,_, which_WDT do_VBP not_RB have_VB access_NN to_TO perfectforeknowledge_NN ,_, face_VBP a_DT more_RBR difficult_JJ task_NN :_: one_CD quarter_NN of_IN new_JJ contentis_NN simply_RB not_RB amenable_JJ to_TO efficient_JJ discovery_NN ._.
Of_IN the_DT remaining_VBG threequarters_NNS ,_, 80_CD %_NN of_IN new_JJ content_NN during_IN a_DT given_VBN week_NN may_MD be_VB discoveredwith_JJ 160_CD %_NN overhead_NN if_IN content_NN is_VBZ recrawled_VBN fully_RB on_IN a_DT monthly_JJ basis_NN ._.
e_LS are_VBP some_DT industrial_JJ proposed_VBN approaches_NNS for_IN improving_VBG the_DT accessibility_NN and_CC discoverability_NN of_IN AJAX_NN as_IN discussedinSection7_NN ._.
There_EX has_VBZ been_VBN extensive_JJ research_NN on_IN crawling_VBG the_DT hidden-web_NN behind_IN forms_NNS =_JJ -_: =[_NN 4_CD ,_, 7_CD ,_, 8_CD ,_, 14_CD ,_, 21_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ sharp_JJ contrast_NN with_IN the_DT the_DT hidden-web_NN induced_VBN as_IN a_DT result_NN of_IN client-side_JJ scripting_NN in_IN general_JJ and_CC AJAX_NNP in_IN particular_JJ ,_, which_WDT has_VBZ gained_VBN very_RB little_JJ attention_NN so_RB far_RB ._.
As_RB far_RB as_IN we_PRP know_VBP ,_, there_EX
PageRank_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, Shark-Search_NN -LRB-_-LRB- 24_CD -RRB-_-RRB- ,_, and_CC InfoSpiders_NNS -LRB-_-LRB- 40_CD -RRB-_-RRB- ._.
Discoverability_NN of_IN the_DT web_NN ._.
Motivated_VBN by_IN the_DT fast_JJ pace_NN of_IN web_NN growth_NN and_CC the_DT need_NN of_IN crawlers_NNS to_TO discover_VB new_JJ content_NN quickly_RB ,_, Dasgupta_NNP et_FW al._FW =_SYM -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP recently_RB posed_VBN the_DT following_JJ question_NN :_: how_WRB can_MD a_DT crawler_NN discover_VB as_IN much_JJ new_JJ content_NN as_IN possible_JJ ,_, while_IN incurring_VBG as_RB little_JJ ``_`` overhead_NN ''_'' as_IN possible_JJ ?_.
Dasgupta_NNP et_FW al._FW formally_RB define_VB the_DT overhead_NN
he_PRP evolving_VBG link_NN structure_NN sheds_VBZ light_NN on_IN design_NN of_IN other_JJ applications_NNS ,_, for_IN example_NN web_NN search_NN engines_NNS detect_VBP importance_NN of_IN a_DT newly_RB crawled_VBN page_NN and_CC model_NN smart_JJ incremental_JJ crawl_NN policies_NNS accordingly_RB =_JJ -_: =[_NN 11_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Moreover_RB ,_, -LRB-_-LRB- 7_CD ,_, 28_CD ,_, 22_CD ,_, 16_CD -RRB-_-RRB- reported_VBD interesting_JJ characteristics_NNS of_IN the_DT archival_JJ web_NN graphs_NNS ,_, such_JJ as_IN the_DT birth_NN and_CC death_NN rate_NN and_CC the_DT life_NN length_NN distribution_NN of_IN web_NN pages_NNS ,_, factors_NNS influencing_VBG persist_VB
onization_NN of_IN previously_RB acquired_VBN pages_NNS to_TO maintain_VB freshness_NN ._.
This_DT paper_NN focuses_VBZ on_IN acquisition_NN ;_: the_DT discovery_NN and_CC synchronization_NN aspects_NNS are_VBP largely_RB orthogonal_JJ and_CC have_VBP been_VBN studied_VBN elsewhere_RB ,_, e.g._FW =_JJ -_: =[_NN 6_CD ,_, 9_CD ,_, 10_CD ,_, 15_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP leave_VBP the_DT problem_NN of_IN dividing_VBG crawling_VBG resources_NNS among_IN these_DT three_CD tasks_NNS as_IN future_JJ work_NN ._.
Prior_JJ work_NN on_IN choosing_VBG the_DT order_NN in_IN which_WDT to_TO acquire_VB new_JJ content_NN -LRB-_-LRB- also_RB known_VBN as_IN ``_`` prioritizing_VBG the_DT crawling_VBG
from_IN the_DT Open_NNP Directory_NNP Project_NNP ._.
6.1_CD Finding_VBG crawl_NN seeds_NNS Discoverability_NN of_IN the_DT web_NN ._.
Motivated_VBN by_IN the_DT fast_JJ pace_NN of_IN web_NN growth_NN and_CC the_DT need_NN of_IN crawlers_NNS to_TO discover_VB new_JJ content_NN quickly_RB ,_, Dasgupta_NNP et_FW al._FW =_SYM -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP recently_RB posed_VBN the_DT following_JJ question_NN :_: how_WRB can_MD a_DT crawler_NN discover_VB as_IN much_JJ new_JJ content_NN as_IN possible_JJ ,_, while_IN incurring_VBG as_RB little_JJ ``_`` overhead_NN ''_'' as_IN possible_JJ ?_.
Dasgupta_NNP et_FW al._FW formally_RB define_VB the_DT overhead_NN
most_RBS impactful_JJ newly_RB discovered_VBN pages_NNS ,_, and_CC -LRB-_-LRB- c_LS -RRB-_-RRB- synchronizing_VBG the_DT repository_NN with_IN known_JJ live_JJ pages_NNS that_WDT have_VBP undergone_VBN impactful_JJ updates_NNS ._.
I_PRP have_VBP had_VBN the_DT opportunity_NN of_IN working_VBG on_IN each_DT of_IN these_DT aspects_NNS =_JJ -_: =[_NN 2_CD ,_, 4_CD ,_, 8_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
s_NN â€¢_CD Discovering_VBG links_NNS to_TO new_JJ pages_NNS :_: Search_VB engines_NNS typically_RB discover_VBP links_NNS to_TO new_JJ pages_NNS by_IN polling_NN known_JJ pages_NNS and_CC extracting_VBG their_PRP$ outgoing_JJ links_NNS ._.
Since_IN the_DT set_NN of_IN outgoing_JJ links_NNS from_IN different_JJ page_NN
okmarking_NN seems_VBZ to_TO be_VB a_DT good_JJ source_NN of_IN new_JJ and_CC active_JJ pages_NNS ._.
As_IN a_DT source_NN of_IN new_JJ pages_NNS ,_, social_JJ bookmarking_NN may_MD help_VB a_DT search_NN engine_NN discover_VBP pages_NNS it_PRP might_MD not_RB otherwise_RB ._.
For_IN instance_NN ,_, Dasgupta_NNP et_FW al._FW =_SYM -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: suggest_VBP that_IN 25_CD %_NN new_JJ pages_NNS are_VBP not_RB discoverable_JJ using_VBG historical_JJ information_NN about_IN old_JJ pages_NNS ._.
As_IN a_DT source_NN of_IN both_CC new_JJ and_CC active_JJ pages_NNS ,_, social_JJ bookmarking_NN may_MD also_RB help_VB more_RBR generally_RB with_IN the_DT ``_`` crawl_NN
been_VBN considered_VBN when_WRB defining_VBG crawl_NN selection_NN methods_NNS are_VBP for_IN example_NN user-specific_JJ interests_NNS -LRB-_-LRB- 18_CD -RRB-_-RRB- ,_, the_DT avoidance_NN of_IN spam_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- and_CC wanting_VBG to_TO obtain_VB fresh_JJ versions_NNS of_IN frequently_RB changing_VBG pages_NNS -LRB-_-LRB- -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Breadth-first_JJ crawling_NN ,_, wherein_WRB pages_NNS are_VBP crawled_VBN in_IN the_DT order_NN they_PRP are_VBP discovered_VBN ,_, has_VBZ been_VBN well-studied_JJ due_JJ to_TO its_PRP$ relative_JJ simplicity_NN ._.
It_PRP has_VBZ also_RB been_VBN shown_VBN to_TO yield_VB high_JJ PageRank_NN pages_NNS in_IN the_DT
e_LS the_DT greedy_JJ objective_NN of_IN finding_NN as_IN many_JJ desirable_JJ pages_NNS for_IN NDCG_NN on_IN the_DT current_JJ iteration_NN ,_, with_IN that_DT of_IN including_VBG those_DT pages_NNS that_WDT are_VBP likely_JJ to_TO be_VB helpful_JJ in_IN picking_VBG the_DT corpus_NN for_IN iteration_NN i_FW +_CC 1_CD =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
To_TO analyze_VB this_DT we_PRP consider_VBP the_DT presence_NN of_IN `_`` helpful_JJ '_'' URLs_NNS at_IN each_DT crawl_NN iteration_NN ,_, being_VBG URLs_NNS that_WDT link_VBP to_TO pages_NNS with_IN a_DT ``_`` Perfect_NNP ''_'' ,_, ``_`` Excellent_JJ ''_'' or_CC ``_`` Good_NNP ''_'' rating_NN ._.
In_IN Figure_NNP 7_CD we_PRP compare_VBP the_DT number_NN of_IN
