IRLbot_NN :_: scaling_VBG to_TO 6_CD billion_CD pages_NNS and_CC beyond_IN
This_DT paper_NN shares_VBZ our_PRP$ experience_NN in_IN designing_VBG a_DT web_NN crawler_NN that_WDT can_MD download_VB billions_NNS of_IN pages_NNS using_VBG a_DT single-server_JJ implementation_NN and_CC models_NNS its_PRP$ performance_NN ._.
We_PRP show_VBP that_IN with_IN the_DT quadratically_RB increasing_VBG complexity_NN of_IN verifying_VBG URL_NN uniqueness_NN ,_, BFS_NNS crawl_VBP order_NN ,_, and_CC fixed_VBN per-host_JJ rate-limiting_JJ ,_, current_JJ crawling_VBG algorithms_NNS can_MD not_RB effectively_RB cope_VB with_IN the_DT sheer_JJ volume_NN of_IN URLs_NNS generated_VBN in_IN large_JJ crawls_VBZ ,_, highly-branching_JJ spam_NN ,_, legitimate_JJ multi-million-page_JJ blog_NN sites_NNS ,_, and_CC infinite_JJ loops_NNS created_VBN by_IN server-side_JJ scripts_NNS ._.
We_PRP offer_VBP a_DT set_NN of_IN techniques_NNS for_IN dealing_VBG with_IN these_DT issues_NNS and_CC test_VB their_PRP$ performance_NN in_IN an_DT implementation_NN we_PRP call_VBP IRLbot_NN ._.
In_IN our_PRP$ recent_JJ experiment_NN that_WDT lasted_VBD 41_CD days_NNS ,_, IRLbot_NN running_VBG on_IN a_DT single_JJ server_NN successfully_RB crawled_VBD 6.3_CD billion_CD valid_JJ HTML_NNP pages_NNS -LRB-_-LRB- $_$ 7.6_CD $_$ billion_CD connection_NN requests_NNS -RRB-_-RRB- and_CC sustained_VBD an_DT average_JJ download_NN rate_NN of_IN 319_CD mb\/s_NNS -LRB-_-LRB- 1,789_CD pages\/s_NN -RRB-_-RRB- ._.
Unlike_IN our_PRP$ prior_JJ experiments_NNS with_IN algorithms_NNS proposed_VBN in_IN related_JJ work_NN ,_, this_DT version_NN of_IN IRLbot_NN did_VBD not_RB experience_VB any_DT bottlenecks_NNS and_CC successfully_RB handled_VBD content_NN from_IN over_IN 117_CD million_CD hosts_NNS ,_, parsed_VBN out_RP 394_CD billion_CD links_NNS ,_, and_CC discovered_VBD a_DT subset_NN of_IN the_DT web_NN graph_NN with_IN 41_CD billion_CD unique_JJ nodes_NNS ._.
http:\/\/www.ietf.org\/rfc\/rfc2616.txt_NN 6_CD http:\/\/www.w3.org\/DesignIssues\/LinkedData.html4.3_NN Pay-Level_NN Domains_NNS In_IN a_DT variation_NN of_IN our_PRP$ algorithm_NN we_PRP use_VBP the_DT notion_NN of_IN pay-level_JJ domains_NNS -LRB-_-LRB- PLDs_NNS -RRB-_-RRB- as_IN defined_VBN in_IN =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT top-level_JJ domain_NN -LRB-_-LRB- TLD_NN -RRB-_-RRB- is_VBZ a_DT domain_NN one_CD level_NN below_IN the_DT root_NN in_IN the_DT DNS_NN tree_NN and_CC appears_VBZ as_IN the_DT label_NN after_IN the_DT final_JJ dot_NN in_IN a_DT domain_NN name_NN -LRB-_-LRB- e.g._FW ,_, ._.
com_NN ,_, ._.
ie_NN -RRB-_-RRB- ._.
A_DT pay-level_JJ domain_NN -LRB-_-LRB- PLD_NN -RRB-_-RRB- is_VBZ a_DT domain_NN th_DT
ity_NN in_IN a_DT document_NN whose_WP$ pay-level_JJ domain_NN -LRB-_-LRB- PLD_NN -RRB-_-RRB- is_VBZ the_DT same_JJ as_IN the_DT document_NN 's_POS PLD_NN :_: here_RB ,_, a_DT PLD_NN is_VBZ defined_VBN as_IN any_DT domain_NN that_WDT requires_VBZ payment_NN at_IN a_DT -LRB-_-LRB- top-leveldomain_NN -RRB-_-RRB- -LRB-_-LRB- TLD_NN -RRB-_-RRB- or_CC country-code_JJ TLD_NN registrar_NN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Taking_VBG an_DT example_NN ,_, let_VB P_NN LD_NN -LRB-_-LRB- uri_NN -RRB-_-RRB- be_VB the_DT PLD_NN extraction_NN function_NN ;_: then_RB :_: P_NN LD_NN -LRB-_-LRB- http_NN :_: \/_: \/_: www.deri.ie_NN \/_: -RRB-_-RRB- =_JJ deri_NN ._.
ie_FW We_PRP can_MD now_RB define_VB a_DT local_JJ entity_NN as_IN follows_VBZ :_: Definition_NN 4_CD ._.
Local_JJ Entity_NN We_PRP define_VBP the_DT set_NN
ch_NN in_IN order_NN to_TO enhance_VB the_DT likeliness_NN to_TO retrieve_VB important_JJ pages_NNS first_RB ._.
Research_NN on_IN improving_VBG the_DT scalability_NN of_IN a_DT Web_NN crawler_NN in_IN order_NN to_TO crawl_VB 6_CD billion_CD pages_NNS and_CC beyond_IN is_VBZ presented_VBN by_IN Lee_NNP et_FW al._FW =_SYM -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Their_PRP$ findings_NNS show_VBP that_IN changing_VBG the_DT BFS_NNS crawling_VBG order_NN and_CC designing_VBG low-overhead_JJ disk-based_JJ data_NNS structures_NNS increase_VBP the_DT efficiency_NN of_IN large-scale_JJ crawlers_NNS ._.
A_DT dedicated_JJ survey_NN about_IN the_DT evolution_NN
load_NN throughput_NN peaks_VBZ at_IN ∼_FW 10MB\/s_FW which_WDT is_VBZ limited_VBN by_IN our_PRP$ 100-Mbps_NNP Internet_NNP uplink_NN ._.
There_EX are_VBP highly_RB optimized_VBN single-server_JJ crawler_NN implementations_NNS that_WDT can_MD sustain_VB higher_JJR download_NN rates_NNS than_IN 100Mbps_NN =_JJ -_: =[_NN 49_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, our_PRP$ Piccolo-based_JJ crawler_NN could_MD potentially_RB scale_VB to_TO even_RB higher_JJR download_NN rates_NNS despite_IN being_VBG built_VBN using_VBG Python_NNP ._.
7_CD Related_NNP Work_NNP Communication-oriented_JJ models_NNS :_: Communicationbased_JJ primitives_NNS
crawler_NN bears_VBZ similarities_NNS to_TO several_JJ other_JJ systems_NNS ,_, including_VBG streaming_NN and_CC parallel_JJ databases_NNS -LRB-_-LRB- 1_CD ,_, 10_CD ,_, 11_CD ,_, 13_CD ,_, 14_CD ,_, 19_CD -RRB-_-RRB- ,_, publish-subscribe_JJ systems_NNS -LRB-_-LRB- 2_CD ,_, 9_CD ,_, 16_CD ,_, 27_CD ,_, 31_CD -RRB-_-RRB- ,_, search_NN engines_NNS and_CC web_NN crawlers_NNS =_JJ -_: =[_NN 8_CD ,_, 12_CD ,_, 20_CD ,_, 21_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC packet_NN filters_NNS -LRB-_-LRB- 23_CD ,_, 25_CD ,_, 30_CD ,_, 32_CD ,_, 34_CD -RRB-_-RRB- ._.
Our_PRP$ design_NN borrows_VBZ techniques_NNS from_IN each_DT ,_, but_CC we_PRP argue_VBP that_IN the_DT substantial_JJ differences_NNS in_IN the_DT workload_NN ,_, scale_NN ,_, and_CC application_NN requirements_NNS of_IN extensible_JJ cra_NN
be_VB distributed_VBN between_IN domains_NNS without_IN overloading_VBG a_DT specific_JJ server_NN ._.
7_CD http:\/\/code.google.com\/p\/ldspider\/_NN 8_CD ``_`` A_DT pay-level_JJ domain_NN -LRB-_-LRB- PLD_NN -RRB-_-RRB- is_VBZ any_DT domain_NN that_WDT requires_VBZ payment_NN at_IN a_DT TLD_NN or_CC ccTLD_NN registrar_NN ._. ''_''
=_SYM -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: LDSpider_NN :_: A_DT crawling_VBG framework_NN for_IN the_DT Web_NN of_IN Linked_NNP Data_NNP 3_CD LDSpider_NN will_MD fetch_VB URIs_NNS in_IN parallel_NN employing_VBG multiple_JJ threads_NNS ._.
The_DT strategy_NN can_MD be_VB requested_VBN to_TO stay_VB on_IN the_DT domains_NNS of_IN the_DT seed_NN URIs_NNS ._.
Cra_NNP
HTML_NNP screen_NN scraping_VBG are_VBP needed_VBN to_TO obtain_VB large_JJ amounts_NNS of_IN data_NNS from_IN diverse_JJ social_JJ websites_NNS ._.
Web_NN crawling_NN has_VBZ been_VBN an_DT area_NN of_IN active_JJ research_NN for_IN over_IN a_DT decade_NN ,_, and_CC many_JJ crawlers_NNS have_VBP been_VBN developed_VBN =_JJ -_: =[_NN 8_CD ,_, 12_CD ,_, 14_CD ,_, 25_CD ,_, 40_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Compared_VBN with_IN general_JJ websites_NNS and_CC wellstructured_JJ Web_NN forums_NNS ,_, social_JJ websites_NNS pose_VBP several_JJ unique_JJ challenges_NNS for_IN Web_NN crawling_NN :_: Duplicate_NNP Links_NNP :_: Online_JJ social_JJ communities_NNS support_VBP many_JJ types_NNS of_IN social_JJ
sufficiently_RB good_JJ set_NN of_IN Web_NN pages_NNS to_TO index_NN and_CC serve_VB ._.
The_DT crawler_NN then_RB continues_VBZ to_TO recrawl_VB some_DT of_IN these_DT pages_NNS at_IN different_JJ frequencies_NNS in_IN order_NN to_TO maintain_VB the_DT freshness_NN of_IN the_DT document_NN collection_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Copyright_NN is_VBZ held_VBN by_IN the_DT International_NNP World_NNP Wide_NN Web_NN Conference_NN Committee_NN -LRB-_-LRB- IW3C2_NN -RRB-_-RRB- ._.
Distribution_NN of_IN these_DT papers_NNS is_VBZ limited_VBN to_TO classroom_NN use_NN ,_, and_CC personal_JJ use_NN by_IN others_NNS ._.
WWW_NN 2009_CD ,_, April_NNP 20_CD --_: 24_CD ,_, 2009_CD ,_,
graph_NN retrieved_VBD with_IN status_NN code_NN 200_CD OK_JJ after_IN following_VBG redirects_NNS ,_, or_CC that_DT maps_VBZ a_DT URI_NNP to_TO the_DT empty_JJ set_NN in_IN the_DT case_NN of_IN failure_NN ._.
Pay-level_JJ domains\/Data_NN providers_NNS Herein_RB ,_, we_PRP use_VBP pay-level_JJ domains_NNS -LRB-_-LRB- PLDs_NNS -RRB-_-RRB- =_JJ -_: =[_NN 68,30_CD -RRB-_-RRB- -_: =_SYM -_: to_TO distinguish_VB individual_JJ data_NNS providers_NNS ._.
A_DT pay-level_JJ domain_NN is_VBZ a_DT direct_JJ sub-domain_NN of_IN a_DT top-level_JJ domain_NN -LRB-_-LRB- TLD_NN -RRB-_-RRB- or_CC a_DT reserved_JJ second-level_JJ country_NN domain_NN -LRB-_-LRB- ccSLD_NN -RRB-_-RRB- ;_: examples_NNS of_IN PLDs_NNS include_VBP dbpedia.org_NN
of_IN the_DT web_NN ._.
Sometimes_RB a_DT search_NN function_NN to_TO return_VB relevant_JJ pages_NNS to_TO the_DT users_NNS `_`` queries_NNS is_VBZ also_RB provided_VBN ._.
Crawler_NN and_CC search_NN function_NN are_VBP considered_VBN to_TO be_VB the_DT fundamental_JJ components_NNS of_IN a_DT search_NN engine_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC each_DT has_VBZ its_PRP$ own_JJ research_NN challenges_NNS and_CC problems_NNS ._.
Web_NN crawler_NN ,_, also_RB known_VBN as_IN spider_NN or_CC robot_NN ,_, is_VBZ responsible_JJ for_IN fetching_VBG pages_NNS ,_, parsing_VBG hyperlinks_NNS ,_, managing_VBG crawl_NN queue_NN ,_, and_CC indexing_NN contents_NNS
r_NN breadth-first_JJ rounds_NNS ;_: similarly_RB ,_, breadth_NN first_JJ crawling_NN leads_VBZ to_TO a_DT more_RBR diverse_JJ dataset_NN earlier_RBR on_IN ,_, rather_RB than_IN a_DT depth-first_JJ approach_NN which_WDT may_MD end_VB up_RP traversing_VBG deep_JJ paths_NNS within_IN a_DT given_VBN site_NN ._.
In_IN =_JJ -_: =[_NN 88_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT authors_NNS justify_VBP a_DT rounds-based_JJ apAlgorithm_NN 1_CD Algorithm_NN for_IN crawling_VBG Require_NNP :_: Seeds_NNP ,_, Rounds_NNP ,_, Pld-Limit_NNP ,_, MinDelay_NNP 1_CD :_: frontier_NN ←_NNP Seeds_NNP 2_CD :_: pld0_NN ..._: n_NN ←_CD new_JJ queue_NN 3_CD :_: stats_NNS ←_CD new_JJ stats_NNS 4_CD :_: while_IN rounds_NNS +_CC
wled_VBD to_TO five_CD ._.
This_DT conclusion_NN ,_, reached_VBD empirically_RB from_IN user_NN session_NN data_NNS ,_, allows_VBZ a_DT crawler_NN to_TO obtain_VB an_DT even_JJ coverage_NN across_IN websites_NNS and_CC domains_NNS on_IN the_DT rapidly_RB expanding_VBG Web_NN ._.
The_DT IRLBot_NN Web-crawler_NN =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_JJ -_: suggests_VBZ domain-specific_JJ budgets_NNS for_IN the_DT number_NN of_IN pages_NNS crawled_VBD ._.
Restrictions_NNS of_IN this_DT sort_NN ,_, which_WDT could_MD be_VB dependant_JJ on_IN the_DT domain_NN 's_POS reputation_NN ,_, size_NN ,_, etc._NN ,_, ensure_VB the_DT scalability_NN and_CC efficiency_NN of_IN
d_NN to_TO form_VB the_DT basis_NN of_IN a_DT search_NN engine_NN 's_POS index_NN ._.
2.1_CD Evaluating_VBG a_DT crawl_NN There_EX are_VBP multiple_JJ perspectives_NNS on_IN what_WP makes_VBZ a_DT good_JJ crawl_NN or_CC good_JJ crawling_NN software_NN ._.
One_CD is_VBZ efficiency_NN ;_: for_IN example_NN ,_, the_DT IRLbot_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: authors_NNS consider_VBP politeness_NN ,_, queuing_VBG ,_, data_NNS structures_NNS and_CC budgeting_NN issues_NNS to_TO crawl_VB 6_CD billion_CD pages_NNS on_IN a_DT single_JJ machine_NN ._.
We_PRP do_VBP not_RB consider_VB these_DT efficiency_NN issues_NNS ,_, although_IN our_PRP$ experiments_NNS consider_VBP
timize_VB for_IN sharpness_NN while_IN the_DT perfect_JJ consistency_NN is_VBZ a_DT prerequisite_NN in_IN data_NN caching_NN ._.
Crawling_VBG of_IN the_DT Web_NN for_IN the_DT purpose_NN of_IN search_NN engines_NNS received_VBD a_DT lot_NN of_IN attention_NN ._.
Key_NN issues_NNS here_RB are_VBP efficiency_NN =_JJ -_: =[_NN 15_CD ,_, 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, freshness_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, importance_NN -LRB-_-LRB- 18_CD -RRB-_-RRB- ,_, relevance_NN to_TO keyword_VB queries_NNS -LRB-_-LRB- 6_CD ,_, 9_CD ,_, 5_CD ,_, 10_CD -RRB-_-RRB- ._.
Different_JJ weights_NNS of_IN importance_NN are_VBP assigned_VBN to_TO the_DT pages_NNS on_IN the_DT Web_NN and_CC resources_NNS are_VBP reserved_JJ -LRB-_-LRB- frequency_NN of_IN crawls_VBZ ,_, craw_NN
