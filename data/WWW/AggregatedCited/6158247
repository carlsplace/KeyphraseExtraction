Ranking_JJ refinement_NN and_CC its_PRP$ application_NN to_TO information_NN retrieval_NN
We_PRP consider_VBP the_DT problem_NN of_IN ranking_JJ refinement_NN ,_, i.e._FW ,_, to_TO improve_VB the_DT accuracy_NN of_IN an_DT existing_VBG ranking_NN function_NN with_IN a_DT small_JJ set_NN of_IN labeled_JJ instances_NNS ._.
We_PRP are_VBP ,_, particularly_RB ,_, interested_JJ in_IN learning_VBG a_DT better_JJR ranking_NN function_NN using_VBG two_CD complementary_JJ sources_NNS of_IN information_NN ,_, ranking_JJ information_NN given_VBN by_IN the_DT existing_VBG ranking_NN function_NN -LRB-_-LRB- i.e._FW ,_, a_DT base_NN ranker_NN -RRB-_-RRB- and_CC that_IN obtained_VBN from_IN users_NNS '_POS feedbacks_NNS ._.
This_DT problem_NN is_VBZ very_RB important_JJ in_IN information_NN retrieval_NN where_WRB the_DT feedback_NN is_VBZ gradually_RB collected_VBN ._.
The_DT key_JJ challenge_NN in_IN combining_VBG the_DT two_CD sources_NNS of_IN information_NN arises_VBZ from_IN the_DT fact_NN that_IN the_DT ranking_JJ information_NN presented_VBN by_IN the_DT base_NN ranker_NN tends_VBZ to_TO be_VB imperfect_JJ and_CC the_DT ranking_JJ information_NN obtained_VBN from_IN users_NNS '_POS feedbacks_NNS tends_VBZ to_TO be_VB noisy_JJ ._.
We_PRP present_VBP a_DT novel_JJ boosting_VBG framework_NN for_IN ranking_JJ refinement_NN that_WDT can_MD effectively_RB leverage_NN the_DT uses_NNS of_IN the_DT two_CD sources_NNS of_IN information_NN ._.
Our_PRP$ empirical_JJ study_NN shows_VBZ that_IN the_DT proposed_VBN algorithm_NN is_VBZ effective_JJ for_IN ranking_JJ refinement_NN ,_, and_CC furthermore_RB significantly_RB outperforms_VBZ the_DT baseline_NN algorithms_NNS that_WDT incorporate_VBP the_DT outputs_NNS from_IN the_DT base_NN ranker_NN as_IN an_DT additional_JJ feature_NN ._.
existing_VBG models_NNS in_IN constructing_VBG new_JJ models_NNS ._.
A_DT reduction_NN in_IN time_NN complexity_NN leads_VBZ to_TO algorithms_NNS that_WDT run_VBP faster_JJR -LRB-_-LRB- 1_CD ,_, 2_CD -RRB-_-RRB- ._.
The_DT utilization_NN of_IN unlabeled_JJ data_NNS reduces_VBZ the_DT workload_NN for_IN skilled_JJ human_JJ agents_NNS =_JJ -_: =[_NN 3_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT reuse_NN of_IN existing_VBG models_NNS ,_, as_IN in_IN online_JJ learning_NN ,_, leads_VBZ to_TO algorithms_NNS that_WDT work_VBP on_IN smaller_JJR amounts_NNS of_IN data_NNS at_IN a_DT time_NN ._.
-LRB-_-LRB- 4_CD ,_, 5_CD -RRB-_-RRB- ._.
1_CD Research_NN philosophy_NN My_PRP$ approach_NN to_TO research_NN focuses_VBZ on_IN the_DT theoreti_NN
procedures_NNS selects_VBZ the_DT comparator_NN that_WDT obtains_VBZ the_DT best_JJS performance_NN on_IN the_DT validation_NN set_VBN during_IN the_DT learning_NN procedure_NN ._.
The_DT proposed_VBN approach_NN is_VBZ evaluated_VBN using_VBG the_DT LETOR_NN -LRB-_-LRB- LEarning_NN TO_TO Rank_NNP -RRB-_-RRB- dataset_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT is_VBZ a_DT standard_JJ benchmark_NN for_IN the_DT task_NN of_IN learning_VBG to_TO rank_VB ._.
The_DT comparison_NN considers_VBZ several_JJ state-of-the-art_JJ ranking_NN algorithms_NNS ,_, such_JJ as_IN RankSVM_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ,_, RankBoost_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, FRank_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, ListNet_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, and_CC
zation_NN models_NNS ._.
Diaz_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- use_VBP score_NN regularization_NN to_TO adjust_VB ad-hoc_JJ retrieval_NN scores_NNS from_IN an_DT initial_JJ retrieval_NN ._.
But_CC those_DT two_CD methods_NNS do_VBP not_RB consider_VB multiple_JJ relationships_NNS between_IN objects_NNS ._.
Jin_NNP et_FW al._FW =_SYM -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: present_VB a_DT different_JJ approach_NN for_IN ranking_JJ refinement_NN ,_, which_WDT utilize_VBP the_DT base_NN ranker_NN and_CC feedbacks_NNS from_IN users_NNS to_TO learning_VBG a_DT better_JJR ranking_NN function_NN under_IN a_DT supervised_JJ learning_NN framework_NN ._.
We_PRP propose_VBP a_DT d_NN
n_NN 1.0_CD -RRB-_-RRB- ,_, at_IN the_DT beginning_NN of_IN 2007_CD for_IN learning_VBG to_TO rank_VB research_NN ._.
Since_IN then_RB ,_, this_DT dataset_NN has_VBZ been_VBN widely_RB used_VBN in_IN many_JJ learning_NN to_TO rank_VB papers_NNS -LRB-_-LRB- Qin_NNP et_FW al._FW ,_, 2008b_CD ;_: Xia_NNP et_FW al._FW ,_, 2008_CD ;_: Elsas_NNP et_FW al._FW ,_, 2008_CD ;_: =_JJ -_: =_JJ Jin_NNP et_FW al._FW ,_, 2008_CD -_: =_JJ -_: ;_: Yeh_NNP et_FW al._FW ,_, 2007_CD ;_: Xu_NNP et_FW al._FW ,_, 2008a_CD ;_: Guiver_NNP and_CC Snelson_NNP ,_, 2008_CD ;_: Geng_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ._.
LETOR1_NN .0_NN was_VBD used_VBN in_IN SIGIR2007_NN workshop_NN on_IN learning_NN to_TO rank_VB for_IN information_NN retrieval_NN 3_CD ._.
At_IN the_DT end_NN of_IN 2007_CD ,_, we_PRP rel_NN
to_TO online_JJ reviews_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, and_CC demonstrate_VB how_WRB to_TO extract_VB demographic-specific_JJ preferences_NNS ._.
Other_JJ studies_NNS proposed_VBN to_TO combine_VB popularity_NN with_IN user_NN feedback_NN or_CC social_JJ annotations_NNS to_TO refine_VB search_NN results_NNS =_JJ -_: =[_NN 4_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
8_CD ._.
DISCUSSION_NN AND_CC FUTURE_NN WORK_VBP We_PRP presented_VBD a_DT ranking_JJ algorithm_NN that_WDT uses_VBZ a_DT behavioral_JJ model_NN of_IN consumers_NNS ,_, based_VBN on_IN utility_NN maximization_NN ._.
The_DT model_NN generates_VBZ an_DT estimate_NN of_IN how_WRB much_JJ each_DT product_NN char_NN
be_VB to_TO compute_VB a_DT proximity_NN measure_NN from_IN the_DT relevant_JJ nodes_NNS ._.
TrustRank_NN -LRB-_-LRB- -LRB-_-LRB- 8_CD -RRB-_-RRB- -RRB-_-RRB- uses_VBZ personalized_JJ pagerank_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- from_IN the_DT trusted_VBN nodes_NNS to_TO discriminate_VB between_IN good_JJ and_CC spammy_JJ nodes_NNS in_IN the_DT web_NN ._.
Recent_JJ work_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: on_IN ranking_JJ refinement_NN uses_VBZ boosting_VBG to_TO learn_VB the_DT new_JJ ranking_JJ function_NN simultaneously_RB from_IN the_DT base_NN ranking_NN function_NN and_CC the_DT user_NN feedback_NN ._.
The_DT problem_NN with_IN the_DT first_JJ approach_NN is_VBZ that_IN it_PRP does_VBZ not_RB take_VB
TOR_NN benchkmar_NN dataset_NN was_VBD released_VBN in_IN the_DT SIGIR_NN 2007_CD Workshop_NNP on_IN Learning_NNP to_TO Rank_NNP for_IN Information_NNP Retrieval_NNP -LRB-_-LRB- LR4IR_NN 2007_CD -RRB-_-RRB- ._.
Since_IN then_RB ,_, this_DT dataset_NN has_VBZ been_VBN widely_RB used_VBN in_IN many_JJ learning_NN to_TO rank_VB papers_NNS =_JJ -_: =[_NN 16_CD ,_, 21_CD ,_, 4_CD ,_, 10_CD ,_, 25_CD ,_, 23_CD ,_, 7_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Although_IN the_DT release_NN of_IN LETOR_NN has_VBZ greatly_RB speeded_VBN up_RP the_DT research_NN on_IN learning_VBG to_TO rank_VB ,_, we_PRP also_RB notice_VBP several_JJ issues_NNS in_IN it_PRP ._.
To_TO make_VB LETOR_NNP more_RBR useful_JJ and_CC reliable_JJ ,_, in_IN this_DT paper_NN ,_, we_PRP discuss_VBP how_WRB to_TO i_FW
The_DT second_JJ group_NN of_IN algorithms_NNS ,_, the_DT pairwise_JJ approaches_NNS ,_, considers_VBZ the_DT pair_NN of_IN documents_NNS as_IN independent_JJ variables_NNS and_CC learns_VBZ a_DT classification_NN -LRB-_-LRB- regression_NN -RRB-_-RRB- model_NN to_TO correctly_RB order_VB the_DT training_NN pairs_NNS =_JJ -_: =[_NN 5_CD ,_, 6_CD ,_, 7_CD ,_, 8_CD ,_, 9_CD ,_, 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT main_JJ problem_NN with_IN these_DT approaches_NNS is_VBZ that_IN their_PRP$ loss_NN functions_NNS are_VBP related_JJ to_TO individual_JJ documents_NNS while_IN most_JJS evaluation_NN metrics_NNS of_IN information_NN retrieval_NN measure_NN the_DT ranking_JJ quality_NN for_IN individ_NN
