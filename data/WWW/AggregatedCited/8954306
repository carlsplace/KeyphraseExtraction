Boosting_VBG SVM_NN classifiers_NNS by_IN ensemble_NN
By_IN far_RB ,_, the_DT support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- achieve_VBP the_DT state-of-the-art_JJ performance_NN for_IN the_DT text_NN classification_NN -LRB-_-LRB- TC_NN -RRB-_-RRB- tasks_NNS ._.
Due_JJ to_TO the_DT complexity_NN of_IN the_DT TC_NN problems_NNS ,_, it_PRP becomes_VBZ a_DT challenge_NN to_TO systematically_RB develop_VB classifiers_NNS with_IN better_JJR performance_NN ._.
We_PRP try_VBP to_TO attack_VB this_DT problem_NN by_IN ensemble_NN methods_NNS ,_, which_WDT are_VBP often_RB used_VBN for_IN boosting_VBG weak_JJ classifiers_NNS ,_, such_JJ as_IN decision_NN tree_NN ,_, neural_JJ networks_NNS ,_, etc._NN ,_, and_CC whether_IN they_PRP are_VBP effective_JJ for_IN strong_JJ classifiers_NNS is_VBZ not_RB clear_JJ ._.
ly_RB have_VB an_DT effect_NN on_IN performance_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- and_CC so_RB in_IN some_DT comparisons_NNS it_PRP should_MD be_VB kept_VBN in_IN mind_NN that_IN it_PRP is_VBZ not_RB possible_JJ to_TO draw_VB hard_JJ conclusions_NNS ._.
5.3.2_CD Performance_NNP Measures_NNS We_PRP mainly_RB follow_VBP the_DT literature_NN =_JJ -_: =[_NN 15_CD ,_, 13_CD ,_, 63_CD ,_, 13_CD -RRB-_-RRB- -_: =_JJ -_: and_CC use_VB the_DT decision_NN measures_NNS of_IN Precision_NN -LRB-_-LRB- Pr_NN -RRB-_-RRB- ,_, Recall_VB -LRB-_-LRB- Re_NNP -RRB-_-RRB- ,_, the_DT F1_NN measure_NN which_WDT combines_VBZ the_DT two_CD ,_, and_CC the_DT `_`` breakeven_NN '_'' point_NN where_WRB precision_NN equals_VBZ recall_NN ._.
Additionally_RB ,_, when_WRB dealing_VBG with_IN multiple_JJ
