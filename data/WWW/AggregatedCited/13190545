Unified_JJ analysis_NN of_IN streaming_NN news_NN
News_NN clustering_NN ,_, categorization_NN and_CC analysis_NN are_VBP key_JJ components_NNS of_IN any_DT news_NN portal_NN ._.
They_PRP require_VBP algorithms_NNS capable_JJ of_IN dealing_VBG with_IN dynamic_JJ data_NNS to_TO cluster_VB ,_, interpret_VB and_CC to_TO temporally_RB aggregate_JJ news_NN articles_NNS ._.
These_DT three_CD tasks_NNS are_VBP often_RB solved_VBN separately_RB ._.
In_IN this_DT paper_NN we_PRP present_VBP a_DT unified_JJ framework_NN to_TO group_NN incoming_JJ news_NN articles_NNS into_IN temporary_JJ but_CC tightly-focused_JJ storylines_NNS ,_, to_TO identify_VB prevalent_JJ topics_NNS and_CC key_JJ entities_NNS within_IN these_DT stories_NNS ,_, and_CC to_TO reveal_VB the_DT temporal_JJ structure_NN of_IN stories_NNS as_IN they_PRP evolve_VBP ._.
We_PRP achieve_VBP this_DT by_IN building_VBG a_DT hybrid_NN clustering_NN and_CC topic_NN model_NN ._.
To_TO deal_VB with_IN the_DT available_JJ wealth_NN of_IN data_NNS we_PRP build_VBP an_DT efficient_JJ parallel_JJ inference_NN algorithm_NN by_IN sequential_JJ Monte_NNP Carlo_NNP estimation_NN ._.
Time_NN and_CC memory_NN costs_NNS are_VBP nearly_RB constant_JJ in_IN the_DT length_NN of_IN the_DT history_NN ,_, and_CC the_DT approach_NN scales_NNS to_TO hundreds_NNS of_IN thousands_NNS of_IN documents_NNS ._.
We_PRP demonstrate_VBP the_DT efficiency_NN and_CC accuracy_NN on_IN the_DT publicly_RB available_JJ TDT_NN dataset_NN and_CC data_NNS of_IN a_DT major_JJ internet_NN news_NN site_NN ._.
ritance_NN tree_NN by_IN placing_VBG each_DT particle_NN at_IN a_DT leaf_NN ,_, while_IN storing_VBG common_JJ information_NN in_IN the_DT internal_JJ nodes_NNS ._.
This_DT makes_VBZ particle_NN writes_VBZ thread-safe_JJ ,_, since_IN no_DT particle_NN is_VBZ ever_RB an_DT ancestor_NN of_IN another_DT -LRB-_-LRB- see_VB -LRB-_-LRB- =_JJ -_: =_JJ Ahmed_NNP et_FW al._FW 2011_CD -_: =--RRB-_NN for_IN more_JJR details_NNS -RRB-_-RRB- ._.
Extended_VBN inheritance_NN trees_NNS Parts_NNS of_IN our_PRP$ algorithm_NN require_VBP storage_NN of_IN sets_NNS of_IN objects_NNS ._.
For_IN example_NN ,_, our_PRP$ story_NN sampling_NN equation_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- needs_VBZ the_DT set_NN of_IN stories_NNS associated_VBN with_IN each_DT na_TO
pired_VBN by_IN -LRB-_-LRB- 6_CD -RRB-_-RRB- ._.
Before_IN we_PRP measure_VBP the_DT coverage_NN of_IN an_DT entire_JJ map_NN ,_, we_PRP consider_VBP the_DT coverage_NN of_IN a_DT single_JJ document_NN ._.
As_IN in_IN the_DT previous_JJ section_NN ,_, documents_NNS are_VBP feature_NN vectors_NNS ._.
Let_VB function_NN coverdi_NN -LRB-_-LRB- w_NN -RRB-_-RRB- :_: W_NN →_NN =_JJ -_: =[_NN 0_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: quantify_VB the_DT amount_NN that_WDT document_VBP di_FW covers_VBZ feature_NN w._NN For_IN example_NN ,_, if_IN W_NN is_VBZ a_DT set_NN of_IN words_NNS ,_, we_PRP can_MD define_VB cover_NN ·_NN -LRB-_-LRB- ·_NN -RRB-_-RRB- as_IN tf-idf_JJ values_NNS ._.
Next_RB ,_, we_PRP extend_VBP cover_NN ·_NN -LRB-_-LRB- ·_NN -RRB-_-RRB- to_TO maps_NNS ._.
Since_IN in_IN our_PRP$ model_NN coverage_NN do_VBP
haf_NN and_CC Guestrin_NN -LRB-_-LRB- 35_CD -RRB-_-RRB- essentially_RB detect_VB a_DT whole_JJ causality_NN chain_NN --_: given_VBN two_CD news_NN articles_NNS ,_, they_PRP provide_VBP a_DT coherent_JJ small_JJ number_NN of_IN news_NN items_NNS connecting_VBG them_PRP ._.
Similarly_RB ,_, some_DT works_NNS in_IN topic_NN tracking_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: ,_, try_VB to_TO identify_VB coherent_JJ story_NN lines_NNS from_IN news_NN ._.
More_RBR recently_RB ,_, some_DT works_NNS -LRB-_-LRB- 16_CD ,_, 16_CD ,_, 29_CD -RRB-_-RRB- have_VBP explored_VBN the_DT usage_NN of_IN large_JJ text_NN mining_NN techniques_NNS ,_, applied_VBN on_IN temporal_JJ corpus_NN ,_, such_JJ as_IN news_NN and_CC books_NNS ._.
Th_NN
