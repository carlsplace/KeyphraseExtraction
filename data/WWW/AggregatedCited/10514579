Detecting_VBG Wikipedia_NNP vandalism_NN with_IN active_JJ learning_NN and_CC statistical_JJ language_NN models_NNS
This_DT paper_NN proposes_VBZ an_DT active_JJ learning_NN approach_NN using_VBG language_NN model_NN statistics_NNS to_TO detect_VB Wikipedia_NNP vandalism_NN ._.
Wikipedia_NNP is_VBZ a_DT popular_JJ and_CC influential_JJ collaborative_JJ information_NN system_NN ._.
The_DT collaborative_JJ nature_NN of_IN authoring_NN ,_, as_RB well_RB as_IN the_DT high_JJ visibility_NN of_IN its_PRP$ content_NN ,_, have_VBP exposed_VBN Wikipedia_NNP articles_NNS to_TO vandalism_NN ._.
Vandalism_NNP is_VBZ defined_VBN as_IN malicious_JJ editing_NN intended_VBN to_TO compromise_VB the_DT integrity_NN of_IN the_DT content_NN of_IN articles_NNS ._.
Extensive_JJ manual_JJ efforts_NNS are_VBP being_VBG made_VBN to_TO combat_VB vandalism_NN and_CC an_DT automated_JJ approach_NN to_TO alleviate_VB the_DT laborious_JJ process_NN is_VBZ needed_VBN ._.
This_DT paper_NN builds_VBZ statistical_JJ language_NN models_NNS ,_, constructing_VBG distributions_NNS of_IN words_NNS from_IN the_DT revision_NN history_NN of_IN Wikipedia_NNP articles_NNS ._.
As_IN vandalism_NN often_RB involves_VBZ the_DT use_NN of_IN unexpected_JJ words_NNS to_TO draw_VB attention_NN ,_, the_DT fitness_NN -LRB-_-LRB- or_CC lack_NN thereof_RB -RRB-_-RRB- of_IN a_DT new_JJ edit_NN when_WRB compared_VBN with_IN language_NN models_NNS built_VBN from_IN previous_JJ versions_NNS may_MD well_RB indicate_VB that_IN an_DT edit_NN is_VBZ a_DT vandalism_NN instance_NN ._.
In_IN addition_NN ,_, the_DT paper_NN adopts_VBZ an_DT active_JJ learning_NN model_NN to_TO solve_VB the_DT problem_NN of_IN noisy_JJ and_CC incomplete_JJ labeling_NN of_IN Wikipedia_NNP vandalism_NN ._.
The_DT Wikipedia_NNP domain_NN with_IN its_PRP$ revision_NN histories_NNS offers_VBZ a_DT novel_JJ context_NN in_IN which_WDT to_TO explore_VB the_DT potential_NN of_IN language_NN models_NNS in_IN characterizing_VBG author_NN intention_NN ._.
As_IN the_DT experimental_JJ results_NNS presented_VBN in_IN the_DT paper_NN demonstrate_VBP ,_, these_DT models_NNS hold_VBP promise_NN for_IN vandalism_NN detection_NN ._.
t_NN we_PRP do_VBP not_RB concern_VB ourselves_PRP with_IN the_DT delimitation_NN of_IN the_DT concept_NN and_CC work_NN with_IN corpora_NN annotated_JJ by_IN humans_NNS ,_, who_WP judge_VBP on_IN a_DT case-by-case_JJ basis_NN ,_, as_IN our_PRP$ ground_NN truth_NN ._.
There_EX are_VBP many_JJ kinds_NNS of_IN vandalism_NN =_JJ -_: =[_NN 21_CD ,_, 18_CD ,_, 7_CD ,_, 23_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Wikipedia_NNP contributors_NNS identify_VBP 20_CD categories_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, of_IN which_WDT we_PRP consider_VBP the_DT following_JJ 4_CD :_: Blanking_NNP Removing_NNP all_DT or_CC significant_JJ parts_NNS of_IN a_DT page_NN 's_POS content_NN ._.
Edit_VB summary_NN vandalism_NN Making_VBG offensive_JJ edi_NN
sion_NN history_NN data_NNS also_RB constitutes_VBZ a_DT novel_JJ knowledge_NN source_NN for_IN NLP_NNP algorithms_NNS ._.
The_DT sequence_NN of_IN article_NN edits_NNS can_MD be_VB used_VBN as_IN training_NN data_NNS for_IN data-driven_JJ NLP_NNP algorithms_NNS ,_, such_JJ as_IN vandalism_NN detection_NN -LRB-_-LRB- =_JJ -_: =_JJ Chin_NNP et_FW al._FW ,_, 2010_CD -_: =--RRB-_NN ,_, text_NN summarization_NN -LRB-_-LRB- Nelken_NNP and_CC Yamangil_NNP ,_, 2008_CD -RRB-_-RRB- ,_, sentence_NN compression_NN -LRB-_-LRB- Yamangil_NNP and_CC Nelken_NNP ,_, 2008_CD -RRB-_-RRB- ,_, unsupervised_JJ extraction_NN of_IN lexical_JJ simplifications_NNS -LRB-_-LRB- Yatskar_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- ,_, the_DT expansion_NN of_IN textual_NN
re_IN set_NN based_VBN on_IN metadata_NN and_CC contentlevel_NN properties_NNS and_CC built_VBD a_DT classifier_NN using_VBG logistic_JJ regression_NN ._.
Smets_FW et_FW al._FW -LRB-_-LRB- 16_CD -RRB-_-RRB- used_VBD Naïve_NNP Bayes_NNP applied_VBD to_TO a_DT bag-of-words_JJ model_NN of_IN the_DT edit_NN text_NN ._.
Chin_NNP et_FW al._FW =_SYM -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: delve_VB deeper_JJR into_IN the_DT field_NN of_IN natural_JJ language_NN processing_NN by_IN constructing_VBG statistical_JJ language_NN models_NNS of_IN an_DT article_NN from_IN its_PRP$ revision_NN history_NN ._.
A_DT different_JJ way_NN of_IN looking_VBG at_IN edit_NN content_NN is_VBZ the_DT intui_NN
ve_IN nature_NN of_IN n-gram_NN analysis_NN ._.
One_CD of_IN the_DT first_JJ was_VBD Smets_NNP et_FW al._FW -LRB-_-LRB- 57_CD -RRB-_-RRB- ,_, utilizing_VBG Bayesian_JJ analysis_NN -LRB-_-LRB- initially_RB shown_VBN useful_JJ in_IN email_JJ spam_NN detection_NN -LRB-_-LRB- 55_CD -RRB-_-RRB- -RRB-_-RRB- and_CC Probabilistic_JJ Sequence_NN Modeling_NN ._.
Similarly_RB ,_, =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_SYM -_: used_VBD a_DT generic_JJ predictive_JJ analysis_NN ,_, while_IN Itakure_NNP et_FW al._FW -LRB-_-LRB- 34_CD -RRB-_-RRB- leveraged_JJ dynamic_NN Markov_NNP com13Expected_NNP DIFF_NNP -LRB-_-LRB- Topic-specific_JJ corpus_NN -RRB-_-RRB- !_.
Warning_NN !_.
Unigrams_NNPS +_CC +_CC +_CC ..._: Mr._NNP Web_NN results_VBZ for_IN ``_`` jet_NN ''_'' is_VBZ Franklin_NNP ,_, Am_NNP
re_IN set_NN based_VBN on_IN metadata_NN and_CC contentlevel_NN properties_NNS and_CC built_VBD a_DT classifier_NN using_VBG logistic_JJ regression_NN ._.
Smets_FW et_FW al._FW -LRB-_-LRB- 16_CD -RRB-_-RRB- used_VBD Naïve_NNP Bayes_NNP applied_VBD to_TO a_DT bag-of-words_JJ model_NN of_IN the_DT edit_NN text_NN ._.
Chin_NNP et_FW al._FW =_SYM -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: delve_VB deeper_JJR into_IN the_DT field_NN of_IN natural_JJ language_NN processing_NN by_IN constructing_VBG statistical_JJ language_NN models_NNS of_IN an_DT article_NN from_IN its_PRP$ revision_NN history_NN ._.
A_DT different_JJ way_NN of_IN looking_VBG at_IN edit_NN content_NN is_VBZ the_DT intui_NN
