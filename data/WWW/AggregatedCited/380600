Query-free_JJ news_NN search_NN
Many_JJ daily_JJ activities_NNS present_VBP information_NN in_IN the_DT form_NN of_IN a_DT stream_NN of_IN text_NN ,_, and_CC often_RB people_NNS can_MD benefit_VB from_IN additional_JJ information_NN on_IN the_DT topic_NN discussed_VBN ._.
TV_NN broadcast_NN news_NN can_MD be_VB treated_VBN as_IN one_CD such_JJ stream_NN of_IN text_NN ;_: in_IN this_DT paper_NN we_PRP discuss_VBP finding_VBG news_NN articles_NNS on_IN the_DT web_NN that_WDT are_VBP relevant_JJ to_TO news_NN currently_RB being_VBG broadcast_VBN ._.
We_PRP evaluated_VBD a_DT variety_NN of_IN algorithms_NNS for_IN this_DT problem_NN ,_, looking_VBG at_IN the_DT impact_NN of_IN inverse_JJ document_NN frequency_NN ,_, stemming_VBG ,_, compounds_NNS ,_, history_NN ,_, and_CC query_NN length_NN on_IN the_DT relevance_NN and_CC coverage_NN of_IN news_NN articles_NNS returned_VBD in_IN real_JJ time_NN during_IN a_DT broadcast_NN ._.
We_PRP also_RB evaluated_VBD several_JJ postprocessing_VBG techniques_NNS for_IN improving_VBG the_DT precision_NN ,_, including_VBG reranking_NN using_VBG additional_JJ terms_NNS ,_, reranking_VBG by_IN document_NN similarity_NN ,_, and_CC filtering_VBG on_IN document_NN similarity_NN ._.
For_IN the_DT best_JJS algorithm_NN ,_, 84_CD %_NN -91_CD %_NN of_IN the_DT articles_NNS found_VBN were_VBD relevant_JJ ,_, with_IN at_IN least_JJS 64_CD %_NN of_IN the_DT articles_NNS being_VBG on_IN the_DT exact_JJ topic_NN of_IN the_DT broadcast_NN ._.
In_IN addition_NN ,_, a_DT relevant_JJ article_NN was_VBD found_VBN for_IN at_IN least_JJS 70_CD %_NN of_IN the_DT topics_NNS ._.
ferences_NNS ._.
These_DT inferences_NNS can_MD be_VB used_VBN to_TO flag_NN anonymous_JJ documents_NNS whose_WP$ author_NN may_MD be_VB re-identified_JJ or_CC documents_NNS that_WDT are_VBP at_IN risk_NN to_TO be_VB -LRB-_-LRB- unintentionally_RB -RRB-_-RRB- linked_VBN to_TO sensitive_JJ topics_NNS ._.
Henzinger_NNP et_FW al._FW =_SYM -_: =-LRB-_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: provide_VB related_JJ web_NN pages_NNS to_TO TV_NN news_NN broadcasts_NNS using_VBG a_DT 2-term_JJ summary_NN -LRB-_-LRB- which_WDT again_RB can_MD be_VB thought_VBN of_IN as_IN a_DT LS_NN -RRB-_-RRB- ._.
This_DT summary_NN is_VBZ extracted_VBN from_IN closed_JJ captions_NNS and_CC various_JJ algorithms_NNS are_VBP used_VBN to_TO compu_VB
in_IN -_: and_CC out-links_NNS ._.
However_RB ,_, the_DT problem_NN of_IN off-topic_JJ links_NNS is_VBZ not_RB particularly_RB addressed_VBN in_IN this_DT work_NN which_WDT is_VBZ an_DT issue_NN we_PRP will_MD discuss_VB in_IN this_DT dissertation_NN work_NN ._.
The_DT work_NN done_VBN by_IN Henzinger_NNP et_FW al._FW in_IN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ also_RB related_JJ to_TO this_DT dissertation_NN ._.
They_PRP use_VBP the_DT closed_JJ captions_NNS from_IN a_DT news_NN broadcast_NN on_IN TV_NN to_TO automatically_RB extract_VB the_DT two_CD most_RBS significant_JJ terms_NNS ._.
These_DT terms_NNS form_VBP a_DT query_NN which_WDT is_VBZ issued_VBN to_TO a_DT n_NN
ows_NN users_NNS to_TO formulate_VB queries_NNS and_CC disambiguates_VBZ them_PRP using_VBG the_DT terms_NNS that_WDT were_VBD selected_VBN automatically_RB ._.
Another_DT query-free_JJ system_NN was_VBD designed_VBN for_IN enriching_VBG television_NN news_NN with_IN articles_NNS from_IN the_DT Web_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT system_NN annotates_VBZ TV_NN broadcast_NN news_NN ,_, using_VBG queries_NNS derived_VBN from_IN closed_VBN captioning_VBG text_NN ,_, with_IN links_NNS to_TO potentially_RB relevant_JJ news_NN wire_NN from_IN the_DT Web_NN ._.
More_RBR recently_RB ,_, many_JJ speechbased_JJ search_NN engines_NNS -LRB-_-LRB-
the_DT user_NN 's_POS information_NN needs_VBZ in_IN a_DT complex_JJ environment_NN becomes_VBZ an_DT important_JJ problem_NN ._.
There_EX is_VBZ much_JJ prior_JJ research_NN on_IN news_NN customization_NN -LRB-_-LRB- Lang_NNP ,_, 1995_CD -RRB-_-RRB- -LRB-_-LRB- Ardissono_NNP et_FW al._FW ,_, 2001_CD -RRB-_-RRB- -LRB-_-LRB- Domingue_NNP &_CC Scott_NNP ,_, 1998_CD -RRB-_-RRB- -LRB-_-LRB- =_JJ -_: =_JJ Henzinger_NNP et_FW al._FW ,_, 2003_CD -_: =--RRB-_NN -LRB-_-LRB- Carreira_NNP et_FW al._FW ,_, 2004_CD -RRB-_-RRB- -LRB-_-LRB- Lai_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- -LRB-_-LRB- Merialdo_NNP et_FW al._FW ,_, 1999_CD -RRB-_-RRB- ._.
-LRB-_-LRB- Billsus_NNP &_CC Pazzani_NNP ,_, 1999_CD -RRB-_-RRB- built_VBD a_DT personal_JJ news_NN agent_NN that_WDT used_VBD time-coded_JJ feedback_NN from_IN the_DT user_NN to_TO learn_VB a_DT user_NN profile_NN ._.
However_RB
cally_RB extract_NN queries_NNS from_IN the_DT input_NN text_NN ._.
Such_JJ combinations_NNS carry_VBP a_DT valuable_JJ amount_NN of_IN information_NN for_IN the_DT given_VBN text_NN and_CC comprise_VBP the_DT building_NN blocks_NNS for_IN relevant_JJ query_NN formulation_NN ._.
The_DT approach_NN of_IN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: encompasses_VBZ tools_NNS that_WDT automatically_RB infer_VBP the_DT contextual_JJ information_NN in_IN order_NN to_TO improve_VB the_DT user_NN experience_NN with_IN relevant_JJ content_NN ._.
To_TO this_DT end_NN ,_, queries_VBZ Figure_NNP 1_CD :_: System_NN overview_NN ._.
are_VBP extracted_VBN from_IN
enues_NNS from_IN the_DT library_NN records_NNS and_CC use_VB them_PRP as_IN search_NN engine_NN queries_NNS in_IN order_NN to_TO obtain_VB resources_NNS that_WDT are_VBP not_RB held_VBN in_IN the_DT digital_JJ library_NN ._.
2.2_CD Search_VB Engine_NNP Queries_NNPS The_DT work_NN done_VBN by_IN Henzinger_NNP et_FW al._FW =_SYM -_: =[_NN 15_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ related_VBN in_IN the_DT sense_NN that_IN they_PRP tried_VBD to_TO determine_VB the_DT ``_`` aboutness_NN ''_'' of_IN news_NN documentations_NNS ._.
They_PRP provide_VBP the_DT user_NN with_IN web_NN pages_NNS related_VBN to_TO TV_NN news_NN broadcasts_NNS using_VBG a_DT 2-term_JJ summary_NN which_WDT can_MD be_VB tho_NN
._.
While_IN the_DT authors_NNS find_VBP that_IN various_JJ structural_JJ elements_NNS of_IN web_NN pages_NNS change_VBP with_IN different_JJ rates_NNS they_PRP do_VBP not_RB specifically_RB mention_VB titles_NNS ._.
2.3_CD Search_VB Engine_NNP Queries_NNPS The_DT work_NN done_VBN by_IN Henzinger_NNP et_FW al._FW =_SYM -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ related_VBN in_IN the_DT sense_NN that_IN they_PRP tried_VBD to_TO determine_VB the_DT ``_`` aboutness_NN ''_'' of_IN news_NN documentations_NNS ._.
They_PRP provide_VBP the_DT user_NN with_IN web_NN pages_NNS related_VBN to_TO TV_NN news_NN broadcasts_NNS using_VBG a_DT 2-term_JJ summary_NN which_WDT can_MD be_VB tho_NN
n_NN that_IN of_IN traditional_JJ NER_NN systems_NNS ._.
Closely_RB related_JJ to_TO our_PRP$ work_NN are_VBP the_DT keyphrase_NN extraction_NN algorithms_NNS where_WRB the_DT goal_NN is_VBZ to_TO find_VB the_DT most_RBS distinctive_JJ or_CC representative_JJ terms_NNS in_IN text_NN -LRB-_-LRB- 27_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 28_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 29_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 31_CD -RRB-_-RRB- ._.
However_RB ,_, the_DT problem_NN setup_NN in_IN these_DT studies_NNS is_VBZ rather_RB different_JJ :_: the_DT keyphrases_NNS are_VBP extracted_VBN from_IN the_DT body_NN of_IN the_DT input_NN document_NN without_IN using_VBG a_DT predefined_JJ list_NN ._.
In_IN our_PRP$ case_NN ,_, we_PRP use_VBP a_DT large_JJ c_NN
find_VB personal_JJ homepages_NNS ._.
Other_JJ examples_NNS of_IN specialized_JJ metasearch_NN engines_NNS include_VBP one_CD that_WDT specializes_VBZ in_IN the_DT topic_NN of_IN nanotechnology_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- ,_, one_CD that_WDT finds_VBZ news_NN articles_NNS related_VBN to_TO closed-caption_JJ text_NN =_JJ -_: =[_NN 39_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC the_DT buying_NN guide_NN finder_NN -LRB-_-LRB- 53_CD -RRB-_-RRB- that_IN we_PRP describe_VBP in_IN depth_NN in_IN Chapter_NN 3_CD ._.
While_IN from_IN an_DT economical_JJ perspective_NN it_PRP seems_VBZ to_TO be_VB compelling_JJ to_TO use_VB metasearch_NN to_TO build_VB specialized_JJ search_NN solutions_NNS -LRB-_-LRB- e.g._FW ,_,
ation_NN is_VBZ an_DT important_JJ technique_NN in_IN information_NN retrieval_NN and_CC natural_JJ language_NN processing_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- ._.
It_PRP is_VBZ widely_RB used_VBN to_TO generate_VB a_DT corpus_NN or_CC expand_VB an_DT existing_VBG corpus_NN for_IN a_DT given_VBN concept_NN -LRB-_-LRB- see_VB for_IN example_NN ,_, =_JJ -_: =[_NN 53_CD ,_, 20_CD ,_, 56_CD ,_, 23_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
It_PRP is_VBZ also_RB used_VBN for_IN generating_VBG topic_NN hierarchies_NNS in_IN question_NN answering_NN -LRB-_-LRB- see_VB for_IN example_NN ,_, -LRB-_-LRB- 35_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Many_JJ query_NN generation_NN methods_NNS work_VBP by_IN selecting_VBG a_DT few_JJ representative_JJ words_NNS or_CC key_JJ words_NNS from_IN a_DT small_JJ
ecifically_RB ,_, these_DT approaches_NNS aims_VBZ at_IN enriching_VBG traditional_JJ TV_NN broadcasts_NNS with_IN semantic_JJ metadata_NN derived_VBN from_IN non-traditional_JJ information_NN sources_NNS as_IN the_DT Internet_NNP ._.
Similarly_RB to_TO our_PRP$ work_NN ,_, the_DT authors_NNS in_IN =_JJ -_: =[_NN 3_CD ,_, 10_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: address_VB the_DT problem_NN of_IN finding_VBG news_NN articles_NNS on_IN the_DT Web_NN relevant_JJ to_TO the_DT ongoing_JJ stream_NN of_IN TV_NN broadcast_NN news_NN ._.
2.2_CD Topic_NN Detection_NN and_CC Tracking_VBG Additional_JJ works_NNS particularly_RB relevant_JJ to_TO our_PRP$ application_NN
the_DT best_JJS results_NNS for_IN rediscovering_VBG that_DT page_NN ._.
Five_CD terms_NNS did_VBD best_JJS at_IN finding_VBG the_DT URI_NNP as_IN the_DT top_JJ result_NN ,_, whereas_IN seven_CD terms_NNS performed_VBN best_RB at_IN finding_VBG the_DT URI_NNP in_IN the_DT top_JJ ten_CD results_NNS ._.
Henzinger_NNP et_FW al._FW =_SYM -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: used_VBN lexical_JJ signatures_NNS derived_VBN from_IN newscast_NN transcripts_NNS to_TO find_VB articles_NNS related_VBN to_TO the_DT newscast_NN in_IN real-time_JJ ._.
Their_PRP$ input_NN ,_, rather_RB than_IN being_VBG a_DT static_JJ web_NN page_NN ,_, was_VBD a_DT constantly-flowing_JJ stream_NN of_IN t_NN
compute_VB document_NN frequencies_NNS ._.
To_TO overcome_VB this_DT ,_, the_DT search_NN engine_NN is_VBZ queried_VBN with_IN each_DT individual_JJ term_NN and_CC the_DT engine_NN 's_POS estimate_NN of_IN the_DT number_NN of_IN resultsisusedasaproxyforthetruedocumentfrequency_NN ,_, e.g._FW =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Thisisnot_IN the_DT true_JJ document_NN frequency_NN because_IN it_PRP fails_VBZ to_TO count_VB multiple_JJ occurrences_NNS of_IN the_DT term_NN in_IN the_DT same_JJ document_NN ,_, and_CC it_PRP fails_VBZ to_TO eliminate_VB double-counting_NN that_WDT results_VBZ from_IN indexing_NN duplicate_VBP c_NN
am_VB of_IN text_NN ''_'' information_NN such_JJ as_IN news_NN and_CC TV_NN broadcasts_NNS ._.
Such_JJ dynamic_JJ content_NN creates_VBZ challenges_NNS that_WDT need_VBP tailored_VBN solutions_NNS ._.
One_CD example_NN is_VBZ the_DT query-free_JJ news_NN search_NN proposed_VBN by_IN Google_NNP engineers_NNS in_IN =_JJ -_: =[_NN 64_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ related_JJ to_TO the_DT algorithmic_JJ challenge_NN of_IN using_VBG changes_NNS in_IN data_NNS streams_NNS to_TO locate_VB interesting_JJ trends_NNS ,_, a_DT challenge_NN identified_VBN by_IN Monika_NNP Henzinger_NNP in_IN her_PRP$ 2003_CD paper_NN ,_, ``_`` Algorithmic_JJ Challenges_NNS in_IN W_NN
ortant_JJ topics_NNS from_IN that_DT ._.
With_IN these_DT extracted_VBN topics_NNS ,_, the_DT system_NN starts_VBZ a_DT Google_NNP search_NN to_TO find_VB news_NN stories_NNS on_IN the_DT web_NN that_WDT cover_VBP the_DT same_JJ topic_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- ._.
Google_NNP did_VBD exactly_RB the_DT same_JJ in_IN a_DT research_NN project_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: to_TO enhance_VB American_JJ TV_NN news_NN with_IN background_NN information_NN from_IN the_DT Internet_NN :_: They_PRP extract_VBP important_JJ topics_NNS from_IN the_DT subtitle_NN channel_NN that_WDT is_VBZ broadcasted_VBN with_IN every_DT news_NN show_NN and_CC give_VB consumers_NNS the_DT poss_NN
ur_NN main_JJ inspiration_NN came_VBD from_IN Web_NN search_NN engines_NNS like_IN Google_NNP or_CC Fireball_NNP ._.
Even_RB with_IN all_PDT those_DT irrelevant_JJ pages_NNS around_IN the_DT Web_NN ,_, they_PRP manage_VBP to_TO create_VB very_RB valuable_JJ results_NNS for_IN a_DT large_JJ range_NN of_IN queries_NNS =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Our_PRP$ task_NN was_VBD not_RB much_RB different_JJ ._.
We_PRP developed_VBD a_DT search_NN engine_NN for_IN Web_NN services_NNS where_WRB developers_NNS are_VBP able_JJ to_TO find_VB what_WP they_PRP need_VBP for_IN their_PRP$ applications_NNS amongst_IN the_DT available_JJ repository_NN ,_, even_RB if_IN the_DT r_NN
b_NN queries_NNS when_WRB related_JJ news_NN is_VBZ found_VBN in_IN a_DT small_JJ database_NN of_IN current_JJ articles_NNS ._.
Henzinger_NNP ,_, et_NNP ._.
al_NNP study_VBD the_DT task_NN of_IN finding_VBG current_JJ news_NN articles_NNS that_WDT supplement_VBP topics_NNS in_IN a_DT stream_NN of_IN TV_NN broadcast_NN news_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
They_PRP automatically_RB generate_VBP queries_NNS based_VBN on_IN the_DT broadcast_NN and_CC filter_NN result_NN sets_NNS using_VBG score_NN thresholds_NNS to_TO optimize_VB precision_NN and_CC recall_NN of_IN ranked_VBN search_NN results_NNS ,_, also_RB independently_RB evaluating_VBG thre_NN
the_DT accuracy_NN of_IN these_DT systems_NNS ._.
Reis_NNP et_FW al._FW -LRB-_-LRB- 27_CD -RRB-_-RRB- clustered_VBN pages_NNS by_IN layout_NN features_NNS to_TO attempt_VB to_TO distinguish_VB between_IN ``_`` section_NN pages_NNS ''_'' and_CC article_NN pages_NNS to_TO facilitate_VB news_NN extraction_NN ._.
Henzinger_NNP et_FW al._FW =_SYM -_: =[_NN 15_CD -RRB-_-RRB- -_: =_SYM -_: described_VBD a_DT system_NN that_WDT suggests_VBZ news_NN articles_NNS on_IN the_DT web_NN based_VBN on_IN broadcast_NN news_NN ._.
It_PRP is_VBZ evident_JJ that_IN classification_NN of_IN a_DT webpage_NN as_IN an_DT article_NN would_MD aid_VB this_DT methodology_NN ._.
While_IN the_DT webpage_NN modificat_NN
r_NN more_RBR challenging_JJ :_: optimizations_NNS are_VBP possible_JJ ,_, but_CC would_MD need_VB to_TO be_VB an_DT area_NN of_IN additional_JJ research_NN ._.
In_IN contrast_NN ,_, our_PRP$ methods_NNS are_VBP directly_RB applicable_JJ today_NN ._.
4.5_CD News_NNP Query_NNP Extraction_NNP Henzinger_NNP et_FW al._FW =_SYM -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: explored_VBD the_DT domain_NN of_IN keyword_JJ extraction_NN from_IN a_DT news_NN source_NN ,_, to_TO automatically_RB drive_VB queries_NNS ._.
In_IN particular_JJ ,_, they_PRP extracted_VBD query_NN terms_NNS from_IN the_DT closed_JJ captioning_NN of_IN television_NN news_NN stories_NNS ,_, to_TO drive_VB
inement_NN of_IN future_JJ searches_NNS ._.
Another_DT area_NN of_IN learning_NN is_VBZ focused_VBN on_IN context_NN learning_NN -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 15_CD ,_, 2_CD -RRB-_-RRB- -RRB-_-RRB- based_VBN on_IN judged_VBN relevant_JJ documents_NNS ,_, query_NN terms_NNS ,_, document_NN vectors_NNS ,_, etc._FW ``_`` Context_NNP as_IN a_DT query_NN ''_'' -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 16_CD ,_, 23_CD ,_, 6_CD ,_, 8_CD ,_, 4_CD -RRB-_-RRB- -_: =--RRB-_NN treats_VBZ the_DT context_NN as_IN a_DT background_NN for_IN topic_NN specific_JJ search_NN and_CC extracts_VBZ the_DT query_NN representing_VBG the_DT context_NN and_CC therefore_RB ,_, the_DT task_NN at_IN hand_NN ._.
Some_DT recent_JJ contextual_JJ search_NN tools_NNS -LRB-_-LRB- e.g._FW ,_, Y_NN !_.
Q_NNP -LRB-_-LRB- 18_CD -RRB-_-RRB- -LRB-_-LRB- htt_NN
goal_NN -RRB-_-RRB- ,_, we_PRP 're_VBP done_VBN ,_, otherwise_RB continue_VBP ;_: As_IN the_DT above_JJ pseudocode_NN suggests_VBZ ,_, we_PRP have_VBP found_VBN that_IN filtering_VBG the_DT output_NN using_VBG a_DT genre_NN screener_NN yields_VBZ higher-quality_JJ results_NNS -LRB-_-LRB- this_DT finding_NN is_VBZ in_IN keeping_VBG with_IN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Genre_NN screening_NN is_VBZ based_VBN on_IN term_NN vectors_NNS ._.
We_PRP combine_VBP terms_NNS associated_VBN with_IN a_DT result_NN --_: including_VBG its_PRP$ title_NN terms_NNS ,_, URL_NN ,_, and_CC ``_`` snippet_NN ''_'' terms_NNS --_: into_IN a_DT result_NN term_NN vector_NN which_WDT we_PRP then_RB compare_VBP against_IN
mation_NN need_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- ._.
To_TO make_VB PIRA_NNP more_RBR receptive_JJ to_TO the_DT appearance_NN of_IN new_JJ ideas_NNS and_CC arguments_NNS in_IN the_DT paper_NN ,_, we_PRP adopted_VBD a_DT query_JJ term_NN aging_NN mechanism_NN similar_JJ to_TO the_DT history_NN algorithm_NN used_VBN by_IN Henzinger_NNP et_NNP al_NNP =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
As_IN a_DT paper_NN evolves_VBZ and_CC new_JJ ideas_NNS appear_VBP ,_, each_DT active_JJ term_NN gradually_RB ages_NNS and_CC is_VBZ replaced_VBN by_IN a_DT new_JJ one_CD from_IN the_DT waiting_VBG list_NN ._.
The_DT aging_NN rate_NN depends_VBZ on_IN how_WRB fast_JJ new_JJ concepts_NNS are_VBP introduced_VBN in_IN the_DT pap_NN
instances_NNS of_IN the_DT Lydia_NNP pipeline_NN using_VBG the_DT Condor_NNP job_NN scheduling_NN system_NN -LRB-_-LRB- 18_CD -RRB-_-RRB- ._.
2_LS -RRB-_-RRB- Dealing_VBG with_IN Near-Duplicate_NNP Articles_NNPS :_: The_DT web_NN contains_VBZ a_DT substantial_JJ fraction_NN of_IN duplicate_VB and_CC near-duplicate_JJ documents_NNS =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP deal_VBP with_IN the_DT duplicate_VB and_CC near-duplicate_JJ article_NN problem_NN by_IN eliminating_VBG duplicate_VB sentences_NNS ._.
To_TO obtain_VB the_DT set_NN of_IN unique_JJ sentences_NNS ,_, as_RB well_RB as_IN for_IN other_JJ tasks_NNS ,_, we_PRP use_VBP the_DT Hadoop_NNP open-source_NN imp_NN
the_DT accuracy_NN of_IN these_DT systems_NNS ._.
Reis_NNP et_FW al._FW -LRB-_-LRB- 28_CD -RRB-_-RRB- clustered_VBN pages_NNS by_IN layout_NN features_NNS to_TO attempt_VB to_TO distinguish_VB between_IN ``_`` section_NN pages_NNS ''_'' and_CC article_NN pages_NNS to_TO facilitate_VB news_NN extraction_NN ._.
Henzinger_NNP et_FW al._FW =_SYM -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: described_VBD a_DT system_NN that_WDT suggests_VBZ news_NN articles_NNS on_IN the_DT web_NN based_VBN on_IN broadcast_NN news_NN ._.
It_PRP is_VBZ evident_JJ that_IN classification_NN of_IN a_DT web_NN page_NN as_IN an_DT article_NN would_MD aid_VB this_DT methodology_NN ._.
While_IN the_DT web_NN page_NN modific_JJ
troduce_VB a_DT framework_NN which_WDT also_RB exploits_VBZ these_DT criteria_NNS ._.
The_DT scientific_JJ scenario_NN ._.
Despite_IN this_DT great_JJ variety_NN of_IN commercial_JJ solutions_NNS for_IN news_NN search_NN engines_NNS ,_, we_PRP found_VBD just_RB a_DT few_JJ papers_NNS on_IN this_DT subject_NN =_JJ -_: =[_NN 4_CD ,_, 5_CD ,_, 7_CD ,_, 8_CD ,_, 10_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
NewsInEssence_NN -LRB-_-LRB- 4_CD ,_, 5_CD -RRB-_-RRB- is_VBZ a_DT system_NN for_IN finding_VBG and_CC summarizing_VBG clusters_NNS of_IN related_JJ news_NN articles_NNS from_IN multiple_JJ sources_NNS on_IN the_DT Web_NN ._.
The_DT system_NN aims_VBZ to_TO generate_VB automatically_RB summaries_NNS of_IN news_NN events_NNS by_IN
on_IN authors_NNS into_IN opposite_JJ camps_NNS within_IN a_DT given_VBN topic_NN in_IN the_DT context_NN of_IN newsgroups_NNS ._.
Finding_VBG news_NN articles_NNS on_IN the_DT web_NN that_WDT are_VBP relevant_JJ to_TO news_NN currently_RB being_VBG broadcast_NN was_VBD explored_VBN by_IN Henzinger_NNP et_FW al._FW =_SYM -_: =[_NN 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Uramoto_NNP and_CC Takeda_NNP -LRB-_-LRB- 25_CD -RRB-_-RRB- describe_VBP methods_NNS for_IN relating_VBG multiple_JJ newspaper_NN articles_NNS based_VBN on_IN a_DT graph_NN constructed_VBN from_IN the_DT similarity_NN matrix_NN ._.
Allan_NNP et_FW al._FW -LRB-_-LRB- 6_CD -RRB-_-RRB- propose_VBP several_JJ methods_NNS for_IN constructing_VBG o_NN
inement_NN of_IN future_JJ searches_NNS ._.
Another_DT area_NN of_IN learning_NN is_VBZ focused_VBN on_IN context_NN learning_NN -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 15_CD ,_, 2_CD -RRB-_-RRB- -RRB-_-RRB- based_VBN on_IN judged_VBN relevant_JJ documents_NNS ,_, query_NN terms_NNS ,_, document_NN vectors_NNS ,_, etc._FW ``_`` Context_NNP as_IN a_DT query_NN ''_'' -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 16_CD ,_, 23_CD ,_, 6_CD ,_, 8_CD ,_, 4_CD -RRB-_-RRB- -_: =--RRB-_NN treats_VBZ the_DT context_NN as_IN a_DT background_NN for_IN topic_NN specific_JJ search_NN and_CC extracts_VBZ the_DT query_NN representing_VBG the_DT context_NN and_CC therefore_RB ,_, the_DT task_NN at_IN hand_NN ._.
Some_DT recent_JJ contextual_JJ search_NN tools_NNS -LRB-_-LRB- e.g._FW ,_, Y_NN !_.
Q_NNP -LRB-_-LRB- 18_CD -RRB-_-RRB- -LRB-_-LRB- htt_NN
from_IN a_DT concordance_NN document_NN generated_VBN for_IN the_DT entity_NN ``_`` George_NNP W._NNP Bush_NNP ''_'' 4.1.2_CD Dealing_VBG with_IN Near-Duplicate_NNP Articles_NNPS It_PRP is_VBZ well_RB known_VBN that_IN news_NN articles_NNS contain_VBP a_DT substantial_JJ fraction_NN of_IN near-duplicates_NN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Since_IN in_IN order_NN to_TO construct_VB concordances_NNS for_IN entities_NNS we_PRP have_VBP to_TO break_VB articles_NNS into_IN sentences_NNS ,_, we_PRP deal_VBP with_IN the_DT duplicate_VB and_CC near-duplicate_JJ article_NN problem_NN by_IN eliminating_VBG duplicate_VB sentences_NNS ._.
If_IN t_NN
nformation_NN repositories_NNS ._.
In_IN contrary_NN ,_, our_PRP$ approach_NN uses_VBZ traditional_JJ search_NN engines_NNS to_TO find_VB related_JJ information_NN thereby_RB accommodating_VBG multiple_JJ and_CC varied_JJ information_NN sources_NNS ._.
In_IN Query-free_JJ News_NNP Search_VB =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_JJ -_: ,_, significant_JJ keywords_NNS -LRB-_-LRB- or_CC ,_, potential_JJ search_NN queries_NNS -RRB-_-RRB- are_VBP extracted_VBN via_IN statistical_JJ methods_NNS that_WDT use_VBP the_DT inverse_JJ document_NN frequency_NN for_IN terms_NNS appearing_VBG in_IN the_DT CC_NN ,_, which_WDT is_VBZ in_IN turn_NN calculated_VBN from_IN Goog_NNP
d_NN to_TO our_PRP$ work_NN are_VBP the_DT keyword_JJ extraction_NN algorithms_NNS where_WRB the_DT goal_NN is_VBZ to_TO find_VB the_DT most_RBS distinctive_JJ or_CC representative_JJ terms_NNS in_IN text_NN ._.
These_DT algorithms_NNS are_VBP typically_RB based_VBN on_IN machine_NN learning_NN techniques_NNS =_JJ -_: =[_NN 8_CD ,_, 21_CD ,_, 12_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, compared_VBN to_TO our_PRP$ user-centric_JJ entity_NN detection_NN problem_NN ,_, they_PRP are_VBP more_RBR suitable_JJ for_IN applications_NNS such_JJ as_IN text_NN summarization_NN ,_, or_CC automatically_RB retrieving_VBG relevant_JJ documents_NNS based_VBN on_IN the_DT extrac_NN
o_NN complete_JJ ._.
Some_DT sites_NNS ,_, however_RB ,_, merit_NN more_RBR frequent_JJ crawls_VBZ ._.
For_IN example_NN ,_, the_DT major_JJ search_NN engines_NNS recrawl_VBP news_NN sites_NNS daily_JJ ,_, or_CC even_RB several_JJ times_NNS a_DT day_NN ,_, in_IN order_NN to_TO keep_VB on_IN top_NN of_IN developing_VBG stories_NNS =_JJ -_: =[_NN 24_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN general_JJ ,_, sites_NNS which_WDT serve_VBP as_IN content_NN sites_NNS might_MD merit_VB frequent_JJ crawls_VBZ in_IN order_NN to_TO enable_VB the_DT engines_NNS to_TO keep_VB track_NN of_IN current_JJ events_NNS ,_, trends_NNS and_CC other_JJ issues_NNS of_IN volatile_JJ temporal_JJ nature_NN ._.
Academ_NNP
es_IN the_DT web_NN ,_, writes_VBZ a_DT document_NN ,_, or_CC chats_VBZ with_IN friends_NNS ,_, the_DT system_NN proactively_RB finds_VBZ objects_NNS that_WDT are_VBP relevant_JJ to_TO the_DT user_NN 's_POS current_JJ desktop_NN activity_NN ,_, and_CC displays_VBZ them_PRP in_IN a_DT separate_JJ window_NN ._.
Henzinger_NN -LRB-_-LRB- =_JJ -_: =_JJ Henzinger_NNP et_FW al._FW ,_, 2005_CD -_: =--RRB-_NN tries_VBZ to_TO automatically_RB find_VB news_NN articles_NNS on_IN the_DT web_NN relevant_JJ to_TO the_DT ongoing_JJ stream_NN of_IN TV_NN broadcast_NN news_NN ._.
Their_PRP$ approach_NN is_VBZ to_TO extract_VB queries_NNS from_IN the_DT ongoing_JJ stream_NN of_IN closed_JJ captions_NNS ,_, issue_NN the_DT q_NN
