Learning_NNP to_TO tag_VB
Social_NN tagging_NN provides_VBZ valuable_JJ and_CC crucial_JJ information_NN for_IN large-scale_JJ web_NN image_NN retrieval_NN ._.
It_PRP is_VBZ ontology-free_JJ and_CC easy_JJ to_TO obtain_VB ;_: however_RB ,_, irrelevant_JJ tags_NNS frequently_RB appear_VBP ,_, and_CC users_NNS typically_RB will_MD not_RB tag_VB all_DT semantic_JJ objects_NNS in_IN the_DT image_NN ,_, which_WDT is_VBZ also_RB called_VBN semantic_JJ loss_NN ._.
To_TO avoid_VB noises_NNS and_CC compensate_VB for_IN the_DT semantic_JJ loss_NN ,_, tag_NN recommendation_NN is_VBZ proposed_VBN in_IN literature_NN ._.
However_RB ,_, current_JJ recommendation_NN simply_RB ranks_VBZ the_DT related_JJ tags_NNS based_VBN on_IN the_DT single_JJ modality_NN of_IN tag_NN co-occurrence_NN on_IN the_DT whole_JJ dataset_NN ,_, which_WDT ignores_VBZ other_JJ modalities_NNS ,_, such_JJ as_IN visual_JJ correlation_NN ._.
This_DT paper_NN proposes_VBZ a_DT multi-modality_JJ recommendation_NN based_VBN on_IN both_CC tag_NN and_CC visual_JJ correlation_NN ,_, and_CC formulates_VBZ the_DT tag_NN recommendation_NN as_IN a_DT learning_NN problem_NN ._.
Each_DT modality_NN is_VBZ used_VBN to_TO generate_VB a_DT ranking_JJ feature_NN ,_, and_CC Rankboost_NN algorithm_NN is_VBZ applied_VBN to_TO learn_VB an_DT optimal_JJ combination_NN of_IN these_DT ranking_JJ features_NNS from_IN different_JJ modalities_NNS ._.
Experiments_NNS on_IN Flickr_NNP data_NNS demonstrate_VBP the_DT effectiveness_NN of_IN this_DT learning-based_JJ multi-modality_JJ recommendation_NN strategy_NN ._.
ular_JJ expressions_NNS -LRB-_-LRB- Appelt_NNP et_FW al._FW ,_, 1993_CD ;_: Grishman_NNP ,_, 1997_CD -RRB-_-RRB- ;_: large_JJ name_NN lists_NNS -LRB-_-LRB- Iwanska_FW et_FW al._FW ,_, 1995_CD -RRB-_-RRB- ;_: sophisticated_JJ rule-based_JJ approaches_NNS -LRB-_-LRB- Morgan_NNP et_FW al._FW ,_, 1995_CD -RRB-_-RRB- and_CC learning_NN algorithms_NNS -LRB-_-LRB- e.g._FW ,_, Sekine_NNP ,_, 1998_CD ;_: =_JJ -_: =_JJ Bennett_NNP et_FW al._FW ,_, 1997_CD -_: =_JJ -_: ;_: Baluja_NNP et_FW al._FW ,_, 1999_CD ;_: Borthwick_NNP et_FW al._FW ,_, 1998_CD ;_: Mikheev_NNP et_FW al._FW ,_, 1999_CD ;_: Bikel_NNP et_FW al._FW ,_, 1999_CD ;_: Seymore_NNP et_FW al._FW ,_, 1999_CD ;_: Bray_NNP ,_, 1999_CD -RRB-_-RRB- ._.
The_DT early_JJ systems_NNS used_VBD the_DT first_JJ three_CD approaches_NNS and_CC rely_VBP on_IN much_JJ manual_NN wo_MD
e_LS been_VBN investigated_VBN across_IN a_DT number_NN of_IN diverse_JJ fields_NNS -LRB-_-LRB- 37_CD ,_, 62_CD ,_, 80_CD ,_, 83_CD -RRB-_-RRB- ,_, specifically_RB focusing_VBG on_IN those_DT which_WDT apply_VBP to_TO the_DT tasks_NNS of_IN scene_NN population_NN ._.
In_IN particular_JJ ,_, named_VBN entity_NN recognition_NN techniques_NNS =_JJ -_: =[_NN 1_CD ,_, 8_CD ,_, 9_CD ,_, 11_CD ,_, 20_CD ,_, 52_CD ,_, 60_CD ,_, 81_CD -RRB-_-RRB- -_: =_JJ -_: ,_, script_NN extraction_NN techniques_NNS -LRB-_-LRB- 85_CD -RRB-_-RRB- and_CC inductive_JJ pattern_NN matching_NN techniques_NNS -LRB-_-LRB- 15_CD ,_, 18_CD ,_, 23_CD ,_, 25_CD ,_, 30_CD ,_, 57_CD ,_, 69_CD ,_, 68_CD ,_, 84_CD -RRB-_-RRB- have_VBP been_VBN comprehensively_RB surveyed_VBN ._.
â€¢_CD Existing_VBG Text-to-Scene_JJ conversion_NN systems_NNS :_: A_DT co_NN
formulas_NNS employ_VBP statistics_NNS of_IN filler_NN frequency_NN and_CC length_NN in_IN the_DT training_NN set_VBN to_TO choose_VB between_IN top_JJ filler_NN candidates_NNS from_IN classifiers_NNS ._.
This_DT scoring_VBG method_NN is_VBZ inspired_VBN by_IN the_DT method_NN used_VBN in_IN RoboTag_NNP -LRB-_-LRB- =_JJ -_: =_JJ Bennett_NNP et_FW al_FW ,_, 1997_CD -_: =--RRB-_NN ._.
Note_VB that_IN we_PRP are_VBP making_VBG a_DT simplifying_VBG assumption_NN that_IN there_EX is_VBZ only_RB one_CD starting_VBG tag_NN for_IN each_DT insertion_NN point_NN ,_, which_WDT is_VBZ not_RB always_RB true_JJ in_IN the_DT domains_NNS we_PRP explore_VBP ._.
However_RB ,_, this_DT assumption_NN is_VBZ mostly_RB
compass_VBZ any_DT type_NN of_IN information_NN that_WDT is_VBZ of_IN interest_NN ._.
Some_DT learning_VBG algorithms_NNS have_VBP been_VBN reported_VBN such_JJ as_IN decision_NN trees_NNS ,_, maximum_NN entropy_NN models_NNS and_CC hidden_JJ markov_NN models_NNS ._.
Sekine_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- and_CC Bennett_NNP et_FW al._FW =_SYM -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: both_DT implemented_VBD their_PRP$ token_JJ identification_NN systems_NNS using_VBG decision_NN trees_NNS ._.
Their_PRP$ decision_NN trees_NNS are_VBP based_VBN on_IN almost_RB identical_JJ features_NNS ,_, ssuch_NN as_IN part-of-speech_NN ,_, character_NN type_NN information_NN and_CC special_JJ d_NN
be_VB also_RB treated_VBN as_IN a_DT multi-classification_JJ task_NN ._.
The_DT idea_NN is_VBZ to_TO decompose_VB Event_NN Recognition_NN into_IN several_JJ classification_NN tasks_NNS and_CC then_RB merge_VB the_DT partial_JJ results_NNS into_IN whole_JJ annotations_NNS ._.
Bennett_NNP et_FW al._FW =_SYM -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: used_VBD two_CD classifiers_NNS to_TO recognize_VB the_DT beginnings_NNS and_CC the_DT endings_NNS of_IN annotations_NNS ._.
The_DT concept_NN of_IN this_DT approach_NN is_VBZ presented_VBN on_IN the_DT Figure_NNP 4.1_CD a._NN After_IN selecting_VBG potential_JJ candidates_NNS for_IN annotation_NN boun_NN
d_NN be_VB tagged_VBN as_IN the_DT opening_NN of_IN an_DT organization_NN ,_, while_IN the_DT next_JJ token_JJ might_MD be_VB tagged_VBN as_IN the_DT closing_NN of_IN person_NN name_NN ._.
We_PRP can_MD think_VB of_IN several_JJ strategies_NNS to_TO solve_VB this_DT problem_NN -LRB-_-LRB- for_IN example_NN ,_, the_DT method_NN by_IN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: will_MD be_VB described_VBN in_IN a_DT later_JJ section_NN -RRB-_-RRB- ,_, but_CC we_PRP used_VBD a_DT probabilistic_JJ method_NN ._.
The_DT instances_NNS in_IN the_DT training_NN corpus_NN corresponding_VBG to_TO a_DT leaf_NN of_IN the_DT decision_NN tree_NN may_MD not_RB all_DT have_VBP the_DT same_JJ tag_NN ._.
At_IN a_DT leaf_NN w_NN
ready_JJ have_VBP been_VBN classified_VBN when_WRB labeling_VBG a_DT sequence_NN from_IN left_NN to_TO right_NN -RRB-_-RRB- ._.
Using_VBG this_DT general_JJ approach_NN ,_, IE_NN systems_NNS have_VBP been_VBN developed_VBN that_WDT use_VBP many_JJ different_JJ trained_JJ classifiers_NNS such_JJ as_IN decision_NN trees_NNS =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, boosting_VBG -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, memory-based_JJ learning_NN -LRB-_-LRB- MBL_NN -RRB-_-RRB- -LRB-_-LRB- 43_CD -RRB-_-RRB- ,_, support-vector_JJ machines_NNS -LRB-_-LRB- SVMs_NNS -RRB-_-RRB- -LRB-_-LRB- 40_CD -RRB-_-RRB- ,_, maximum_NN entropy_NN -LRB-_-LRB- MaxEnt_NN -RRB-_-RRB- -LRB-_-LRB- 17_CD -RRB-_-RRB- ,_, transformation-based_JJ learning_NN -LRB-_-LRB- TBL_NN -RRB-_-RRB- -LRB-_-LRB- 68_CD -RRB-_-RRB- and_CC many_JJ others_NNS -LRB-_-LRB- 64_CD -RRB-_-RRB- ._.
Many_JJ IE_NN systems_NNS sim_VBP
