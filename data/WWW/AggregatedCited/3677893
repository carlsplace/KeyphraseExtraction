Site_NN level_NN noise_NN removal_NN for_IN search_NN engines_NNS
The_DT currently_RB booming_JJ search_NN engine_NN industry_NN has_VBZ determined_VBN many_JJ online_JJ organizations_NNS to_TO attempt_VB to_TO artificially_RB increase_VB their_PRP$ ranking_NN in_IN order_NN to_TO attract_VB more_JJR visitors_NNS to_TO their_PRP$ web_NN sites_NNS ._.
At_IN the_DT same_JJ time_NN ,_, the_DT growth_NN of_IN the_DT web_NN has_VBZ also_RB inherently_RB generated_VBD several_JJ navigational_JJ hyperlink_NN structures_NNS that_WDT have_VBP a_DT negative_JJ impact_NN on_IN the_DT importance_NN measures_NNS employed_VBN by_IN current_JJ search_NN engines_NNS ._.
In_IN this_DT paper_NN we_PRP propose_VBP and_CC evaluate_VBP algorithms_NNS for_IN identifying_VBG all_PDT these_DT noisy_JJ links_NNS on_IN the_DT web_NN graph_NN ,_, may_MD them_PRP be_VB spam_JJ or_CC simple_JJ relationships_NNS between_IN real_JJ world_NN entities_NNS represented_VBN by_IN sites_NNS ,_, replication_NN of_IN content_NN ,_, etc._NN ._.
Unlike_IN prior_JJ work_NN ,_, we_PRP target_VBP a_DT different_JJ type_NN of_IN noisy_JJ link_NN structures_NNS ,_, residing_VBG at_IN the_DT site_NN level_NN ,_, instead_RB of_IN the_DT page_NN level_NN ._.
We_PRP thus_RB investigate_VBP and_CC annihilate_VBP site_NN level_NN mutual_JJ reinforcement_NN relationships_NNS ,_, abnormal_JJ support_NN coming_VBG from_IN one_CD site_NN towards_IN another_DT ,_, as_RB well_RB as_IN complex_JJ link_NN alliances_NNS between_IN web_NN sites_NNS ._.
Our_PRP$ experiments_NNS with_IN the_DT link_NN database_NN of_IN the_DT TodoBR_NN search_NN engine_NN show_VBP a_DT very_RB strong_JJ increase_NN in_IN the_DT quality_NN of_IN the_DT output_NN rankings_NNS after_IN having_VBG applied_VBN our_PRP$ techniques_NNS ._.
classifying_VBG spam_NN pages_NNS ._.
Similarly_RB ,_, Carvalho_NNP et_FW al._FW focused_VBN on_IN identifying_VBG ``_`` noisy_JJ ''_'' links_NNS ,_, which_WDT are_VBP sites_NNS with_IN abnormal_JJ support_NN between_IN each_DT other_JJ ,_, by_IN measuring_VBG the_DT amount_NN of_IN linking_VBG between_IN two_CD sites_NNS =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Becchetti_NNP et_NNP al_NNP analyzed_VBD the_DT heuristics_NNS --_: purely_RB linkbased_JJ analyses_NNS ,_, Pagerank_NNP ,_, Trustrank_NNP ,_, Truncated_NNP PageRank_NNP ,_, and_CC various_JJ combinations_NNS of_IN these_DT heuristics_NNS --_: for_IN spam_NN detection_NN and_CC compared_VBN their_PRP$ per_IN
version_NN of_IN TrustRank_NNP ,_, designed_VBN to_TO patch_NN some_DT vulnerabilities_NNS within_IN TrustRank_NNP ._.
In_IN a_DT similar_JJ vein_NN ,_, Krishnan_NNP and_CC Raj_NNP -LRB-_-LRB- 12_CD -RRB-_-RRB- propose_VBP a_DT link-based_JJ system_NN that_WDT propagates_VBZ distrust_VB ._.
Da_NN Costa_NNP Carvalho_NNP et_FW al._FW =_SYM -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: focus_NN on_IN the_DT link_NN graph_NN model_NN of_IN the_DT web_NN ,_, but_CC at_IN the_DT site_NN level_NN instead_RB of_IN at_IN the_DT page_NN level_NN ._.
Their_PRP$ algorithm_NN attempts_VBZ to_TO detect_VB suspicious_JJ links_NNS so_IN these_DT can_MD be_VB ignored_VBN when_WRB PageRank_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- is_VBZ run_VBN ._.
Fe_NNP
cn_IN 3_CD MSP_NNP Laboratory_NNP Dept._NNP of_IN Electronic_NNP Engineering_NNP Tsinghua_NNP University_NNP Beijing_NNP ,_, 100084_CD ,_, P.R._NN China_NNP fengg03@mails.tsinghua.edu.cn_NN defined_VBN as_IN a_DT research_NN issue_NN and_CC several_JJ methods_NNS have_VBP been_VBN proposed_VBN -LRB-_-LRB- 1_LS -RRB-_-RRB- =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =-[_NN 3_CD -RRB-_-RRB- -LRB-_-LRB- 4_CD -RRB-_-RRB- -LRB-_-LRB- 5_CD -RRB-_-RRB- -LRB-_-LRB- 7_CD -RRB-_-RRB- -LRB-_-LRB- 8_CD -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- -LRB-_-LRB- 12_CD -RRB-_-RRB- -LRB-_-LRB- 13_CD -RRB-_-RRB- ._.
Anti-spam_NN is_VBZ a_DT challenging_JJ task_NN ,_, because_IN new_JJ spam_NN techniques_NNS are_VBP being_VBG developed_VBN continuously_RB while_IN anti-spam_JJ methods_NNS are_VBP usually_RB created_VBN only_RB based_VBN on_IN those_DT known_VBN spamming_VBG
lassifiers_NNS -LRB-_-LRB- 16_CD ,_, 5_CD -RRB-_-RRB- ,_, propagating_VBG trust_NN or_CC distrust_VB through_IN links_NNS -LRB-_-LRB- 21_CD ,_, 32_CD -RRB-_-RRB- ,_, detecting_VBG anomalous_JJ behavior_NN of_IN link-based_JJ ranking_JJ algorithms_NNS -LRB-_-LRB- 35_CD ,_, 2_CD -RRB-_-RRB- ,_, or_CC removing_VBG links_NNS that_WDT look_VBP suspicious_JJ for_IN some_DT reason_NN =_JJ -_: =[_NN 15_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Content_NN spam_NN is_VBZ done_VBN by_IN maliously_RB crafting_VBG the_DT content_NN of_IN Web_NN pages_NNS -LRB-_-LRB- 22_CD -RRB-_-RRB- ,_, for_IN instance_NN ,_, by_IN inserting_VBG keywords_NNS that_WDT are_VBP more_RBR related_JJ to_TO popular_JJ query_NN terms_NNS than_IN to_TO the_DT actual_JJ content_NN of_IN the_DT pages_NNS ._.
Me_PRP
Section_NN 6_CD ,_, we_PRP conclude_VBP the_DT paper_NN ._.
2_CD Related_NNP Work_NNP There_EX are_VBP roughly_RB three_CD strategies_NNS for_IN detecting_VBG spam_NN ._.
Link_NNP Analysis_NNP :_: This_DT detects_VBZ malicious_JJ link_NN sets_VBZ called_VBN linkfarms_NNS ,_, by_IN analyzing_VBG link_NN structures_NNS =_JJ -_: =[_NN 7,8,9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
It_PRP can_MD detect_VB linkspams_NNS with_IN high_JJ accuracy_NN ,_, and_CC does_VBZ not_RB depend_VB on_IN languages_NNS ._.
However_RB ,_, it_PRP suffers_VBZ from_IN the_DT drawback_NN that_IN it_PRP generally_RB has_VBZ a_DT high_JJ computational_JJ cost_NN ,_, and_CC that_IN it_PRP can_MD only_RB be_VB used_VBN for_IN
s_NN -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 4_CD -RRB-_-RRB- -RRB-_-RRB- ,_, propagating_VBG trust_NN or_CC distrust_VB through_IN links_NNS -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 13_CD -RRB-_-RRB- -RRB-_-RRB- ,_, detecting_VBG anomalous_JJ behavior_NN of_IN link-based_JJ ranking_JJ algorithms_NNS -LRB-_-LRB- 30_CD -RRB-_-RRB- ,_, removing_VBG links_NNS that_WDT look_VBP suspicious_JJ for_IN some_DT reason_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =--RRB-_NN ,_, or_CC using_VBG ``_`` bursts_NNS ''_'' of_IN linking_VBG activity_NN as_IN a_DT suspicious_JJ signal_NN -LRB-_-LRB- 25_CD -RRB-_-RRB- ._.
Content_NN spam_NN is_VBZ done_VBN by_IN maliciously_RB crafting_VBG the_DT content_NN of_IN Web_NN pages_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- ,_, for_IN instance_NN ,_, by_IN inserting_VBG keywords_NNS that_WDT are_VBP more_JJR rela_NN
classifying_VBG spam_NN pages_NNS ._.
Similarly_RB ,_, Carvalho_NNP et_FW al._FW focused_VBN on_IN identifying_VBG ``_`` noisy_JJ ''_'' links_NNS ,_, which_WDT are_VBP sites_NNS with_IN abnormal_JJ support_NN between_IN each_DT other_JJ ,_, by_IN measuring_VBG the_DT amount_NN of_IN linking_VBG between_IN two_CD sites_NNS =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Becchetti_NNP et_NNP al_NNP analyzed_VBD the_DT heuristics_NNS --_: purely_RB linkbased_JJ analyses_NNS ,_, Pagerank_NNP ,_, Trustrank_NNP ,_, Truncated_NNP PageRank_NNP ,_, and_CC various_JJ combinations_NNS of_IN these_DT heuristics_NNS --_: for_IN spam_NN detection_NN and_CC compared_VBN their_PRP$ per_IN
vement_NN in_IN the_DT final_JJ quality_NN of_IN the_DT answers_NNS provided_VBN by_IN the_DT search_NN engine_NN ._.
We_PRP have_VBP also_RB proposed_VBN a_DT novel_JJ method_NN for_IN removing_VBG noisy_JJ links_NNS from_IN the_DT collection_NN of_IN web_NN documents_NNS indexed_VBN by_IN a_DT search_NN engine_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Unlike_IN prior_JJ works_NNS on_IN this_DT topic_NN ,_, our_PRP$ method_NN detects_VBZ and_CC removes_VBZ noisy_JJ link_NN structures_NNS residing_VBG at_IN the_DT site_NN level_NN ,_, instead_RB of_IN at_IN the_DT page_NN level_NN ._.
Thus_RB ,_, we_PRP have_VBP proposed_VBN site_NN level_NN versions_NNS for_IN existi_NNS
rocesses_NNS compute_VBP the_DT most_RBS important_JJ pages_NNS based_VBN on_IN the_DT importance_NN of_IN the_DT pages_NNS that_WDT link_VBP to_TO them_PRP ._.
In_IN spite_NN of_IN minimizing_VBG the_DT problem_NN ,_, these_DT strategies_NNS can_MD still_RB be_VB easily_RB affected_VBN by_IN noise_NN on_IN the_DT web_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT hypergraph_NN model_NN allows_VBZ for_IN obtaining_VBG reliable_JJ votes_NNS for_IN quality_NN by_IN choosing_VBG the_DT most_RBS appropriate_JJ partition_NN granularity_NN for_IN a_DT given_VBN collection_NN ._.
For_IN instance_NN ,_, if_IN links_NNS of_IN a_DT collection_NN are_VBP noisy_JJ ,_,
