Topical_JJ TrustRank_NN :_: using_VBG topicality_NN to_TO combat_VB web_NN spam_NN
Web_NN spam_NN is_VBZ behavior_NN that_WDT attempts_VBZ to_TO deceive_VB search_NN engine_NN ranking_NN algorithms_NNS ._.
TrustRank_NNP is_VBZ a_DT recent_JJ algorithm_NN that_WDT can_MD combat_VB web_NN spam_NN ._.
However_RB ,_, TrustRank_NN is_VBZ vulnerable_JJ in_IN the_DT sense_NN that_IN the_DT seed_NN set_NN used_VBN by_IN TrustRank_NN may_MD not_RB be_VB sufficiently_RB representative_JJ to_TO cover_VB well_RB the_DT different_JJ topics_NNS on_IN the_DT Web_NN ._.
Also_RB ,_, for_IN a_DT given_VBN seed_NN set_NN ,_, TrustRank_NNP has_VBZ a_DT bias_NN towards_IN larger_JJR communities_NNS ._.
We_PRP propose_VBP the_DT use_NN of_IN topical_JJ information_NN to_TO partition_NN the_DT seed_NN set_NN and_CC calculate_VB trust_NN scores_NNS for_IN each_DT topic_NN separately_RB to_TO address_VB the_DT above_JJ issues_NNS ._.
A_DT combination_NN of_IN these_DT trust_NN scores_NNS for_IN a_DT page_NN is_VBZ used_VBN to_TO determine_VB its_PRP$ ranking_NN ._.
Experimental_JJ results_NNS on_IN two_CD large_JJ datasets_NNS show_VBP that_IN our_PRP$ Topical_NNP TrustRank_NNP has_VBZ a_DT better_JJR performance_NN than_IN TrustRank_NNP in_IN demoting_VBG spam_NN sites_NNS or_CC pages_NNS ._.
Compared_VBN to_TO TrustRank_NNP ,_, our_PRP$ best_JJS technique_NN can_MD decrease_VB spam_NN from_IN the_DT top_NN ranked_VBD sites_NNS by_IN as_RB much_JJ as_IN 43.1_CD %_NN ._.
t_NN of_IN TrustRank_NNP ,_, an_DT eigenvector-based_JJ trust_NN inference_NN method_NN for_IN web_NN pages_NNS ._.
Their_PRP$ solution_NN also_RB applies_VBZ in_IN our_PRP$ setting_NN ._.
More_RBR recently_RB ,_, Wu_NNP et_FW al._FW proposed_VBN improvements_NNS over_IN the_DT seed_NN selection_NN algorithm_NN =_JJ -_: =[_NN 34_CD -RRB-_-RRB- -_: =_SYM -_: introducing_VBG topical_JJ TrustRank_NN ._.
Our_PRP$ method_NN is_VBZ inspired_VBN by_IN the_DT Advogato_NNP -LRB-_-LRB- 23_CD -RRB-_-RRB- trust_NN metric_NN ._.
Both_DT Advogato_NNP and_CC MaxTrust_NNP satisfy_VBP the_DT bottleneck_NN property_NN ._.
In_IN particular_JJ ,_, assuming_VBG that_IN Sybils_NNS are_VBP only_RB conne_NN
dout_NN -LRB-_-LRB- i_LS -RRB-_-RRB- n_NN i_FW :_: -LRB-_-LRB- i_LS ,_, j_NN -RRB-_-RRB- ∈_NN E_NN i_LS =_JJ 1_CD where_WRB dout_NN -LRB-_-LRB- i_LS -RRB-_-RRB- is_VBZ the_DT out-degree_NN of_IN node_NN i._NN While_IN many_JJ modifications_NNS to_TO PageRank_NNP exist_VB ,_, a_DT vast_JJ majority_NN of_IN them_PRP require_VBP oracle_NN input_NN in_IN the_DT form_NN of_IN white\/blacklists_NNS -LRB-_-LRB- 6_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 18_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 37_CD -RRB-_-RRB- -_: =_SYM -_: ._.
As_IN a_DT result_NN ,_, they_PRP are_VBP beyond_IN the_DT scope_NN of_IN this_DT paper_NN ._.
A_DT single_JJ iteration_NN of_IN PageRank_NN with_IN α_NN =_JJ 1_CD and_CC all_DT πi_NNS replaced_VBN with_IN 1_CD leads_VBZ to_TO our_PRP$ last_JJ method_NN ,_, which_WDT is_VBZ called_VBN Weighted_JJ In-Degree_NN -LRB-_-LRB- WIN_NN -RRB-_-RRB- in_IN -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
t_NN of_IN TrustRank_NNP ,_, an_DT eigenvector-based_JJ trust_NN inference_NN method_NN for_IN web_NN pages_NNS ._.
Their_PRP$ solution_NN also_RB applies_VBZ in_IN our_PRP$ setting_NN ._.
More_RBR recently_RB ,_, Wu_NNP et_FW al._FW proposed_VBN improvements_NNS over_IN the_DT seed_NN selection_NN algorithm_NN =_JJ -_: =[_NN 32_CD -RRB-_-RRB- -_: =_SYM -_: introducing_VBG topical_JJ TrustRank_NN ._.
Our_PRP$ method_NN is_VBZ inspired_VBN by_IN the_DT Advogato_NNP -LRB-_-LRB- 21_CD -RRB-_-RRB- trust_NN metric_NN ._.
Both_DT Advogato_NNP and_CC MaxTrust_NNP satisfy_VBP the_DT bottleneck_NN property_NN ._.
In_IN particular_JJ ,_, assuming_VBG that_IN Sybils_NNS are_VBP only_RB conne_NN
ed_IN an_DT initial_JJ group_NN spam_NN detection_NN method_NN ,_, but_CC it_PRP is_VBZ much_RB less_RBR effective_JJ than_IN the_DT proposed_VBN method_NN in_IN this_DT paper_NN ._.
In_IN a_DT wide_JJ field_NN ,_, the_DT most_RBS investigated_VBN spam_NN activities_NNS have_VBP been_VBN in_IN the_DT domains_NNS of_IN Web_NN =_JJ -_: =[_NN 4_CD ,_, 5_CD ,_, 28_CD ,_, 30_CD ,_, 33_CD ,_, 35_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Email_NNP -LRB-_-LRB- 6_CD -RRB-_-RRB- ._.
Web_NN spam_NN has_VBZ two_CD main_JJ types_NNS :_: content_NN spam_NN and_CC link_NN spam_NN ._.
Link_NN spam_NN is_VBZ spam_NN on_IN hyperlinks_NNS ,_, which_WDT does_VBZ not_RB exist_VB in_IN reviews_NNS as_IN there_EX is_VBZ usually_RB no_DT link_NN in_IN them_PRP ._.
Content_NN spam_NN adds_VBZ irrelev_NN
s_NN effect_NN on_IN retrieval_NN ,_, we_PRP tackled_VBD this_DT problem_NN from_IN a_DT different_JJ approach_NN ._.
Web_NN graphs_NNS provide_VBP important_JJ information_NN about_IN their_PRP$ components_NNS '_POS interconnections_NNS and_CC there_EX has_VBZ been_VBN a_DT broad_JJ range_NN of_IN studies_NNS =_JJ -_: =[_NN 10_CD ,_, 12_CD ,_, 25_CD ,_, 24_CD ,_, 8_CD ,_, 28_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: on_IN how_WRB to_TO exploit_VB link-based_JJ characteristics_NNS to_TO detect_VB more_RBR sophisticated_JJ forms_NNS of_IN spam_NN ,_, e.g._FW ,_, link_NN spamming_NN ._.
Link_NN spamming_NN involves_VBZ boosting_VBG the_DT rank_NN of_IN certain_JJ pages_NNS by_IN setting_VBG up_RP specific_JJ link_NN str_NN
est_NN set_NN is_VBZ the_DT handling_NN of_IN hosts_NNS from_IN the_DT same_JJ domain_NN and_CC IP_NNP ._.
Since_IN no_DT IP_NNP and_CC domain_NN was_VBD allowed_VBN to_TO be_VB split_VBN between_IN training_NN and_CC testing_NN ,_, we_PRP might_MD have_VB to_TO reconsider_VB the_DT applicability_NN of_IN propagation_NN =_JJ -_: =[_NN 30_CD ,_, 46_CD -RRB-_-RRB- -_: =_JJ -_: and_CC graph_NN stacking_VBG -LRB-_-LRB- 35_CD -RRB-_-RRB- ._.
The_DT Web_NN Spam_NNP Challenge_NNP data_NNS sets_NNS were_VBD labeled_VBN by_IN uniform_JJ random_JJ sampling_NN and_CC graph_NN stacking_VBG appeared_VBD to_TO be_VB efficient_JJ in_IN several_JJ results_NNS -LRB-_-LRB- 11_CD -RRB-_-RRB- including_VBG our_PRP$ prior_JJ work_NN -LRB-_-LRB- 16_CD -RRB-_-RRB- ._.
Th_NN
fic_JJ or_CC person-specific_JJ PageRank_NN -LRB-_-LRB- 8_CD ,_, 24_CD -RRB-_-RRB- ,_, and_CC on_IN the_DT use_NN of_IN non-random_JJ jump_NN vectors_NNS for_IN personalization_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Related_JJ work_NN on_IN identifying_VBG web_NN spam_NN has_VBZ examined_VBN methods_NNS for_IN propagating_VBG from_IN trustedpages_NNS =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Recent_JJ work_NN by_IN Nie_NN et_FW al._FW -LRB-_-LRB- 19_CD -RRB-_-RRB- focused_VBN on_IN eigenvectors_NNS or_CC counts_NNS to_TO set_VB node_NN priors_NNS ._.
In_IN the_DT content_NN domain_NN ,_, Cronen-Townsend_NNP et_FW al._FW -LRB-_-LRB- 5_CD -RRB-_-RRB- have_VBP looked_VBN at_IN techniques_NNS for_IN predicting_VBG the_DT quality_NN of_IN results_NNS
Q_NNP but_CC an_DT overwhelming_JJ majority_NN of_IN honest_JJ agents_NNS believe_VBP it_PRP is_VBZ not_RB relevant_JJ to_TO Q._NNP As_IN this_DT is_VBZ still_RB an_DT emerging_VBG field_NN of_IN study_NN ,_, there_EX are_VBP several_JJ definitions_NNS currently_RB in_IN use_NN for_IN web_NN spam_NN ._.
Most_JJS of_IN them_PRP =_JJ -_: =[_NN 2_CD ,_, 3_CD ,_, 4_CD ,_, 5_CD ,_, 6_CD ,_, 7_CD ,_, 8_CD ,_, 9_CD -RRB-_-RRB- -_: =_SYM -_: define_VB web_NN spam_NN in_IN terms_NNS of_IN actions_NNS by_IN a_DT webmaster_NN ._.
Our_PRP$ definition_NN differs_VBZ by_IN immediately_RB offering_VBG measurable_JJ criteria_NNS ,_, as_IN we_PRP will_MD show_VB we_PRP can_MD simulate_VB honest_JJ users_NNS ._.
Our_PRP$ definition_NN also_RB has_VBZ an_DT advant_NN
n_NN useful_JJ information_NN ,_, they_PRP can_MD overload_NN the_DT servers_NNS which_WDT provide_VBP various_JJ services_NNS to_TO the_DT users_NNS ._.
There_EX are_VBP roughly_RB three_CD strategies_NNS for_IN combatting_VBG spam_NN ._.
One_CD is_VBZ Regulation_NNP ,_, such_JJ as_IN the_DT ``_`` no_DT follow_VB tag_NN ''_'' =_SYM -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT strategy_NN does_VBZ not_RB detect_VB spams_NNS ,_, but_CC tries_VBZ to_TO prevent_VB spams_NNS from_IN affecting_VBG the_DT results_NNS of_IN automated_JJ link_NN analyses_NNS ._.
Another_DT is_VBZ Link_NNP Analysis_NNP ,_, which_WDT detects_VBZ spams_NNS and_CC junk_NN mutual_JJ link_NN sets_NNS ,_, by_IN lin_NN
am_VBP emails_NNS are_VBP mainly_RB ads_NNS ._.
Spam_NN reviews_NNS are_VBP very_RB different_JJ as_IN they_PRP give_VBP false_JJ opinions_NNS ,_, which_WDT are_VBP much_RB harder_JJR to_TO detect_VB even_RB manually_RB ._.
Thus_RB ,_, most_RBS existing_JJ methods_NNS for_IN detecting_VBG web_NN spam_NN and_CC email_NN spam_NN =_JJ -_: =[_NN 3_CD ,_, 7_CD ,_, 9_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: are_VBP unsuitable_JJ for_IN review_NN spam_NN ._.
In_IN this_DT work_NN ,_, we_PRP study_VBD review_NN spam_NN ._.
Our_PRP$ investigation_NN is_VBZ based_VBN on_IN 5.8_CD million_CD reviews_NNS and_CC 2.14_CD million_CD reviewers_NNS -LRB-_-LRB- members_NNS who_WP wrote_VBD at_IN least_JJS one_CD review_NN -RRB-_-RRB- crawled_VBD from_IN a_DT
ri_IN trust_NN vector_NN v_LS is_VBZ of_IN critical_JJ importance_NN ,_, and_CC a_DT number_NN of_IN techniques_NNS have_VBP been_VBN suggested_VBN ,_, including_VBG the_DT use_NN of_IN expert-selected_JJ whitelists_NNS ,_, high_JJ PageRank_NN pages_NNS ,_, and_CC topicallysegmented_VBD trusted_VBN pages_NNS =_JJ -_: =[_NN 10_CD ,_, 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN summary_NN ,_, link-based_JJ ranking_NN algorithms_NNS like_IN HITS_NNP ,_, PageRank_NNP ,_, and_CC TrustRank_NN attempt_NN to_TO estimate_VB a_DT page_NN 's_POS intrinsic_JJ quality_NN by_IN analyzing_VBG the_DT hyperlink_NN structure_NN of_IN the_DT Web_NN ._.
Fundamentally_RB ,_, the_DT qualit_NN
e_LS have_VBP expanded_VBN on_IN this_DT approach_NN to_TO consider_VB the_DT representativeness_NN of_IN the_DT members_NNS of_IN the_DT seed_NN set_VBN across_IN a_DT collection_NN of_IN topics_NNS and_CC so_RB we_PRP re-weight_VBP them_PRP to_TO form_VB a_DT better_JJR performing_VBG Topical_JJ TrustRank_NN =_JJ -_: =[_NN 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
TrustRank_NNP and_CC Topical_NNP TrustRank_NNP use_VB essentially_RB the_DT same_JJ mechanism_NN to_TO calculate_VB trust_NN as_IN PageRank_NN uses_VBZ to_TO calculate_VB authority_NN ._.
However_RB ,_, intuition_NN suggests_VBZ that_IN estimates_NNS of_IN trust_NN -LRB-_-LRB- ala_NN TrustRank_NN -RRB-_-RRB- can_MD
ranking_NN techniques_NNS were_VBD required_VBN ._.
Recent_JJ work_NN on_IN graph_NN based_JJ algorithms_NNS are_VBP addressing_VBG this_DT issue_NN ,_, the_DT most_RBS popular_JJ being_VBG TrustRank_NN -LRB-_-LRB- 35_CD ,_, 33_CD ,_, 32_CD -RRB-_-RRB- ._.
Extensions_NNS to_TO TrustRank_NNP ,_, including_VBG topical_JJ trust_NN rank_NN =_JJ -_: =[_NN 85_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC other_JJ approaches_NNS that_WDT analyze_VBP link-farms_NNS -LRB-_-LRB- 6_CD -RRB-_-RRB- -LRB-_-LRB- 84_CD -RRB-_-RRB- have_VBP also_RB been_VBN proposed_VBN ._.
To_TO combat_VB plagiarism_NN and_CC page_NN stitching_NN ,_, detecting_VBG phrase_NN level_NN duplication_NN on_IN a_DT global_JJ scale_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- have_VBP also_RB been_VBN previo_VBN
ing_JJ many_JJ different_JJ PageRank_NN vectors_NNS with_IN different_JJ trust_NN vectors_NNS efficiently_RB ._.
In_IN -LRB-_-LRB- 15_CD -RRB-_-RRB- Gyongyi_NNP et_FW al._FW use_VBP the_DT trust_NN vector_NN to_TO combat_NN spam_NN ._.
In_IN -LRB-_-LRB- 16_CD -RRB-_-RRB- topic_NN specific_JJ PageRank_NN vectors_NNS are_VBP calculated_VBN and_CC in_IN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_JJ -_: topic_NN specific_JJ TrustRank_NN values_NNS are_VBP calculated_VBN to_TO combat_VB spam_NN ._.
In_IN -LRB-_-LRB- 21_CD -RRB-_-RRB- Haveliwala_NNP et_FW al._FW present_VBP an_DT accelerated_JJ method_NN of_IN calculating_VBG PageRank_NNP ._.
Abiteboul_NNP et_FW al._FW present_VBP an_DT online_JJ adaptive_JJ page_NN import_NN
ional_JJ link_NN spam_NN detection_NN algorithms_NNS -LRB-_-LRB- 18-23_CD -RRB-_-RRB- have_VBP adopted_VBN a_DT fully_RB automatic_JJ approach_NN that_WDT does_VBZ not_RB require_VB human_JJ input_NN ._.
PageRank_NNP based_VBN schemes_NNS such_JJ as_IN SpamRank_NN -LRB-_-LRB- 18_CD -RRB-_-RRB- ,_, TrustRank_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- ,_, Topical_JJ TrustRank_NN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Anti-Trust_NNP Rank_NNP -LRB-_-LRB- 21_CD -RRB-_-RRB- ,_, HostRank_NN -LRB-_-LRB- 22_CD -RRB-_-RRB- ,_, BadRank_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- etc._NN have_VBP been_VBN proposed_VBN ._.
Statistical_JJ approaches_NNS based_VBN on_IN machine_NN learning_NN that_WDT detect_VBP link_NN spam_NN by_IN finding_VBG missing_JJ statistical_JJ features_NNS have_VBP also_RB re_VB
opic-specific_JJ web_NN link_NN analysis_NN -LRB-_-LRB- 10_CD ,_, 18_CD ,_, 21_CD -RRB-_-RRB- ,_, and_CC analysis_NN of_IN the_DT topical_JJ structure_NN of_IN the_DT Web_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
Web_NN page_NN classification_NN can_MD also_RB help_VB improve_VB the_DT quality_NN of_IN query_NN search_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- and_CC web_NN spam_NN demotion_NN =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
∗_NNP Technical_NNP Report_NNP LU-CSE-06-011_NNP ,_, Department_NNP of_IN Computer_NNP Science_NNP and_CC Engineering_NNP ,_, Lehigh_NNP University_NNP ,_, Bethlehem_NNP ,_, PA_NN ,_, 18015_CD ._.
1sThe_NN general_JJ problem_NN of_IN text_NN classification_NN is_VBZ well-studied_JJ and_CC different_JJ
posts_NNS ._.
3_LS ._.
FILTERING_NN :_: THE_DT STATE_NN OF_IN THE_DT ART_NN As_IN Web_NN spammers_NNS manipulate_VBP several_JJ aspects_NNS of_IN content_NN as_RB well_RB as_IN linkage_NN -LRB-_-LRB- 29_CD -RRB-_-RRB- ,_, effective_JJ spam_NN hunting_NN must_MD combine_VB a_DT variety_NN of_IN content_NN -LRB-_-LRB- 24_CD ,_, 37_CD ,_, 25_CD -RRB-_-RRB- and_CC link_NN =_JJ -_: =[_NN 30_CD ,_, 23_CD ,_, 43_CD ,_, 6_CD ,_, 5_CD ,_, 40_CD ,_, 44_CD -RRB-_-RRB- -_: =_SYM -_: based_VBN methods_NNS ._.
The_DT current_JJ LiWA_NN solution_NN is_VBZ based_VBN on_IN the_DT lessons_NNS learned_VBD from_IN the_DT Web_NN Spam_NN Challenges_NNS -LRB-_-LRB- 13_CD -RRB-_-RRB- ._.
As_IN it_PRP has_VBZ turned_VBN out_RP ,_, the_DT feature_NN set_NN described_VBN in_IN -LRB-_-LRB- 14_CD -RRB-_-RRB- and_CC the_DT bag_NN of_IN words_NNS representation_NN
ears_NNS in_IN -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
Recently_RB several_JJ results_NNS has_VBZ appeared_VBN that_WDT apply_VBP rank_JJ propagation_NN to_TO extend_VB initial_JJ trust_NN or_CC distrust_VB judgments_NNS over_IN a_DT small_JJ set_NN of_IN seed_NN pages_NNS or_CC sites_NNS to_TO the_DT entire_JJ web_NN ,_, such3_NN as_IN trust_NN =_JJ -_: =[_NN 12_CD ,_, 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, distrust_VB -LRB-_-LRB- 20_CD ,_, 6_CD -RRB-_-RRB- propagation_NN in_IN the_DT neighborhood_NN or_CC their_PRP$ combination_NN -LRB-_-LRB- 25_CD -RRB-_-RRB- as_RB well_RB as_IN graph_NN based_JJ similarity_NN measures_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ._.
These_DT methods_NNS are_VBP either_RB based_VBN on_IN propagating_VBG trust_NN forward_RB or_CC distrust_VB bac_NN
mentally_RB ,_, we_PRP do_VBP ground_VB our_PRP$ evaluation_NN in_IN the_DT specific_JJ context_NN of_IN community-based_JJ information_NN sharing_NN ._.
Research_NN on_IN trust_NN and_CC reputation_NN in_IN P2P_NN networks_NNS -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 1_CD ,_, 5_CD ,_, 10_CD ,_, 17_CD ,_, 22_CD -RRB-_-RRB- -RRB-_-RRB- and_CC on_IN the_DT Web_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 14_CD ,_, 34_CD -RRB-_-RRB- -_: =--RRB-_NN can_MD inform_VB the_DT development_NN of_IN SocialTrust_NNP ._.
Note_VB that_IN there_EX are_VBP some_DT key_JJ differences_NNS between_IN these_DT environments_NNS and_CC social_JJ networks_NNS ._.
For_IN example_NN ,_, P2P_NN networks_NNS often_RB are_VBP concerned_VBN with_IN high_JJ node_NN churn_VB
a_DT ,_, Haveliwala_NNP ,_, 2002_CD -RRB-_-RRB- ,_, and_CC on_IN the_DT use_NN of_IN non-random_JJ jump_NN vectors_NNS for_IN personalization_NN -LRB-_-LRB- Jeh_NNP and_CC Widom_NNP ,_, 2003_CD -RRB-_-RRB- ._.
Related_JJ work_NN on_IN identifying_VBG web_NN spam_NN has_VBZ examined_VBN methods_NNS for_IN propagating_VBG from_IN trustedpages_NNS -LRB-_-LRB- =_JJ -_: =_JJ Wu_NNP et_FW al._FW ,_, 2006_CD -_: =-]_CD ._.
Recent_JJ work_NN by_IN Nie_NN et_FW al._FW -LRB-_-LRB- Nie_NN et_FW al._FW ,_, 2006_CD -RRB-_-RRB- focused_VBN on_IN eigenvectors_NNS or_CC counts_NNS to_TO set_VB node_NN priors_NNS ._.
In_IN the_DT content_NN domain_NN ,_, Cronen-Townsend_NNP et_FW al._FW -LRB-_-LRB- Cronen-Townsend_NNP et_FW al._FW ,_, 2002_CD -RRB-_-RRB- have_VBP looked_VBN at_IN techni_NNS
Project_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ._.
For_IN the_DT bias_NN issue_NN ,_, we_PRP propose_VBP that_IN the_DT trustworthiness_NN of_IN a_DT page_NN should_MD be_VB differentiated_VBN by_IN different_JJ topics_NNS ,_, relying_VBG on_IN the_DT fact_NN that_IN two_CD linked_JJ pages_NNS are_VBP typically_RB on_IN related_JJ topics_NNS =_JJ -_: =[_NN 4_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Our_PRP$ Topical_JJ TrustRank_NN approach_NN partitions_NNS the_DT set_NN of_IN trusted_VBN seed_NN pages_NNS into_IN topically_RB coherent_JJ groups_NNS and_CC then_RB calculates_VBZ TrustRank_NNP for_IN each_DT topic_NN ._.
The_DT final_JJ ranking_NN is_VBZ based_VBN on_IN a_DT balanced_JJ combinat_NN
ure_VB the_DT performance_NN ._.
6_CD ._.
EXPERIMENTS_NNS 6.1_CD Data_NNP sets_VBZ We_PRP used_VBD two_CD data_NNS sets_NNS to_TO evaluate_VB our_PRP$ proposed_VBN Topical_NNP TrustRank_NNP algorithm_NN ._.
The_DT first_JJ data_NN set_NN is_VBZ a_DT general_JJ web_NN crawl_NN from_IN Stanford_NNP 's_POS WebBase_NNP project_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP used_VBD the_DT data_NNS set_VBN for_IN January_NNP ,_, 2001_CD as_IN this_DT data_NN set_NN has_VBZ been_VBN used_VBN by_IN several_JJ other_JJ researchers_NNS -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 14_CD ,_, 15_CD ,_, 19_CD -RRB-_-RRB- -RRB-_-RRB- ._.
We_PRP downloaded_VBD the_DT link_NN graph_NN ,_, and_CC made_VBD use_NN of_IN the_DT Internet_NNP Archive_NNP -LRB-_-LRB- 18_CD -RRB-_-RRB- to_TO ch_VB
ing_JJ high_JJ quality_NN web_NN pages_NNS ._.
Others_NNS try_VBP to_TO find_VB a_DT shortcut_NN by_IN manipulating_VBG web_NN page_NN features_NNS on_IN which_WDT search_NN engines_NNS '_POS ranking_JJ algorithms_NNS are_VBP based_VBN ._.
This_DT behavior_NN is_VBZ usually_RB called_VBN ``_`` search_NN engine_NN spam_NN ''_'' =_SYM -_: =[_NN 24_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Henzinger_NNP et_FW al._FW -LRB-_-LRB- 16_CD -RRB-_-RRB- mention_VBP that_IN search_NN engine_NN spam_NN is_VBZ one_CD of_IN the_DT major_JJ challenges_NNS faced_VBN by_IN search_NN engines_NNS ._.
Copyright_NN is_VBZ held_VBN by_IN the_DT International_NNP World_NNP Wide_NN Web_NN Conference_NN Committee_NN -LRB-_-LRB- IW3C2_NN -RRB-_-RRB- ._.
Dist_NN
checked_VBN ._.
If_IN the_DT distribution_NN does_VBZ n't_RB follow_VB a_DT typical_JJ pattern_NN ,_, the_DT page_NN will_MD be_VB penalized_VBN ._.
Acharya_NNP et_FW al._FW -LRB-_-LRB- 1_LS -RRB-_-RRB- first_RB publicly_RB proposed_VBN using_VBG historical_JJ data_NNS to_TO identify_VB link_NN spam_NN pages_NNS ._.
Wu_NNP and_CC Davison_NNP =_SYM -_: =[_NN 28_CD -RRB-_-RRB- -_: =_SYM -_: used_VBD the_DT intersection_NN of_IN the_DT incoming_JJ and_CC outgoing_JJ link_NN sets_NNS plus_CC a_DT propagation_NN step_NN to_TO detect_VB link_NN farms_NNS ._.
Mishne_FW et_FW al._FW -LRB-_-LRB- 20_CD -RRB-_-RRB- employed_VBD a_DT language_NN model_NN to_TO detect_VB comment_NN spam_NN ._.
Drost_NNP and_CC Scheffer_NNP -LRB-_-LRB- 8_CD -RRB-_-RRB-
to_TO the_DT pages_NNS ._.
Sometimes_RB it_PRP is_VBZ not_RB easy_JJ for_IN a_DT non-expert_JJ to_TO identify_VB these_DT spam_NN pages_NNS ._.
So_RB ,_, it_PRP is_VBZ quite_RB possible_JJ that_IN bigger_JJR communities_NNS will_MD contain_VB more_JJR spam_NN pages_NNS ._.
An_DT evidence_NN is_VBZ that_IN Wu_NNP and_CC Davison_NNP =_SYM -_: =[_NN 27_CD -RRB-_-RRB- -_: =_SYM -_: found_VBD that_IN pages_NNS within_IN a_DT response_NN data_NN set_NN for_IN popular_JJ queries_NNS utilize_VBP cloaking_VBG behavior_NN more_JJR than_IN twice_RB as_RB often_RB as_IN pages_NNS within_IN a_DT response_NN data_NN set_NN for_IN normal_JJ queries_NNS ._.
Hence_RB ,_, the_DT TrustRank_NNP bias_NN ma_NN
istribution_NN of_IN these_DT papers_NNS is_VBZ limited_VBN to_TO classroom_NN use_NN ,_, and_CC personal_JJ use_NN by_IN others_NNS ._.
WWW_NN 2006_CD ,_, May_NNP 23_CD --_: 26_CD ,_, 2006_CD ,_, Edinburgh_NNP ,_, Scotland_NNP ._.
ACM_NN 1-59593-323-9_CD \/_: 06\/0005_CD ._.
Many_JJ kinds_NNS of_IN spam_NN have_VBP been_VBN discovered_VBN =_JJ -_: =[_NN 24_CD ,_, 12_CD ,_, 6_CD -RRB-_-RRB- -_: =_JJ -_: ,_, but_CC there_EX is_VBZ no_DT universal_JJ method_NN that_WDT can_MD detect_VB all_DT kinds_NNS of_IN spam_NN at_IN the_DT same_JJ time_NN ._.
Gyöngyi_FW et_FW al._FW -LRB-_-LRB- 13_CD -RRB-_-RRB- present_VBP the_DT TrustRank_NNP algorithm_NN to_TO combat_VB web_NN spam_NN ._.
The_DT basic_JJ idea_NN of_IN this_DT algorithm_NN is_VBZ that_IN
dinburgh_RB ,_, Scotland_NNP ._.
ACM_NN 1-59593-323-9_CD \/_: 06\/0005_CD ._.
Many_JJ kinds_NNS of_IN spam_NN have_VBP been_VBN discovered_VBN -LRB-_-LRB- 24_CD ,_, 12_CD ,_, 6_CD -RRB-_-RRB- ,_, but_CC there_EX is_VBZ no_DT universal_JJ method_NN that_WDT can_MD detect_VB all_DT kinds_NNS of_IN spam_NN at_IN the_DT same_JJ time_NN ._.
Gyöngyi_FW et_FW al._FW =_SYM -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: present_VB the_DT TrustRank_NNP algorithm_NN to_TO combat_VB web_NN spam_NN ._.
The_DT basic_JJ idea_NN of_IN this_DT algorithm_NN is_VBZ that_IN a_DT link_NN between_IN two_CD pages_NNS on_IN the_DT Web_NN signifies_VBZ trust_NN between_IN them_PRP ;_: i.e._FW ,_, a_DT link_NN from_IN page_NN A_NN to_TO page_NN B_NN is_VBZ a_DT
inally_RB ,_, pages_NNS are_VBP ranked_VBN by_IN this_DT unified_JJ score_NN ._.
Experiments_NNS show_VBP that_IN Topic-sensitive_JJ PageRank_NNP has_VBZ better_JJR performance_NN than_IN PageRank_NNP in_IN generating_VBG better_JJR response_NN lists_NNS to_TO a_DT given_VBN query_NN ._.
Jeh_NN and_CC Widom_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: specialize_VB the_DT global_JJ notion_NN of_IN importance_NN that_IN PageRank_NNP provides_VBZ to_TO create_VB personalized_JJ views_NNS of_IN importance_NN by_IN introducing_VBG the_DT idea_NN of_IN preference_NN sets_NNS ._.
The_DT rankings_NNS of_IN results_NNS can_MD then_RB be_VB biased_VBN acc_NN
gine_NN ,_, spam_NN ,_, TrustRank_NN ,_, PageRank_NN 1_CD ._.
INTRODUCTION_NN Web_NN surfers_NNS depend_VBP on_IN search_NN engines_NNS to_TO locate_VB information_NN on_IN the_DT Web_NN ._.
For_IN most_JJS queries_NNS ,_, only_RB the_DT first_JJ screen_NN of_IN the_DT results_NNS is_VBZ viewed_VBN by_IN the_DT searcher_NN =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, typically_RB just_RB the_DT top_JJ 10_CD results_NNS for_IN a_DT query_NN ._.
Since_IN more_JJR traffic_NN to_TO a_DT commercial_JJ web_NN site_NN may_MD bring_VB more_JJR profit_NN ,_, content_NN providers_NNS usually_RB want_VBP their_PRP$ web_NN pages_NNS to_TO be_VB ranked_VBN as_RB high_JJ as_IN possible_JJ in_IN t_NN
response_NN list_NN is_VBZ calculated_VBN and_CC these_DT URLs_NNS are_VBP resorted_VBN to_TO generate_VB a_DT new_JJ output_NN for_IN the_DT user_NN ._.
Our_PRP$ approach_NN makes_VBZ similar_JJ use_NN of_IN human-edited_JJ directories_NNS ,_, but_CC our_PRP$ goal_NN is_VBZ to_TO demote_VB spam_NN ._.
Guha_NNP et_FW al._FW =_SYM -_: =[_NN 11_CD -RRB-_-RRB- -_: =_JJ -_: study_NN how_WRB to_TO propagate_VB trust_NN scores_NNS among_IN a_DT connected_JJ network_NN of_IN people_NNS ._.
Different_JJ propagation_NN schemes_NNS for_IN both_DT trust_NN score_NN and_CC distrust_VB score_NN are_VBP studied_VBN based_VBN on_IN a_DT network_NN from_IN a_DT real_JJ social_JJ commun_NN
ect_VB a_DT special_JJ kind_NN of_IN spam_NN that_WDT provides_VBZ pages_NNS by_IN stitching_VBG together_RB sentences_NNS from_IN a_DT repository_NN ._.
While_IN the_DT idea_NN of_IN a_DT focused_JJ or_CC custom_NN PageRank_NN vector_NN has_VBZ existed_VBN from_IN the_DT beginning_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, Haveliwala_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: was_VBD the_DT first_JJ to_TO propose_VB the_DT idea_NN of_IN bringing_VBG topical_JJ information_NN into_IN PageRank_NN calculation_NN ._.
In_IN his_PRP$ technique_NN ,_, pages_NNS listed_VBN in_IN the_DT dmoz_NN ODP_NN are_VBP used_VBN to_TO calculate_VB the_DT biased_VBN PageRank_NN values_NNS for_IN each_DT o_NN
detect_VB link_NN farms_NNS ._.
Mishne_FW et_FW al._FW -LRB-_-LRB- 20_CD -RRB-_-RRB- employed_VBD a_DT language_NN model_NN to_TO detect_VB comment_NN spam_NN ._.
Drost_NNP and_CC Scheffer_NNP -LRB-_-LRB- 8_CD -RRB-_-RRB- proposed_VBN using_VBG a_DT machine_NN learning_NN method_NN to_TO detect_VB link_NN spam_NN ._.
Recently_RB ,_, Fetterly_NNP et_FW al._FW =_SYM -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: describe_VBP methods_NNS to_TO detect_VB a_DT special_JJ kind_NN of_IN spam_NN that_WDT provides_VBZ pages_NNS by_IN stitching_VBG together_RB sentences_NNS from_IN a_DT repository_NN ._.
While_IN the_DT idea_NN of_IN a_DT focused_JJ or_CC custom_NN PageRank_NN vector_NN has_VBZ existed_VBN from_IN the_DT beg_VBP
d_NN by_IN different_JJ topics_NNS ;_: i.e._FW ,_, the_DT page_NN should_MD be_VB more_RBR trusted_VBN in_IN the_DT topics_NNS that_IN it_PRP is_VBZ relevant_JJ to_TO ._.
This_DT relies_VBZ on_IN the_DT fact_NN that_IN a_DT link_NN between_IN two_CD pages_NNS is_VBZ usually_RB created_VBN in_IN a_DT topic-specific_JJ context_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Our_PRP$ approach_NN ,_, called_VBN Topical_NNP TrustRank_NNP ,_, partitions_VBZ the_DT set_NN of_IN trusted_VBN seed_NN pages_NNS into_IN topically_RB coherent_JJ groups_NNS and_CC then_RB calculates_VBZ TrustRank_NNP for_IN each_DT topic_NN ._.
The_DT final_JJ ranking_NN is_VBZ based_VBN on_IN a_DT balanced_JJ
be_VB methods_NNS to_TO detect_VB a_DT special_JJ kind_NN of_IN spam_NN that_WDT provides_VBZ pages_NNS by_IN stitching_VBG together_RB sentences_NNS from_IN a_DT repository_NN ._.
While_IN the_DT idea_NN of_IN a_DT focused_JJ or_CC custom_NN PageRank_NN vector_NN has_VBZ existed_VBN from_IN the_DT beginning_NN =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Haveliwala_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- was_VBD the_DT first_JJ to_TO propose_VB the_DT idea_NN of_IN bringing_VBG topical_JJ information_NN into_IN PageRank_NN calculation_NN ._.
In_IN his_PRP$ technique_NN ,_, pages_NNS listed_VBN in_IN the_DT dmoz_NN ODP_NN are_VBP used_VBN to_TO calculate_VB the_DT biased_VBN PageRank_NN
roposed_VBN using_VBG historical_JJ data_NNS to_TO identify_VB link_NN spam_NN pages_NNS ._.
Wu_NNP and_CC Davison_NNP -LRB-_-LRB- 28_CD -RRB-_-RRB- used_VBD the_DT intersection_NN of_IN the_DT incoming_JJ and_CC outgoing_JJ link_NN sets_NNS plus_CC a_DT propagation_NN step_NN to_TO detect_VB link_NN farms_NNS ._.
Mishne_FW et_FW al._FW =_SYM -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: employed_VBN a_DT language_NN model_NN to_TO detect_VB comment_NN spam_NN ._.
Drost_NNP and_CC Scheffer_NNP -LRB-_-LRB- 8_CD -RRB-_-RRB- proposed_VBN using_VBG a_DT machine_NN learning_NN method_NN to_TO detect_VB link_NN spam_NN ._.
Recently_RB ,_, Fetterly_NNP et_FW al._FW -LRB-_-LRB- 10_CD -RRB-_-RRB- describe_VBP methods_NNS to_TO detect_VB a_DT spec_NN
Others_NNS try_VBP to_TO find_VB a_DT shortcut_NN by_IN manipulating_VBG web_NN page_NN features_NNS on_IN which_WDT search_NN engines_NNS '_POS ranking_JJ algorithms_NNS are_VBP based_VBN ._.
This_DT behavior_NN is_VBZ usually_RB called_VBN ``_`` search_NN engine_NN spam_NN ''_'' -LRB-_-LRB- 24_CD ,_, 12_CD -RRB-_-RRB- ._.
Henzinger_NNP et_FW al._FW =_SYM -_: =[_NN 16_CD -RRB-_-RRB- -_: =_JJ -_: mention_NN that_WDT search_VBP engine_NN spam_NN is_VBZ one_CD of_IN the_DT major_JJ challenges_NNS faced_VBN by_IN search_NN engines_NNS ._.
Copyright_NN is_VBZ held_VBN by_IN the_DT International_NNP World_NNP Wide_NN Web_NN Conference_NN Committee_NN -LRB-_-LRB- IW3C2_NN -RRB-_-RRB- ._.
Distribution_NN of_IN these_DT paper_NN
tance_NN by_IN introducing_VBG the_DT idea_NN of_IN preference_NN sets_NNS ._.
The_DT rankings_NNS of_IN results_NNS can_MD then_RB be_VB biased_VBN according_VBG to_TO this_DT personalized_JJ notion_NN ._.
For_IN this_DT ,_, they_PRP used_VBD the_DT biased_VBN PageRank_NN formula_NN ._.
Chakrabarti_NNP et_FW al._FW =_SYM -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: characterized_VBN linking_VBG behaviors_NNS on_IN the_DT Web_NN using_VBG topical_JJ classification_NN ._.
Using_VBG a_DT classifier_NN trained_VBN on_IN ODP_NN topics_NNS ,_, they_PRP generated_VBD a_DT topic-topic_JJ citation_NN matrix_NN of_IN links_NNS between_IN pages_NNS that_WDT showed_VBD a_DT cl_NN
earchers_NNS have_VBP worked_VBN to_TO combat_VB different_JJ kinds_NNS of_IN web_NN spam_NN ,_, and_CC we_PRP list_VBP just_RB a_DT few_JJ of_IN them_PRP here_RB ._.
Fetterly_NNP et_FW al._FW propose_VBP using_VBG statistical_JJ analysis_NN to_TO detect_VB spam_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Benczur_NNP et_FW al._FW propose_VBP SpamRank_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: in_IN which_WDT for_IN each_DT page_NN ,_, the_DT PageRank_NNP distribution_NN of_IN all_DT incoming_JJ links_NNS is_VBZ checked_VBN ._.
If_IN the_DT distribution_NN does_VBZ n't_RB follow_VB a_DT typical_JJ pattern_NN ,_, the_DT page_NN will_MD be_VB penalized_VBN ._.
Acharya_NNP et_FW al._FW -LRB-_-LRB- 1_LS -RRB-_-RRB- first_RB publicly_RB
-LRB-_-LRB- 28_CD -RRB-_-RRB- used_VBD the_DT intersection_NN of_IN the_DT incoming_JJ and_CC outgoing_JJ link_NN sets_NNS plus_CC a_DT propagation_NN step_NN to_TO detect_VB link_NN farms_NNS ._.
Mishne_FW et_FW al._FW -LRB-_-LRB- 20_CD -RRB-_-RRB- employed_VBD a_DT language_NN model_NN to_TO detect_VB comment_NN spam_NN ._.
Drost_NN and_CC Scheffer_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: proposed_VBN using_VBG a_DT machine_NN learning_NN method_NN to_TO detect_VB link_NN spam_NN ._.
Recently_RB ,_, Fetterly_NNP et_FW al._FW -LRB-_-LRB- 10_CD -RRB-_-RRB- describe_VBP methods_NNS to_TO detect_VB a_DT special_JJ kind_NN of_IN spam_NN that_WDT provides_VBZ pages_NNS by_IN stitching_VBG together_RB sentences_NNS from_IN
ing_JJ high_JJ quality_NN web_NN pages_NNS ._.
Others_NNS try_VBP to_TO find_VB a_DT shortcut_NN by_IN manipulating_VBG web_NN page_NN features_NNS on_IN which_WDT search_NN engines_NNS '_POS ranking_JJ algorithms_NNS are_VBP based_VBN ._.
This_DT behavior_NN is_VBZ usually_RB called_VBN ``_`` search_NN engine_NN spam_NN ''_'' =_SYM -_: =[_NN 24_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Henzinger_NNP et_FW al._FW -LRB-_-LRB- 16_CD -RRB-_-RRB- mention_VBP that_IN search_NN engine_NN spam_NN is_VBZ one_CD of_IN the_DT major_JJ challenges_NNS faced_VBN by_IN search_NN engines_NNS ._.
Copyright_NN is_VBZ held_VBN by_IN the_DT International_NNP World_NNP Wide_NN Web_NN Conference_NN Committee_NN -LRB-_-LRB- IW3C2_NN -RRB-_-RRB- ._.
Dist_NN
ted_VBD a_DT topic-topic_JJ citation_NN matrix_NN of_IN links_NNS between_IN pages_NNS that_WDT showed_VBD a_DT clear_JJ dominant_JJ diagonal_NN ,_, which_WDT meant_VBD that_IN pages_NNS were_VBD more_RBR likely_JJ to_TO point_VB to_TO pages_NNS sharing_VBG their_PRP$ topic_NN ._.
Recently_RB ,_, Chirita_NNP et_FW al._FW =_SYM -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: described_VBD the_DT method_NN of_IN combining_VBG ODP_NN data_NNS with_IN search_NN engine_NN results_NNS to_TO generate_VB a_DT personalized_JJ search_NN result_NN ._.
Based_VBN on_IN a_DT predefined_JJ user_NN profile_NN ,_, the_DT distance_NN of_IN this_DT file_NN to_TO each_DT URL_NN received_VBN from_IN
easures_NNS to_TO combat_VB it_PRP ._.
A_DT number_NN of_IN researchers_NNS have_VBP worked_VBN to_TO combat_VB different_JJ kinds_NNS of_IN web_NN spam_NN ,_, and_CC we_PRP list_VBP just_RB a_DT few_JJ of_IN them_PRP here_RB ._.
Fetterly_NNP et_FW al._FW propose_VBP using_VBG statistical_JJ analysis_NN to_TO detect_VB spam_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Benczur_NNP et_FW al._FW propose_VBP SpamRank_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- in_IN which_WDT for_IN each_DT page_NN ,_, the_DT PageRank_NNP distribution_NN of_IN all_DT incoming_JJ links_NNS is_VBZ checked_VBN ._.
If_IN the_DT distribution_NN does_VBZ n't_RB follow_VB a_DT typical_JJ pattern_NN ,_, the_DT page_NN will_MD be_VB penaliz_NN
nk_IN algorithm_NN ._.
The_DT first_JJ data_NN set_NN is_VBZ a_DT general_JJ web_NN crawl_NN from_IN Stanford_NNP 's_POS WebBase_NNP project_NN -LRB-_-LRB- 17_CD -RRB-_-RRB- ._.
We_PRP used_VBD the_DT data_NNS set_VBN for_IN January_NNP ,_, 2001_CD as_IN this_DT data_NN set_NN has_VBZ been_VBN used_VBN by_IN several_JJ other_JJ researchers_NNS -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 14_CD ,_, 15_CD ,_, 19_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
We_PRP downloaded_VBD the_DT link_NN graph_NN ,_, and_CC made_VBD use_NN of_IN the_DT Internet_NNP Archive_NNP -LRB-_-LRB- 18_CD -RRB-_-RRB- to_TO check_VB page_NN content_NN when_WRB necessary_JJ ._.
The_DT link_NN graph_NN contained_VBD about_IN 65M_NN pages_NNS that_WDT had_VBD a_DT viable_JJ URL_NN string_NN ._.
We_PRP also_RB download_VBP
