Detecting_VBG spam_NN web_NN pages_NNS through_IN content_NN analysis_NN
In_IN this_DT paper_NN ,_, we_PRP continue_VBP our_PRP$ investigations_NNS of_IN ``_`` web_NN spam_NN ''_'' :_: the_DT injection_NN of_IN artificially-created_JJ pages_NNS into_IN the_DT web_NN in_IN order_NN to_TO influence_VB the_DT results_NNS from_IN search_NN engines_NNS ,_, to_TO drive_VB traffic_NN to_TO certain_JJ pages_NNS for_IN fun_NN or_CC profit_NN ._.
This_DT paper_NN considers_VBZ some_DT previously-undescribed_JJ techniques_NNS for_IN automatically_RB detecting_VBG spam_NN pages_NNS ,_, examines_VBZ the_DT effectiveness_NN of_IN these_DT techniques_NNS in_IN isolation_NN and_CC when_WRB aggregated_VBN using_VBG classification_NN algorithms_NNS ._.
When_WRB combined_VBN ,_, our_PRP$ heuristics_NNS correctly_RB identify_VBP 2,037_CD -LRB-_-LRB- 86.2_CD %_NN -RRB-_-RRB- of_IN the_DT 2,364_CD spam_NN pages_NNS -LRB-_-LRB- 13.8_CD %_NN -RRB-_-RRB- in_IN our_PRP$ judged_VBN collection_NN of_IN 17,168_CD pages_NNS ,_, while_IN misidentifying_VBG 526_CD spam_NN and_CC non-spam_JJ pages_NNS -LRB-_-LRB- 3.1_CD %_NN -RRB-_-RRB- ._.
since_IN it_PRP has_VBZ nothing_NN to_TO do_VB with_IN the_DT request_NN ._.
Although_IN there_EX have_VBP been_VBN many_JJ improvements_NNS ,_, search_NN and_CC rank_NN algorithms_NNS have_VBP not_RB yet_RB eliminated_VBN the_DT ability_NN of_IN such_JJ ``_`` spam_NN ''_'' pages_NNS to_TO populate_VB search_NN results_NNS =_JJ -_: =[_NN 142_CD ,_, 126_CD -RRB-_-RRB- -_: =_SYM -_: ._.
On_IN the_DT other_JJ hand_NN ,_, sometimes_RB the_DT intent_NN of_IN text_NN is_VBZ to_TO communicate_VB a_DT picture_NN ,_, as_IN in_IN Figure_NNP 50_CD ._.
How_WRB can_MD this_DT representation_NN be_VB distinguished_VBN from_IN the_DT spam-like_JJ content_NN of_IN Figure_NNP 49_CD ?_.
How116_NN -LRB-_-LRB- A_NN -RRB-_-RRB- Crawle_NN
s._NN To_TO generate_VB the_DT content_NN of_IN the_DT synthetic_JJ collection_NN ,_, it_PRP was_VBD necessary_JJ to_TO produce_VB pages_NNS that_WDT appeared_VBD to_TO be_VB legitimate_JJ so_RB that_IN search_NN engines_NNS would_MD not_RB find_VB them_PRP suspicious_JJ or_CC classify_VB them_PRP as_IN spam_NN =_JJ -_: =[_NN 129_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Designing_NNP such_PDT a_DT collection_NN is_VBZ challenging_JJ because_IN the_DT search_NN engines_NNS '_POS algorithms_NNS for_IN detecting_VBG spam_NN are_VBP proprietary_JJ and_CC constantly_RB changing_VBG ._.
Although_IN the_DT pages_NNS could_MD have_VB been_VBN generated_VBN from_IN other_JJ
ns_RB ,_, such_JJ as_IN information_NN extraction_NN from_IN electronic_JJ data_NNS -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, discovering_VBG interesting_JJ usage_NN patterns_NNS in_IN text_NN collections_NNS ,_, -LRB-_-LRB- 12_CD -RRB-_-RRB- finding_VBG advertising_NN keywords_NNS on_IN web_NN pages_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, detecting_VBG spam_NN web_NN pages_NNS =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: and_CC mining_VBG the_DT shopping_NN preferences_NNS of_IN web_NN surfers_NNS ._.
Most_JJS of_IN these_DT data_NNS mining_NN applications_NNS employ_VBP automatic_JJ or_CC semi-automatic_JJ machine_NN learning_NN techniques_NNS that_WDT make_VBP use_NN of_IN features_NNS as_IN the_DT atomic_JJ units_NNS
rmation_NN can_MD then_RB be_VB used_VBN with_IN common_JJ ,_, link-based_JJ ranking_NN algorithms_NNS ,_, such_JJ as_IN PageRank_NNP or_CC HITS_NNP ._.
The_DT same_JJ authors_NNS also_RB present_VBP their_PRP$ findings_NNS on_IN cloaking_NN and_CC redirection_NN techniques_NNS -LRB-_-LRB- 29_CD -RRB-_-RRB- ._.
Ntoulas_FW et_FW al._FW =_SYM -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: present_VB a_DT technique_NN of_IN detecting_VBG spam_NN pages_NNS by_IN content_NN analysis_NN ._.
This_DT work_NN only_RB takes_VBZ query_JJ independent_JJ features_NNS into_IN account_NN ,_, while_IN Svore_NNP et_FW al._FW -LRB-_-LRB- 26_CD -RRB-_-RRB- also_RB use_VBP query_JJ dependent_JJ information_NN ._.
A_DT system_NN t_NN
resented_VBN in_IN the_DT literature_NN ._.
-LRB-_-LRB- 11_CD -RRB-_-RRB- introduce_VBP several_JJ commercial_JJ software_NN and_CC methodologies_NNS that_WDT allow_VBP users_NNS to_TO define_VB a_DT set_NN of_IN rules_NNS to_TO filter_NN junk_NN emails_NNS ._.
The_DT problem_NN of_IN this_DT approach_NN ,_, as_IN mentioned_VBN in_IN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: ,_, is_VBZ that_IN users_NNS are_VBP not_RB always_RB capable_JJ of_IN defining_VBG solid_JJ rules_NNS ._.
Furthermore_RB ,_, since_IN junk_NN emails_NNS change_VBP every_DT day_NN ,_, existing_VBG rules_NNS need_VBP to_TO be_VB periodically_RB updated_VBN ,_, which_WDT is_VBZ a_DT time-consuming_JJ and_CC ineffecti_NNS
unethical_JJ ._.
Gradually_RB ,_, more_JJR pages_NNS are_VBP introduced_VBN on_IN the_DT Web_NN that_WDT are_VBP considered_VBN legitimate_JJ when_WRB in_IN fact_NN they_PRP are_VBP not_RB and_CC ranked_VBD high_JJ when_WRB they_PRP should_MD not_RB be_VB by_IN existing_VBG search_NN engines_NNS ._.
As_IN reported_VBN in_IN =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT significant_JJ portion_NN of_IN existing_VBG Web_NN pages_NNS --_: 14_CD %_NN in_IN the_DT year_NN of_IN 2006_CD --_: are_VBP spam_NN ._.
O._NNP Gervasi_NNP et_FW al._FW -LRB-_-LRB- Eds_NNP ._. -RRB-_-RRB-
:_: ICCSA_NN 2008_CD ,_, Part_NNP II_NNP ,_, LNCS_NNP 5073_CD ,_, pp_NN ._.
204_CD --_: 219_CD ,_, 2008_CD ._.
c_NN ○_CD Springer-Verlag_NNP Berlin_NNP Heidelberg_NNP 2008I_NN
Gradually_RB ,_, more_JJR documents_NNS are_VBP introduced_VBN on_IN the_DT Web_NN that_WDT are_VBP considered_VBN legitimate_JJ when_WRB in_IN fact_NN they_PRP are_VBP not_RB and_CC ranked_VBD high_JJ when_WRB they_PRP should_MD not_RB be_VB by_IN existing_VBG search_NN engines_NNS ._.
As_IN reported_VBN in_IN -LRB-_-LRB- 7_CD -RRB-_-RRB- and_CC =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT significant_JJ portion_NN of_IN existing_VBG Web_NN documents_NNS --_: between_IN 14_CD %_NN and_CC 22_CD %_NN in_IN the_DT year_NN of_IN 2006_CD --_: are_VBP spam_NN ._.
Spamming_NNP is_VBZ a_DT serious_JJ Web_NN IR_NN problem_NN ,_, since_IN it_PRP -LRB-_-LRB- i_LS -RRB-_-RRB- affects_VBZ the_DT quality_NN of_IN Web_NN searches_NNS ,_, -LRB-_-LRB- ii_LS -RRB-_-RRB- damages_NNS
t_NN ideas_NNS spread_VBD more_RBR quickly_RB in_IN the_DT blogosphere_NN than_IN by_IN email_NN ._.
In_IN previous_JJ work_NN on_IN linkback_NN spam_NN ,_, -LRB-_-LRB- 18_CD -RRB-_-RRB- examines_VBZ ways_NNS that_IN the_DT language_NN appearing_VBG in_IN a_DT blog_NN can_MD be_VB used_VBN as_IN a_DT blocking_NN defense_NN ._.
Similarly_RB ,_, =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: studies_NNS how_WRB the_DT language_NN of_IN web_NN pages_NNS ,_, including_VBG blogs_NNS ,_, can_MD be_VB used_VBN to_TO detect_VB spam_NN ._.
In_IN -LRB-_-LRB- 12_CD -RRB-_-RRB- the_DT authors_NNS use_VBP Support_NN Vector_NNP Machines_NNP -LRB-_-LRB- SVM_NNP -RRB-_-RRB- to_TO classify_VB blog_NN spam_NN ._.
10_CD ._.
CONCLUSION_NN In_IN this_DT paper_NN ,_, we_PRP descr_VBP
b_NN '_'' 08_CD ,_, April_NNP 22_CD ,_, 2008_CD Beijing_NNP ,_, China_NNP ._.
Copyright_NN 2008_CD ACM_NNP 978-1-60558-159-0_CD ..._: $_$ 5.00_CD ._.
2_CD ._.
RELATED_NNS WORK_VBP There_EX has_VBZ been_VBN a_DT large_JJ amount_NN of_IN recent_JJ work_NN on_IN automatic_JJ and_CC semi-automatic_JJ detection_NN of_IN web_NN spam_NN =_JJ -_: =[_NN 8_CD ,_, 7_CD ,_, 6_CD ,_, 20_CD ,_, 17_CD ,_, 19_CD ,_, 5_CD ,_, 4_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Much_JJ of_IN that_DT work_NN has_VBZ focused_VBN on_IN graph-based_JJ methods_NNS for_IN detecting_VBG link_NN farms_NNS ,_, i.e._FW ,_, groups_NNS of_IN sites_NNS that_WDT exploit_VBP link_NN structure_NN to_TO push_VB up_RP the_DT ranking_NN of_IN other_JJ sites_NNS beyond_IN what_WP it_PRP should_MD be_VB -LRB-_-LRB- 9_CD ,_, 2_CD ,_,
atures_VBZ Web_NN Spam_NN Web_NN Spam_NN Detection_NN A_NN Reference_NNP Collection_NNP Web_NN Links_NNP Topological_NNP Web_NN Spam_NN Counting_VBG of_IN Supporters_NNS Content-based_JJ Spam_NNP detection_NN Web_NN Topology_NNP Conclusions_NNP Most_NNP of_IN the_DT features_NNS reported_VBN in_IN -LRB-_-LRB- =_JJ -_: =_JJ Ntoulas_FW et_FW al._FW ,_, 2006_CD -_: =-]_CD Number_NN of_IN word_NN in_IN the_DT page_NN and_CC title_NN Average_JJ word_NN length_NN Fraction_NN of_IN anchor_NN text_NN Fraction_NN of_IN visible_JJ text_NN Compression_NN rate_NN Corpus_NNP precision_NN and_CC corpus_NN recall_VBP Query_NNP precision_NN and_CC query_NN recall_NN Indepen_NN
ness_NN for_IN our_PRP$ search_NN ._.
If_IN we_PRP can_MD identify_VB a_DT candidate_NN bad_JJ title_NN ,_, we_PRP will_MD not_RB waste_VB our_PRP$ time_NN but_CC proceed_VB with_IN the_DT generation_NN of_IN a_DT LS_NN as_IN the_DT more_RBR promising_JJ approach_NN for_IN web_NN page_NN discovery_NN ._.
Ntoulas_FW et_FW al._FW =_SYM -_: =[_NN 32_CD -RRB-_-RRB- -_: =_SYM -_: used_VBN methods_NNS based_VBN on_IN web_NN pages_NNS '_POS content_NN to_TO identify_VB spam_NN web_NN pages_NNS ._.
One_CD of_IN their_PRP$ experiments_NNS shows_VBZ that_IN web_NN pages_NNS '_POS titles_NNS consisting_VBG of_IN more_JJR than_IN 24_CD terms_NNS are_VBP likely_JJ to_TO be_VB spam_NN ._.
This_DT result_NN confirms_VBZ
levant_NN ,_, or_CC because_IN it_PRP can_MD not_RB be_VB defined_VBN ._.
In_IN the_DT first_JJ category_NN we_PRP placed_VBD URLs_NNS of_IN educational_JJ institutions_NNS -LRB-_-LRB- domains_NNS ending_VBG in_IN ._.
edu_NN -RRB-_-RRB- ._.
Academicians_NNS are_VBP not_RB in_IN the_DT business_NN of_IN linking_VBG to_TO commercial_JJ sites_NNS =_JJ -_: =[_NN 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
When_WRB they_PRP do_VBP ,_, they_PRP do_VBP not_RB often_RB convey_VB trust_NN in_IN the_DT site_NN ._.
College_NNP libraries_NNS and_CC academicians_NNS ,_, for_IN example_NN ,_, sometimes_RB point_NN to_TO untrustworthy_JJ sites_NNS as_IN examples_NNS to_TO help_VB students_NNS critically_RB think_VBP about_IN
orted_VBN as_IN a_DT normal_JJ page_NN ._.
2.3_CD Term_NN Spamicity_NN and_CC Term_NN Spam_NN Detection_NN The_DT term-based_JJ ranking_NN methods_NNS such_JJ as_IN TFIDF_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- adopted_VBN by_IN web_NN search_NN engines_NNS are_VBP victims_NNS of_IN term_NN spam_NN ._.
The_DT previous_JJ studies_NNS -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =--RRB-_NN showed_VBD that_IN the_DT algorithms_NNS used_VBN by_IN search_NN engines_NNS to_TO rank_VB web_NN pages_NNS based_VBN on_IN their_PRP$ content_NN information_NN use_VBP various_JJ forms_NNS of_IN the_DT fundamental_JJ TFIDF_NN metric_NN ._.
A_DT web_NN page_NN p_NN and_CC a_DT search_NN query_NN Q_NNP can_MD be_VB reg_NN
nclusions_NNS and_CC directions_NNS for_IN future_JJ work_NN are_VBP given_VBN in_IN Section_NN 6_CD ._.
2_CD Related_NNP Work_NNP Spam_NNP has_VBZ historically_RB been_VBN studied_VBN in_IN the_DT contexts_NNS of_IN e-mail_JJ -LRB-_-LRB- Drucker_NNP et_FW al._FW ,_, 2002_CD -RRB-_-RRB- ,_, and_CC the_DT Web_NN -LRB-_-LRB- Gyöngyi_FW et_FW al._FW ,_, 2004_CD ;_: =_JJ -_: =_JJ Ntoulas_FW et_FW al._FW ,_, 2006_CD -_: =--RRB-_NN ._.
Recently_RB ,_, researchers_NNS have_VBP began_VBN to_TO look_VB at_IN opinion_NN spam_NN as_RB well_RB -LRB-_-LRB- Jindal_NNP and_CC Liu_NNP ,_, 2008_CD ;_: Wu_NNP et_FW al._FW ,_, 2010_CD ;_: Yoo_NNP and_CC Gretzel_NNP ,_, 2009_CD -RRB-_-RRB- ._.
Jindal_NNP and_CC Liu_NNP -LRB-_-LRB- 2008_CD -RRB-_-RRB- find_VBP that_IN opinion_NN spam_NN is_VBZ both_CC widespread_JJ and_CC
d_NN site_NN 's_POS original_JJ content_NN plus_CC numerous_JJ links_NNS to_TO websites_NNS promoted_VBN by_IN the_DT attacker_NN -LRB-_-LRB- e.g._FW ,_, other_JJ compromised_VBN sites_NNS ,_, online_NN stores_NNS -RRB-_-RRB- ._.
This_DT technique_NN ,_, ``_`` link_NN stuffing_NN ,_, ''_'' has_VBZ been_VBN observed_VBN for_IN several_JJ years_NNS =_JJ -_: =[_NN 34_CD -RRB-_-RRB- -_: =_SYM -_: in_IN non-compromised_JJ websites_NNS ._.
Requests_NNS originating_VBG from_IN pages_NNS of_IN search_NN results_NNS ,_, for_IN queries_NNS deemed_VBD relevant_JJ to_TO what_WP the_DT attacker_NN wants_VBZ to_TO promote_VB ,_, are_VBP redirected_VBN to_TO a_DT website_NN of_IN the_DT attacker_NN 's_POS choosi_NNS
ased_JJ measures_NNS are_VBP useful_JJ for_IN the_DT task_NN ._.
Drost_NNP et_FW al._FW -LRB-_-LRB- 4_CD -RRB-_-RRB- extended_VBD the_DT list_NN by_IN adding_VBG features_NNS based_VBN on_IN checksums_NNS and_CC word_NN weighting_NN techniques_NNS ._.
This_DT direction_NN was_VBD further_RB explored_VBN by_IN Ntoulas_FW et_FW al._FW in_IN =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Mishne_FW et_FW al._FW -LRB-_-LRB- 10_CD -RRB-_-RRB- analyzed_VBD the_DT contents_NNS of_IN a_DT Web_NN document_NN to_TO compare_VB its_PRP$ language_NN model_NN with_IN that_DT of_IN the_DT citing_VBG blog_NN in_IN order_NN to_TO detect_VB blog_NN spam_NN ._.
Fetterly_NNP et_FW al._FW -LRB-_-LRB- 8_CD -RRB-_-RRB- reported_VBN on_IN techniques_NNS for_IN ide_NN
were_VBD designed_VBN to_TO mislead_VB search_NN engines_NNS ._.
In_IN 2006_CD ,_, it_PRP is_VBZ estimated_VBN that_IN about_IN one_CD seventh_JJ of_IN English_JJ Web_NN pages_NNS are_VBP spam_NN and_CC these_DT spam_NNS lead_VBP to_TO great_JJ obstacle_NN in_IN users_NNS '_POS information_NN acquisition_NN process_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Therefore_RB ,_, spam_NN detection_NN is_VBZ regarded_VBN as_IN a_DT major_JJ challenge_NN for_IN Web_NN search_NN service_NN providers_NNS -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
State-of-the-art_JJ anti-spam_JJ techniques_NNS usually_RB make_VBP use_NN of_IN Web_NN page_NN features_NNS ,_, either_CC content-based_JJ or_CC
detection_NN in_IN the_DT web_NN ,_, which_WDT is_VBZ an_DT extremely_RB important_JJ task_NN ._.
These_DT algorithms_NNS can_MD be_VB roughly_RB divided_VBN into_IN two_CD classes_NNS :_: content-based_JJ methods_NNS ,_, and_CC graph_NN based_JJ approaches_NNS ._.
The_DT content-based_JJ approaches_NNS -LRB-_-LRB- =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =--RRB-_NN focus_NN on_IN the_DT content_NN of_IN the_DT webpage_NN ,_, e.g._FW number_NN of_IN words_NNS in_IN the_DT page_NN and_CC page_NN title_NN ,_, amount_NN of_IN anchor_NN text_NN ,_, fraction_NN of_IN visible_JJ content_JJ etc._NN to_TO separate_VB a_DT spam-page_NN from_IN a_DT non-spam_JJ page_NN ._.
Graph-base_NN
ed_IN an_DT initial_JJ group_NN spam_NN detection_NN method_NN ,_, but_CC it_PRP is_VBZ much_RB less_RBR effective_JJ than_IN the_DT proposed_VBN method_NN in_IN this_DT paper_NN ._.
In_IN a_DT wide_JJ field_NN ,_, the_DT most_RBS investigated_VBN spam_NN activities_NNS have_VBP been_VBN in_IN the_DT domains_NNS of_IN Web_NN =_JJ -_: =[_NN 4_CD ,_, 5_CD ,_, 28_CD ,_, 30_CD ,_, 33_CD ,_, 35_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Email_NNP -LRB-_-LRB- 6_CD -RRB-_-RRB- ._.
Web_NN spam_NN has_VBZ two_CD main_JJ types_NNS :_: content_NN spam_NN and_CC link_NN spam_NN ._.
Link_NN spam_NN is_VBZ spam_NN on_IN hyperlinks_NNS ,_, which_WDT does_VBZ not_RB exist_VB in_IN reviews_NNS as_IN there_EX is_VBZ usually_RB no_DT link_NN in_IN them_PRP ._.
Content_NN spam_NN adds_VBZ irrelev_NN
analysis_NN based_VBN on_IN data_NNS compression_NN algorithms_NNS -LRB-_-LRB- Bratko_NNP et_FW al._FW 2006_CD -RRB-_-RRB- ,_, machine_NN learning_NN -LRB-_-LRB- Goodman_NNP ,_, Heckerman_NNP ,_, and_CC Rounthwaite_NNP 2005_CD ;_: Sahami_FW et_FW al._FW 1998_CD -RRB-_-RRB- or_CC statistics_NNS -LRB-_-LRB- Fetterly_NNP ,_, Manasse_NNP ,_, and_CC Najork_NNP 2004_CD ;_: =_JJ -_: =_JJ Ntoulas_FW et_FW al._FW 2006_CD -_: =_JJ -_: ;_: Yoshida_NNP et_FW al._FW 2004_CD -RRB-_-RRB- ._.
Spammers_NNS have_VBP extended_VBN their_PRP$ targets_NNS to_TO social_JJ networking_VBG sites_NNS because_IN of_IN the_DT popularity_NN of_IN the_DT sites_NNS and_CC easy_JJ access_NN to_TO user_NN information_NN like_IN name_NN ,_, gender_NN ,_, and_CC age_NN ._.
Re-centl_NN
the_DT page_NN and_CC the_DT HTML_NNP markup_NN that_WDT defines_VBZ the_DT page_NN layout_NN ._.
Accordingly_RB ,_, we_PRP collect_VBP multiple_JJ quality_NN features_NNS for_IN each_DT document_NN ,_, hypothesizing_VBG -LRB-_-LRB- based_VBN on_IN previous_JJ findings_NNS in_IN web_NN page_NN content_NN analysis_NN =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =--RRB-_NN that_IN their_PRP$ combination_NN will_MD be_VB more_RBR effective_JJ in_IN determining_VBG the_DT true_JJ quality_NN of_IN the_DT document_NN than_IN each_DT feature_NN on_IN its_PRP$ own_JJ ._.
We_PRP use_VBP a_DT mix_NN of_IN both_CC novel_JJ quality_NN features_NNS and_CC quality_NN features_NNS used_VBN in_IN p_NN
ting_VBG up_RP specific_JJ link_NN structures_NNS among_IN them_PRP ._.
It_PRP can_MD not_RB be_VB properly_RB modeled_VBN by_IN content-based_JJ filters_NNS ,_, as_IN these_DT filters_NNS are_VBP generally_RB designed_VBN to_TO recognize_VB term_NN spam_NN -LRB-_-LRB- i.e._FW ,_, misleading_JJ document_NN content_NN -RRB-_-RRB- =_JJ -_: =[_NN 8_CD ,_, 28_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Gyöngyi_FW et_FW al._FW -LRB-_-LRB- 10_CD -RRB-_-RRB- exploits_VBZ the_DT intuition_NN that_IN good_JJ pages_NNS ,_, i.e._FW ,_, those_DT of_IN high_JJ quality_NN ,_, are_VBP unlikely_JJ to_TO point_VB to_TO low_JJ quality_NN or_CC spam_NN pages_NNS ._.
Having_VBG collected_VBN a_DT set_NN of_IN good_JJ pages_NNS as_IN its_PRP$ seed_NN in_IN a_DT sup_NN
n_NN the_DT unique_JJ confines_NNS of_IN a_DT wiki\/Wikipedia_NN environment_NN ._.
For_IN example_NN ,_, analysis_NN of_IN destination_NN content_NN -LRB-_-LRB- i.e._FW ,_, HTML_NNP -RRB-_-RRB- is_VBZ one_CD such_JJ strategy_NN ,_, attempting_VBG to_TO quantify_VB ``_`` commercial_JJ intention_NN ''_'' and_CC SEO_NNP strategies_NNS =_JJ -_: =[_NN 19_CD ,_, 31_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Sec_NN ._.
5.2_CD examines_VBZ how_WRB these_DT techniques_NNS fare_VBP on_IN Wikipedia_NNP ,_, where_WRB nofollow_NN is_VBZ used_VBN and_CC most_JJS link_NN spam_NN is_VBZ not_RB commercial_JJ in_IN nature_NN -LRB-_-LRB- 41_CD -RRB-_-RRB- ._.
Another_DT oft-proposed_JJ technique_NN is_VBZ semantic_JJ NLP_NN analysis_NN ,_, i.e._FW ,_, m_NN
nd_NN could_MD be_VB easily_RB ported_VBN to_TO other_JJ languages\/projects_NNS ._.
The_DT feature_NN set_NN includes_VBZ :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- Wikipedia_FW metadata_FW processing_NN ,_, -LRB-_-LRB- 2_LS -RRB-_-RRB- HTML_NNP landing_NN site_NN analysis_NN -LRB-_-LRB- including_VBG the_DT quantification_NN of_IN ``_`` commercial_JJ intent_NN ''_'' =_SYM -_: =[_NN 25_CD ,_, 41_CD -RRB-_-RRB- -_: =--RRB-_NN ,_, and_CC -LRB-_-LRB- 3_LS -RRB-_-RRB- third-party_JJ data_NNS -LRB-_-LRB- e.g._FW ,_, from_IN web_NN crawlers_NNS -LRB-_-LRB- 1_LS -RRB-_-RRB- -RRB-_-RRB- ._.
Most_RBS importantly_RB ,_, the_DT attack_NN vectors_NNS described_VBN herein_RB are_VBP quantified_VBN as_IN features_NNS ._.
However_RB ,_, because_IN the_DT attack_NN vectors_NNS are_VBP not_RB in_IN active_JJ use_NN -LRB-_-LRB-
tom_NN -RRB-_-RRB- 19Features_NNS :_: Site_NN •_CD •_NN We_PRP fetch_VBP and_CC process_VBP the_DT HTML_NNP source_NN of_IN the_DT landing_NN site_NN Spam_NNP destinations_NNS marginally_RB more_RBR profane\/commercial_JJ -LRB-_-LRB- SEO_NNP ?_. -RRB-_-RRB-
•_JJ Re‐implement_NN features_NNS from_IN a_DT study_NN of_IN email_JJ spam_NN URLs_NNS =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: •_FW Opposite_FW results_VBZ from_IN that_DT work_NN •_NNP TAKEAWAY_NNP :_: Subtlety_NN and_CC link_NN diversity_NN impair_VBP this_DT analysis_NN 20Features_VBZ :_: 3_CD rd_NN Party_NNP -LRB-_-LRB- 1_LS -RRB-_-RRB- Two_CD third‐party_NN sources_NNS queried_VBD :_: •_NNP •_NNP Alexa_NNP WIS_NNP -LRB-_-LRB- 10_CD -RRB-_-RRB- :_: Data_NN from_IN web_NN crawling_VBG
top_JJ level_NN window_NN or_CC frame_NN ,_, and_CC applies_VBZ a_DT generic_JJ label_NN called_VBN sources_NNS ._.
HTML_NNP Content_NNP ._.
Beyond_IN features_NNS associated_VBN with_IN URLs_NNS ,_, the_DT content_NN of_IN a_DT page_NN often_RB proves_VBZ indicative_JJ of_IN the_DT presence_NN of_IN spam_NN -LRB-_-LRB- 24_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 28_CD -RRB-_-RRB- ._.
This_DT includes_VBZ the_DT terms_NNS appearing_VBG on_IN a_DT page_NN and_CC similar_JJ layout_NN across_IN spam_NN webpages_NNS ._.
To_TO capture_VB page_NN content_NN ,_, the_DT web_NN browser_NN saves_VBZ a_DT final_JJ landing_NN page_NN 's_POS HTML_NNP in_IN addition_NN to_TO the_DT HTML_NNP of_IN all_DT s_NNS
nd_NN could_MD be_VB easily_RB ported_VBN to_TO other_JJ languages\/projects_NNS ._.
The_DT feature_NN set_NN includes_VBZ :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- Wikipedia_FW metadata_FW processing_NN ,_, -LRB-_-LRB- 2_LS -RRB-_-RRB- HTML_NNP landing_NN site_NN analysis_NN -LRB-_-LRB- including_VBG the_DT quantification_NN of_IN ``_`` commercial_JJ intent_NN ''_'' =_SYM -_: =[_NN 25_CD ,_, 41_CD -RRB-_-RRB- -_: =--RRB-_NN ,_, and_CC -LRB-_-LRB- 3_LS -RRB-_-RRB- third-party_JJ data_NNS -LRB-_-LRB- e.g._FW ,_, from_IN web_NN crawlers_NNS -LRB-_-LRB- 1_LS -RRB-_-RRB- -RRB-_-RRB- ._.
Most_RBS importantly_RB ,_, the_DT attack_NN vectors_NNS described_VBN herein_RB are_VBP quantified_VBN as_IN features_NNS ._.
However_RB ,_, because_IN the_DT attack_NN vectors_NNS are_VBP not_RB in_IN active_JJ use_NN -LRB-_-LRB-
and_CC if_IN a_DT site_NN is_VBZ caught_VBN using_VBG such_JJ techniques_NNS ,_, it_PRP could_MD be_VB removed_VBN from_IN the_DT search_NN index_NN ._.
To_TO detect_VB black-hat_JJ SEO_NNP pages_NNS ,_, many_JJ approaches_NNS have_VBP been_VBN proposed_VBN ._.
Some_DT are_VBP based_VBN on_IN the_DT content_NN of_IN the_DT pages_NNS =_JJ -_: =[_NN 15_CD ,_, 5_CD ,_, 21_CD -RRB-_-RRB- -_: =_JJ -_: ,_, some_DT are_VBP based_VBN on_IN the_DT presence_NN of_IN cloaking_NN -LRB-_-LRB- 25_CD ,_, 27_CD -RRB-_-RRB- ,_, while_IN some_DT others_NNS are_VBP based_VBN on_IN the_DT link_NN structure_NN leading_VBG to_TO the_DT pages_NNS -LRB-_-LRB- 26_CD ,_, 4_CD -RRB-_-RRB- ._.
The_DT SEO_NNP attacks_NNS that_WDT we_VBP study_NN in_IN this_DT paper_NN are_VBP different_JJ from_IN tr_NN
luster_NN by_IN majority_NN vote_NN ,_, 2_CD ._.
propagating_VBG the_DT predicted_VBN labels_NNS to_TO neighboring_JJ hosts_NNS ,_, and_CC 3_CD ._.
using_VBG the_DT predicted_VBN labels_NNS of_IN neighboring_JJ hosts_NNS as_IN new_JJ features_NNS and_CC retraining_VBG the_DT classifier_NN ._.
Ntoulas_FW et_FW al._FW =_SYM -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: considers_VBZ some_DT previously_RB undescribed_JJ techniques_NNS for_IN automatically_RB detecting_VBG spam_NN pages_NNS ,_, examines_VBZ the_DT effectiveness_NN of_IN these_DT techniques_NNS in_IN isolation_NN and_CC when_WRB aggregated_VBN using_VBG classification_NN algorithm_NN
he_PRP documents_NNS are_VBP scored_VBN by_IN -LCB-_-LRB- scT_NN D_NN -LRB-_-LRB- D_NN -RRB-_-RRB- if_IN p_NN -LRB-_-LRB- D_NN -RRB-_-RRB- ≥_NN 60_CD scSF_NN -LRB-_-LRB- D_NN -RRB-_-RRB- =_JJ −_FW ∞_FW else_RB ._.
4_CD Quality_NNP Biasing_NNP Stage_NNP While_IN there_EX is_VBZ an_DT abundance_NN of_IN features_NNS that_WDT can_MD be_VB associated_VBN with_IN document_NN quality_NN -LRB-_-LRB- see_VB ,_, for_IN instance_NN ,_, =_JJ -_: =[_NN 3_CD ,_, 8_CD ,_, 14_CD ,_, 17_CD -RRB-_-RRB- -_: =_SYM -_: for_IN an_DT extensive_JJ examination_NN of_IN such_JJ features_NNS -RRB-_-RRB- for_IN our_PRP$ submission_NN we_PRP chose_VBD to_TO focus_VB on_IN two_CD features_NNS that_IN we_PRP found_VBD to_TO have_VB a_DT highly_RB positive_JJ effect_NN on_IN the_DT retrieval_NN performance_NN in_IN our_PRP$ preliminary_JJ expe_NN
les_FW over_IN the_DT content-only_JJ features_NNS in_IN order_NN to_TO assess_VB performance_NN by_IN completely_RB eliminating_VBG linkage_NN information_NN ._.
The_DT feature_NN sets_VBZ available_JJ for_IN these_DT ensembles_NNS are_VBP the_DT following_NN :_: •_NN -LRB-_-LRB- A_NN -RRB-_-RRB- Public_JJ content_NN =_JJ -_: =[_NN 40_CD ,_, 11_CD -RRB-_-RRB- -_: =_JJ -_: features_NNS without_IN any_DT link_NN based_VBN information_NN ._.
Features_NNS for_IN the_DT page_NN with_IN maximum_JJ PageRank_NN in_IN the_DT host_NN are_VBP not_RB used_VBN to_TO save_VB the_DT PageRank_NNP computation_NN ._.
Corpus_NNP precision_NN ,_, the_DT fraction_NN of_IN words_NNS in_IN a_DT page_NN t_NN
which_WDT consist_VBP of_IN specially_RB crafted_VBN webpages_NNS with_IN inflated_JJ relevance_NN to_TO a_DT set_NN of_IN target_NN search_NN terms_NNS ._.
Attempts_NNS to_TO counter_RB blackhat_VB SEO_NNP have_VBP been_VBN proposed_VBN mainly_RB in_IN the_DT information_NN retrieval_NN community_NN =_JJ -_: =[_NN 18_CD ,_, 24_CD -RRB-_-RRB- -_: =_JJ -_: ,_, but_CC with_IN very_RB limited_JJ success_NN against_IN the_DT recent_JJ surge_NN of_IN blackhat_FW SEO_FW adopters_NNS -LRB-_-LRB- 11_CD -RRB-_-RRB- ._.
In_IN the_DT meantime_NN ,_, blackhat_NN SEO_NN has_VBZ not_RB captured_VBN sufficient_JJ attention_NN from_IN the_DT security_NN community_NN ,_, perhaps_RB because_IN
ference_NN ._.
The_DT average_JJ number_NN of_IN PC_NN members_NNS for_IN R_NNP and_CC Q_NNP was_VBD 28.831_CD -LRB-_-LRB- std_NN ._.
dev_NN ._.
was_VBD 0.477_CD -RRB-_-RRB- and_CC 69.6_CD -LRB-_-LRB- std_NN ._.
dev_NN ._.
was_VBD 21.7_CD -RRB-_-RRB- ,_, respectively_RB -LRB-_-LRB- see_VB Figure_NNP 1_CD Inset_NNP -RRB-_-RRB- ._.
The_DT main_JJ Figure_NNP 1_CD has_VBZ two_CD Y-axes_NNS ,_, adopted_VBN from_IN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: :_: Left_VBN Yaxis_NNP indicates_VBZ the_DT fraction_NN of_IN conferences_NNS -LRB-_-LRB- histogram_NN -RRB-_-RRB- while_IN Right_NNP Y-axis_NNP indicates_VBZ the_DT probability_NN of_IN a_DT conference_NN being_VBG in_IN Q_NNP -LRB-_-LRB- line_NN graph_NN -RRB-_-RRB- ._.
In_IN general_JJ ,_, with_IN increasing_VBG numbers_NNS of_IN papers_NNS being_VBG
heuristics_NNS ,_, such_JJ as_IN URL_NN structure_NN and_CC average_JJ change_NN throughout_IN a_DT site_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- ,_, and_CC continued_VBN with_IN site-dependent_JJ heuristics_NNS ,_, such_JJ as_IN the_DT words_NNS used_VBN in_IN a_DT page_NN or_CC title_NN and_CC the_DT fraction_NN of_IN visible_JJ content_NN =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Urvoy_NNP et_NNP al_NNP modelized_VBD the_DT style_NN of_IN HTML_NNP documents_NNS based_VBN on_IN properties_NNS such_JJ as_IN spacing_NN and_CC HTML_NNP tags_NNS to_TO determine_VB stylistic_JJ similarities_NNS that_WDT could_MD be_VB used_VBN to_TO identify_VB authors_NNS -LRB-_-LRB- 18_CD -RRB-_-RRB- ._.
Mishne_NNP ,_, Carmel_NNP ,_, a_DT
assifier_RB using_VBG real_JJ CFPs_NNS of_IN Computer_NNP Science_NNP conferences_NNS ,_, we_PRP demonstrate_VBP that_IN the_DT PC_NN characteristics_NNS can_MD be_VB used_VBN as_IN a_DT quick_JJ indicator_NN the_DT quality_NN of_IN the_DT conferences_NNS ._.
Our_PRP$ paper_NN is_VBZ inspired_VBN by_IN the_DT work_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: in_IN which_WDT the_DT authors_NNS built_VBD classifiers_NNS to_TO detect_VB spam_NN web_NN pages_NNS ._.
However_RB ,_, our_PRP$ problem_NN is_VBZ arguably_RB more_RBR difficult_JJ than_IN theirs_JJ :_: spam_NN web_NN pages_NNS are_VBP relatively_RB easier_JJR to_TO judge_VB ,_, while_IN reputable_JJ or_CC questio_NN
ndependent_JJ of_IN the_DT particular_JJ query_NN issued_VBN by_IN the_DT user_NN ._.
Popular_NNP techniques_NNS that_WDT compute_VBP the_DT general_JJ quality_NN of_IN a_DT page_NN include_VBP PageRank_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ,_, HITS_NN -LRB-_-LRB- 17_CD -RRB-_-RRB- and_CC the_DT likelihood_NN that_IN the_DT page_NN is_VBZ a_DT ``_`` spam_NN ''_'' page_NN =_JJ -_: =[_NN 25_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Here_RB ,_, we_PRP will_MD use_VB pr_NN -LRB-_-LRB- D_NN -RRB-_-RRB- to_TO denote_VB this_DT query-independent_JJ part_NN of_IN the_DT final_JJ ranking_NN function_NN for_IN document_NN D._NNP The_NNP final_JJ ranking_NN score_NN r_NN -LRB-_-LRB- D_NN ,_, q_NN -RRB-_-RRB- of_IN a_DT document_NN will_MD depend_VB on_IN both_CC the_DT query-dependent_JJ and_CC
s_NN so_IN these_DT can_MD be_VB ignored_VBN when_WRB PageRank_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- is_VBZ run_VBN ._.
Fetterly_RB ,_, Manasse_NN and_CC Najork_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- examine_VBP statistical_JJ ways_NNS of_IN analyzing_VBG URLs_NNS ,_, host_NN names_NNS ,_, the_DT web_NN graph_NN and_CC individual_JJ page_NN content_NN ._.
Ntoulas_FW et_FW al._FW =_SYM -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: develop_VB other_JJ content-based_JJ methods_NNS of_IN deciding_VBG whether_IN a_DT page_NN is_VBZ spam_NN ._.
Cloaking_VBG spam_NN ,_, where_WRB one_CD page_NN is_VBZ shown_VBN to_TO a_DT search_NN engine_NN and_CC another_DT to_TO a_DT user_NN for_IN the_DT same_JJ ,_, as_RB well_RB as_IN redirection_NN spam_NN ,_, wher_NN
tion_NN ._.
While_IN there_EX are_VBP critical_JJ differences_NNS between_IN the_DT two_CD ,_, a_DT review_NN of_IN web-spam_JJ research_NN provides_VBZ useful_JJ insight_NN ._.
Prior_JJ work_NN to_TO detect_VB web_NN spams_NNS can_MD be_VB categorized_VBN into_IN content_NN and_CC link_NN analysis_NN ._.
In_IN =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: the_DT authors_NNS distinguish_VBP web_NN spams_NNS from_IN normal_JJ web_NN pages_NNS based_VBN on_IN statistical_JJ properties_NNS insFigure_NN 1_CD :_: Examples_NNS of_IN repetitive_JJ patterns_NNS in_IN posting_VBG times_NNS ,_, post_NN contents_NNS ,_, and_CC affiliated_JJ links_NNS in_IN splogs_NNS ._.
t_NN
3_CD MSP_NNP Laboratory_NNP Dept._NNP of_IN Electronic_NNP Engineering_NNP Tsinghua_NNP University_NNP Beijing_NNP ,_, 100084_CD ,_, P.R._NN China_NNP fengg03@mails.tsinghua.edu.cn_NN defined_VBN as_IN a_DT research_NN issue_NN and_CC several_JJ methods_NNS have_VBP been_VBN proposed_VBN -LRB-_-LRB- 1_LS -RRB-_-RRB- -LRB-_-LRB- 2_LS -RRB-_-RRB- =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =-[_NN 4_CD -RRB-_-RRB- -LRB-_-LRB- 5_CD -RRB-_-RRB- -LRB-_-LRB- 7_CD -RRB-_-RRB- -LRB-_-LRB- 8_CD -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- -LRB-_-LRB- 12_CD -RRB-_-RRB- -LRB-_-LRB- 13_CD -RRB-_-RRB- ._.
Anti-spam_NN is_VBZ a_DT challenging_JJ task_NN ,_, because_IN new_JJ spam_NN techniques_NNS are_VBP being_VBG developed_VBN continuously_RB while_IN anti-spam_JJ methods_NNS are_VBP usually_RB created_VBN only_RB based_VBN on_IN those_DT known_JJ spamming_JJ te_NN
nt_NN of_IN Web_NN pages_NNS -LRB-_-LRB- 22_CD -RRB-_-RRB- ,_, for_IN instance_NN ,_, by_IN inserting_VBG keywords_NNS that_WDT are_VBP more_RBR related_JJ to_TO popular_JJ query_NN terms_NNS than_IN to_TO the_DT actual_JJ content_NN of_IN the_DT pages_NNS ._.
Methods_NNS for_IN detecting_VBG this_DT type_NN of_IN spam_NN use_NN classifiers_NNS =_JJ -_: =[_NN 28_CD -RRB-_-RRB- -_: =_JJ -_: or_CC look_VB at_IN language_NN model_NN disagreement_NN -LRB-_-LRB- 27_CD -RRB-_-RRB- ._.
To_TO some_DT extent_NN ,_, these_DT techniques_NNS overlap_VBP with_IN some_DT of_IN the_DT methods_NNS used_VBN in_IN e-mail_JJ spam_NN filtering_VBG ._.
Cloaking_VBG consists_VBZ of_IN sending_VBG different_JJ content_NN to_TO a_DT searc_NN
ere_NN has_VBZ been_VBN work_NN on_IN web_NN spam_NN detection_NN ._.
While_IN there_EX are_VBP critical_JJ differences_NNS between_IN the_DT two_CD ,_, a_DT review_NN is_VBZ useful_JJ ._.
Prior_JJ work_NN to_TO detect_VB web_NN spams_NNS can_MD be_VB categorized_VBN into_IN content_NN and_CC link_NN analysis_NN ._.
In_IN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: the_DT authors_NNS distinguish_VBP web_NN spams_NNS from_IN normal_JJ web_NN pages_NNS based_VBN on_IN statistical_JJ properties_NNS in_IN the_DT content_NN ,_, such_JJ as_IN number_NN of_IN words_NNS ,_, average_JJ word_NN length_NN ,_, or_CC term_NN frequencies_NNS in_IN title_NN ,_, anchor_NN text_NN ,_, tokeni_NNS
be_VB our_PRP$ machine_NN learning_VBG entry_NN for_IN that_DT challenge_NN ._.
Our_PRP$ machine_NN learning_VBG approach_NN starts_NNS by_IN supplementing_VBG the_DT raw_JJ data_NNS provided_VBN by_IN the_DT Web_NN Spam_NNP Challenge_NNP with_IN additional_JJ ,_, human-engineered_JJ content-based_JJ =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_JJ -_: and_CC link-based_JJ -LRB-_-LRB- 2_CD -RRB-_-RRB- features_NNS ._.
We_PRP then_RB build_VBP a_DT rough_JJ classifier_NN using_VBG the_DT raw_JJ data_NNS and_CC these_DT supplemental_JJ features_NNS ,_, and_CC use_VB this_DT classifier_NN to_TO label_VB all_DT of_IN the_DT unlabeled_JJ graph_NN nodessprovided_VBN by_IN the_DT Web_NN
ayed_VBN by_IN content_NN and_CC splog_NN regularity_NN features_NNS ._.
1sMost_NN of_IN previous_JJ work_NN in_IN spam_NN detection_NN comes_VBZ from_IN web_NN spam_NN detection_NN ._.
Prior_JJ work_NN to_TO detect_VB web_NN spams_NNS can_MD be_VB further_RB categorized_VBN into_IN content_NN analysis_NN =_JJ -_: =[_NN 6,7_CD -RRB-_-RRB- -_: =_JJ -_: and_CC link_NN analysis_NN -LRB-_-LRB- 2,3_CD -RRB-_-RRB- ._.
Our_PRP$ work_NN combines_VBZ traditional_JJ features_NNS with_IN temporal_JJ and_CC link_NN features_NNS that_WDT are_VBP unique_JJ to_TO blogs_NNS ._.
The_DT rest_NN of_IN this_DT paper_NN is_VBZ organized_VBN as_IN follows_VBZ ._.
In_IN the_DT next_JJ section_NN we_PRP provid_VBP
e_LS not_RB spam_NN ._.
Some_DT other_JJ pages_NNS look_VBP fine_JJ in_IN isolation_NN ,_, but_CC in_IN context_NN are_VBP clearly_RB spam_NN ._.
Several_JJ approaches_NNS based_VBN on_IN statistical_JJ analysis_NN and_CC machine_NN learning_NN have_VBP been_VBN proposed_VBN for_IN detecting_VBG spam_NN pages_NNS =_JJ -_: =[_NN 4,9,12_CD ,_, 14,19-20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, none_NN of_IN them_PRP are_VBP guaranteed_VBN to_TO succeed_VB against_IN all_DT spammers_NNS ._.
When_WRB search_NN engines_NNS counteract_VBP Web_NN spam_NN using_VBG these_DT approaches_NNS ,_, they_PRP simply_RB escalate_VB the_DT arms_NNS race_NN :_: the_DT approaches_NNS work_VBP for_IN a_DT sh_NN
ique_VB used_VBN to_TO be_VB popular_JJ but_CC now_RB it_PRP is_VBZ quite_RB easy_JJ to_TO be_VB detecteds3_JJ .2_NN ._.
Fighting_NN Web_NN spam_NN Defeating_VBG Web_NN spam_NN does_VBZ not_RB require_VB perfection_NN ,_, but_CC only_RB to_TO alter_VB the_DT economic_JJ balance_NN for_IN the_DT would-be_JJ spammers_NNS =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT Web_NN site_NN owner_NN will_MD spam_VB if_IN she_PRP or_CC he_PRP perceives_VBZ that_IN it_PRP is_VBZ economically_RB justified_JJ to_TO pay_VB more_JJR to_TO spend_VB a_DT certain_JJ amount_NN of_IN money_NN in_IN spamming_VBG a_DT search_NN engine_NN instead_RB of_IN spending_VBG the_DT same_JJ amount_NN of_IN
roblem_NN ._.
The_DT manipulation_NN problem_NN is_VBZ also_RB called_VBN the_DT Web_NN spam_NN ,_, which_WDT refers_VBZ to_TO hyperlinked_JJ pages_NNS on_IN the_DT World_NNP Wide_NN Web_NN that_WDT are_VBP created_VBN with_IN the_DT intention_NN of_IN misleading_JJ engines_NNS -LRB-_-LRB- 12_CD -RRB-_-RRB- ._.
It_PRP is_VBZ reported_VBN in_IN =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_SYM -_: that_IN approximately_RB 70_CD %_NN of_IN all_DT pages_NNS in_IN the_DT ._.
biz_NN domain_NN are_VBP spam_NN and_CC that_IN about_IN 35_CD %_NN of_IN the_DT pages_NNS in_IN the_DT ._.
us_PRP domain_NN belong_VBP to_TO spam_VB category_NN ._.
The_DT reason_NN for_IN the_DT increasing_VBG amount_NN of_IN Web_NN spam_NN is_VBZ explaine_NN
ted_VBN with_IN the_DT intention_NN of_IN misleading_JJ search_NN engines_NNS -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
It_PRP is_VBZ reported_VBN that_IN approximately_RB 70_CD %_NN of_IN all_DT pages_NNS in_IN the_DT ._.
biz_NN domain_NN and_CC about_IN 35_CD %_NN of_IN the_DT pages_NNS in_IN the_DT ._.
us_PRP domain_NN belong_VBP to_TO the_DT spam_NN category_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT reason_NN for_IN the_DT increasing_VBG amount_NN of_IN Web_NN spam_NN is_VBZ explained_VBN in_IN -LRB-_-LRB- 12_CD -RRB-_-RRB- :_: some_DT web_NN site_NN operators_NNS try_VBP to_TO influence_VB the_DT positioning_NN of_IN their_PRP$ pages_NNS within_IN search_NN results_NNS because_IN of_IN the_DT large_JJ fraction_NN of_IN
am_VBP emails_NNS are_VBP mainly_RB ads_NNS ._.
Spam_NN reviews_NNS are_VBP very_RB different_JJ as_IN they_PRP give_VBP false_JJ opinions_NNS ,_, which_WDT are_VBP much_RB harder_JJR to_TO detect_VB even_RB manually_RB ._.
Thus_RB ,_, most_RBS existing_JJ methods_NNS for_IN detecting_VBG web_NN spam_NN and_CC email_NN spam_NN =_JJ -_: =[_NN 3_CD ,_, 7_CD ,_, 9_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: are_VBP unsuitable_JJ for_IN review_NN spam_NN ._.
In_IN this_DT work_NN ,_, we_PRP study_VBD review_NN spam_NN ._.
Our_PRP$ investigation_NN is_VBZ based_VBN on_IN 5.8_CD million_CD reviews_NNS and_CC 2.14_CD million_CD reviewers_NNS -LRB-_-LRB- members_NNS who_WP wrote_VBD at_IN least_JJS one_CD review_NN -RRB-_-RRB- crawled_VBD from_IN a_DT
nt_NN of_IN Web_NN pages_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- ,_, for_IN instance_NN ,_, by_IN inserting_VBG keywords_NNS that_WDT are_VBP more_RBR related_JJ to_TO popular_JJ query_NN terms_NNS than_IN to_TO the_DT actual_JJ content_NN of_IN the_DT pages_NNS ._.
Methods_NNS for_IN detecting_VBG this_DT type_NN of_IN spam_NN use_NN classifiers_NNS =_JJ -_: =[_NN 22_CD -RRB-_-RRB- -_: =_JJ -_: or_CC look_VB at_IN language_NN model_NN disagreement_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ._.
To_TO some_DT extent_NN ,_, these_DT techniques_NNS overlap_VBP with_IN some_DT of_IN the_DT methods_NNS used_VBN in_IN e-mail_JJ spam_NN filtering_VBG ._.
Cloaking_VBG consists_VBZ of_IN sending_VBG different_JJ content_NN to_TO a_DT searc_NN
pam_NN problem_NN has_VBZ primarily_RB focused_VBN on_IN the_DT classification_NN of_IN spam_NN web_NN pages_NNS ._.
By_IN combining_VBG these_DT classification_NN techniques_NNS ,_, spam_NN pages_NNS can_MD be_VB detected_VBN with_IN a_DT high_JJ degree_NN of_IN precision_NN ,_, usually_RB around_IN 80_CD %_NN =_JJ -_: =[_NN 1_CD ,_, 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, it_PRP is_VBZ unclear_JJ how_WRB much_JJ effect_NN this_DT web_NN spam_NN has_VBZ on_IN the_DT quality_NN of_IN results_NNS ._.
There_EX are_VBP a_DT few_JJ important_JJ questions_NNS currently_RB unanswered_JJ :_: 1_CD ._.
How_WRB does_VBZ webspam_NN affect_VB result_NN quality_NN ?_.
2_CD ._.
Are_VBP partic_JJ
son_NN with_IN popular_JJ pages_NNS ,_, Blogspot_NNP pages_NNS are_VBP more_RBR than_IN twice_RB as_RB likely_JJ to_TO contain_VB JavaScript_NNP redirection_NN spam_NN ._.
However_RB ,_, in_IN both_DT cases_NNS ,_, the_DT occurrence_NN of_IN JavaScript_NNP redirection_NN is_VBZ less_JJR than_IN 1_CD in_IN 100_CD ._.
In_IN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT average_JJ amount_NN of_IN spam_NN in_IN English_JJ web_NN pages_NNS was_VBD observed_VBN to_TO be_VB around_IN 15_CD %_NN ._.
Based_VBN on_IN this_DT ,_, one_PRP can_MD very_RB approximately_RB estimate_VB that_IN about_IN 2.3_CD %_NN -LRB-_-LRB- 1_CD in_IN 43_CD -RRB-_-RRB- of_IN popular_JJ English_JJ spam_NN pages_NNS and_CC 5.1_CD %_NN -LRB-_-LRB- 1_CD
spam_NN has_VBZ been_VBN recognized_VBN as_IN one_CD of_IN the_DT top_JJ challenges_NNS in_IN the_DT search_NN engine_NN industry_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
A_DT lot_NN of_IN recent_JJ work_NN has_VBZ addressed_VBN the_DT problem_NN of_IN detecting_VBG or_CC demoting_VBG web_NN spam_NN ,_, including_VBG both_DT content_JJ spam_NN =_JJ -_: =[_NN 16_CD ,_, 12_CD -RRB-_-RRB- -_: =_JJ -_: and_CC link_NN spam_NN -LRB-_-LRB- 22_CD ,_, 13_CD -RRB-_-RRB- ._.
However_RB ,_, any_DT time_NN an_DT anti-spam_JJ technique_NN is_VBZ developed_VBN ,_, spammers_NNS will_MD design_VB new_JJ spamming_VBG techniques_NNS to_TO confuse_VB search_NN engine_NN ranking_NN methods_NNS and_CC spam_NN detection_NN mechanisms_NNS ._.
Mac_NN
heuristics_NNS ,_, such_JJ as_IN URL_NN structure_NN and_CC average_JJ change_NN throughout_IN a_DT site_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- ,_, and_CC continued_VBN with_IN site-dependent_JJ heuristics_NNS ,_, such_JJ as_IN the_DT words_NNS used_VBN in_IN a_DT page_NN or_CC title_NN and_CC the_DT fraction_NN of_IN visible_JJ content_NN =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Urvoy_NNP et_NNP al_NNP modelized_VBD the_DT style_NN of_IN HTML_NNP documents_NNS based_VBN on_IN properties_NNS such_JJ as_IN spacing_NN and_CC HTML_NNP tags_NNS to_TO determine_VB stylistic_JJ similarities_NNS that_WDT could_MD be_VB used_VBN to_TO identify_VB authors_NNS -LRB-_-LRB- 18_CD -RRB-_-RRB- ._.
Mishne_NNP ,_, Carmel_NNP ,_, a_DT
e_LS not_RB spam_NN ._.
Some_DT other_JJ pages_NNS look_VBP fine_JJ in_IN isolation_NN ,_, but_CC in_IN context_NN are_VBP clearly_RB spam_NN ._.
Several_JJ approaches_NNS based_VBN on_IN statistical_JJ analysis_NN and_CC machine_NN learning_NN have_VBP been_VBN proposed_VBN for_IN detecting_VBG spam_NN pages_NNS =_JJ -_: =[_NN 4,9,12_CD ,_, 14,19-20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, none_NN of_IN them_PRP are_VBP guaranteed_VBN to_TO succeed_VB against_IN all_DT spammers_NNS ._.
When_WRB search_NN engines_NNS counteract_VBP web_NN spam_NN using_VBG these_DT approaches_NNS ,_, they_PRP simply_RB escalate_VB the_DT arms_NNS race_NN :_: the_DT approaches_NNS work_VBP for_IN a_DT sh_NN
web_NN spam_NN ,_, though_IN still_RB not_RB at_IN the_DT same_JJ level_NN as_IN e-mail_JJ ._.
Web_NN spam_NN detection_NN includes_VBZ the_DT use_NN of_IN local_JJ content-based_JJ features_NNS -LRB-_-LRB- 22_CD -RRB-_-RRB- and_CC identifying_VBG statistical_JJ outliers_NNS -LRB-_-LRB- 25_CD -RRB-_-RRB- ._.
Other_JJ combinational_JJ models_NNS =_JJ -_: =[_NN 68_CD -RRB-_-RRB- -_: =_SYM -_: for_IN web_NN spam_NN detection_NN are_VBP also_RB beginning_VBG to_TO be_VB explored_VBN ._.
Since_IN blog_NN comment_NN spam_NN has_VBZ been_VBN a_DT problem_NN for_IN a_DT while_NN ,_, some_DT existing_VBG work_NN -LRB-_-LRB- 60_CD -RRB-_-RRB- ,_, as_RB well_RB as_IN commercial_JJ tools_NNS -LRB-_-LRB- e.g._FW ,_, Akismet_NNP ,_, -RRB-_-RRB- ,_, address_VBP the_DT pr_NN
merous_JJ methods_NNS for_IN detecting_VBG link_NN spam_NN besides_IN the_DT SpamRank-type_JJ algorithms_NNS we_PRP have_VBP mentioned_VBN here_RB ._.
Examples_NNS include_VBP applying_VBG machine_NN learning_VBG to_TO link-based_JJ features_NNS -LRB-_-LRB- 3_CD -RRB-_-RRB- ,_, the_DT analysis_NN of_IN page_NN content_NN =_JJ -_: =[_NN 15_CD ,_, 17_CD -RRB-_-RRB- -_: =_JJ -_: ,_, TrustRank_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- and_CC Anti-TrustRank_JJ -LRB-_-LRB- 18_CD -RRB-_-RRB- ,_, and_CC statistical_JJ analysis_NN of_IN various_JJ page_NN features_NNS -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
Finally_RB ,_, in_IN a_DT follow-up_NN to_TO this_DT paper_NN we_PRP use_VBP the_DT local_JJ algorithm_NN developed_VBD here_RB to_TO design_VB several_JJ local_JJ
ed_VBN with_IN the_DT intention_NN of_IN misleading_JJ search_NN engines_NNS -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
It_PRP is_VBZ reported_VBN that_IN approximately_RB 70_CD %_NN of_IN all_DT pages_NNS in_IN the_DT ._.
biz_NN domain_NN and_CC about_IN 35_CD %_NN of_IN the_DT pages_NNS in_IN the_DT ._.
us_PRP domain_NN belong_VBP to_TO the_DT spam_NN category_NN =_JJ -_: =[_NN 75_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT reason_NN for_IN the_DT increasing_VBG amount_NN of_IN Web_NN spam_NN is_VBZ explained_VBN in_IN -LRB-_-LRB- 75_CD -RRB-_-RRB- :_: Some_DT Web_NN site_NN operators_NNS try_VBP to_TO influence_VB the_DT positioning_NN of_IN their_PRP$ pages_NNS within_IN search_NN results_NNS because_IN of_IN the_DT large_JJ fraction_NN of_IN
cations_NNS besides_IN playing_VBG a_DT central_JJ role_NN in_IN many_JJ other_JJ important_JJ areas_NNS ._.
These_DT applications_NNS include_VBP :_: •_FW Near-duplicate_FW detection_NN -LRB-_-LRB- 4_CD ,_, 8_CD ,_, 16_CD ,_, 22_CD -RRB-_-RRB- ._.
•_FW Classification\/filtering_FW tasks_NNS like_IN detecting_VBG spam_NN pages_NNS =_JJ -_: =[_NN 41_CD -RRB-_-RRB- -_: =_JJ -_: ,_, spelling_NN correction_NN -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, sense_NN disambiguation_NN -LRB-_-LRB- 40_CD -RRB-_-RRB- ._.
•_CD Recommendation_NN systems_NNS -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
•_NNP Computing_NNP co-occurrence_NN and_CC co-citation_NN similarity_NN -LRB-_-LRB- 7_CD ,_, 13_CD -RRB-_-RRB- ._.
•_CD Discovering_VBG related_JJ tags_NNS in_IN folksonomies_NNS -LRB-_-LRB- 14_CD ,_, 35_CD -RRB-_-RRB- ._.
on_IN the_DT number_NN of_IN different_JJ words_NNS in_IN a_DT page_NN ,_, or_CC in_IN the_DT page_NN title_NN ,_, the_DT average_JJ length_NN of_IN words_NNS ,_, the_DT amount_NN of_IN anchor_NN text_NN ,_, the_DT fraction_NN of_IN stop-words_NNS within_IN a_DT page_NN and_CC the_DT fraction_NN of_IN visible_JJ content_NN =_JJ -_: =_JJ -LRB-_-LRB- NNMF06_NN -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT similar_JJ approach_NN that_WDT is_VBZ optimized_VBN towards_IN weblogs_NNS is_VBZ proposed_VBN by_IN Narisawa_NNP et_FW al._FW -LRB-_-LRB- NYIT06_NN -RRB-_-RRB- ._.
Automated_NNP text_NN analysis_NN methods_NNS are_VBP generally_RB imprecise_JJ ._.
Approaches_NNS to_TO increase_VB their_PRP$ precision_NN include_VBP
n_NN his_PRP$ or_CC her_PRP$ Web_NN page_NN ,_, and_CC even_RB copying_VBG large_JJ pieces_NNS of_IN text_NN from_IN popular_JJ Web_NN sites_NNS ._.
The_DT keywords_NNS are_VBP often_RB hidden_VBN by_IN showing_VBG them_PRP in_IN the_DT same_JJ color_NN as_IN the_DT background_NN of_IN the_DT Web_NN page_NN ._.
Ntoulas_FW et_FW al._FW =_SYM -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP investigated_VBN the_DT text_NN and_CC format_NN properties_NNS of_IN keyword_FW spamming_FW pages_NNS ._.
For_IN instance_NN ,_, they_PRP have_VBP found_VBN a_DT clear_JJ correlation_NN between_IN the_DT ``_`` spammicity_NN ''_'' of_IN a_DT page_NN ,_, and_CC the_DT number_NN of_IN keywords_NNS in_IN the_DT pag_NN
ted_VBN with_IN the_DT intention_NN of_IN misleading_JJ search_NN engines_NNS -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
It_PRP is_VBZ reported_VBN that_IN approximately_RB 70_CD %_NN of_IN all_DT pages_NNS in_IN the_DT ._.
biz_NN domain_NN and_CC about_IN 35_CD %_NN of_IN the_DT pages_NNS in_IN the_DT ._.
us_PRP domain_NN belong_VBP to_TO the_DT spam_NN category_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT reason_NN for_IN the_DT increasing_VBG amount_NN of_IN Web_NN spam_NN is_VBZ explained_VBN in_IN -LRB-_-LRB- 12_CD -RRB-_-RRB- :_: some_DT web_NN site_NN operators_NNS try_VBP to_TO influence_VB the_DT positioning_NN of_IN their_PRP$ pages_NNS within_IN search_NN results_NNS because_IN of_IN the_DT large_JJ fraction_NN of_IN
bination_NN of_IN these_DT techniques_NNS is_VBZ even_RB more_RBR effective_JJ ._.
Considering_VBG the_DT fact_NN ,_, that_IN ``_`` victory_NN does_VBZ not_RB require_VB perfection_NN ,_, just_RB a_DT rate_NN of_IN detection_NN that_WDT alters_VBZ the_DT economic_JJ balance_NN for_IN a_DT would-be_JJ spammer_NN ''_'' =_SYM -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, these_DT results_NNS sound_VBP very_RB promising_JJ ,_, but_CC also_RB spammers_NNS are_VBP improving_VBG their_PRP$ techniques_NNS all_PDT the_DT time_NN ._.
One_CD of_IN the_DT facts_NNS that_WDT make_VBP the_DT fight_NN against_IN spam_NN so_RB hard_RB is_VBZ that_IN spammer_NN serve_VBP different_JJ sites_NNS to_TO
2006-05_CD dataset_NN ,_, and_CC other_JJ features_NNS from_IN external_JJ data_NNS sources_NNS ._.
Our_PRP$ contributions_NNS to_TO the_DT Web_NN Spam_NNP Challenge_NNP fall_VB into_IN two_CD categories_NNS ._.
First_RB ,_, we_PRP used_VBD the_DT features_NNS introduced_VBN in_IN our_PRP$ earlier_JJR work_NN -LRB-_-LRB- -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Second_RB ,_, we_PRP incorporated_VBD features_NNS that_WDT are_VBP economic_JJ in_IN nature_NN ,_, namely_RB domain_NN registrar_NN information_NN and_CC Google_NNP AdSense_NNP publisher_NN ID_NN ._.
In_IN addition_NN to_TO the_DT features_NNS provided_VBN by_IN the_DT organizers_NNS of_IN the_DT chal_NN
alternate_JJ somewhat_RB more_RBR robust_JJ against_IN manipulations_NNS but_CC performing_VBG similarly_RB well_RB we_PRP suggest_VBP Companion_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
Our_PRP$ results_NNS are_VBP complementary_JJ to_TO the_DT recent_JJ results_NNS of_IN -LRB-_-LRB- 2_CD -RRB-_-RRB- based_VBN on_IN link_NN structure_NN and_CC of_IN =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_SYM -_: based_VBN on_IN content_NN analysis_NN ._.
We_PRP leave_VBP classification_NN based_VBN on_IN the_DT combination_NN of_IN features_NNS as_IN future_JJ work_NN ._.
2_CD ._.
RELATED_JJ RESULTS_NNS Next_IN we_PRP survey_VBP related_JJ results_NNS both_CC for_IN hyperlink_NN based_JJ spam_NN detection_NN and_CC s_NN
g_NN more_RBR dependent_JJ on_IN higher_JJR placements_NNS in_IN search_NN engines_NNS ._.
In_IN order_NN for_IN a_DT web_NN developer_NN to_TO increase_VB a_DT website_NN 's_POS ranking_NN ,_, they_PRP often_RB try_VBP to_TO deliberately_RB manipulate_VB this_DT outcome_NN -LRB-_-LRB- Henzinger_NN et_FW al._FW 2002:1_CD ;_: =_JJ -_: =_JJ Ntoulas_FW et_FW al._FW 2006_CD -_: =--RRB-_NN ._.
Henzinger_NNP et_FW al._FW refers_VBZ to_TO this_DT process_NN as_IN search_NN engine_NN spam_NN ._.
Implementing_VBG SEO_NN strategies_NNS is_VBZ not_RB spamming_VBG ,_, but_CC unethical_JJ practice_NN within_IN SEO_NNP with_IN regards_VBZ to_TO manipulating_VBG spiders_NNS and_CC redirecting_VBG us_PRP
d_NN on_IN web_NN page_NN content_NN ,_, link_NN structure_NN ,_, or_CC a_DT combination_NN of_IN these_DT ._.
Successful_JJ techniques_NNS include_VBP the_DT application_NN of_IN machine_NN learning_NN techniques_NNS to_TO link-based_JJ features_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, the_DT analysis_NN of_IN page_NN content_NN =_JJ -_: =[_NN 14_CD ,_, 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, TrustRank_NN -LRB-_-LRB- 9_CD -RRB-_-RRB- and_CC Anti-TrustRank_JJ -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, statistical_JJ analysis_NN of_IN various_JJ page_NN features_NNS -LRB-_-LRB- 6_CD -RRB-_-RRB- ,_, and_CC transductive_JJ link_NN spam_NN detection_NN -LRB-_-LRB- 18_CD -RRB-_-RRB- ._.
One_CD successful_JJ technique_NN for_IN spam_NN detection_NN has_VBZ been_VBN to_TO identify_VB
l_NN words_NNS ,_, etc_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ._.
Based_VBN on_IN such_JJ attributes_NNS ,_, it_PRP is_VBZ fairly_RB straightforward_JJ to_TO build_VB robust_JJ ,_, genre_NN independent_JJ ,_, classification_NN systems_NNS that_WDT can_MD sort_VB salads_NNS from_IN natural_JJ texts_NNS with_IN a_DT pretty_RB high_JJ accuracy_NN =_JJ -_: =[_NN 5_CD ,_, 13_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Some_DT spammers_NNS use_VBP templates_NNS ,_, scripts_NNS ,_, or_CC grammar_NN based_VBN generators_NNS like_IN the_DT ``_`` Dada-engine_NN ''_'' -LRB-_-LRB- 3_CD -RRB-_-RRB- to_TO mimic_VB efficiently_RB natural_JJ texts_NNS ._.
The_DT main_JJ weakness_NN of_IN these_DT generators_NNS is_VBZ their_PRP$ low_JJ productivity_NN and_CC t_NN
mated_VBN that_IN 10_CD %_NN to_TO 15_CD %_NN of_IN the_DT content_NN on_IN the_DT web_NN is_VBZ spam_NN -LRB-_-LRB- 24_CD -RRB-_-RRB- ._.
Spam_NNP is_VBZ prevalent_JJ in_IN some_DT web_NN portions_NNS ._.
For_IN instance_NN ,_, it_PRP was_VBD observed_VBN that_IN approximately_RB 70_CD %_NN of_IN the_DT pages_NNS under_IN the_DT ._.
BIZ_NN domain_NN were_VBD spam_NN =_JJ -_: =[_NN 43_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_JJS users_NNS are_VBP not_RB interested_JJ in_IN browsing_VBG spam_NN pages_NNS ._.
Therefore_RB ,_, these_DT data_NNS should_MD not_RB be_VB indexed_VBN ._.
5.2_CD Selection_NN of_IN descriptive_JJ texts_NNS Current_NNP search_NN engines_NNS index_NN all_DT terms_NNS contained_VBN in_IN documents_NNS to_TO
vance_NN or_CC importance_NN of_IN some_DT Web_NN page_NN or_CC pages_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
It_PRP has_VBZ been_VBN observed_VBN that_IN spam_NN and_CC non-spam_JJ pages_NNS exhibit_VBP different_JJ statistical_JJ properties_NNS which_WDT can_MD be_VB exploited_VBN for_IN building_VBG automatic_JJ classifiers_NNS =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: ._.
From_IN a_DT machine_NN learning_NN perspective_NN ,_, the_DT spam_NN detection_NN task_NN differs_VBZ from_IN a_DT typical_JJ classification_NN task_NN since_IN not_RB only_RB do_VBP we_PRP have_VB standard_JJ features_NNS available_JJ for_IN every_DT page\/host_NN ,_, but_CC we_PRP are_VBP also_RB giv_NN
ms_NNS into_IN their_PRP$ ranking_JJ schemes_NNS ,_, web_NN spam_NN appears_VBZ in_IN sophisticated_JJ forms_NNS that_WDT manipulate_VBP content_NN as_RB well_RB as_IN linkage_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ._.
In_IN addition_NN to_TO link-based_JJ ,_, spam_NN hunters_NNS use_VBP a_DT variety_NN of_IN content_NN based_VBN features_NNS =_JJ -_: =[_NN 8_CD ,_, 16_CD ,_, 9_CD -RRB-_-RRB- -_: =_SYM -_: to_TO detect_VB web_NN spam_NN ;_: a_DT recent_JJ measurement_NN of_IN their_PRP$ combination_NN appears_VBZ in_IN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
Content_NN based_VBN email_JJ spam_NN detection_NN methods_NNS worked_VBD well_RB for_IN web_NN spam_NN already_RB at_IN the_DT Web_NN Spam_NNP Challenge_NNP 2007_CD -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
1.1_CD Data_NN
ude_NN bookmark_NN ,_, comment_NN and_CC post_NN spam_NN that_WDT became_VBD widespread_JJ with_IN the_DT explosion_NN of_IN the_DT social_JJ media_NNS ._.
Various_JJ top-level_JJ or_CC otherwise_RB selected_VBN domains_NNS may_MD have_VB different_JJ spamming_JJ behavior_NN ;_: Ntoulas_NNP et_FW al._FW =_SYM -_: =[_NN 37_CD -RRB-_-RRB- -_: =_JJ -_: give_VB an_DT invaluable_JJ comparison_NN that_WDT show_VBP major_JJ differences_NNS among_IN national_JJ domains_NNS and_CC languages_NNS of_IN the_DT page_NN ._.
For_IN the_DT ._.
de_IN domain_NN their_PRP$ findings_NNS agree_VBP with_IN 16.5_CD %_NN of_IN all_DT pages_NNS being_VBG spam_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- while_IN for_IN th_DT
nchor_JJ text_NN and_CC link_NN analysis_NN algorithms_NNS into_IN their_PRP$ ranking_JJ schemes_NNS ,_, Web_NN spam_NN appears_VBZ in_IN sophisticated_JJ forms_NNS that_WDT manipulate_VBP content_NN as_RB well_RB as_IN linkage_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ._.
Spam_NNP hunters_NNS use_VBP a_DT variety_NN of_IN both_DT content_NN =_JJ -_: =[_NN 7_CD ,_, 19_CD -RRB-_-RRB- -_: =_JJ -_: and_CC link_NN -LRB-_-LRB- 12_CD ,_, 6_CD ,_, 25_CD ,_, 3_CD ,_, 2_CD -RRB-_-RRB- based_VBN features_NNS to_TO detect_VB Web_NN spam_NN ;_: a_DT recent_JJ measurement_NN of_IN their_PRP$ combination_NN appears_VBZ in_IN -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
Recently_RB several_JJ results_NNS has_VBZ appeared_VBN that_WDT apply_VBP rank_JJ propagation_NN to_TO extend_VB ini_NNS
g_NN into_IN this_DT aspect_NN of_IN the_DT blogosphere_NN ._.
Although_IN it_PRP is_VBZ a_DT relatively_RB new_JJ phenomenon_NN ,_, researchers_NNS have_VBP compared_VBN it_PRP with_IN the_DT existing_VBG work_NN on_IN web_NN -LRB-_-LRB- link_NN -RRB-_-RRB- spam_NN detection_NN ._.
For_IN web_NN spam_NN detection_NN ,_, authors_NNS in_IN =_JJ -_: =[_NN 42_CD -RRB-_-RRB- -_: =_SYM -_: distinguish_VBP between_IN normal_JJ web_NN pages_NNS and_CC spam_NN webpages_NNS based_VBN on_IN the_DT statistical_JJ properties_NNS like_IN ,_, number_NN of_IN words_NNS ,_, average_JJ length_NN of_IN words_NNS ,_, anchor_NN text_NN ,_, title_NN keyword_VBD frequency_NN ,_, tokenized_VBN URL_NN ._.
Some_DT wo_MD
ike_JJ previous_JJ research_NN ,_, we_PRP propose_VBP to_TO use_VB the_DT category_NN propagation_NN as_IN an_DT intermediate_JJ step_NN towards_IN the_DT computation_NN of_IN new_JJ features_NNS which_WDT can_MD improve_VB current_JJ machine_NN learning_NN methods_NNS for_IN spam_NN detection_NN =_JJ -_: =[_NN 3_CD ,_, 6_CD ,_, 7_CD ,_, 15_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP deploy_VBP the_DT syntactic_JJ and_CC semantic_JJ features_NNS in_IN two_CD applications_NNS :_: Web_NN spam_NN detection_NN ._.
Our_PRP$ intuition_NN is_VBZ that_IN spammers_NNS have_VBP an_DT incentive_NN to_TO aim_VB at_IN the_DT top_JJ results_NNS of_IN frequent_JJ queries_NNS ,_, and_CC to_TO aim_VB at_IN q_NN
ws_NNS from_IN both_CC academia_NN and_CC industry_NN ._.
However_RB ,_, the_DT existing_VBG work_NN has_VBZ been_VBN mainly_RB focused_VBN on_IN extracting_VBG and_CC summarizing_VBG opinions_NNS from_IN reviews_NNS using_VBG natural_JJ language_NN processing_NN and_CC data_NN mining_NN techniques_NNS =_JJ -_: =[_NN 7_CD ,_, 12_CD ,_, 19_CD ,_, 20_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Little_JJ is_VBZ known_VBN about_IN the_DT characteristics_NNS of_IN reviews_NNS and_CC behaviors_NNS of_IN reviewers_NNS ._.
There_EX is_VBZ also_RB no_RB reported_VBD study_NN on_IN the_DT trustworthiness_NN of_IN opinions_NNS in_IN reviews_NNS ._.
Due_JJ to_TO the_DT fact_NN that_IN there_EX is_VBZ no_DT quali_NN
roadly_RB classified_VBN in_IN two_CD groups_NNS :_: content_NN -LRB-_-LRB- or_CC keyword_JJ -RRB-_-RRB- spam_NN ,_, and_CC link_NN spam_NN ._.
Content_NN spam_NN refers_VBZ to_TO changes_NNS in_IN the_DT content_NN of_IN the_DT pages_NNS ,_, for_IN instance_NN by_IN inserting_VBG a_DT large_JJ number_NN of_IN keywords_NNS -LRB-_-LRB- 9_CD ,_, 11_CD -RRB-_-RRB- ._.
In_IN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_JJ -_: ,_, it_PRP is_VBZ shown_VBN that_IN 82-86_CD %_NN of_IN spam_NN pages_NNS of_IN this_DT type_NN can_MD be_VB detected_VBN by_IN an_DT automatic_JJ classifier_NN ._.
The_DT features_NNS used_VBN for_IN the_DT classification_NN include_VBP ,_, amongst_IN others_NNS :_: the_DT number_NN of_IN words_NNS in_IN the_DT text_NN of_IN th_DT
ount_NN of_IN spam_NN pages_NNS ._.
Many_JJ approaches_NNS exist_VBP to_TO identify_VB spam_NN pages_NNS based_VBN on_IN page_NN content_NN ,_, hyperlink_NN structure_NN ,_, URL_NN form_NN ,_, the_DT similarity_NN between_IN pages_NNS of_IN a_DT single_JJ host_NN and_CC combinations_NNS of_IN those_DT features_NNS =_JJ -_: =[_NN 1_CD ,_, 2_CD ,_, 3_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN the_DT TREC_NN experiments_NNS we_PRP implemented_VBD a_DT basic_JJ spam_NN detection_NN mechanism_NN ,_, that_WDT relies_VBZ on_IN page_NN content_NN ,_, page_NN title_NN features_NNS and_CC URL_NN form_NN ._.
In_IN a_DT first_JJ step_NN ,_, we_PRP determined_VBD the_DT number_NN of_IN different_JJ hostna_NNS
rmation_NN can_MD then_RB be_VB used_VBN with_IN common_JJ ,_, link-based_JJ ranking_NN algorithms_NNS ,_, such_JJ as_IN PageRank_NNP or_CC HITS_NNP ._.
The_DT same_JJ authors_NNS also_RB present_VBP their_PRP$ findings_NNS on_IN cloaking_NN and_CC redirection_NN techniques_NNS -LRB-_-LRB- 21_CD -RRB-_-RRB- ._.
Ntoulas_FW et_FW al._FW =_SYM -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: present_VB a_DT technique_NN of_IN detecting_VBG spam_NN pages_NNS by_IN content_NN analysis_NN ._.
This_DT work_NN only_RB takes_VBZ query_JJ independent_JJ features_NNS into_IN account_NN ,_, while_IN Svore_NNP et_FW al._FW -LRB-_-LRB- 18_CD -RRB-_-RRB- also_RB use_VBP query_JJ dependent_JJ information_NN ._.
A_DT system_NN t_NN
nerating_VBG pages_NNS by_IN developing_VBG tools_NNS to_TO find_VB invalid_JJ links_NNS ,_, to_TO automatically_RB correct_VB links_NNS that_WDT lead_VBP to_TO file_VB not_RB found_VBN errors_NNS -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC to_TO find_VB irrelevant_JJ -LRB-_-LRB- and_CC possibly_RB annoying_JJ or_CC offensive_JJ -RRB-_-RRB- spam_NN pages_NNS =_JJ -_: =[_NN 12_CD ,_, 17_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, none_NN consider_VBP that_IN the_DT link_NN context_NN changes_NNS over_IN time_NN ._.
That_DT is_VBZ ,_, the_DT two_CD end_NN points_NNS of_IN a_DT link_NN may_MD change_VB in_IN different_JJ ``_`` directions_NNS ''_'' rendering_VBG the_DT link_NN inappropriate_JJ ._.
Therefore_RB ,_, in_IN this_DT paper_NN
s_NNS become_VBP a_DT sort_NN of_IN obsession_NN for_IN many_JJ companies_NNS '_POS IT_NNP departments_NNS ,_, and_CC the_DT raison_FW d’être_FW of_IN spamming_VBG companies_NNS ._.
Some_DT estimates_NNS indicate_VBP that_IN at_IN least_JJS 13.8_CD %_NN of_IN all_DT English-language_JJ pages_NNS indexed_VBN is_VBZ spam_NN =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: while_IN experts_NNS consider_VBP web_NN spamming_VBG the_DT single_JJ most_RBS difficult_JJ challenge_NN web_NN searching_VBG is_VBZ facing_VBG today_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
Search_VB engines_NNS typically_RB see_VBP web_NN spam_NN as_IN an_DT interference_NN to_TO their_PRP$ operations_NNS and_CC would_MD like_VB t_NN
downweighted_VBN ._.
This_DT can_MD be_VB accomplished_VBN naturally_RB by_IN mixing_VBG the_DT Document_NNP Frequency_NN -LRB-_-LRB- DF_NN -RRB-_-RRB- with_IN the_DT correlation_NN function_NN ._.
Thus_RB ,_, the_DT ACR_NN used_VBN in_IN this_DT paper_NN is_VBZ defined_VBN as_IN :_: ACR_NN -LRB-_-LRB- y_NN ,_, xk_NN -RRB-_-RRB- =_JJ log_NN -LRB-_-LRB- DF_NN -LRB-_-LRB- xk_NN -RRB-_-RRB- -RRB-_-RRB- ·_FW |_FW ρ_NN -LRB-_-LRB- y_NN ,_, xk_NN -RRB-_-RRB- |_NN =_JJ -_: =-LRB-_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: It_PRP is_VBZ easy_JJ to_TO see_VB that_IN the_DT proposed_VBN function_NN is_VBZ a_DT combination_NN of_IN supervised_JJ and_CC unsupervised_JJ weighting_NN functions_NNS ,_, since_IN the_DT correlation_NN takes_VBZ the_DT class_NN labels_NNS into_IN consideration_NN ,_, while_IN DF_NN does_VBZ not_RB ._.
A_DT
arch_NN engines_NNS referrals_NNS ._.
For_IN example_NN ,_, Jacob_NNP Nielsen_NNP 's_POS site_NN ``_`` HypertextNow_NNP ''_'' ,_, which_WDT attracts_VBZ visitors_NNS interested_JJ in_IN web_NN ratings_NNS and_CC usability_NN ,_, receives_VBZ about_IN a_DT third_JJ of_IN its_PRP$ traffic_NN through_IN such_JJ referrals_NNS =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC search_NN engine_NN referrals_NNS have_VBP increased_VBN by_IN about_RB 10_CD %_NN in_IN the_DT last_JJ year_NN ._.
For_IN many_JJ commercial_JJ web_NN sites_NNS ,_, an_DT increase_NN in_IN search_NN engine_NN referrals_NNS translates_VBZ to_TO an_DT increase_NN in_IN sales_NNS ,_, revenue_NN ,_, and_CC ,_, one_CD
uss_JJ prior_JJ studies_NNS that_WDT exhibit_VBP commonalities_NNS with_IN our_PRP$ own_JJ ._.
Machine_NN learning_NN techniques_NNS ,_, similar_JJ to_TO the_DT C4_NN .5_CD classifier_NN that_IN we_PRP used_VBD in_IN Section_NNP 5_CD ,_, have_VBP been_VBN successfully_RB used_VBN to_TO fight_VB email_NN spam_NN -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 16_CD ,_, 28_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Here_RB ,_, we_PRP confirm_VBP the_DT potential_NN of_IN machine_NN learning_VBG to_TO identify_VB spam_NN text_NN ,_, but_CC we_PRP focus_VBP on_IN the_DT orthogonal_JJ problem_NN of_IN web_NN spam_NN ,_, where_WRB the_DT text_NN is_VBZ meant_VBN for_IN search_NN engine_NN consumption_NN and_CC not_RB human_JJ rea_NN
am_VB web_NN page_NN to_TO fool_VB all_DT of_IN our_PRP$ techniques_NNS ,_, we_PRP may_MD see_VB some_DT degradation_NN of_IN the_DT classification_NN performance_NN over_IN time_NN ._.
To_TO accommodate_VB for_IN this_DT we_PRP plan_VBP to_TO study_VB how_WRB we_PRP can_MD use_VB naturalslanguage_NN techniques_NNS =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: to_TO recognize_VB artificially_RB generated_VBN text_NN ._.
Additionally_RB ,_, the_DT heuristic_NN methods_NNS that_IN we_PRP presented_VBD in_IN this_DT paper_NN may_MD very_RB well_RB serve_VB as_IN part_NN of_IN a_DT ``_`` multi-layered_JJ ''_'' spam_NN detection_NN system_NN ._.
In_IN the_DT first_JJ laye_NN
ing_JJ Classification_NN Accuracy_NN We_PRP have_VBP also_RB experimented_VBN with_IN various_JJ techniques_NNS for_IN improving_VBG the_DT accuracy_NN of_IN our_PRP$ classifier_NN ._.
Here_RB ,_, we_PRP will_MD report_VB on_IN the_DT two_CD most_RBS popular_JJ ones_NNS :_: bagging_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- and_CC boosting_VBG =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Both_DT of_IN these_DT techniques_NNS essentially_RB create_VBP a_DT set_NN of_IN classifiers_NNS ,_, which_WDT are_VBP then_RB combined_VBN to_TO form_VB a_DT composite_JJ classifier_NN ._.
In_IN most_JJS cases_NNS ,_, the_DT composite_JJ classifier_NN performs_VBZ better_JJR than_IN any_DT individual_NN
uss_JJ prior_JJ studies_NNS that_WDT exhibit_VBP commonalities_NNS with_IN our_PRP$ own_JJ ._.
Machine_NN learning_NN techniques_NNS ,_, similar_JJ to_TO the_DT C4_NN .5_CD classifier_NN that_IN we_PRP used_VBD in_IN Section_NNP 5_CD ,_, have_VBP been_VBN successfully_RB used_VBN to_TO fight_VB email_NN spam_NN -LRB-_-LRB- e.g._FW =_JJ -_: =[_NN 16_CD ,_, 28_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Here_RB ,_, we_PRP confirm_VBP the_DT potential_NN of_IN machine_NN learning_VBG to_TO identify_VB spam_NN text_NN ,_, but_CC we_PRP focus_VBP on_IN the_DT orthogonal_JJ problem_NN of_IN web_NN spam_NN ,_, where_WRB the_DT text_NN is_VBZ meant_VBN for_IN search_NN engine_NN consumption_NN and_CC not_RB human_JJ rea_NN
hich_NN finds_VBZ non-spam_JJ pages_NNS by_IN following_VBG links_NNS from_IN an_DT initial_JJ seed_NN set_NN of_IN trusted_VBN pages_NNS ._.
Benczúr_NNP et_FW al._FW -LRB-_-LRB- 4_CD -RRB-_-RRB- show_VBP how_WRB to_TO penalize_VB pages_NNS that_WDT have_VBP ``_`` suspiciously_RB ''_'' increased_VBD their_PRP$ PageRank_NN ._.
Wu_NNP and_CC Davison_NNP =_SYM -_: =[_NN 29_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Gyöngyi_NNP and_CC Garcia-Molina_NNP -LRB-_-LRB- 12_CD -RRB-_-RRB- study_NN how_WRB to_TO detect_VB link_NN farms_NNS -LRB-_-LRB- i.e._FW sites_NNS exchanging_VBG links_NNS for_IN mutual_JJ benefit_NN -RRB-_-RRB- ._.
In_IN -LRB-_-LRB- 8_CD -RRB-_-RRB- we_PRP showed_VBD ways_NNS of_IN identifying_VBG link_NN spam_NN based_VBN on_IN divergence_NN of_IN sites_NNS from_IN po_NN
ce_NN of_IN serving_VBG different_JJ copies_NNS of_IN a_DT web_NN page_NN depending_VBG on_IN whether_IN the_DT visitor_NN is_VBZ a_DT crawler_NN or_CC a_DT user_NN ._.
Gyöngyi_NNP and_CC Garcia-Molina_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- present_VBP an_DT overview_NN of_IN current_JJ cloaking_VBG techniques_NNS ._.
Wu_NNP and_CC Davison_NNP =_SYM -_: =[_NN 30_CD -RRB-_-RRB- -_: =_SYM -_: demonstrate_VBP the_DT effectiveness_NN of_IN a_DT cloaking_VBG detection_NN method_NN that_WDT is_VBZ based_VBN on_IN calculating_VBG common_JJ words_NNS among_IN three_CD separate_JJ copies_NNS of_IN a_DT page_NN ._.
It_PRP should_MD be_VB noted_VBN that_IN cloaking_VBG has_VBZ uses_NNS which_WDT are_VBP benef_NN
show_VBP that_IN generating_VBG pages_NNS with_IN links_NNS targeting_VBG a_DT single_JJ page_NN is_VBZ the_DT most_RBS effective_JJ means_NNS of_IN link_NN spam_NN ._.
To_TO this_DT end_NN ,_, Zhang_NNP et_FW al._FW -LRB-_-LRB- 31_CD -RRB-_-RRB- show_VBP how_WRB to_TO make_VB PageRank_NN robust_JJ against_IN attacks_NNS ;_: Gyöngyi_NNP et_FW al._FW =_SYM -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: introduce_VB TrustRank_NNP which_WDT finds_VBZ non-spam_JJ pages_NNS by_IN following_VBG links_NNS from_IN an_DT initial_JJ seed_NN set_NN of_IN trusted_VBN pages_NNS ._.
Benczúr_NNP et_FW al._FW -LRB-_-LRB- 4_CD -RRB-_-RRB- show_VBP how_WRB to_TO penalize_VB pages_NNS that_WDT have_VBP ``_`` suspiciously_RB ''_'' increased_VBD their_PRP$ Pag_NN
ivity_NN features_NNS of_IN pages_NNS into_IN a_DT rulebased_JJ classifier_NN ,_, in_IN order_NN to_TO identify_VB link_NN spam_NN ._.
Baeza-Yates_NNP et_FW al._FW -LRB-_-LRB- 3_CD -RRB-_-RRB- present_VBP a_DT study_NN of_IN collusion_NN topologies_NNS designed_VBD tot_NN boost_NN PageRank_NN -LRB-_-LRB- 24_CD -RRB-_-RRB- while_IN Adali_NNP et_FW al._FW =_SYM -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: show_VBP that_IN generating_VBG pages_NNS with_IN links_NNS targeting_VBG a_DT single_JJ page_NN is_VBZ the_DT most_RBS effective_JJ means_NNS of_IN link_NN spam_NN ._.
To_TO this_DT end_NN ,_, Zhang_NNP et_FW al._FW -LRB-_-LRB- 31_CD -RRB-_-RRB- show_VBP how_WRB to_TO make_VB PageRank_NN robust_JJ against_IN attacks_NNS ;_: Gyöngyi_NNP et_FW al._FW ._.
fits_NNS ._.
According_VBG to_TO the_DT US_NNP Census_NNP Bureau_NNP ,_, total_JJ US_NNP e-Commerce_NN sales_NNS in_IN 2004_CD amounted_VBD to_TO $_$ 69.2_CD billion_CD -LRB-_-LRB- or_CC 1.9_CD %_NN of_IN total_JJ US_NNP sales_NNS -RRB-_-RRB- ,_, and_CC web-based_JJ e-Commerce_NN continues_VBZ to_TO grow_VB at_IN a_DT rate_NN of_IN 7.8_CD %_NN per_IN year_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Forrester_NNP Research_NNP predicts_VBZ that_IN online_JJ US_NNP business-toconsumer_NN sales_NNS of_IN goods_NNS including_VBG auctions_NNS and_CC travel_NN will_MD amount_VB to_TO $_$ 172_CD billion_CD in_IN 2005_CD -LRB-_-LRB- 18_CD -RRB-_-RRB- ,_, and_CC will_MD grow_VB to_TO $_$ 329_CD billion_CD in_IN 2010_CD ,_, accountin_NN
merce_NN continues_VBZ to_TO grow_VB at_IN a_DT rate_NN of_IN 7.8_CD %_NN per_IN year_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- ._.
Forrester_NNP Research_NNP predicts_VBZ that_IN online_JJ US_NNP business-toconsumer_NN sales_NNS of_IN goods_NNS including_VBG auctions_NNS and_CC travel_NN will_MD amount_VB to_TO $_$ 172_CD billion_CD in_IN 2005_CD =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC will_MD grow_VB to_TO $_$ 329_CD billion_CD in_IN 2010_CD ,_, accounting_VBG for_IN 13_CD %_NN of_IN all_DT US_NNP retail_JJ sales_NNS ._.
In_IN order_NN for_IN commercial_JJ web_NN sites_NNS to_TO tap_VB into_IN this_DT accelerating_VBG market_NN ,_, they_PRP have_VBP to_TO increase_VB their_PRP$ traffic_NN ,_, which_WDT i_LS
for_IN search_NN engine_NN consumption_NN and_CC not_RB human_JJ readers_NNS ._.
Regarding_VBG the_DT general_JJ role_NN and_CC mechanics_NNS of_IN web_NN spam_NN ,_, Henzinger_NNP et_FW al._FW -LRB-_-LRB- 15_CD -RRB-_-RRB- acknowledged_VBD the_DT impact_NN of_IN web_NN spam_NN on_IN search_NN engine_NN quality_NN ._.
Perkins_NNP =_SYM -_: =[_NN 25_CD -RRB-_-RRB- -_: =_SYM -_: defines_VBZ a_DT number_NN of_IN spamming_VBG techniques_NNS ,_, in_IN a_DT paper_NN advocating_VBG ethical_JJ behavior_NN ._.
Gyöngyi_NNP and_CC GarciaMolina_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- provide_VBP a_DT more_RBR formal_JJ taxonomy_NN of_IN web_NN spam_NN ._.
Metaxas_NNP and_CC DeStefano_NNP -LRB-_-LRB- 20_CD -RRB-_-RRB- point_NN out_IN the_DT rel_NN
on_IN topologies_NNS designed_VBN tot_NN boost_NN PageRank_NN -LRB-_-LRB- 24_CD -RRB-_-RRB- while_IN Adali_NNP et_FW al._FW -LRB-_-LRB- 1_LS -RRB-_-RRB- show_VBP that_IN generating_VBG pages_NNS with_IN links_NNS targeting_VBG a_DT single_JJ page_NN is_VBZ the_DT most_RBS effective_JJ means_NNS of_IN link_NN spam_NN ._.
To_TO this_DT end_NN ,_, Zhang_NNP et_FW al._FW =_SYM -_: =[_NN 31_CD -RRB-_-RRB- -_: =_SYM -_: show_VB how_WRB to_TO make_VB PageRank_NN robust_JJ against_IN attacks_NNS ;_: Gyöngyi_NNP et_FW al._FW -LRB-_-LRB- 11_CD -RRB-_-RRB- introduce_VBP TrustRank_NN which_WDT finds_VBZ non-spam_JJ pages_NNS by_IN following_VBG links_NNS from_IN an_DT initial_JJ seed_NN set_NN of_IN trusted_VBN pages_NNS ._.
Benczúr_NNP et_FW al._FW -LRB-_-LRB- 4_LS -RRB-_-RRB- s_NN
ct_VB it_PRP and_CC ameliorate_VB its_PRP$ effect_NN on_IN link-based_JJ ranking_JJ algorithms_NNS ._.
Amitay_NNP et_FW al._FW -LRB-_-LRB- 2_LS -RRB-_-RRB- feed_NN connectivity_NN features_NNS of_IN pages_NNS into_IN a_DT rulebased_JJ classifier_NN ,_, in_IN order_NN to_TO identify_VB link_NN spam_NN ._.
Baeza-Yates_NNP et_FW al._FW =_SYM -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: present_VB a_DT study_NN of_IN collusion_NN topologies_NNS designed_VBD tot_NN boost_NN PageRank_NN -LRB-_-LRB- 24_CD -RRB-_-RRB- while_IN Adali_NNP et_FW al._FW -LRB-_-LRB- 1_LS -RRB-_-RRB- show_VBP that_IN generating_VBG pages_NNS with_IN links_NNS targeting_VBG a_DT single_JJ page_NN is_VBZ the_DT most_RBS effective_JJ means_NNS of_IN link_NN spam_NN ._.
pages_NNS ._.
5.1_CD Improving_NN Classification_NN Accuracy_NN We_PRP have_VBP also_RB experimented_VBN with_IN various_JJ techniques_NNS for_IN improving_VBG the_DT accuracy_NN of_IN our_PRP$ classifier_NN ._.
Here_RB ,_, we_PRP will_MD report_VB on_IN the_DT two_CD most_RBS popular_JJ ones_NNS :_: bagging_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: and_CC boosting_VBG -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
Both_DT of_IN these_DT techniques_NNS essentially_RB create_VBP a_DT set_NN of_IN classifiers_NNS ,_, which_WDT are_VBP then_RB combined_VBN to_TO form_VB a_DT composite_JJ classifier_NN ._.
In_IN most_JJS cases_NNS ,_, the_DT composite_JJ classifier_NN performs_VBZ better_RB th_DT
pam_NN and_CC cloaking_NN ._.
Link_NN spam_NN is_VBZ the_DT practice_NN of_IN adding_VBG extraneous_JJ and_CC misleading_JJ links_NNS to_TO web_NN pages_NNS ,_, or_CC adding_VBG extraneous_JJ pages_NNS just_RB to_TO contain_VB links_NNS ._.
An_DT early_JJ paper_NN investigating_VBG link_NN spam_NN is_VBZ Davison_NNP =_SYM -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT considered_VBD nepotistic_JJ links_NNS ._.
Since_IN then_RB ,_, a_DT number_NN of_IN papers_NNS have_VBP focused_VBN on_IN link_NN spam_NN and_CC ways_NNS to_TO detect_VB it_PRP and_CC ameliorate_VB its_PRP$ effect_NN on_IN link-based_JJ ranking_JJ algorithms_NNS ._.
Amitay_NNP et_FW al._FW -LRB-_-LRB- 2_LS -RRB-_-RRB- feed_NN c_NN
variation_NN in_IN the_DT number_NN of_IN words_NNS in_IN each_DT page_NN within_IN a_DT site_NN ,_, and_CC frequent_JJ and_CC extensive_JJ content_NN revisions_NNS of_IN pages_NNS between_IN successive_JJ visits_NNS ,_, are_VBP ,_, in_IN most_JJS cases_NNS ,_, good_JJ indicators_NNS of_IN spam_NN web_NN pages_NNS ._.
In_IN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_JJ -_: we_PRP investigated_VBD the_DT special_JJ case_NN of_IN ``_`` cut-and-paste_JJ ''_'' content_NN spam_NN ,_, where_WRB web_NN pages_NNS are_VBP mosaics_NNS of_IN textual_JJ chunks_NNS copied_VBN from_IN legitimate_JJ pages_NNS on_IN the_DT web_NN ,_, and_CC we_PRP presented_VBD methods_NNS for_IN detecting_VBG such_JJ pa_NN
et_FW al._FW -LRB-_-LRB- 2_LS -RRB-_-RRB- feed_NN connectivity_NN features_NNS of_IN pages_NNS into_IN a_DT rulebased_JJ classifier_NN ,_, in_IN order_NN to_TO identify_VB link_NN spam_NN ._.
Baeza-Yates_NNP et_FW al._FW -LRB-_-LRB- 3_CD -RRB-_-RRB- present_VBP a_DT study_NN of_IN collusion_NN topologies_NNS designed_VBD tot_NN boost_NN PageRank_NN =_JJ -_: =[_NN 24_CD -RRB-_-RRB- -_: =_SYM -_: while_IN Adali_NNP et_FW al._FW -LRB-_-LRB- 1_LS -RRB-_-RRB- show_VBP that_IN generating_VBG pages_NNS with_IN links_NNS targeting_VBG a_DT single_JJ page_NN is_VBZ the_DT most_RBS effective_JJ means_NNS of_IN link_NN spam_NN ._.
To_TO this_DT end_NN ,_, Zhang_NNP et_FW al._FW -LRB-_-LRB- 31_CD -RRB-_-RRB- show_VBP how_WRB to_TO make_VB PageRank_NN robust_JJ against_IN
2_LS -RRB-_-RRB- study_NN how_WRB to_TO detect_VB link_NN farms_NNS -LRB-_-LRB- i.e._FW sites_NNS exchanging_VBG links_NNS for_IN mutual_JJ benefit_NN -RRB-_-RRB- ._.
In_IN -LRB-_-LRB- 8_CD -RRB-_-RRB- we_PRP showed_VBD ways_NNS of_IN identifying_VBG link_NN spam_NN based_VBN on_IN divergence_NN of_IN sites_NNS from_IN power_NN laws_NNS ._.
Finally_RB ,_, Mishne_NNP et_FW al._FW =_SYM -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: present_VB a_DT probabilistic_JJ method_NN operating_VBG on_IN word_NN frequencies_NNS ,_, which_WDT identifies_VBZ the_DT special_JJ case_NN of_IN link_NN spam_NN within_IN blog_NN comments_NNS ._.
Our_PRP$ work_NN in_IN this_DT paper_NN is_VBZ complementary_JJ to_TO these_DT studies_NNS ,_, since_IN we_PRP a_DT
avison_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- ,_, which_WDT considered_VBD nepotistic_JJ links_NNS ._.
Since_IN then_RB ,_, a_DT number_NN of_IN papers_NNS have_VBP focused_VBN on_IN link_NN spam_NN and_CC ways_NNS to_TO detect_VB it_PRP and_CC ameliorate_VB its_PRP$ effect_NN on_IN link-based_JJ ranking_JJ algorithms_NNS ._.
Amitay_NNP et_FW al._FW =_SYM -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: feed_NN connectivity_NN features_NNS of_IN pages_NNS into_IN a_DT rulebased_JJ classifier_NN ,_, in_IN order_NN to_TO identify_VB link_NN spam_NN ._.
Baeza-Yates_NNP et_FW al._FW -LRB-_-LRB- 3_CD -RRB-_-RRB- present_VBP a_DT study_NN of_IN collusion_NN topologies_NNS designed_VBD tot_NN boost_NN PageRank_NN -LRB-_-LRB- 24_CD -RRB-_-RRB- while_IN
-LRB-_-LRB- 31_CD -RRB-_-RRB- show_VBP how_WRB to_TO make_VB PageRank_NN robust_JJ against_IN attacks_NNS ;_: Gyöngyi_NNP et_FW al._FW -LRB-_-LRB- 11_CD -RRB-_-RRB- introduce_VBP TrustRank_NN which_WDT finds_VBZ non-spam_JJ pages_NNS by_IN following_VBG links_NNS from_IN an_DT initial_JJ seed_NN set_NN of_IN trusted_VBN pages_NNS ._.
Benczúr_NNP et_FW al._FW =_SYM -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: show_VB how_WRB to_TO penalize_VB pages_NNS that_WDT have_VBP ``_`` suspiciously_RB ''_'' increased_VBD their_PRP$ PageRank_NN ._.
Wu_NNP and_CC Davison_NNP -LRB-_-LRB- 29_CD -RRB-_-RRB- and_CC Gyöngyi_NNP and_CC Garcia-Molina_NNP -LRB-_-LRB- 12_CD -RRB-_-RRB- study_NN how_WRB to_TO detect_VB link_NN farms_NNS -LRB-_-LRB- i.e._FW sites_NNS exchanging_VBG links_NNS for_IN mu_NN
ing_NN links_NNS from_IN an_DT initial_JJ seed_NN set_NN of_IN trusted_VBN pages_NNS ._.
Benczúr_NNP et_FW al._FW -LRB-_-LRB- 4_CD -RRB-_-RRB- show_VBP how_WRB to_TO penalize_VB pages_NNS that_WDT have_VBP ``_`` suspiciously_RB ''_'' increased_VBD their_PRP$ PageRank_NN ._.
Wu_NNP and_CC Davison_NNP -LRB-_-LRB- 29_CD -RRB-_-RRB- and_CC Gyöngyi_NNP and_CC Garcia-Molina_NNP =_SYM -_: =[_NN 12_CD -RRB-_-RRB- -_: =_JJ -_: study_NN how_WRB to_TO detect_VB link_NN farms_NNS -LRB-_-LRB- i.e._FW sites_NNS exchanging_VBG links_NNS for_IN mutual_JJ benefit_NN -RRB-_-RRB- ._.
In_IN -LRB-_-LRB- 8_CD -RRB-_-RRB- we_PRP showed_VBD ways_NNS of_IN identifying_VBG link_NN spam_NN based_VBN on_IN divergence_NN of_IN sites_NNS from_IN power_NN laws_NNS ._.
Finally_RB ,_, Mishne_NNP et_FW al._FW -LRB-_-LRB- 2_CD
zinger_NN et_FW al._FW -LRB-_-LRB- 15_CD -RRB-_-RRB- acknowledged_VBD the_DT impact_NN of_IN web_NN spam_NN on_IN search_NN engine_NN quality_NN ._.
Perkins_NNP -LRB-_-LRB- 25_CD -RRB-_-RRB- defines_VBZ a_DT number_NN of_IN spamming_VBG techniques_NNS ,_, in_IN a_DT paper_NN advocating_VBG ethical_JJ behavior_NN ._.
Gyöngyi_NNP and_CC GarciaMolina_NNP =_SYM -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: provide_VBP a_DT more_RBR formal_JJ taxonomy_NN of_IN web_NN spam_NN ._.
Metaxas_NNP and_CC DeStefano_NNP -LRB-_-LRB- 20_CD -RRB-_-RRB- point_NN out_IN the_DT relationship_NN between_IN web_NN spam_NN and_CC other_JJ sources_NNS of_IN untrustworthy_JJ information_NN ,_, namely_RB propaganda_NN ._.
In_IN general_JJ ,_, these_DT
quality_NN ._.
Perkins_NNP -LRB-_-LRB- 25_CD -RRB-_-RRB- defines_VBZ a_DT number_NN of_IN spamming_VBG techniques_NNS ,_, in_IN a_DT paper_NN advocating_VBG ethical_JJ behavior_NN ._.
Gyöngyi_NNP and_CC GarciaMolina_NNP -LRB-_-LRB- 13_CD -RRB-_-RRB- provide_VBP a_DT more_RBR formal_JJ taxonomy_NN of_IN web_NN spam_NN ._.
Metaxas_NNP and_CC DeStefano_NNP =_SYM -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: point_NN out_IN the_DT relationship_NN between_IN web_NN spam_NN and_CC other_JJ sources_NNS of_IN untrustworthy_JJ information_NN ,_, namely_RB propaganda_NN ._.
In_IN general_JJ ,_, these_DT studies_NNS recognize_VBP and_CC address_VBP three_CD principal_JJ kinds_NNS of_IN web_NN spam_NN :_: link_NN
users_NNS to_TO visit_VB their_PRP$ web_NN sites_NNS ._.
The_DT practices_NNS of_IN crafting_VBG web_NN pages_NNS for_IN the_DT sole_JJ purpose_NN of_IN increasing_VBG the_DT ranking_NN of_IN these_DT or_CC some_DT affiliated_JJ pages_NNS ,_, without_IN improving_VBG the_DT utility_NN to_TO 1_CD A_NN recent_JJ study_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_JJ -_: showed_VBD that_IN approximately_RB 80_CD %_NN of_IN search_NN engine_NN users_NNS look_VBP at_IN no_DT more_JJR than_IN the_DT first_JJ 3_CD batches_NNS of_IN results_NNS ._.
Therefore_RB ,_, unless_IN a_DT site_NN is_VBZ listed_VBN in_IN the_DT first_JJ few_JJ results_NNS ,_, it_PRP is_VBZ highly_RB unlikely_JJ to_TO see_VB its_PRP$
t_NN combine_VB our_PRP$ individual_JJ methods_NNS to_TO create_VB a_DT highly_RB efficient_JJ and_CC reasonably-accurate_JJ spam_NN detection_NN algorithm_NN ._.
The_DT approaches_NNS described_VBN in_IN this_DT paper_NN extend_VB our_PRP$ previous_JJ work_NN in_IN identifying_VBG web_NN spam_NN =_JJ -_: =[_NN 8_CD ,_, 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT remainder_NN of_IN our_PRP$ paper_NN is_VBZ structured_VBN as_IN follows_VBZ :_: In_IN Section_NN 2_CD we_PRP describe_VBP our_PRP$ experimental_JJ framework_NN and_CC the_DT real-world_JJ data_NNS set_VBN that_IN we_PRP used_VBD ._.
In_IN Section_NN 3_CD we_PRP estimate_VBP the_DT prevalence_NN of_IN spam_NN in_IN
