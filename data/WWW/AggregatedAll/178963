Learning_NNP to_TO tag_VB
Social_NN tagging_NN provides_VBZ valuable_JJ and_CC crucial_JJ information_NN for_IN large-scale_JJ web_NN image_NN retrieval_NN ._.
It_PRP is_VBZ ontology-free_JJ and_CC easy_JJ to_TO obtain_VB ;_: however_RB ,_, irrelevant_JJ tags_NNS frequently_RB appear_VBP ,_, and_CC users_NNS typically_RB will_MD not_RB tag_VB all_DT semantic_JJ objects_NNS in_IN the_DT image_NN ,_, which_WDT is_VBZ also_RB called_VBN semantic_JJ loss_NN ._.
To_TO avoid_VB noises_NNS and_CC compensate_VB for_IN the_DT semantic_JJ loss_NN ,_, tag_NN recommendation_NN is_VBZ proposed_VBN in_IN literature_NN ._.
However_RB ,_, current_JJ recommendation_NN simply_RB ranks_VBZ the_DT related_JJ tags_NNS based_VBN on_IN the_DT single_JJ modality_NN of_IN tag_NN co-occurrence_NN on_IN the_DT whole_JJ dataset_NN ,_, which_WDT ignores_VBZ other_JJ modalities_NNS ,_, such_JJ as_IN visual_JJ correlation_NN ._.
This_DT paper_NN proposes_VBZ a_DT multi-modality_JJ recommendation_NN based_VBN on_IN both_CC tag_NN and_CC visual_JJ correlation_NN ,_, and_CC formulates_VBZ the_DT tag_NN recommendation_NN as_IN a_DT learning_NN problem_NN ._.
Each_DT modality_NN is_VBZ used_VBN to_TO generate_VB a_DT ranking_JJ feature_NN ,_, and_CC Rankboost_NN algorithm_NN is_VBZ applied_VBN to_TO learn_VB an_DT optimal_JJ combination_NN of_IN these_DT ranking_JJ features_NNS from_IN different_JJ modalities_NNS ._.
Experiments_NNS on_IN Flickr_NNP data_NNS demonstrate_VBP the_DT effectiveness_NN of_IN this_DT learning-based_JJ multi-modality_JJ recommendation_NN strategy_NN ._.
ular_JJ expressions_NNS -LRB-_-LRB- Appelt_NNP et_FW al._FW ,_, 1993_CD ;_: Grishman_NNP ,_, 1997_CD -RRB-_-RRB- ;_: large_JJ name_NN lists_NNS -LRB-_-LRB- Iwanska_FW et_FW al._FW ,_, 1995_CD -RRB-_-RRB- ;_: sophisticated_JJ rule-based_JJ approaches_NNS -LRB-_-LRB- Morgan_NNP et_FW al._FW ,_, 1995_CD -RRB-_-RRB- and_CC learning_NN algorithms_NNS -LRB-_-LRB- e.g._FW ,_, Sekine_NNP ,_, 1998_CD ;_: =_JJ -_: =_JJ Bennett_NNP et_FW al._FW ,_, 1997_CD -_: =_JJ -_: ;_: Baluja_NNP et_FW al._FW ,_, 1999_CD ;_: Borthwick_NNP et_FW al._FW ,_, 1998_CD ;_: Mikheev_NNP et_FW al._FW ,_, 1999_CD ;_: Bikel_NNP et_FW al._FW ,_, 1999_CD ;_: Seymore_NNP et_FW al._FW ,_, 1999_CD ;_: Bray_NNP ,_, 1999_CD -RRB-_-RRB- ._.
The_DT early_JJ systems_NNS used_VBD the_DT first_JJ three_CD approaches_NNS and_CC rely_VBP on_IN much_JJ manual_NN wo_MD
e_LS been_VBN investigated_VBN across_IN a_DT number_NN of_IN diverse_JJ fields_NNS -LRB-_-LRB- 37_CD ,_, 62_CD ,_, 80_CD ,_, 83_CD -RRB-_-RRB- ,_, specifically_RB focusing_VBG on_IN those_DT which_WDT apply_VBP to_TO the_DT tasks_NNS of_IN scene_NN population_NN ._.
In_IN particular_JJ ,_, named_VBN entity_NN recognition_NN techniques_NNS =_JJ -_: =[_NN 1_CD ,_, 8_CD ,_, 9_CD ,_, 11_CD ,_, 20_CD ,_, 52_CD ,_, 60_CD ,_, 81_CD -RRB-_-RRB- -_: =_JJ -_: ,_, script_NN extraction_NN techniques_NNS -LRB-_-LRB- 85_CD -RRB-_-RRB- and_CC inductive_JJ pattern_NN matching_NN techniques_NNS -LRB-_-LRB- 15_CD ,_, 18_CD ,_, 23_CD ,_, 25_CD ,_, 30_CD ,_, 57_CD ,_, 69_CD ,_, 68_CD ,_, 84_CD -RRB-_-RRB- have_VBP been_VBN comprehensively_RB surveyed_VBN ._.
â€¢_CD Existing_VBG Text-to-Scene_JJ conversion_NN systems_NNS :_: A_DT co_NN
formulas_NNS employ_VBP statistics_NNS of_IN filler_NN frequency_NN and_CC length_NN in_IN the_DT training_NN set_VBN to_TO choose_VB between_IN top_JJ filler_NN candidates_NNS from_IN classifiers_NNS ._.
This_DT scoring_VBG method_NN is_VBZ inspired_VBN by_IN the_DT method_NN used_VBN in_IN RoboTag_NNP -LRB-_-LRB- =_JJ -_: =_JJ Bennett_NNP et_FW al_FW ,_, 1997_CD -_: =--RRB-_NN ._.
Note_VB that_IN we_PRP are_VBP making_VBG a_DT simplifying_VBG assumption_NN that_IN there_EX is_VBZ only_RB one_CD starting_VBG tag_NN for_IN each_DT insertion_NN point_NN ,_, which_WDT is_VBZ not_RB always_RB true_JJ in_IN the_DT domains_NNS we_PRP explore_VBP ._.
However_RB ,_, this_DT assumption_NN is_VBZ mostly_RB
compass_VBZ any_DT type_NN of_IN information_NN that_WDT is_VBZ of_IN interest_NN ._.
Some_DT learning_VBG algorithms_NNS have_VBP been_VBN reported_VBN such_JJ as_IN decision_NN trees_NNS ,_, maximum_NN entropy_NN models_NNS and_CC hidden_JJ markov_NN models_NNS ._.
Sekine_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- and_CC Bennett_NNP et_FW al._FW =_SYM -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: both_DT implemented_VBD their_PRP$ token_JJ identification_NN systems_NNS using_VBG decision_NN trees_NNS ._.
Their_PRP$ decision_NN trees_NNS are_VBP based_VBN on_IN almost_RB identical_JJ features_NNS ,_, ssuch_NN as_IN part-of-speech_NN ,_, character_NN type_NN information_NN and_CC special_JJ d_NN
be_VB also_RB treated_VBN as_IN a_DT multi-classification_JJ task_NN ._.
The_DT idea_NN is_VBZ to_TO decompose_VB Event_NN Recognition_NN into_IN several_JJ classification_NN tasks_NNS and_CC then_RB merge_VB the_DT partial_JJ results_NNS into_IN whole_JJ annotations_NNS ._.
Bennett_NNP et_FW al._FW =_SYM -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: used_VBD two_CD classifiers_NNS to_TO recognize_VB the_DT beginnings_NNS and_CC the_DT endings_NNS of_IN annotations_NNS ._.
The_DT concept_NN of_IN this_DT approach_NN is_VBZ presented_VBN on_IN the_DT Figure_NNP 4.1_CD a._NN After_IN selecting_VBG potential_JJ candidates_NNS for_IN annotation_NN boun_NN
d_NN be_VB tagged_VBN as_IN the_DT opening_NN of_IN an_DT organization_NN ,_, while_IN the_DT next_JJ token_JJ might_MD be_VB tagged_VBN as_IN the_DT closing_NN of_IN person_NN name_NN ._.
We_PRP can_MD think_VB of_IN several_JJ strategies_NNS to_TO solve_VB this_DT problem_NN -LRB-_-LRB- for_IN example_NN ,_, the_DT method_NN by_IN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: will_MD be_VB described_VBN in_IN a_DT later_JJ section_NN -RRB-_-RRB- ,_, but_CC we_PRP used_VBD a_DT probabilistic_JJ method_NN ._.
The_DT instances_NNS in_IN the_DT training_NN corpus_NN corresponding_VBG to_TO a_DT leaf_NN of_IN the_DT decision_NN tree_NN may_MD not_RB all_DT have_VBP the_DT same_JJ tag_NN ._.
At_IN a_DT leaf_NN w_NN
ready_JJ have_VBP been_VBN classified_VBN when_WRB labeling_VBG a_DT sequence_NN from_IN left_NN to_TO right_NN -RRB-_-RRB- ._.
Using_VBG this_DT general_JJ approach_NN ,_, IE_NN systems_NNS have_VBP been_VBN developed_VBN that_WDT use_VBP many_JJ different_JJ trained_JJ classifiers_NNS such_JJ as_IN decision_NN trees_NNS =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, boosting_VBG -LRB-_-LRB- 15_CD -RRB-_-RRB- ,_, memory-based_JJ learning_NN -LRB-_-LRB- MBL_NN -RRB-_-RRB- -LRB-_-LRB- 43_CD -RRB-_-RRB- ,_, support-vector_JJ machines_NNS -LRB-_-LRB- SVMs_NNS -RRB-_-RRB- -LRB-_-LRB- 40_CD -RRB-_-RRB- ,_, maximum_NN entropy_NN -LRB-_-LRB- MaxEnt_NN -RRB-_-RRB- -LRB-_-LRB- 17_CD -RRB-_-RRB- ,_, transformation-based_JJ learning_NN -LRB-_-LRB- TBL_NN -RRB-_-RRB- -LRB-_-LRB- 68_CD -RRB-_-RRB- and_CC many_JJ others_NNS -LRB-_-LRB- 64_CD -RRB-_-RRB- ._.
Many_JJ IE_NN systems_NNS sim_VBP
tity_NN ,_, place_NN -RRB-_-RRB- using_VBG decision_NN trees_NNS -LRB-_-LRB- ID3_NN -RRB-_-RRB- ,_, an_DT easier_JJR task_NN than_IN also_RB learning_VBG to_TO place_NN tags_NNS ._.
It_PRP is_VBZ also_RB less_RBR general_JJ to_TO rely_VB on_IN hand_NN coded_VBD rules_NNS for_IN a_DT significant_JJ part_NN of_IN the_DT tagging_VBG task_NN ._.
Bikel_NNP et_FW al._FW -LRB-_-LRB- =_JJ -_: =_JJ Bikel_NNP et_FW al._FW ,_, 1997_CD -_: =--RRB-_NN report_NN on_IN Nymble_NNP ,_, an_DT HMM-based_JJ name_NN tagging_VBG system_NN operating_VBG in_IN English_NNP and_CC Spanish_NNP ._.
Nymble_NNP performs_VBZ well_RB ,_, turning_VBG in_IN F-measures_NNS of_IN 90_CD and_CC 93_CD respectively_RB in_IN Spanish_NNP and_CC English_NNP on_IN the_DT MUC-6_NN task_NN ._.
T_NN
65_CD for_IN pruning_NN ._.
5_CD Related_NNP Work_NNP Vilain_NNP and_CC Day_NNP -LRB-_-LRB- Vilain_NNP and_CC Day_NNP ,_, 1996_CD -RRB-_-RRB- report_NN on_IN an_DT approach_NN which_WDT learns_VBZ and_CC applies_VBZ rule_NN sequences_NNS for_IN the_DT name_NN tagging_NN task_NN -LRB-_-LRB- based_VBN on_IN Eric_NNP Brill_NNP 's_POS rule_NN sequence_NN work_NN -LRB-_-LRB- =_JJ -_: =_JJ Brill_NNP ,_, 1993_CD -_: =--RRB-_NN -RRB-_-RRB- ._.
It_PRP uses_VBZ a_DT greedy_JJ algorithm_NN to_TO generate_VB and_CC apply_VB rules_NNS ,_, incrementally_RB refining_VBG the_DT target_NN concept_NN ._.
They_PRP report_VBP their_PRP$ best_JJS precision\/recall_NN results_NNS for_IN machine-learned_JJ rules_NNS on_IN the_DT MUC-6_NN task_NN with_IN
ability_NN to_TO tag_VB proper_JJ names_NNS such_JJ as_IN organization_NN ,_, person_NN ,_, and_CC place_NN names_NNS in_IN multilingual_JJ texts_NNS has_VBZ great_JJ value_NN for_IN tasks_NNS like_IN information_NN extraction_NN ,_, information_NN retrieval_NN ,_, and_CC machine_NN translation_NN -LRB-_-LRB- =_JJ -_: =_JJ Aone_NNP ,_, Charocopos_NNP ,_, and_CC Gorlinsky_NNP ,_, 1997_CD -_: =--RRB-_NN ._.
The_DT most_RBS successful_JJ systems_NNS currently_RB rely_VBP on_IN handcoded_JJ patterns_NNS to_TO identify_VB the_DT desired_VBN names_NNS in_IN texts_NNS -LRB-_-LRB- Adv_NNP ,_, 1995_CD ;_: Def_NNP ,_, 1996_CD -RRB-_-RRB- ._.
This_DT approach_NN achieves_VBZ its_PRP$ best_JJS performance_NN using_VBG different_JJ handcoded_NNS
ce_NN of_IN our_PRP$ users_NNS -RRB-_-RRB- that_IN the_DT tagging_NN procedure_NN induced_VBN by_IN the_DT system_NN be_VB easily_RB explained_VBN in_IN terms_NNS of_IN how_WRB it_PRP makes_VBZ its_PRP$ decisions_NNS ._.
This_DT was_VBD one_CD of_IN the_DT factors_NNS that_WDT led_VBD us_PRP to_TO consider_VB using_VBG decision_NN trees_NNS -LRB-_-LRB- =_JJ -_: =_JJ Quinlan_NNP ,_, 1993_CD -_: =--RRB-_NN as_IN a_DT key_JJ component_NN of_IN the_DT system_NN ._.
Other_JJ potential_JJ learning_NN or_CC statistical_JJ approaches_NNS for_IN a_DT problem_NN like_IN this_DT -LRB-_-LRB- e.g._FW ,_, Neural_NNP Nets_NNPS or_CC Hidden_NNP Markov_NNP Models_NNS -RRB-_-RRB- did_VBD not_RB offer_VB this_DT advantage_NN ._.
The_DT RoboTag_NNP sys_NNS
at_IN the_DT bottom_NN of_IN the_DT table_NN ._.
The_DT best_JJS system_NN in_IN the_DT MUC-6_NN named_VBN entity_NN task_NN ,_, using_VBG hand-coded_JJ rules_NNS ,_, returned_VBD F-Measures_NNS of_IN 98.50_CD for_IN person_NN ,_, 96.96_CD for_IN place_NN ,_, and_CC 92.48_CD for_IN entity_NN as_IN shown_VBN in_IN Table_NNP 3_CD -LRB-_-LRB- =_JJ -_: =_JJ Krupka_NNP ,_, 1995_CD -_: =--RRB-_NN ._.
We_PRP found_VBD that_IN RoboTag_NNP 's_POS best_JJS English_JJ results_NNS were_VBD obtained_VBN with_IN a_DT sampling_NN ratio_NN of_IN 10_CD ,_, a_DT radius_NN of_IN 2_CD ,_, and_CC certainty_NN factors_NNS of_IN 0.75_CD for_IN pruning_NN for_IN all_PDT the_DT tag_NN types_NNS ._.
4.2_CD Japanese_JJ Results_NNS In_FW Japa_FW
or_CC entity_NN ._.
Our_PRP$ English_JJ score_NN is_VBZ significantly_RB better_JJR ,_, especially_RB for_IN the_DT person_NN and_CC place_NN tasks_NNS ._.
Because_IN their_PRP$ Japanese_JJ results_NNS were_VBD not_RB reported_VBN we_PRP can_MD not_RB compare_VB our_PRP$ Japanese_JJ performance_NN ._.
Gallippi_NN -LRB-_-LRB- =_JJ -_: =_JJ Gallippi_NNP ,_, 1996_CD -_: =--RRB-_NN presents_VBZ an_DT approach_NN to_TO tag_VB classification_NN using_VBG decision_NN trees_NNS ._.
Hand-coded_JJ rules_NNS are_VBP employed_VBN to_TO delimit_VB proper_JJ nouns_NNS within_IN the_DT text_NN ._.
Each_DT proper_JJ noun_NN is_VBZ then_RB classified_VBN into_IN an_DT appropriate_JJ type_NN -LRB-_-LRB-
