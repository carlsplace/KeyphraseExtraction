Large-scale_JJ text_NN categorization_NN by_IN batch_NN mode_NN active_JJ learning_NN
Large-scale_JJ text_NN categorization_NN is_VBZ an_DT important_JJ research_NN topic_NN for_IN Web_NN data_NNS mining_NN ._.
One_CD of_IN the_DT challenges_NNS in_IN large-scale_JJ text_NN categorization_NN is_VBZ how_WRB to_TO reduce_VB the_DT human_JJ efforts_NNS in_IN labeling_NN text_NN documents_NNS for_IN building_VBG reliable_JJ classification_NN models_NNS ._.
In_IN the_DT past_NN ,_, there_EX have_VBP been_VBN many_JJ studies_NNS on_IN applying_VBG active_JJ learning_VBG methods_NNS to_TO automatic_JJ text_NN categorization_NN ,_, which_WDT try_VBP to_TO select_VB the_DT most_RBS informative_JJ documents_NNS for_IN labeling_NN manually_RB ._.
Most_JJS of_IN these_DT studies_NNS focused_VBD on_IN selecting_VBG a_DT single_JJ unlabeled_JJ document_NN in_IN each_DT iteration_NN ._.
As_IN a_DT result_NN ,_, the_DT text_NN categorization_NN model_NN has_VBZ to_TO be_VB retrained_VBN after_IN each_DT labeled_VBN document_NN is_VBZ solicited_VBN ._.
In_IN this_DT paper_NN ,_, we_PRP present_VBP a_DT novel_JJ active_JJ learning_NN algorithm_NN that_WDT selects_VBZ a_DT batch_NN of_IN text_NN documents_NNS for_IN labeling_NN manually_RB in_IN each_DT iteration_NN ._.
The_DT key_NN of_IN the_DT batch_NN mode_NN active_JJ learning_NN is_VBZ how_WRB to_TO reduce_VB the_DT redundancy_NN among_IN the_DT selected_VBN examples_NNS such_JJ that_IN each_DT example_NN provides_VBZ unique_JJ information_NN for_IN model_NN updating_VBG ._.
To_TO this_DT end_NN ,_, we_PRP use_VBP the_DT Fisher_NNP information_NN matrix_NN as_IN the_DT measurement_NN of_IN model_NN uncertainty_NN and_CC choose_VB the_DT set_NN of_IN documents_NNS to_TO effectively_RB maximize_VB the_DT Fisher_NNP information_NN of_IN a_DT classification_NN model_NN ._.
Extensive_JJ experiments_NNS with_IN three_CD different_JJ datasets_NNS have_VBP shown_VBN that_IN our_PRP$ algorithm_NN is_VBZ more_RBR effective_JJ than_IN the_DT state-of-the-art_JJ active_JJ learning_NN techniques_NNS for_IN text_NN categorization_NN and_CC can_MD be_VB a_DT promising_JJ tool_NN toward_IN large-scale_JJ text_NN categorization_NN for_IN World_NN Wide_NN Web_NN documents_NNS ._.
nformation_NN for_IN model_NN updating_VBG ._.
To_TO this_DT end_NN ,_, we_PRP propose_VBP a_DT framework_NN of_IN batch_NN mode_NN active_JJ learning_NN that_WDT measures_VBZ the_DT overall_JJ information_NN for_IN a_DT set_NN of_IN unlabeled_JJ examples_NNS by_IN the_DT Fisher_NNP information_NN matrix_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP formulate_VBP the_DT batch_NN mode_NN active_JJ learning_NN framework_NN into_IN an_DT SDP_NN problem_NN ,_, and_CC present_VB an_DT effective_JJ optimization_NN algorithm_NN based_VBN on_IN the_DT bound_VBN optimization_NN technique_NN ._.
Further_RB ,_, we_PRP present_VBP the_DT kernel_NN v_LS
sifier_NN creation_NN and_CC data_NN annotation_NN ._.
Examples_NNS of_IN AL_NN used_VBN in_IN language_NN engineering_NN include_VBP named_VBN entity_NN recognition_NN -LRB-_-LRB- Shen_NNP et_FW al._FW ,_, 2004_CD ;_: Tomanek_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ,_, text_NN categorization_NN -LRB-_-LRB- Lewis_NNP and_CC Gale_NNP ,_, 1994_CD ;_: =_JJ -_: =_JJ Hoi_FW et_FW al._FW ,_, 2006_CD -_: =--RRB-_NN ,_, part-of-speech_JJ tagging_NN -LRB-_-LRB- Ringger_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ,_, and_CC parsing_NN -LRB-_-LRB- Thompson_NNP et_FW al._FW ,_, 1999_CD ;_: Becker_NNP and_CC Osborne_NNP ,_, 2005_CD -RRB-_-RRB- ._.
AL_NNP is_VBZ a_DT supervised_JJ machine_NN learning_NN technique_NN in_IN which_WDT the_DT learner_NN is_VBZ in_IN control_NN of_IN the_DT
erland_NN ._.
Copyright_NN 2010_CD ACM_NNP 978-1-60558-896-4_CD \/_: 10\/07_CD ..._: $_$ 10.00_CD ._.
number_NN of_IN unlabeled_JJ documents_NNS ,_, such_JJ as_IN web_NN pages_NNS ,_, newspapers_NNS and_CC journal_NN articles_NNS ._.
In_IN recent_JJ years_NNS ,_, a_DT new_JJ approach_NN called_VBN active_JJ learning_NN =_JJ -_: =[_NN 1_CD ,_, 3_CD ,_, 5_CD ,_, 6_CD ,_, 9_CD ,_, 11_CD ,_, 13_CD ,_, 14_CD ,_, 15_CD ,_, 16_CD ,_, 18_CD ,_, 20_CD ,_, 25_CD -RRB-_-RRB- -_: =_SYM -_: has_VBZ been_VBN developed_VBN in_IN the_DT machine_NN learning_NN community_NN with_IN the_DT goal_NN of_IN reducing_VBG the_DT labeling_NN cost_NN by_IN identifying_VBG and_CC presenting_VBG the_DT most_RBS informative_JJ examples_NNS from_IN the_DT unlabeled_JJ examples_NNS for_IN the_DT human_JJ
d_NN examples_NNS in_IN a_DT method_NN called_VBN `_`` batch_NN mode_NN active_JJ learning_NN '_'' by_IN measuring_VBG the_DT model_NN uncertainty_NN and_CC choosing_VBG a_DT batch_NN of_IN documents_NNS to_TO effectively_RB maximize_VB the_DT Fisher_NNP information_NN of_IN a_DT classification_NN model_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Fisher_NNP 's_POS methods_NNS are_VBP useful_JJ in_IN other_JJ classification_NN algorithms_NNS ._.
Support_NN vector_NN machines_NNS -LRB-_-LRB- SVMs_NNS -RRB-_-RRB- ,_, presented_VBN later_RB in_IN this_DT paper_NN ,_, have_VBP shown_VBN superb_JJ performance_NN for_IN text_NN classification_NN tasks_NNS ._.
They_PRP are_VBP a_DT
ve_IN sampling_NN approach_NN for_IN SVM_NNP active_JJ learning_NN ,_, which_WDT also_RB incorporates_VBZ a_DT diversity_NN measure_NN ._.
Specifically_RB ,_, they_PRP query_VBP cluster_NN centroids_NNS for_IN instances_NNS that_WDT lie_VBP close_RB to_TO the_DT decision_NN boundary_NN ._.
Hoi_FW et_FW al._FW =_SYM -_: =[_NN 7_CD ,_, 8_CD -RRB-_-RRB- -_: =_SYM -_: extend_VB the_DT Fisher_NNP information_NN framework_NN to_TO the_DT batch-mode_JJ setting_NN for_IN binary_JJ logistic_JJ regression_NN ._.
Hoi_FW et_FW al._FW -LRB-_-LRB- 9_CD -RRB-_-RRB- propose_VBP a_DT novel_JJ batch-mode_JJ active_JJ learning_NN scheme_NN on_IN SVMs_NNS that_WDT exploits_VBZ semi-supervise_JJ
ation_NN from_IN a_DT mixture_NN of_IN labeled_JJ and_CC unlabeled_JJ documents_NNS ._.
The_DT well-known_JJ examples_NNS within_IN this_DT category_NN include_VBP Transductive_JJ SVM_NN for_IN text_NN categorization_NN -LRB-_-LRB- 75_CD ,_, 148_CD -RRB-_-RRB- ._.
The_DT third_JJ approach_NN is_VBZ active_JJ learning_NN =_JJ -_: =[_NN 97_CD ,_, 58_CD ,_, 59_CD -RRB-_-RRB- -_: =_SYM -_: that_WDT aims_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ documents_NNS for_IN manually_RB labeling_VBG ._.
Finally_RB ,_, in_IN addition_NN to_TO semi-supervisedCHAPTER_NN 2_CD ._.
BACKGROUND_NN REVIEW_NNP :_: LEARNING_VBG WITH_IN UNLABELED_FW DATA36_FW learning_NN and_CC a_DT
r_NN et_FW al._FW ,_, 2001_CD -RRB-_-RRB- and_CC the_DT query-by-committee_NN -LRB-_-LRB- QBC_NN -RRB-_-RRB- algorithm_NN by_IN -LRB-_-LRB- Seung_NNP et_FW al._FW ,_, 1992_CD -RRB-_-RRB- ._.
In_IN addition_NN ,_, there_EX are_VBP algorithms_NNS designed_VBN for_IN reducing_VBG the_DT redundancy_NN in_IN queries_NNS which_WDT may_MD be_VB worth_JJ investigating_VBG -LRB-_-LRB- =_JJ -_: =_JJ Hoi_FW et_FW al._FW ,_, 2006_CD -_: =--RRB-_NN ._.
Also_RB ,_, -LRB-_-LRB- Hoi_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- shows_VBZ that_IN Logistic_JJ Regression_NN -LRB-_-LRB- LR_NN -RRB-_-RRB- outperforms_VBZ SVM_NNP when_WRB used_VBN with_IN active_JJ learning_NN ,_, yielding_VBG higher_JJR F-score_NN on_IN the_DT Reuters21578_NN data_NN set_NN -LRB-_-LRB- binary_JJ classification_NN ,_, 10,788_CD docu_NN
-LRB-_-LRB- 43_CD -RRB-_-RRB- ._.
Finally_RB ,_, to_TO minimize_VB the_DT human_JJ effort_NN of_IN labeling_NN training_NN data_NNS ,_, we_PRP can_MD study_VB active_JJ learning_NN techniques_NNS to_TO provide_VB users_NNS the_DT most_RBS informative_JJ examples_NNS for_IN labeling_NN during_IN the_DT annotation_NN tasks_NNS =_JJ -_: =[_NN 45_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 46_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 47_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 48_CD -RRB-_-RRB- ._.
VI_NNP ._.
CONCLUSION_NN In_IN this_DT paper_NN we_PRP proposed_VBD a_DT novel_JJ transductive_JJ learning_NN algorithm_NN for_IN face_NN annotation_NN ._.
In_IN contrast_NN to_TO traditional_JJ approaches_NNS using_VBG supervised_JJ learning_NN methods_NNS ,_, we_PRP pr_VBP
1_CD ._.
INTRODUCTION_NN With_IN the_DT rapid_JJ growth_NN of_IN text_NN information_NN on_IN the_DT World_NNP Wide_NN Web_NN -LRB-_-LRB- WWW_NN -RRB-_-RRB- ,_, text_NN classification_NN has_VBZ become_VBN one_CD of_IN the_DT most_RBS important_JJ topic_NN in_IN both_CC the_DT community_NN of_IN research_NN and_CC engineering_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB there_EX are_VBP two_CD major_JJ problems_NNS with_IN current_JJ algorithms_NNS involving_VBG in_IN text_NN classification_NN task_NN ._.
One_CD key_JJ challenge_NN is_VBZ that_IN almost_RB all_PDT the_DT algorithms_NNS treat_VBP the_DT problem_NN as_IN a_DT balanced_JJ classification_NN
-LRB-_-LRB- 43_CD -RRB-_-RRB- ._.
Finally_RB ,_, to_TO minimize_VB the_DT human_JJ effort_NN of_IN labeling_NN training_NN data_NNS ,_, we_PRP can_MD study_VB active_JJ learning_NN techniques_NNS to_TO provide_VB users_NNS the_DT most_RBS informative_JJ examples_NNS for_IN labeling_NN during_IN the_DT annotation_NN tasks_NNS =_JJ -_: =[_NN 45_CD -RRB-_-RRB- -_: =_SYM -_: --_: -LRB-_-LRB- 48_CD -RRB-_-RRB- ._.
VI_NNP ._.
CONCLUSION_NN In_IN this_DT paper_NN ,_, we_PRP proposed_VBD a_DT novel_JJ transductive_JJ learning_NN algorithm_NN for_IN face_NN annotation_NN ._.
In_IN contrast_NN to_TO traditional_JJ approaches_NNS using_VBG supervised_JJ learning_NN methods_NNS ,_, we_PRP proposed_VBD the_DT T_NN
as_IN interactive_JJ video_NN retrieval_NN -LRB-_-LRB- 39_CD -RRB-_-RRB- and_CC image\/video_NN annotation_NN -LRB-_-LRB- 40_CD -RRB-_-RRB- ._.
To_TO these_DT problems_NNS ,_, we_PRP will_MD explore_VB the_DT proposed_VBN multimodal_JJ and_CC multilevel_JJ framework_NN together_RB with_IN active_JJ learning_NN techniques_NNS -LRB-_-LRB- 41_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 42_CD -RRB-_-RRB- -_: =_SYM -_: to_TO overcome_VB these_DT open_JJ challenges_NNS ._.
We_PRP may_MD also_RB study_VB more_RBR effective_JJ kernel_NN learning_NN methods_NNS ,_, such_JJ as_IN the_DT nonparametric_JJ kernel_NN learning_NN for_IN improving_VBG the_DT retrieval_NN performance_NN -LRB-_-LRB- 43_CD -RRB-_-RRB- ._.
Lastly_RB ,_, we_PRP may_MD stu_VB
c_NN approaches_NNS ,_, we_PRP learn_VBP a_DT sampling_NN distribution_NN by_IN formally_RB formulating_VBG the_DT batch_NN mode_NN active_JJ learning_NN problem_NN ._.
Finally_RB ,_, our_PRP$ work_NN is_VBZ different_JJ from_IN some_DT other_JJ recent_JJ work_NN on_IN batch_NN mode_NN active_JJ learning_NN =_JJ -_: =[_NN 8_CD ,_, 6_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
These_DT studies_NNS were_VBD mainly_RB based_VBN on_IN kernel_NN logistic_JJ regressions_NNS ,_, which_WDT may_MD not_RB be_VB able_JJ to_TO applicable_JJ to_TO SVM_NNP models_NNS directly_RB ._.
5_CD ._.
Conclusion_NN We_PRP proposed_VBD a_DT novel_JJ semi-supervised_JJ SVM_NN batch_NN mode_NN active_JJ le_FW
ively_RB until_IN most_JJS of_IN the_DT examples_NNS can_MD be_VB classified_VBN with_IN reasonably_RB high_JJ confidence_NN ._.
One_CD of_IN the_DT key_JJ issues_NNS in_IN active_JJ learning_NN is_VBZ how_WRB to_TO measure_VB the_DT classification_NN uncertainty_NN of_IN unlabeled_JJ examples_NNS ._.
In_IN =_JJ -_: =[_NN 6_CD ,_, 7_CD ,_, 8_CD ,_, 14_CD ,_, 21_CD ,_, 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT number_NN of_IN distinct_JJ classification_NN models_NNS are_VBP first_RB generated_VBN ._.
Then_RB ,_, the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN is_VBZ measured_VBN by_IN the_DT amount_NN of_IN disagreement_NN among_IN the_DT ensemble_NN of_IN classification_NN
ines_NNS in_IN finding_VBG relevant_JJ documents_NNS and_CC to_TO facilitate_VB users_NNS in_IN browsing_VBG Web_NN pages_NNS or_CC Web_NN sites_NNS ._.
In_IN the_DT past_JJ decade_NN ,_, a_DT number_NN of_IN statistical_JJ learning_NN techniques_NNS have_VBP been_VBN applied_VBN to_TO text_NN categorization_NN =_JJ -_: =[_NN 34_CD -RRB-_-RRB- -_: =_JJ -_: ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, decision_NN trees_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, Bayesian_JJ classifiers_NNS -LRB-_-LRB- 32_CD -RRB-_-RRB- ,_, inductive_JJ rule_NN learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, neural_JJ networks_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Empirical_JJ s_NN
introduce_VB the_DT theoretical_JJ foundation_NN of_IN our_PRP$ active_JJ learning_NN algorithm_NN ._.
Based_VBN on_IN the_DT theoretical_JJ framework_NN ,_, we_PRP then_RB formulate_VBP the_DT active_JJ learning_NN problem_NN into_IN a_DT semi-definite_JJ programming_NN -LRB-_-LRB- SDP_NN -RRB-_-RRB- problem_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Finally_RB ,_, we_PRP present_VBP an_DT efficient_JJ learning_NN algorithm_NN for_IN the_DT related_JJ optimization_NN problem_NN based_VBN on_IN the_DT eigen_NN space_NN simplification_NN and_CC a_DT bound_VBN optimization_NN strategy_NN ._.
4.1_CD Theoretical_NNP Foundation_NNP Our_NNP act_NN
nique_VB among_IN all_PDT the_DT methods_NNS mentioned_VBN above_IN ._.
Recently_RB ,_, logistic_JJ regression_NN ,_, a_DT traditional_JJ statistical_JJ tool_NN ,_, has_VBZ attracted_VBN considerable_JJ attention_NN for_IN text_NN categorization_NN and_CC high-dimension_JJ data_NNS mining_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Several_JJ recent_JJ studies_NNS have_VBP shown_VBN that_IN the_DT logistic_JJ regression_NN model_NN can_MD achieve_VB comparable_JJ classification_NN accuracy_NN as_IN SVMs_NNS in_IN text_NN categorization_NN ._.
Compared_VBN to_TO SVMs_NNS ,_, the_DT logistic_JJ regression_NN model_NN ha_NN
ively_RB until_IN most_JJS of_IN the_DT examples_NNS can_MD be_VB classified_VBN with_IN reasonably_RB high_JJ confidence_NN ._.
One_CD of_IN the_DT key_JJ issues_NNS in_IN active_JJ learning_NN is_VBZ how_WRB to_TO measure_VB the_DT classification_NN uncertainty_NN of_IN unlabeled_JJ examples_NNS ._.
In_IN =_JJ -_: =[_NN 6_CD ,_, 7_CD ,_, 8_CD ,_, 14_CD ,_, 21_CD ,_, 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT number_NN of_IN distinct_JJ classification_NN models_NNS are_VBP first_RB generated_VBN ._.
Then_RB ,_, the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN is_VBZ measured_VBN by_IN the_DT amount_NN of_IN disagreement_NN among_IN the_DT ensemble_NN of_IN classification_NN
that_WDT tries_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ examples_NNS for_IN labeling_NN manually_RB ._.
Although_IN previous_JJ studies_NNS have_VBP shown_VBN the_DT promising_JJ performance_NN of_IN semi-supervised_JJ learning_NN for_IN text_NN categorization_NN =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT high_JJ computation_NN cost_NN has_VBZ limited_VBN its_PRP$ application_NN -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP focus_VBP our_PRP$ discussion_NN on_IN active_JJ learning_NN ._.
Active_JJ learning_NN ,_, or_CC called_VBN pool-based_JJ active_JJ learning_NN ,_, has_VBZ been_VBN extensively_RB stu_VBP
stic_JJ regression_NN tool_NN developed_VBN by_IN Komarek_NNP and_CC Moore_NNP recently_RB -LRB-_-LRB- 13_CD -RRB-_-RRB- ._.
To_TO implement_VB our_PRP$ active_JJ learning_NN algorithm_NN based_VBN on_IN the_DT bound_VBN optimization_NN approach_NN ,_, we_PRP employ_VBP a_DT standard_JJ math_NN package_NN ,_, i.e._FW ,_, LAPACK_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_JJ -_: ,_, to_TO solve_VB the_DT eigen_NN decomposition_NN in_IN our_PRP$ algorithm_NN efficiently_RB ._.
The_DT SVM_NNP light_NN package_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- is_VBZ used_VBN in_IN our_PRP$ experiments_NNS for_IN the_DT implementation_NN of_IN SVM_NNP ,_, which_WDT has_VBZ been_VBN considered_VBN as_IN the_DT state-of-the-art_JJ
tive_JJ learning_NN ._.
Active_JJ learning_NN ,_, or_CC called_VBN pool-based_JJ active_JJ learning_NN ,_, has_VBZ been_VBN extensively_RB studied_VBN in_IN machine_NN learning_NN for_IN many_JJ years_NNS and_CC has_VBZ already_RB been_VBN employed_VBN for_IN text_NN categorization_NN in_IN the_DT past_NN =_JJ -_: =[_NN 16_CD ,_, 17_CD ,_, 21_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_RBS active_JJ learning_NN algorithms_NNS are_VBP conducted_VBN in_IN the_DT iterative_JJ fashion_NN ._.
In_IN each_DT iteration_NN ,_, the_DT example_NN with_IN the_DT highest_JJS classification_NN uncertainty_NN is_VBZ chosen_VBN for_IN labeling_NN manually_RB ._.
Then_RB ,_, the_DT classifi_NNS
I_PRP 1\/2_CD p_NN qi_NN =_JJ 1_CD ,_, qi_FW ≥_FW 0_CD ,_, i_FW =_JJ 1_CD ,_, ..._: ,_, n_NN I_CD 1\/2_CD p_NN M_NN 0_CD -LRB-_-LRB- 10_CD -RRB-_-RRB- The_DT above_JJ problem_NN belongs_VBZ to_TO the_DT family_NN of_IN Semi-definite_JJ programming_NN and_CC can_MD be_VB solved_VBN by_IN the_DT standard_JJ convex_NN optimization_NN packages_NNS such_JJ as_IN SeDuMi_NN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_SYM -_: ._.
4.4_CD Eigen_NNP Space_NNP Simplification_NNP Although_IN the_DT formulation_NN in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- is_VBZ mathematically_RB sound_JJ ,_, directly_RB solving_VBG the_DT optimization_NN problem_NN could_MD be_VB computationally_RB expensive_RB due_JJ to_TO the_DT large_JJ size_NN of_IN matrix_NN
odel_NN suitable_JJ for_IN probabilistic_JJ binary_JJ classification_NN ._.
Recently_RB ,_, logistic_JJ regression_NN has_VBZ been_VBN actively_RB studied_VBN in_IN statistical_JJ machine_NN learning_NN community_NN due_JJ to_TO its_PRP$ close_JJ relation_NN to_TO SVMs_NNS and_CC Adaboost_NN =_JJ -_: =[_NN 33_CD ,_, 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Compared_VBN with_IN many_JJ other_JJ statistical_JJ learning_NN models_NNS ,_, such_JJ as_IN SVMs_NNS ,_, the_DT logistic_JJ regression_NN model_NN has_VBZ the_DT following_JJ advantages_NNS :_: •_CD It_PRP is_VBZ a_DT high_JJ performance_NN classifier_NN that_WDT can_MD be_VB efficiently_RB trained_VBN w_NN
tive_JJ learning_NN ._.
Active_JJ learning_NN ,_, or_CC called_VBN pool-based_JJ active_JJ learning_NN ,_, has_VBZ been_VBN extensively_RB studied_VBN in_IN machine_NN learning_NN for_IN many_JJ years_NNS and_CC has_VBZ already_RB been_VBN employed_VBN for_IN text_NN categorization_NN in_IN the_DT past_NN =_JJ -_: =[_NN 16_CD ,_, 17_CD ,_, 21_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_RBS active_JJ learning_NN algorithms_NNS are_VBP conducted_VBN in_IN the_DT iterative_JJ fashion_NN ._.
In_IN each_DT iteration_NN ,_, the_DT example_NN with_IN the_DT highest_JJS classification_NN uncertainty_NN is_VBZ chosen_VBN for_IN labeling_NN manually_RB ._.
Then_RB ,_, the_DT classifi_NNS
lassification_NN model_NN from_IN the_DT mixture_NN of_IN labeled_JJ and_CC unlabeled_JJ examples_NNS -LRB-_-LRB- 30_CD -RRB-_-RRB- ._.
A_DT comprehensive_JJ study_NN of_IN semi-supervised_JJ learning_NN techniques_NNS can_MD be_VB found_VBN in_IN -LRB-_-LRB- 25_CD ,_, 38_CD -RRB-_-RRB- ._.
Another_DT solution_NN is_VBZ active_JJ learning_NN =_JJ -_: =[_NN 19_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: that_WDT tries_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ examples_NNS for_IN labeling_NN manually_RB ._.
Although_IN previous_JJ studies_NNS have_VBP shown_VBN the_DT promising_JJ performance_NN of_IN semi-supervised_JJ learning_NN for_IN text_NN categorization_NN
or_CC the_DT test_NN example_NN ._.
Another_DT group_NN of_IN approaches_NNS measure_VBP the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN by_IN how_WRB far_RB the_DT example_NN is_VBZ away_RB from_IN the_DT classification_NN boundary_NN -LRB-_-LRB- i.e._FW ,_, classification_NN margin_NN -RRB-_-RRB- =_JJ -_: =[_NN 4_CD ,_, 24_CD ,_, 31_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT most_RBS well-known_JJ approaches_NNS within_IN this_DT group_NN is_VBZ support_NN vector_NN machine_NN active_JJ learning_NN developed_VBN by_IN Tong_NNP and_CC Koller_NNP -LRB-_-LRB- 31_CD -RRB-_-RRB- ._.
Due_JJ to_TO its_PRP$ popularity_NN and_CC success_NN in_IN the_DT previous_JJ studies_NNS ,_, it_PRP is_VBZ
egorization_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, decision_NN trees_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, Bayesian_JJ classifiers_NNS -LRB-_-LRB- 32_CD -RRB-_-RRB- ,_, inductive_JJ rule_NN learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, neural_JJ networks_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Empirical_JJ studies_NNS in_IN recent_JJ years_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- have_VBP shown_VBN that_IN SVM_NN is_VBZ the_DT state-of-the-art_JJ technique_NN among_IN all_PDT the_DT methods_NNS mentioned_VBN above_IN ._.
Recently_RB ,_, logistic_JJ regression_NN ,_, a_DT traditional_JJ statistical_JJ tool_NN ,_, has_VBZ
-_: supervised_JJ learning_NN ,_, which_WDT tries_VBZ to_TO learn_VB a_DT classification_NN model_NN from_IN the_DT mixture_NN of_IN labeled_JJ and_CC unlabeled_JJ examples_NNS -LRB-_-LRB- 30_CD -RRB-_-RRB- ._.
A_DT comprehensive_JJ study_NN of_IN semi-supervised_JJ learning_NN techniques_NNS can_MD be_VB found_VBN in_IN =_JJ -_: =[_NN 25_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Another_DT solution_NN is_VBZ active_JJ learning_NN -LRB-_-LRB- 19_CD ,_, 26_CD -RRB-_-RRB- that_WDT tries_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ examples_NNS for_IN labeling_NN manually_RB ._.
Although_IN previous_JJ studies_NNS have_VBP shown_VBN the_DT promising_JJ performance_NN of_IN sem_NN
rization_NN ._.
Compared_VBN to_TO SVMs_NNS ,_, the_DT logistic_JJ regression_NN model_NN has_VBZ the_DT advantage_NN in_IN that_IN it_PRP is_VBZ usually_RB more_RBR efficient_JJ than_IN SVMs_NNS in_IN model_NN training_NN ,_, especially_RB when_WRB the_DT number_NN of_IN training_NN documents_NNS is_VBZ large_JJ =_JJ -_: =[_NN 13_CD ,_, 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT motivates_VBZ us_PRP to_TO choose_VB logistic_JJ regression_NN as_IN the_DT basis_NN classifier_NN for_IN large-scale_JJ text_NN categorization_NN ._.
The_DT other_JJ critical_JJ issue_NN for_IN large-scale_JJ text_NN document_NN categorization_NN is_VBZ how_WRB to_TO reduce_VB th_DT
rization_NN ._.
Compared_VBN to_TO SVMs_NNS ,_, the_DT logistic_JJ regression_NN model_NN has_VBZ the_DT advantage_NN in_IN that_IN it_PRP is_VBZ usually_RB more_RBR efficient_JJ than_IN SVMs_NNS in_IN model_NN training_NN ,_, especially_RB when_WRB the_DT number_NN of_IN training_NN documents_NNS is_VBZ large_JJ =_JJ -_: =[_NN 13_CD ,_, 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT motivates_VBZ us_PRP to_TO choose_VB logistic_JJ regression_NN as_IN the_DT basis_NN classifier_NN for_IN large-scale_JJ text_NN categorization_NN ._.
The_DT other_JJ critical_JJ issue_NN for_IN large-scale_JJ text_NN document_NN categorization_NN is_VBZ how_WRB to_TO reduce_VB th_DT
te_NN users_NNS in_IN browsing_VBG Web_NN pages_NNS or_CC Web_NN sites_NNS ._.
In_IN the_DT past_JJ decade_NN ,_, a_DT number_NN of_IN statistical_JJ learning_NN techniques_NNS have_VBP been_VBN applied_VBN to_TO text_NN categorization_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_VBZ =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: ,_, decision_NN trees_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, Bayesian_JJ classifiers_NNS -LRB-_-LRB- 32_CD -RRB-_-RRB- ,_, inductive_JJ rule_NN learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, neural_JJ networks_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Empirical_JJ studies_NNS in_IN recent_JJ years_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- have_VBP shown_VBN that_IN SVM_NN is_VBZ
ining_NN ,_, information_NN retrieval_NN and_CC statistical_JJ learning_NN -LRB-_-LRB- 15_CD ,_, 35_CD -RRB-_-RRB- ._.
Essentially_RB the_DT text_NN categorization_NN techniques_NNS have_VBP been_VBN the_DT key_NN toward_IN automated_JJ categorization_NN of_IN large-scale_JJ Web_NN pages_NNS and_CC Web_NN sites_NNS =_JJ -_: =[_NN 18_CD ,_, 27_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT is_VBZ further_RB applied_VBN to_TO improve_VB Web_NN searching_VBG engines_NNS in_IN finding_VBG relevant_JJ documents_NNS and_CC to_TO facilitate_VB users_NNS in_IN browsing_VBG Web_NN pages_NNS or_CC Web_NN sites_NNS ._.
In_IN the_DT past_JJ decade_NN ,_, a_DT number_NN of_IN statistical_JJ learni_NNS
ur_NN conclusions_NNS ._.
2_CD ._.
RELATED_NNS WORK_VBP Text_NN categorization_NN is_VBZ a_DT long-term_JJ research_NN topic_NN which_WDT has_VBZ been_VBN actively_RB studied_VBN in_IN the_DT communities_NNS of_IN Web_NN data_NNS mining_NN ,_, information_NN retrieval_NN and_CC statistical_JJ learning_NN =_JJ -_: =[_NN 15_CD ,_, 35_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Essentially_RB the_DT text_NN categorization_NN techniques_NNS have_VBP been_VBN the_DT key_NN toward_IN automated_JJ categorization_NN of_IN large-scale_JJ Web_NN pages_NNS and_CC Web_NN sites_NNS -LRB-_-LRB- 18_CD ,_, 27_CD -RRB-_-RRB- ,_, which_WDT is_VBZ further_RB applied_VBN to_TO improve_VB Web_NN searching_VBG en_IN
d_NN choose_VB the_DT set_NN of_IN examples_NNS that_WDT efficiently_RB maximize_VBP the_DT Fisher_NNP information_NN of_IN the_DT classification_NN model_NN ._.
Fisher_NNP information_NN matrix_NN has_VBZ been_VBN used_VBN widely_RB in_IN statistics_NNS for_IN measuring_VBG model_NN uncertainty_NN =_JJ -_: =[_NN 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, in_IN the_DT Cramer-Rao_NNP bound_VBD ,_, Fisher_NNP information_NN matrix_NN provides_VBZ the_DT low_NN bound_VBN for_IN the_DT variance_NN of_IN a_DT statistical_JJ model_NN ._.
In_IN this_DT study_NN ,_, we_PRP choose_VBP the_DT set_NN of_IN examples_NNS that_WDT can_MD well_RB represent_VB t_NN
Web_NN pages_NNS or_CC Web_NN sites_NNS ._.
In_IN the_DT past_JJ decade_NN ,_, a_DT number_NN of_IN statistical_JJ learning_NN techniques_NNS have_VBP been_VBN applied_VBN to_TO text_NN categorization_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, decision_NN trees_NNS =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Bayesian_JJ classifiers_NNS -LRB-_-LRB- 32_CD -RRB-_-RRB- ,_, inductive_JJ rule_NN learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, neural_JJ networks_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Empirical_JJ studies_NNS in_IN recent_JJ years_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- have_VBP shown_VBN that_IN SVM_NN is_VBZ the_DT state-of-the-art_JJ
learning_VBG algorithm_NN based_VBN on_IN the_DT bound_VBN optimization_NN approach_NN ,_, we_PRP employ_VBP a_DT standard_JJ math_NN package_NN ,_, i.e._FW ,_, LAPACK_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ,_, to_TO solve_VB the_DT eigen_NN decomposition_NN in_IN our_PRP$ algorithm_NN efficiently_RB ._.
The_DT SVM_NNP light_JJ package_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ used_VBN in_IN our_PRP$ experiments_NNS for_IN the_DT implementation_NN of_IN SVM_NNP ,_, which_WDT has_VBZ been_VBN considered_VBN as_IN the_DT state-of-the-art_JJ tool_NN for_IN text_NN categorization_NN ._.
Since_IN SVM_NN is_VBZ not_RB parameter-free_JJ and_CC can_MD be_VB very_RB sensitive_JJ to_TO
statistical_JJ learning_NN techniques_NNS have_VBP been_VBN applied_VBN to_TO text_NN categorization_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, decision_NN trees_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, Bayesian_JJ classifiers_NNS -LRB-_-LRB- 32_CD -RRB-_-RRB- ,_, inductive_JJ rule_NN learning_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: ,_, neural_JJ networks_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Empirical_JJ studies_NNS in_IN recent_JJ years_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- have_VBP shown_VBN that_IN SVM_NN is_VBZ the_DT state-of-the-art_JJ technique_NN among_IN all_PDT the_DT methods_NNS mentioned_VBN above_IN ._.
Recent_JJ
for_IN the_DT related_JJ optimization_NN problem_NN based_VBN on_IN the_DT eigen_NN space_NN simplification_NN and_CC a_DT bound_VBN optimization_NN strategy_NN ._.
4.1_CD Theoretical_NNP Foundation_NNP Our_NNP active_JJ learning_NN methodology_NN is_VBZ motivated_VBN by_IN the_DT work_NN in_IN =_JJ -_: =[_NN 37_CD -RRB-_-RRB- -_: =_JJ -_: ,_, in_IN which_WDT the_DT author_NN presented_VBD a_DT theoretical_JJ framework_NN of_IN active_JJ learning_NN based_VBN on_IN the_DT Fisher_NNP information_NN matrix_NN ._.
Given_VBN the_DT Fisher_NNP information_NN matrix_NN represents_VBZ the_DT overall_JJ uncertainty_NN of_IN a_DT classific_JJ
ining_NN ,_, information_NN retrieval_NN and_CC statistical_JJ learning_NN -LRB-_-LRB- 15_CD ,_, 35_CD -RRB-_-RRB- ._.
Essentially_RB the_DT text_NN categorization_NN techniques_NNS have_VBP been_VBN the_DT key_NN toward_IN automated_JJ categorization_NN of_IN large-scale_JJ Web_NN pages_NNS and_CC Web_NN sites_NNS =_JJ -_: =[_NN 18_CD ,_, 27_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT is_VBZ further_RB applied_VBN to_TO improve_VB Web_NN searching_VBG engines_NNS in_IN finding_VBG relevant_JJ documents_NNS and_CC to_TO facilitate_VB users_NNS in_IN browsing_VBG Web_NN pages_NNS or_CC Web_NN sites_NNS ._.
In_IN the_DT past_JJ decade_NN ,_, a_DT number_NN of_IN statistical_JJ learni_NNS
or_CC the_DT test_NN example_NN ._.
Another_DT group_NN of_IN approaches_NNS measure_VBP the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN by_IN how_WRB far_RB the_DT example_NN is_VBZ away_RB from_IN the_DT classification_NN boundary_NN -LRB-_-LRB- i.e._FW ,_, classification_NN margin_NN -RRB-_-RRB- =_JJ -_: =[_NN 4_CD ,_, 24_CD ,_, 31_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT most_RBS well-known_JJ approaches_NNS within_IN this_DT group_NN is_VBZ support_NN vector_NN machine_NN active_JJ learning_NN developed_VBN by_IN Tong_NNP and_CC Koller_NNP -LRB-_-LRB- 31_CD -RRB-_-RRB- ._.
Due_JJ to_TO its_PRP$ popularity_NN and_CC success_NN in_IN the_DT previous_JJ studies_NNS ,_, it_PRP is_VBZ
or_CC the_DT test_NN example_NN ._.
Another_DT group_NN of_IN approaches_NNS measure_VBP the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN by_IN how_WRB far_RB the_DT example_NN is_VBZ away_RB from_IN the_DT classification_NN boundary_NN -LRB-_-LRB- i.e._FW ,_, classification_NN margin_NN -RRB-_-RRB- =_JJ -_: =[_NN 4_CD ,_, 24_CD ,_, 31_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT most_RBS well-known_JJ approaches_NNS within_IN this_DT group_NN is_VBZ support_NN vector_NN machine_NN active_JJ learning_NN developed_VBN by_IN Tong_NNP and_CC Koller_NNP -LRB-_-LRB- 31_CD -RRB-_-RRB- ._.
Due_JJ to_TO its_PRP$ popularity_NN and_CC success_NN in_IN the_DT previous_JJ studies_NNS ,_, it_PRP is_VBZ
the_DT past_JJ decade_NN ,_, a_DT number_NN of_IN statistical_JJ learning_NN techniques_NNS have_VBP been_VBN applied_VBN to_TO text_NN categorization_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, decision_NN trees_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, Bayesian_JJ classifiers_NNS =_JJ -_: =[_NN 32_CD -RRB-_-RRB- -_: =_JJ -_: ,_, inductive_JJ rule_NN learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, neural_JJ networks_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Empirical_JJ studies_NNS in_IN recent_JJ years_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- have_VBP shown_VBN that_IN SVM_NN is_VBZ the_DT state-of-the-art_JJ technique_NN among_IN all_PDT the_DT me_PRP
ively_RB until_IN most_JJS of_IN the_DT examples_NNS can_MD be_VB classified_VBN with_IN reasonably_RB high_JJ confidence_NN ._.
One_CD of_IN the_DT key_JJ issues_NNS in_IN active_JJ learning_NN is_VBZ how_WRB to_TO measure_VB the_DT classification_NN uncertainty_NN of_IN unlabeled_JJ examples_NNS ._.
In_IN =_JJ -_: =[_NN 6_CD ,_, 7_CD ,_, 8_CD ,_, 14_CD ,_, 21_CD ,_, 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT number_NN of_IN distinct_JJ classification_NN models_NNS are_VBP first_RB generated_VBN ._.
Then_RB ,_, the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN is_VBZ measured_VBN by_IN the_DT amount_NN of_IN disagreement_NN among_IN the_DT ensemble_NN of_IN classification_NN
documents_NNS ,_, the_DT key_NN is_VBZ to_TO exploit_VB the_DT unlabeled_JJ documents_NNS ._.
One_CD solution_NN is_VBZ the_DT semi-supervised_JJ learning_NN ,_, which_WDT tries_VBZ to_TO learn_VB a_DT classification_NN model_NN from_IN the_DT mixture_NN of_IN labeled_JJ and_CC unlabeled_JJ examples_NNS =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT comprehensive_JJ study_NN of_IN semi-supervised_JJ learning_NN techniques_NNS can_MD be_VB found_VBN in_IN -LRB-_-LRB- 25_CD ,_, 38_CD -RRB-_-RRB- ._.
Another_DT solution_NN is_VBZ active_JJ learning_NN -LRB-_-LRB- 19_CD ,_, 26_CD -RRB-_-RRB- that_WDT tries_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ examples_NNS for_IN l_NN
tive_JJ learning_NN ._.
Active_JJ learning_NN ,_, or_CC called_VBN pool-based_JJ active_JJ learning_NN ,_, has_VBZ been_VBN extensively_RB studied_VBN in_IN machine_NN learning_NN for_IN many_JJ years_NNS and_CC has_VBZ already_RB been_VBN employed_VBN for_IN text_NN categorization_NN in_IN the_DT past_NN =_JJ -_: =[_NN 16_CD ,_, 17_CD ,_, 21_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_RBS active_JJ learning_NN algorithms_NNS are_VBP conducted_VBN in_IN the_DT iterative_JJ fashion_NN ._.
In_IN each_DT iteration_NN ,_, the_DT example_NN with_IN the_DT highest_JJS classification_NN uncertainty_NN is_VBZ chosen_VBN for_IN labeling_NN manually_RB ._.
Then_RB ,_, the_DT classifi_NNS
tive_JJ learning_NN ._.
Active_JJ learning_NN ,_, or_CC called_VBN pool-based_JJ active_JJ learning_NN ,_, has_VBZ been_VBN extensively_RB studied_VBN in_IN machine_NN learning_NN for_IN many_JJ years_NNS and_CC has_VBZ already_RB been_VBN employed_VBN for_IN text_NN categorization_NN in_IN the_DT past_NN =_JJ -_: =[_NN 16_CD ,_, 17_CD ,_, 21_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_RBS active_JJ learning_NN algorithms_NNS are_VBP conducted_VBN in_IN the_DT iterative_JJ fashion_NN ._.
In_IN each_DT iteration_NN ,_, the_DT example_NN with_IN the_DT highest_JJS classification_NN uncertainty_NN is_VBZ chosen_VBN for_IN labeling_NN manually_RB ._.
Then_RB ,_, the_DT classifi_NNS
techniques_NNS have_VBP been_VBN applied_VBN to_TO text_NN categorization_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, decision_NN trees_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, Bayesian_JJ classifiers_NNS -LRB-_-LRB- 32_CD -RRB-_-RRB- ,_, inductive_JJ rule_NN learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, neural_JJ networks_NNS =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Empirical_JJ studies_NNS in_IN recent_JJ years_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- have_VBP shown_VBN that_IN SVM_NN is_VBZ the_DT state-of-the-art_JJ technique_NN among_IN all_PDT the_DT methods_NNS mentioned_VBN above_IN ._.
Recently_RB ,_, logistic_JJ regressio_NN
-_: supervised_JJ learning_NN ,_, which_WDT tries_VBZ to_TO learn_VB a_DT classification_NN model_NN from_IN the_DT mixture_NN of_IN labeled_JJ and_CC unlabeled_JJ examples_NNS -LRB-_-LRB- 30_CD -RRB-_-RRB- ._.
A_DT comprehensive_JJ study_NN of_IN semi-supervised_JJ learning_NN techniques_NNS can_MD be_VB found_VBN in_IN =_JJ -_: =[_NN 25_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Another_DT solution_NN is_VBZ active_JJ learning_NN -LRB-_-LRB- 19_CD ,_, 26_CD -RRB-_-RRB- that_WDT tries_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ examples_NNS for_IN labeling_NN manually_RB ._.
Although_IN previous_JJ studies_NNS have_VBP shown_VBN the_DT promising_JJ performance_NN of_IN sem_NN
ively_RB until_IN most_JJS of_IN the_DT examples_NNS can_MD be_VB classified_VBN with_IN reasonably_RB high_JJ confidence_NN ._.
One_CD of_IN the_DT key_JJ issues_NNS in_IN active_JJ learning_NN is_VBZ how_WRB to_TO measure_VB the_DT classification_NN uncertainty_NN of_IN unlabeled_JJ examples_NNS ._.
In_IN =_JJ -_: =[_NN 6_CD ,_, 7_CD ,_, 8_CD ,_, 14_CD ,_, 21_CD ,_, 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT number_NN of_IN distinct_JJ classification_NN models_NNS are_VBP first_RB generated_VBN ._.
Then_RB ,_, the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN is_VBZ measured_VBN by_IN the_DT amount_NN of_IN disagreement_NN among_IN the_DT ensemble_NN of_IN classification_NN
lassification_NN model_NN from_IN the_DT mixture_NN of_IN labeled_JJ and_CC unlabeled_JJ examples_NNS -LRB-_-LRB- 30_CD -RRB-_-RRB- ._.
A_DT comprehensive_JJ study_NN of_IN semi-supervised_JJ learning_NN techniques_NNS can_MD be_VB found_VBN in_IN -LRB-_-LRB- 25_CD ,_, 38_CD -RRB-_-RRB- ._.
Another_DT solution_NN is_VBZ active_JJ learning_NN =_JJ -_: =[_NN 19_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: that_WDT tries_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ examples_NNS for_IN labeling_NN manually_RB ._.
Although_IN previous_JJ studies_NNS have_VBP shown_VBN the_DT promising_JJ performance_NN of_IN semi-supervised_JJ learning_NN for_IN text_NN categorization_NN
ur_NN conclusions_NNS ._.
2_CD ._.
RELATED_NNS WORK_VBP Text_NN categorization_NN is_VBZ a_DT long-term_JJ research_NN topic_NN which_WDT has_VBZ been_VBN actively_RB studied_VBN in_IN the_DT communities_NNS of_IN Web_NN data_NNS mining_NN ,_, information_NN retrieval_NN and_CC statistical_JJ learning_NN =_JJ -_: =[_NN 15_CD ,_, 35_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Essentially_RB the_DT text_NN categorization_NN techniques_NNS have_VBP been_VBN the_DT key_NN toward_IN automated_JJ categorization_NN of_IN large-scale_JJ Web_NN pages_NNS and_CC Web_NN sites_NNS -LRB-_-LRB- 18_CD ,_, 27_CD -RRB-_-RRB- ,_, which_WDT is_VBZ further_RB applied_VBN to_TO improve_VB Web_NN searching_VBG en_IN
ively_RB until_IN most_JJS of_IN the_DT examples_NNS can_MD be_VB classified_VBN with_IN reasonably_RB high_JJ confidence_NN ._.
One_CD of_IN the_DT key_JJ issues_NNS in_IN active_JJ learning_NN is_VBZ how_WRB to_TO measure_VB the_DT classification_NN uncertainty_NN of_IN unlabeled_JJ examples_NNS ._.
In_IN =_JJ -_: =[_NN 6_CD ,_, 7_CD ,_, 8_CD ,_, 14_CD ,_, 21_CD ,_, 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT number_NN of_IN distinct_JJ classification_NN models_NNS are_VBP first_RB generated_VBN ._.
Then_RB ,_, the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN is_VBZ measured_VBN by_IN the_DT amount_NN of_IN disagreement_NN among_IN the_DT ensemble_NN of_IN classification_NN
