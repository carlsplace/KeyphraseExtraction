A_DT contextual-bandit_JJ approach_NN to_TO personalized_JJ news_NN article_NN recommendation_NN
Personalized_VBN web_NN services_NNS strive_VBP to_TO adapt_VB their_PRP$ services_NNS -LRB-_-LRB- advertisements_NNS ,_, news_NN articles_NNS ,_, etc._NN -RRB-_-RRB- to_TO individual_JJ users_NNS by_IN making_VBG use_NN of_IN both_CC content_NN and_CC user_NN information_NN ._.
Despite_IN a_DT few_JJ recent_JJ advances_NNS ,_, this_DT problem_NN remains_VBZ challenging_JJ for_IN at_IN least_JJS two_CD reasons_NNS ._.
First_RB ,_, web_NN service_NN is_VBZ featured_VBN with_IN dynamically_RB changing_VBG pools_NNS of_IN content_NN ,_, rendering_VBG traditional_JJ collaborative_JJ filtering_VBG methods_NNS inapplicable_JJ ._.
Second_RB ,_, the_DT scale_NN of_IN most_JJS web_NN services_NNS of_IN practical_JJ interest_NN calls_VBZ for_IN solutions_NNS that_WDT are_VBP both_DT fast_JJ in_IN learning_NN and_CC computation_NN ._.
In_IN this_DT work_NN ,_, we_PRP model_VBP personalized_JJ recommendation_NN of_IN news_NN articles_NNS as_IN a_DT contextual_JJ bandit_NN problem_NN ,_, a_DT principled_JJ approach_NN in_IN which_WDT a_DT learning_NN algorithm_NN sequentially_RB selects_VBZ articles_NNS to_TO serve_VB users_NNS based_VBN on_IN contextual_JJ information_NN about_IN the_DT users_NNS and_CC articles_NNS ,_, while_IN simultaneously_RB adapting_VBG its_PRP$ article-selection_JJ strategy_NN based_VBN on_IN user-click_JJ feedback_NN to_TO maximize_VB total_JJ user_NN clicks_NNS ._.
The_DT contributions_NNS of_IN this_DT work_NN are_VBP three-fold_JJ ._.
First_RB ,_, we_PRP propose_VBP a_DT new_JJ ,_, general_JJ contextual_JJ bandit_NN algorithm_NN that_WDT is_VBZ computationally_RB efficient_JJ and_CC well_RB motivated_VBN from_IN learning_VBG theory_NN ._.
Second_RB ,_, we_PRP argue_VBP that_IN any_DT bandit_NN algorithm_NN can_MD be_VB reliably_RB evaluated_VBN offline_NN using_VBG previously_RB recorded_VBN random_JJ traffic_NN ._.
Finally_RB ,_, using_VBG this_DT offline_JJ evaluation_NN method_NN ,_, we_PRP successfully_RB applied_VBD our_PRP$ new_JJ algorithm_NN to_TO a_DT Yahoo_NNP !_.
Front_NN Page_NNP Today_NNP Module_NNP dataset_NN containing_VBG over_IN 33_CD million_CD events_NNS ._.
Results_NNS showed_VBD a_DT 12.5_CD %_NN click_VBP lift_NN compared_VBN to_TO a_DT standard_JJ context-free_JJ bandit_NN algorithm_NN ,_, and_CC the_DT advantage_NN becomes_VBZ even_RB greater_JJR when_WRB data_NNS gets_VBZ more_RBR scarce_JJ ._.
reinforcement_NN learning_NN algorithm_NN motivated_VBN by_IN the_DT KWIK_NNP algorithm_NN of_IN Walsh_NNP et_FW al._FW -LRB-_-LRB- 2009_CD -RRB-_-RRB- has_VBZ showed_VBN encouraging_JJ results_NNS in_IN a_DT challenging_JJ online_NN news_NN article_NN recommendation_NN problem_NN on_IN Yahoo_NNP !_.
Frontpage_NN -LRB-_-LRB- =_JJ -_: =_JJ Li_NNP et_FW al._FW 2010_CD -_: =--RRB-_NN ._.
The_DT study_NN in_IN the_DT present_JJ paper_NN raises_VBZ several_JJ important_JJ theoretical_JJ directions_NNS ._.
We_PRP list_VBP seven_CD of_IN them_PRP to_TO conclude_VB the_DT paper_NN ._.
First_RB ,_, we_PRP would_MD like_VB to_TO extend_VB the_DT KWIK_NNP framework_NN to_TO the_DT ``_`` unrealizable_JJ ''_''
roblem_NN ,_, and_CC also_RB illustrates_VBZ how_WRB the_DT algorithm_NN may_MD be_VB implemented_VBN efficiently_RB for_IN special_JJ classes_NNS of_IN experts_NNS ._.
The_DT problem_NN we_PRP study_VBP is_VBZ personalized_VBN news_NN article_NN recommendation_NN on_IN the_DT Yahoo_NNP !_.
front_JJ page_NN =_JJ -_: =[_NN 1_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Each_DT time_NN a_DT user_NN visits_VBZ the_DT front_JJ page_NN ,_, a_DT news_NN article_NN out_IN of_IN 24Alina_NNP Beygelzimer_NNP ,_, John_NNP Langford_NNP ,_, Lihong_NNP Li_NNP a_DT small_JJ pool_NN of_IN hand-picked_JJ candidates_NNS is_VBZ highlighted_VBN ._.
The_DT goal_NN is_VBZ to_TO highlight_VB the_DT most_JJS
o_NN predict_VBP the_DT probability_NN of_IN a_DT user_NN clicking_VBG on_IN a_DT given_VBN advertisement_NN ._.
This_DT setting_NN has_VBZ been_VBN used_VBN for_IN other_JJ applications_NNS including_VBG making_VBG article_NN recommendations_NNS on_IN web_NN portals_NNS -LRB-_-LRB- Agarwal_NNP et_FW al._FW ,_, 2009_CD ,_, =_JJ -_: =_JJ Li_NNP et_FW al._FW ,_, 2010_CD -_: =-]_CD ._.
In_IN this_DT paper_NN ,_, we_PRP give_VBP a_DT theoretical_JJ analysis_NN of_IN a_DT variant_NN of_IN LinUCB_NN ,_, a_DT natural_JJ upper_JJ confidence_NN bound_VBD algorithm_NN introduced_VBN and_CC experimentally_RB demonstrated_VBN to_TO be_VB effective_JJ by_IN Li_NNP et_FW al._FW -LRB-_-LRB- 2010_CD -RRB-_-RRB- ._.
We_PRP u_VBP
the_DT user_NN ._.
Furthermore_RB ,_, it_PRP is_VBZ typically_RB desirable_JJ to_TO learn_VB a_DT feature-based_JJ model_NN that_WDT can_MD generalize_VB to_TO new_JJ or_CC previously_RB unseen_JJ articles_NNS and_CC users_NNS ;_: this_DT is_VBZ often_RB called_VBN the_DT contextual_NN bandits_VBZ problem_NN =_JJ -_: =[_NN 13_CD ,_, 15_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Although_IN there_EX exist_VBP approaches_NNS that_WDT have_VBP addressed_VBN these_DT challenges_NNS individually_RB ,_, to_TO our_PRP$ knowledge_NN there_EX is_VBZ no_DT single_JJ approach_NN which_WDT solves_VBZ both_DT simultaneously_RB and_CC is_VBZ also_RB practical_JJ to_TO implement_VB ._.
F_NN
ot_IN independent_JJ of_IN the_DT actions_NNS taken_VBN in_IN the_DT past_NN -LRB-_-LRB- since_IN the_DT algorithm_NN 's_POS choices_NNS of_IN future_JJ actions_NNS depend_VBP on_IN the_DT random_JJ confidence_NN set_NN constructed_VBN from_IN past_JJ data_NNS -RRB-_-RRB- ._.
In_IN fact_NN ,_, several_JJ authors_NNS -LRB-_-LRB- Auer_NNP ,_, 2000_CD ,_, =_JJ -_: =_JJ Li_NNP et_FW al._FW ,_, 2010_CD -_: =_JJ -_: ,_, Walsh_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- fell_VBD victim_NN of_IN making_VBG a_DT mistake_NN because_IN they_PRP did_VBD not_RB recognize_VB this_DT issue_NN ._.
Correct_JJ solutions_NNS require_VBP new_JJ martingale_NN techniques_NNS which_WDT we_PRP provide_VBP here_RB ._.
The_DT smaller_JJR confidence_NN sets_NNS
action_NN is_VBZ given_VBN by_IN φ_NN -LRB-_-LRB- x_NN -RRB-_-RRB- ·_FW w_FW ,_, where_WRB w_NN is_VBZ an_DT unknown_JJ weight_NN vector_NN ._.
The_DT computational_JJ complexity_NN of_IN most_JJS existing_VBG algorithms_NNS is_VBZ nevertheless_RB linear_JJ in_IN the_DT number_NN of_IN actions_NNS -LRB-_-LRB- Abe_NN et_FW al._FW ,_, 2003_CD ;_: Auer_NNP ,_, 2002_CD ;_: =_JJ -_: =_JJ Li_NNP et_FW al._FW ,_, 2010_CD -_: =--RRB-_NN ._.
Furthermore_RB ,_, rather_RB than_IN being_VBG specified_VBN explicitly_RB ,_, the_DT linear_JJ space_NN in_IN which_WDT our_PRP$ parameterizations_NNS lie_VBP are_VBP given_VBN by_IN the_DT underlying_VBG graphical_NN or_CC locality_NN structure_NN of_IN the_DT model_NN ._.
More_RBR recent_JJ work_NN o_NN
blem_NN of_IN selecting_NN content_NN items_NNS to_TO present_VB to_TO a_DT user_NN who_WP is_VBZ intent_JJ on_IN browsing_VBG for_IN information_NN ._.
Examples_NNS of_IN content_NN optimization_NN are_VBP article_NN publishing_NN on_IN portal_JJ Websites_NNS -LRB-_-LRB- 2_CD ,_, 1_CD -RRB-_-RRB- ,_, news_NN personalization_NN =_JJ -_: =[_NN 16_CD ,_, 27_CD -RRB-_-RRB- -_: =_JJ -_: ,_, recommendation_NN of_IN dynamically_RB changing_VBG items_NNS -LRB-_-LRB- updates_NNS ,_, tweets_NNS ,_, etc_NN -RRB-_-RRB- ,_, and_CC computational_JJ advertising_NN -LRB-_-LRB- 11_CD ,_, 33_CD -RRB-_-RRB- ._.
This_DT work_NN will_MD address_VB the_DT variant_NN that_WDT displays_VBZ the_DT best_JJS set_NN of_IN trending_VBG queries_NNS from_IN th_DT
._.
Instead_RB it_PRP usually_RB arrives_VBZ in_IN batches_NNS over_IN a_DT certain_JJ period_NN of_IN time_NN ._.
We_PRP now_RB try_VBP to_TO quantify_VB the_DT impact_NN of_IN this_DT delay_NN by_IN doing_VBG some_DT simulations_NNS that_WDT mimic_VBP the_DT problem_NN of_IN news_NN articles_NNS recommendation_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: that_WDT will_MD be_VB described_VBN in_IN section_NN 5_CD ._.
4Regret_NN 4500 4000 3500 3000_CD 2500 2000 1500 1000_CD 500_CD α_NN =_JJ 2_CD α_NN =_JJ 1_CD α_NN =_JJ 0.5_CD α_NN =_JJ 0.25_CD Asymptotic_JJ lower_JJR bound_VBD Regret_NNP 7000 6000 5000 4000_CD 3000 2000 1000_CD 10_CD 2_CD 0_CD 10_CD 3_CD 10_CD 4_CD T_NN 10_CD 5_CD
ow_RB accurate_JJ the_DT offline_JJ evaluator_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- is_VBZ when_WRB non-random_JJ log_NN data_NNS are_VBP used_VBN instead_RB ._.
To_TO obtain_VB non-random_JJ log_NN data_NNS ,_, we_PRP ran_VBD the_DT LinUCB_NN algorithm_NN using_VBG the_DT offline_JJ bandit_NN simulation_NN procedure_NN ,_, both_DT from_IN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, on_IN our_PRP$ random_JJ log_NN data_NNS D0_NN and_CC recorded_JJ events_NNS -LRB-_-LRB- x_NN ,_, a_DT ,_, r_NN -RRB-_-RRB- for_IN which_WDT LinUCB_NN chose_VBD arm_NN a_DT for_IN context_NN x._NN Note_VBP that_IN π_NN is_VBZ a_DT deterministic_JJ learning_NN algorithm_NN ,_, and_CC may_MD choose_VB different_JJ arms_NNS for_IN the_DT same_JJ contex_NN
back_RB ._.
However_RB ,_, this_DT generality_NN comes_VBZ at_IN the_DT price_NN of_IN tractability_NN for_IN all_DT but_CC specific_JJ cases_NNS ,_, which_WDT do_VBP not_RB include_VB our_PRP$ model_NN ._.
Our_PRP$ work_NN is_VBZ also_RB somewhat_RB related_JJ to_TO the_DT contextual_JJ bandit_NN problem_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 9_CD ,_, 10_CD -RRB-_-RRB- -_: =--RRB-_NN ,_, where_WRB the_DT standard_JJ multi-armed_JJ bandits_NNS setting_VBG is_VBZ augmented_VBN with_IN some_DT side-information_NN provided_VBN in_IN each_DT round_NN ,_, which_WDT can_MD be_VB used_VBN to_TO determine_VB which_WDT action_NN to_TO pick_VB ._.
While_IN we_PRP also_RB consider_VBP additional_JJ
ncorporate_JJ various_JJ assumptions_NNS about_IN the_DT dependencies_NNS of_IN the_DT payoff_NN function_NN on_IN the_DT chosen_JJ actions_NNS and_CC observed_VBN contexts_NNS ._.
It_PRP also_RB allows_VBZ us_PRP to_TO generalize_VB several_JJ approaches_NNS proposed_VBN in_IN the_DT literature_NN =_JJ -_: =[_NN 3_CD ,_, 5_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN the_DT following_NN ,_, we_PRP will_MD prove_VB that_IN in_IN many_JJ practical_JJ applications_NNS ,_, CGP-UCB_NN attains_VBZ sublinear_JJ contextual_JJ regret_NN -LRB-_-LRB- i.e._FW ,_, is_VBZ able_JJ to_TO compete_VB with_IN the_DT optimal_JJ mapping_NN from_IN contexts_NNS to_TO actions_NNS -RRB-_-RRB- ._.
4_CD Bound_VBN
committing_VBG bandit_NN setup_NN ._.
There_EX are_VBP several_JJ extensions_NNS that_WDT call_VBP for_IN future_JJ research_NN which_WDT we_PRP outline_VBP below_IN ._.
First_RB ,_, an_DT extension_NN of_IN the_DT basic_JJ committing_VBG bandits_NNS setup_NN to_TO the_DT case_NN of_IN contextual_JJ bandits_NNS =_JJ -_: =[_NN 10_CD ,_, 11_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ natural_JJ ._.
In_IN this_DT setup_NN before_IN choosing_VBG an_DT arm_NN an_DT additional_JJ ``_`` context_NN ''_'' isprovidedtothedecision_NN maker_NN ._.
The_DT problem_NN is_VBZ to_TO choose_VB a_DT decision_NN rule_NN from_IN a_DT given_VBN class_NN that_WDT prescribes_VBZ what_WDT arm_NN to_TO choose_VB f_SYM
died_VBD in_IN reinforcement_NN learning_NN algorithms_NNS ._.
Multi-armed_JJ bandit_NN algorithms_NNS have_VBP been_VBN widely_RB studied_VBN in_IN the_DT Machine_NNP Learning_NNP community_NN and_CC recently_RB applied_VBN to_TO multiclass_JJ online_NN learning_NN -LRB-_-LRB- see_VB ,_, e.g._FW ,_, -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: ,_, -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 6_CD -RRB-_-RRB- -RRB-_-RRB- ._.
In_IN multiclass_JJ bandit_NN algorithms_VBZ the_DT feature_NN vectors_NNS of_IN the_DT training_NN examples_NNS are_VBP considered_VBN as_IN side_JJ information_NN given_VBN to_TO the_DT gambler_NN to_TO help_VB him_PRP choose_VB the_DT next_JJ arm_NN to_TO pull_VB --_: these_DT b_NN
tic_JJ ._.
Contentbased_JJ filtering_VBG helps_VBZ to_TO identify_VB new_JJ items_NNS which_WDT well_RB match_VBP anexisting_VBG user_NN 's_POS consumption_NN profile_NN ,_, but_CC the_DT recommended_VBN items_NNS are_VBP always_RB similar_JJ to_TO the_DT items_NNS previously_RB taken_VBN by_IN the_DT user_NN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Hybrid_NN approaches_NNS -LRB-_-LRB- 11_CD -RRB-_-RRB- have_VBP been_VBN developed_VBN by_IN combining_VBG two_CD or_CC more_JJR recommendation_NN techniques_NNS ;_: for_IN example_NN ,_, the_DT inability_NN of_IN collaborative_JJ filtering_VBG to_TO recommend_VB new_JJ items_NNS is_VBZ commonly_RB alleviated_VBN by_IN
ee_NN of_IN Õ_NN -LRB-_-LRB- T_NN 2\/3_CD -RRB-_-RRB- ._.
Algorithms_NNS with_IN stronger_JJR regret_NN guarantees_NNS may_MD be_VB designed_VBN under_IN various_JJ modeling_NN assumptions_NNS about_IN the_DT bandit_NN ._.
Assuming_VBG the_DT expected_VBN payoff_NN of_IN an_DT arm_NN is_VBZ linear_JJ in_IN its_PRP$ features_NNS ,_, Auer_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: describes_VBZ the_DT LinRel_NNP algorithm_NN that_WDT is_VBZ essentially_RB a_DT UCB-type_JJ approach_NN and_CC shows_VBZ that_IN one_CD of_IN its_PRP$ variants_NNS has_VBZ a_DT regret_NN of_IN Õ_NN -LRB-_-LRB- √_CD T_NN -RRB-_-RRB- ,_, a_DT significant_JJ improvement_NN over_IN earlier_JJR algorithms_NNS -LRB-_-LRB- 1_LS -RRB-_-RRB- ._.
Finally_RB ,_, we_PRP not_RB
ret_NN ,_, RA_NN -LRB-_-LRB- T_NN -RRB-_-RRB- \/_: T_NN ,_, converges_VBZ to_TO 0_CD with_IN probability_NN 1_CD ._.
In_IN contrast_NN to_TO the_DT unguided_JJ exploration_NN strategy_NN adopted_VBN by_IN ǫgreedy_NN ,_, another_DT class_NN of_IN algorithms_NNS generally_RB known_VBN as_IN upper_JJ confidence_NN bound_VBD algorithms_NNS =_JJ -_: =[_NN 4_CD ,_, 7_CD ,_, 17_CD -RRB-_-RRB- -_: =_SYM -_: use_VB a_DT smarter_RBR way_NN to_TO balance_VB exploration_NN and_CC exploitation_NN ._.
Specifically_RB ,_, in_IN trial_NN t_NN ,_, these_DT algorithms_NNS estimate_VBP both_CC the_DT mean_JJ payoff_NN ˆµt_NN ,_, a_DT of_IN each_DT arm_NN a_DT as_RB well_RB as_IN a_DT corresponding_JJ confidence_NN interval_NN
ent-based_JJ filtering_VBG and_CC hybrid_NN approaches_NNS ,_, can_MD provide_VB meaningful_JJ recommendations_NNS at_IN an_DT individual_JJ level_NN by_IN leveraging_VBG users_NNS '_POS interests_NNS as_IN demonstrated_VBN by_IN their_PRP$ past_JJ activity_NN ._.
Collaborative_JJ filtering_VBG =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_JJ -_: ,_, by_IN recognizing_VBG similarities_NNS across_IN users_NNS based_VBN on_IN their_PRP$ consumption_NN history_NN ,_, provides_VBZ a_DT good_JJ recommendation_NN solution_NN to_TO the_DT scenarios_NNS where_WRB overlap_VBP in_IN historical_JJ consumption_NN across_IN users_NNS is_VBZ relative_JJ
er_IN a_DT purely_RB exploring_VBG nor_CC a_DT purely_RB exploiting_VBG algorithm_NN works_VBZ best_JJS in_IN general_JJ ,_, and_CC a_DT good_JJ tradeoff_NN is_VBZ needed_VBN ._.
The_DT context-free_JJ K-armed_JJ bandit_NN problem_NN has_VBZ been_VBN studied_VBN by_IN statisticians_NNS for_IN a_DT long_JJ time_NN =_JJ -_: =[_NN 9_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT simplest_JJS and_CC most_JJS straightforward_JJ algorithms_NNS is_VBZ ǫ-greedy_NN ._.
In_IN each_DT trial_NN t_NN ,_, this_DT algorithm_NN first_RB estimates_VBZ the_DT average_JJ payoff_NN ˆµt_NN ,_, a_DT of_IN each_DT arm_NN a._NN Then_RB ,_, with_IN probability_NN 1_CD −_FW ǫ_FW ,_, it_PRP chooses_VBZ
model_NN ,_, the_DT predictive_JJ variance_NN of_IN the_DT expected_VBN payoff_NN x_NN ⊤_CD t_NN ,_, aθ_FW ∗_FW a_DT is_VBZ evaluated_VBN as_IN x_NN ⊤_CD t_NN ,_, aA_NN −_NN 1_CD a_DT xt_NN ,_, a_DT ,_, and_CC then_RB q_CD x_CC ⊤_CD t_NN ,_, aA_NN −_NN 1_CD a_DT xt_NN ,_, a_DT becomes_VBZ the_DT standard_JJ deviation_NN ._.
Furthermore_RB ,_, in_IN information_NN theory_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT differential_JJ entropy_NN of_IN p_NN -LRB-_-LRB- θa_NN -RRB-_-RRB- is_VBZ defined_VBN as_IN −_NN 1_CD 2_CD ln_NN -LRB-_-LRB- -LRB-_-LRB- 2π_NN -RRB-_-RRB- d_FW detAa_FW -RRB-_-RRB- ._.
The_DT entropy_NN of_IN p_NN -LRB-_-LRB- θa_NN -RRB-_-RRB- when_WRB updated_VBN by_IN the_DT inclusion_NN of_IN the_DT new_JJ point_NN xt_NN ,_, a_DT then_RB becomes_VBZ −_CD 1_CD 2_CD ln_NN -LRB-_-LRB- -LRB-_-LRB- 2π_NN -RRB-_-RRB- d_NN det_NN -LRB-_-LRB- Aa_NN +_CC xt_NN ,_, ax_NN ⊤_CD t_NN ,_, a_DT -RRB-_-RRB- -RRB-_-RRB- ._.
T_NN
clear_JJ how_WRB to_TO evaluate_VB π_NN based_VBN only_RB on_IN such_JJ logged_VBN data_NNS ._.
This_DT evaluation_NN problem_NN may_MD be_VB viewed_VBN as_IN a_DT special_JJ case_NN of_IN the_DT so-called_JJ ``_`` off-policy_NN evaluation_NN problem_NN ''_'' in_IN reinforcement_NN learning_NN -LRB-_-LRB- see_VB ,_, c.f._FW ,_, =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
One_CD solution_NN is_VBZ to_TO build_VB a_DT simulator_NN to_TO model_VB the_DT bandit_NN process_NN from_IN the_DT logged_VBN data_NNS ,_, and_CC then_RB evaluate_VB π_NN with_IN the_DT simulator_NN ._.
However_RB ,_, the_DT modeling_NN step_NN will_MD introduce_VB bias_NN in_IN the_DT simulator_NN and_CC so_RB
s_NN features_NNS ,_, Auer_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- describes_VBZ the_DT LinRel_NNP algorithm_NN that_WDT is_VBZ essentially_RB a_DT UCB-type_JJ approach_NN and_CC shows_VBZ that_IN one_CD of_IN its_PRP$ variants_NNS has_VBZ a_DT regret_NN of_IN Õ_NN -LRB-_-LRB- √_CD T_NN -RRB-_-RRB- ,_, a_DT significant_JJ improvement_NN over_IN earlier_JJR algorithms_NNS =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Finally_RB ,_, we_PRP note_VBP that_IN there_EX exist_VBP another_DT class_NN of_IN bandit_NN algorithms_NNS based_VBN on_IN Bayes_NNP rule_NN ,_, such_JJ as_IN Gittins_NNP index_NN methods_NNS -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
With_IN appropriately_RB defined_VBN prior_JJ distributions_NNS ,_, Bayesian_JJ approaches_NNS may_MD
ing_NN traffic_NN ._.
This_DT strategy_NN ,_, with_IN random_JJ exploration_NN on_IN an_DT ǫ_NN fraction_NN of_IN the_DT traffic_NN and_CC greedy_JJ exploitation_NN on_IN the_DT rest_NN ,_, is_VBZ known_VBN as_IN ǫ-greedy_NN ._.
Advanced_NNP exploration_NN approaches_NNS such_JJ as_IN EXP3_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- or_CC UCB1_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: could_MD be_VB applied_VBN as_RB well_RB ._.
Intuitively_RB ,_, we_PRP need_VBP to_TO distribute_VB more_JJR traffic_NN to_TO new_JJ content_NN to_TO learn_VB its_PRP$ value_NN more_RBR quickly_RB ,_, and_CC fewer_JJR users_NNS to_TO track_VB temporal_JJ changes_NNS of_IN existing_VBG content_NN ._.
Recently_RB ,_, pers_NNS
ing_NN helps_VBZ to_TO identify_VB new_JJ items_NNS which_WDT well_RB match_VBP anexisting_VBG user_NN 's_POS consumption_NN profile_NN ,_, but_CC the_DT recommended_VBN items_NNS are_VBP always_RB similar_JJ to_TO the_DT items_NNS previously_RB taken_VBN by_IN the_DT user_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Hybrid_NN approaches_VBZ =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP been_VBN developed_VBN by_IN combining_VBG two_CD or_CC more_JJR recommendation_NN techniques_NNS ;_: for_IN example_NN ,_, the_DT inability_NN of_IN collaborative_JJ filtering_VBG to_TO recommend_VB new_JJ items_NNS is_VBZ commonly_RB alleviated_VBN by_IN combining_VBG it_PRP with_IN conten_NN
arity_NN changing_VBG over_IN time_NN as_RB well_RB ._.
Furthermore_RB ,_, a_DT significant_JJ number_NN of_IN visitors_NNS are_VBP likely_JJ to_TO be_VB entirely_RB new_JJ with_IN no_DT historical_JJ consumption_NN record_NN whatsoever_RB ;_: this_DT is_VBZ known_VBN as_IN a_DT cold-start_JJ situation_NN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: ._.
These_DT issues_NNS make_VBP traditional_JJ recommender-system_JJ approaches_NNS difficult_JJ to_TO apply_VB ,_, as_IN shown_VBN by_IN prior_JJ empirical_JJ studies_NNS -LRB-_-LRB- 12_CD -RRB-_-RRB- ._.
It_PRP thus_RB becomes_VBZ indispensable_JJ to_TO learn_VB the_DT goodness_NN of_IN match_NN between_IN user_NN in_IN
A._NN ACM_NNP 978-1-60558-799-8_CD \/_: 10\/04_CD ._.
service_NN vendors_NNS acquire_VBP and_CC maintain_VBP a_DT large_JJ amount_NN of_IN content_NN in_IN their_PRP$ repository_NN ,_, for_IN instance_NN ,_, for_IN filtering_VBG news_NN articles_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- or_CC for_IN the_DT display_NN of_IN advertisements_NNS =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Moreover_RB ,_, the_DT content_NN of_IN such_PDT a_DT web-service_JJ repository_NN changes_NNS dynamically_RB ,_, undergoing_VBG frequent_JJ insertions_NNS and_CC deletions_NNS ._.
In_IN such_PDT a_DT setting_NN ,_, it_PRP is_VBZ crucial_JJ to_TO quickly_RB identify_VB interesting_JJ content_NN for_IN
s_NN has_VBZ a_DT regret_NN of_IN Õ_NN -LRB-_-LRB- √_CD T_NN -RRB-_-RRB- ,_, a_DT significant_JJ improvement_NN over_IN earlier_JJR algorithms_NNS -LRB-_-LRB- 1_LS -RRB-_-RRB- ._.
Finally_RB ,_, we_PRP note_VBP that_IN there_EX exist_VBP another_DT class_NN of_IN bandit_NN algorithms_NNS based_VBN on_IN Bayes_NNP rule_NN ,_, such_JJ as_IN Gittins_NNP index_NN methods_NNS =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
With_IN appropriately_RB defined_VBN prior_JJ distributions_NNS ,_, Bayesian_JJ approaches_NNS may_MD have_VB good_JJ performance_NN ._.
These_DT methods_NNS require_VBP extensive_JJ offline_JJ engineering_NN to_TO obtain_VB good_JJ prior_JJ models_NNS ,_, and_CC are_VBP often_RB computat_JJ
n_NN the_DT remaining_VBG traffic_NN ._.
This_DT strategy_NN ,_, with_IN random_JJ exploration_NN on_IN an_DT ǫ_NN fraction_NN of_IN the_DT traffic_NN and_CC greedy_JJ exploitation_NN on_IN the_DT rest_NN ,_, is_VBZ known_VBN as_IN ǫ-greedy_NN ._.
Advanced_NNP exploration_NN approaches_NNS such_JJ as_IN EXP3_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: or_CC UCB1_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- could_MD be_VB applied_VBN as_RB well_RB ._.
Intuitively_RB ,_, we_PRP need_VBP to_TO distribute_VB more_JJR traffic_NN to_TO new_JJ content_NN to_TO learn_VB its_PRP$ value_NN more_RBR quickly_RB ,_, and_CC fewer_JJR users_NNS to_TO track_VB temporal_JJ changes_NNS of_IN existing_VBG content_NN ._.
Re_NNP
ret_NN ,_, RA_NN -LRB-_-LRB- T_NN -RRB-_-RRB- \/_: T_NN ,_, converges_VBZ to_TO 0_CD with_IN probability_NN 1_CD ._.
In_IN contrast_NN to_TO the_DT unguided_JJ exploration_NN strategy_NN adopted_VBN by_IN ǫgreedy_NN ,_, another_DT class_NN of_IN algorithms_NNS generally_RB known_VBN as_IN upper_JJ confidence_NN bound_VBD algorithms_NNS =_JJ -_: =[_NN 4_CD ,_, 7_CD ,_, 17_CD -RRB-_-RRB- -_: =_SYM -_: use_VB a_DT smarter_RBR way_NN to_TO balance_VB exploration_NN and_CC exploitation_NN ._.
Specifically_RB ,_, in_IN trial_NN t_NN ,_, these_DT algorithms_NNS estimate_VBP both_CC the_DT mean_JJ payoff_NN ˆµt_NN ,_, a_DT of_IN each_DT arm_NN a_DT as_RB well_RB as_IN a_DT corresponding_JJ confidence_NN interval_NN
er_IN a_DT purely_RB exploring_VBG nor_CC a_DT purely_RB exploiting_VBG algorithm_NN works_VBZ best_JJS in_IN general_JJ ,_, and_CC a_DT good_JJ tradeoff_NN is_VBZ needed_VBN ._.
The_DT context-free_JJ K-armed_JJ bandit_NN problem_NN has_VBZ been_VBN studied_VBN by_IN statisticians_NNS for_IN a_DT long_JJ time_NN =_JJ -_: =[_NN 9_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT simplest_JJS and_CC most_JJS straightforward_JJ algorithms_NNS is_VBZ ǫ-greedy_NN ._.
In_IN each_DT trial_NN t_NN ,_, this_DT algorithm_NN first_RB estimates_VBZ the_DT average_JJ payoff_NN ˆµt_NN ,_, a_DT of_IN each_DT arm_NN a._NN Then_RB ,_, with_IN probability_NN 1_CD −_FW ǫ_FW ,_, it_PRP chooses_VBZ
s_NN of_IN existing_VBG content_NN ._.
Recently_RB ,_, personalized_JJ recommendation_NN has_VBZ become_VBN a_DT desirable_JJ feature_NN for_IN websites_NNS to_TO improve_VB user_NN satisfaction_NN by_IN tailoring_VBG content_NN presentation_NN to_TO suit_VB individual_JJ users_NNS '_POS needs_NNS =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Personalization_NN involves_VBZ a_DT process_NN of_IN gathering_VBG and_CC storing_VBG user_NN attributes_NNS ,_, managing_VBG content_NN assets_NNS ,_, and_CC ,_, based_VBN on_IN an_DT analysis_NN of_IN current_JJ and_CC past_JJ users_NNS '_POS behavior_NN ,_, delivering_VBG the_DT individually_RB best_JJS
l_NN 26_CD --_: 30_CD ,_, 2010_CD ,_, Raleigh_NNP ,_, North_NNP Carolina_NNP ,_, USA_NNP ._.
ACM_NN 978-1-60558-799-8_CD \/_: 10\/04_CD ._.
service_NN vendors_NNS acquire_VBP and_CC maintain_VBP a_DT large_JJ amount_NN of_IN content_NN in_IN their_PRP$ repository_NN ,_, for_IN instance_NN ,_, for_IN filtering_VBG news_NN articles_NNS =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: or_CC for_IN the_DT display_NN of_IN advertisements_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
Moreover_RB ,_, the_DT content_NN of_IN such_PDT a_DT web-service_JJ repository_NN changes_NNS dynamically_RB ,_, undergoing_VBG frequent_JJ insertions_NNS and_CC deletions_NNS ._.
In_IN such_PDT a_DT setting_NN ,_, it_PRP is_VBZ crucial_JJ to_TO
er_IN a_DT purely_RB exploring_VBG nor_CC a_DT purely_RB exploiting_VBG algorithm_NN works_VBZ best_JJS in_IN general_JJ ,_, and_CC a_DT good_JJ tradeoff_NN is_VBZ needed_VBN ._.
The_DT context-free_JJ K-armed_JJ bandit_NN problem_NN has_VBZ been_VBN studied_VBN by_IN statisticians_NNS for_IN a_DT long_JJ time_NN =_JJ -_: =[_NN 9_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT simplest_JJS and_CC most_JJS straightforward_JJ algorithms_NNS is_VBZ ǫ-greedy_NN ._.
In_IN each_DT trial_NN t_NN ,_, this_DT algorithm_NN first_RB estimates_VBZ the_DT average_JJ payoff_NN ˆµt_NN ,_, a_DT of_IN each_DT arm_NN a._NN Then_RB ,_, with_IN probability_NN 1_CD −_FW ǫ_FW ,_, it_PRP chooses_VBZ
2.1_CD A_DT Multi-armed_JJ Bandit_NN Formulation_NNP The_DT problem_NN of_IN personalized_JJ news_NN article_NN recommendation_NN can_MD be_VB naturally_RB modeled_VBN as_IN a_DT multi-armed_JJ bandit_NN problem_NN with_IN context_NN information_NN ._.
Following_VBG previous_JJ work_NN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_JJ -_: ,_, we_PRP call_VBP it_PRP a_DT contextual_JJ bandit_NN ._.
1_CD Formally_RB ,_, a_DT contextual-bandit_JJ algorithm_NN A_NN proceeds_VBZ in_IN discrete_JJ trials_NNS t_NN =_JJ 1_CD ,_, 2,3_CD ,_, ..._: In_IN trial_NN t_NN :_: 1_CD ._.
The_DT algorithm_NN observes_VBZ the_DT current_JJ user_NN ut_NN and_CC a_DT set_NN At_IN of_IN ar_NN
pool_NN is_VBZ large_JJ ._.
In_IN the_DT future_NN ,_, we_PRP plan_VBP to_TO investigate_VB bandit_NN approaches_NNS to_TO other_JJ similar_JJ web-based_JJ serviced_VBN such_JJ as_IN online_NN advertising_NN ,_, and_CC compare_VB our_PRP$ algorithms_NNS to_TO related_JJ methods_NNS such_JJ as_IN Banditron_NN =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT second_JJ direction_NN is_VBZ to_TO extend_VB the_DT bandit_NN formulation_NN and_CC algorithms_NNS in_IN which_WDT an_DT ``_`` arm_NN ''_'' may_MD refer_VB to_TO a_DT complex_JJ object_NN rather_RB than_IN an_DT item_NN -LRB-_-LRB- like_IN an_DT article_NN -RRB-_-RRB- ._.
An_DT example_NN is_VBZ ranking_JJ ,_, where_WRB an_DT arm_NN corre_NN
lely_RB on_IN content_NN information_NN ._.
In_IN practice_NN ,_, we_PRP usually_RB explore_VBP the_DT unknown_NN by_IN collecting_VBG consumers_NNS '_POS feedback_NN in_IN real_JJ time_NN to_TO evaluate_VB the_DT popularity_NN of_IN new_JJ content_NN while_IN monitoring_VBG changes_NNS in_IN its_PRP$ value_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN instance_NN ,_, a_DT small_JJ amount_NN of_IN traffic_NN can_MD be_VB designated_VBN for_IN such_JJ exploration_NN ._.
Based_VBN on_IN the_DT users_NNS '_POS response_NN -LRB-_-LRB- such_JJ as_IN clicks_NNS -RRB-_-RRB- to_TO randomly_RB selected_VBN content_NN on_IN this_DT small_JJ slice_NN of_IN traffic_NN ,_, the_DT most_JJS po_NN
imate_NN of_IN the_DT coefficients_NNS :_: ˆθa_NN =_JJ -LRB-_-LRB- D_NN ⊤_CD a_DT Da_NN +_CC Id_NN -RRB-_-RRB- −_NN 1_CD D_NN ⊤_NN a_DT ca_MD ,_, -LRB-_-LRB- 3_CD -RRB-_-RRB- where_WRB Id_NN is_VBZ the_DT d_FW ×_FW d_FW identity_NN matrix_NN ._.
When_WRB components_NNS in_IN ca_MD are_VB independent_JJ conditioned_VBN on_IN corresponding_JJ rows_NNS in_IN Da_NN ,_, it_PRP can_MD be_VB shown_VBN =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_SYM -_: that_IN ,_, with_IN probability_NN at_IN least_JJS 1_CD −_FW δ_FW ,_, ˛_FW ˛x_FW ⊤_FW t_NN ,_, a_DT ˆ_FW q_FW θa_FW −_FW E_NN -LRB-_-LRB- rt_NN ,_, a_DT |_FW xt_FW ,_, a_DT -RRB-_-RRB- ˛_FW ≤_FW α_FW x_NN ⊤_CD t_NN ,_, a_DT -LRB-_-LRB- D_NNP ⊤_NNP a_DT Da_NN +_CC Id_NN -RRB-_-RRB- −_FW 1xt_FW ,_, a_DT -LRB-_-LRB- 4_CD -RRB-_-RRB- for_IN any_DT δ_NN -RRB-_-RRB- 0_CD and_CC xt_NN ,_, a_DT ∈_NN R_NN d_NN ,_, where_WRB α_NN =_JJ 1_CD +_CC p_NN ln_NN -LRB-_-LRB- 2_CD \/_: δ_NN -RRB-_-RRB- \/_: 2_CD is_VBZ a_DT constant_NN ._.
In_IN other_JJ words_NNS ,_, t_NN
es_NNS may_MD have_VB good_JJ performance_NN ._.
These_DT methods_NNS require_VBP extensive_JJ offline_JJ engineering_NN to_TO obtain_VB good_JJ prior_JJ models_NNS ,_, and_CC are_VBP often_RB computationally_RB prohibitive_JJ without_IN coupling_NN with_IN approximation_NN techniques_NNS =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
3_LS ._.
ALGORITHM_NN Given_IN asymptotic_JJ optimality_NN and_CC the_DT strong_JJ regret_NN bound_VBD of_IN UCB_NNP methods_NNS for_IN context-free_JJ bandit_NN algorithms_NNS ,_, it_PRP is_VBZ tempting_JJ to_TO devise_VB similar_JJ algorithms_NNS for_IN contextual_JJ bandit_NN problems_NNS ._.
Gi_NN
orical_JJ consumption_NN record_NN whatsoever_RB ;_: this_DT is_VBZ known_VBN as_IN a_DT cold-start_JJ situation_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ._.
These_DT issues_NNS make_VBP traditional_JJ recommender-system_JJ approaches_NNS difficult_JJ to_TO apply_VB ,_, as_IN shown_VBN by_IN prior_JJ empirical_JJ studies_NNS =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
It_PRP thus_RB becomes_VBZ indispensable_JJ to_TO learn_VB the_DT goodness_NN of_IN match_NN between_IN user_NN interests_NNS and_CC content_NN when_WRB one_CD or_CC both_DT of_IN them_PRP are_VBP new_JJ ._.
However_RB ,_, acquiring_VBG such_JJ information_NN can_MD be_VB expensive_JJ and_CC may_MD reduce_VB
nd_NN capture_NN nonlinearity_NN in_IN these_DT raw_JJ features_NNS ,_, we_PRP carried_VBD out_RP conjoint_NN analysis_NN based_VBN on_IN random_JJ exploration_NN data_NNS collected_VBN in_IN September_NNP 2008_CD ._.
Following_VBG a_DT previous_JJ approach_NN to_TO dimensionality_NN reduction_NN =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, we_PRP projected_VBD user_NN features_NNS onto_IN article_NN categories_NNS and_CC then_RB clustered_VBD users_NNS with_IN similar_JJ preferences_NNS into_IN groups_NNS ._.
More_RBR specifically_RB :_: •_VB We_PRP first_RB used_VBD logistic_JJ regression_NN -LRB-_-LRB- LR_NN -RRB-_-RRB- to_TO fit_VB a_DT bilinear_JJ model_NN
t_NN ,_, at_IN 14_CD :_: end_NN for_IN Finally_RB ,_, we_PRP note_VBP that_IN ,_, under_IN the_DT assumption_NN that_IN input_NN features_NNS xt_VBP ,_, a_DT were_VBD drawn_VBN i.i.d._RB from_IN a_DT normal_JJ distribution_NN -LRB-_-LRB- in_IN addition_NN to_TO the_DT modeling_NN assumption_NN in_IN Eq_NN ._.
-LRB-_-LRB- 2_LS -RRB-_-RRB- -RRB-_-RRB- ,_, Pavlidis_FW et_FW al._FW =_SYM -_: =[_NN 22_CD -RRB-_-RRB- -_: =_SYM -_: came_VBD up_RP with_IN a_DT similar_JJ algorithm_NN that_WDT uses_VBZ a_DT least-squares_JJ solution_NN ˜_FW θa_FW instead_RB of_IN our_PRP$ ridge-regression_NN solution_NN -LRB-_-LRB- ˆ_FW θa_FW in_IN Eq_NN ._.
-LRB-_-LRB- 3_LS -RRB-_-RRB- -RRB-_-RRB- to_TO compute_VB the_DT UCB_NNP ._.
However_RB ,_, our_PRP$ approach_NN -LRB-_-LRB- and_CC theoretical_JJ analysi_NNS
