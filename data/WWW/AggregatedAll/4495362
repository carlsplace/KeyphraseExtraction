Detecting_VBG near-duplicates_NNS for_IN web_NN crawling_VBG
Near-duplicate_JJ web_NN documents_NNS are_VBP abundant_JJ ._.
Two_CD such_JJ documents_NNS differ_VBP from_IN each_DT other_JJ in_IN a_DT very_RB small_JJ portion_NN that_WDT displays_VBZ advertisements_NNS ,_, for_IN example_NN ._.
Such_JJ differences_NNS are_VBP irrelevant_JJ for_IN web_NN search_NN ._.
So_IN the_DT quality_NN of_IN a_DT web_NN crawler_NN increases_NNS if_IN it_PRP can_MD assess_VB whether_IN a_DT newly_RB crawled_VBN web_NN page_NN is_VBZ a_DT near-duplicate_NN of_IN a_DT previously_RB crawled_VBN web_NN page_NN or_CC not_RB ._.
In_IN the_DT course_NN of_IN developing_VBG a_DT near-duplicate_JJ detection_NN system_NN for_IN a_DT multi-billion_JJ page_NN repository_NN ,_, we_PRP make_VBP two_CD research_NN contributions_NNS ._.
First_RB ,_, we_PRP demonstrate_VBP that_IN Charikar_NNP 's_POS fingerprinting_NN technique_NN is_VBZ appropriate_JJ for_IN this_DT goal_NN ._.
Second_RB ,_, we_PRP present_VBP an_DT algorithmic_JJ technique_NN for_IN identifying_VBG existing_VBG f-bit_NN fingerprints_NNS that_WDT differ_VBP from_IN a_DT given_VBN fingerprint_NN in_IN at_IN most_JJS k_NN bit-positions_NNS ,_, for_IN small_JJ k._NNP Our_NNP technique_NN is_VBZ useful_JJ for_IN both_CC online_JJ queries_NNS -LRB-_-LRB- single_JJ fingerprints_NNS -RRB-_-RRB- and_CC all_DT batch_NN queries_NNS -LRB-_-LRB- multiple_JJ fingerprints_NNS -RRB-_-RRB- ._.
Experimental_JJ evaluation_NN over_IN real_JJ data_NNS confirms_VBZ the_DT practicality_NN of_IN our_PRP$ design_NN ._.
or_CC four_CD types_NNS of_IN document_NN collections_NNS :_: a_LS -RRB-_-RRB- Web_NN Documents_NNS :_: Near-duplicate_JJ systems_NNS have_VBP been_VBN developed_VBN for_IN finding_VBG related-pages_NNS -LRB-_-LRB- 25_CD -RRB-_-RRB- ,_, for_IN extracting_VBG structured_JJ data_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, and_CC for_IN identifying_VBG web_NN mirrors_VBZ =_JJ -_: =[_NN 6,7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
b_LS -RRB-_-RRB- Files_NNS in_IN a_DT file_NN system_NN :_: Manber_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- develops_VBZ algorithms_NNS for_IN near-duplicate_JJ detection_NN to_TO reduce_VB storage_NN for_IN files_NNS ._.
The_DT Venti_NNP file_NN system_NN -LRB-_-LRB- 48_CD -RRB-_-RRB- and_CC the_DT Low-bandwidth_JJ file_NN system_NN -LRB-_-LRB- 45_CD -RRB-_-RRB- have_VBP similar_JJ mo_NN
Web_NN Documents_NNS :_: Near-duplicate_JJ systems_NNS have_VBP been_VBN developed_VBN for_IN finding_VBG related-pages_NNS -LRB-_-LRB- 25_CD -RRB-_-RRB- ,_, for_IN extracting_VBG structured_JJ data_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, and_CC for_IN identifying_VBG web_NN mirrors_VBZ -LRB-_-LRB- 6,7_CD -RRB-_-RRB- ._.
b_LS -RRB-_-RRB- Files_NNS in_IN a_DT file_NN system_NN :_: Manber_NN =_JJ -_: =[_NN 42_CD -RRB-_-RRB- -_: =_SYM -_: develops_VBZ algorithms_NNS for_IN near-duplicate_JJ detection_NN to_TO reduce_VB storage_NN for_IN files_NNS ._.
The_DT Venti_NNP file_NN system_NN -LRB-_-LRB- 48_CD -RRB-_-RRB- and_CC the_DT Low-bandwidth_JJ file_NN system_NN -LRB-_-LRB- 45_CD -RRB-_-RRB- have_VBP similar_JJ motivations_NNS ._.
c_LS -RRB-_-RRB- E-mails_NNS :_: Kolcz_NNP et_NNP al_NNP -LRB-_-LRB- 40_CD -RRB-_-RRB-
s._VB The_DT set_NN of_IN shingles_NNS constitutes_VBZ the_DT set_NN of_IN features_NNS of_IN a_DT document_NN ._.
The_DT choice_NN of_IN k_NN is_VBZ crucial_JJ 3_CD ._.
Hashes_NNS of_IN successive_JJ k-grams_NNS can_MD be_VB efficiently_RB computed_VBN by_IN using_VBG Rabin_NNP 's_POS fingerprinting_VBG technique_NN =_JJ -_: =[_NN 49_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Manber_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- created_VBD shingles_NNS over_IN characters_NNS ._.
The_DT COPS_NN system_NN by_IN Brin_NNP et_FW al_FW -LRB-_-LRB- 8_CD -RRB-_-RRB- used_VBN sentences_NNS for_IN creating_VBG shingles_NNS ._.
Broder_NNP et_FW al_FW -LRB-_-LRB- 12_CD ,_, 14_CD -RRB-_-RRB- created_VBD shingles_NNS over_IN words_NNS ._.
The_DT total_JJ number_NN of_IN shingles_NNS
r_NN algorithm_NN was_VBD improved_VBN by_IN Brodal_NNP and_CC G_NNP ¸_FW asienec_FW -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC Brodal_NNP and_CC Venkatesh_NNP -LRB-_-LRB- 11_CD -RRB-_-RRB- ._.
For_IN large_JJ d_NN ,_, some_DT progress_NN is_VBZ reported_VBN by_IN Greene_NNP ,_, Parnas_NNP and_CC Yao_NNP -LRB-_-LRB- 31_CD -RRB-_-RRB- ,_, Dolev_NNP et_FW al_FW -LRB-_-LRB- 28_CD -RRB-_-RRB- and_CC Arslan_NN and_CC E˘gecio˘glu_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Our_PRP$ problem_NN differs_VBZ from_IN the_DT one_CD addressed_VBN by_IN the_DT theory_NN community_NN in_IN two_CD aspects_NNS ._.
First_RB ,_, we_PRP assume_VBP that_IN the_DT input_NN consists_VBZ of_IN bit-strings_NNS chosen_VBN uniformly_RB at_IN random_JJ -LRB-_-LRB- with_IN some_DT non-uniformity_JJ introd_NN
solutions_NNS are_VBP known_VBN for_IN general_JJ n_NN ,_, f_FW and_CC d._NN A_NN theoretical_JJ study_NN was_VBD initiated_VBN by_IN Yao_NNP and_CC Yao_NNP -LRB-_-LRB- 53_CD -RRB-_-RRB- ,_, who_WP developed_VBD an_DT efficient_JJ algorithm_NN for_IN d_NN =_JJ 1_CD ._.
Their_PRP$ algorithm_NN was_VBD improved_VBN by_IN Brodal_NNP and_CC G_NNP ¸_NNP asienec_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Brodal_NNP and_CC Venkatesh_NNP -LRB-_-LRB- 11_CD -RRB-_-RRB- ._.
For_IN large_JJ d_NN ,_, some_DT progress_NN is_VBZ reported_VBN by_IN Greene_NNP ,_, Parnas_NNP and_CC Yao_NNP -LRB-_-LRB- 31_CD -RRB-_-RRB- ,_, Dolev_NNP et_FW al_FW -LRB-_-LRB- 28_CD -RRB-_-RRB- and_CC Arslan_NN and_CC E˘gecio˘glu_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
Our_PRP$ problem_NN differs_VBZ from_IN the_DT one_CD addressed_VBN by_IN th_DT
l_NN n_NN ,_, f_FW and_CC d._NN A_NN theoretical_JJ study_NN was_VBD initiated_VBN by_IN Yao_NNP and_CC Yao_NNP -LRB-_-LRB- 53_CD -RRB-_-RRB- ,_, who_WP developed_VBD an_DT efficient_JJ algorithm_NN for_IN d_NN =_JJ 1_CD ._.
Their_PRP$ algorithm_NN was_VBD improved_VBN by_IN Brodal_NNP and_CC G_NNP ¸_FW asienec_FW -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC Brodal_NN and_CC Venkatesh_NN =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN large_JJ d_NN ,_, some_DT progress_NN is_VBZ reported_VBN by_IN Greene_NNP ,_, Parnas_NNP and_CC Yao_NNP -LRB-_-LRB- 31_CD -RRB-_-RRB- ,_, Dolev_NNP et_FW al_FW -LRB-_-LRB- 28_CD -RRB-_-RRB- and_CC Arslan_NN and_CC E˘gecio˘glu_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
Our_PRP$ problem_NN differs_VBZ from_IN the_DT one_CD addressed_VBN by_IN the_DT theory_NN community_NN in_IN two_CD aspe_NN
that_IN the_DT notion_NN of_IN similarity_NN is_VBZ ``_`` semantic_JJ ''_'' rather_RB than_IN ``_`` syntactic_JJ ''_'' ,_, quite_RB different_JJ from_IN the_DT notion_NN of_IN duplicates_NNS or_CC near-duplicates_NNS discussed_VBN above_IN ._.
One_CD approach_NN is_VBZ to_TO use_VB Latent_JJ Semantic_JJ Indexing_NN =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Another_DT approach_NN is_VBZ to_TO exploit_VB the_DT linkage_NN structure_NN of_IN the_DT web_NN -LRB-_-LRB- see_VB Dean_NNP and_CC Henzinger_NNP -LRB-_-LRB- 25_CD -RRB-_-RRB- who_WP build_VBP upon_IN Kleinberg_NNP 's_POS idea_NN of_IN hubs_NNS and_CC authorities_NNS -LRB-_-LRB- 39_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Going_VBG further_RBR along_IN these_DT lines_NNS ,_, Kumar_FW et_FW
,_, 43_CD ,_, 46_CD -RRB-_-RRB- use_VBP some_DT specialized_JJ knowledge_NN to_TO limit_VB the_DT crawl_NN to_TO pages_NNS pertaining_VBG to_TO specific_JJ topics_NNS ._.
For_IN web_NN crawling_NN ,_, issues_NNS like_IN freshness_NN and_CC efficient_JJ resource_NN usage_NN have_VBP previously_RB been_VBN addressed_VBN =_JJ -_: =[_NN 15_CD ,_, 16_CD ,_, 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, the_DT problem_NN of_IN elimination_NN of_IN near-duplicate_JJ web_NN documents_NNS in_IN a_DT generic_JJ crawl_NN has_VBZ not_RB received_VBN attention_NN ._.
∗_NNP Anish_NNP worked_VBD on_IN this_DT problem_NN at_IN Google_NNP in_IN Dec_NNP 2005_CD ._.
Copyright_NN is_VBZ held_VBN by_IN the_DT Inte_NNP
structured_VBN data_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, and_CC for_IN identifying_VBG web_NN mirrors_VBZ -LRB-_-LRB- 6,7_CD -RRB-_-RRB- ._.
b_LS -RRB-_-RRB- Files_NNS in_IN a_DT file_NN system_NN :_: Manber_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- develops_VBZ algorithms_NNS for_IN near-duplicate_JJ detection_NN to_TO reduce_VB storage_NN for_IN files_NNS ._.
The_DT Venti_NNP file_NN system_NN =_JJ -_: =[_NN 48_CD -RRB-_-RRB- -_: =_JJ -_: and_CC the_DT Low-bandwidth_JJ file_NN system_NN -LRB-_-LRB- 45_CD -RRB-_-RRB- have_VBP similar_JJ motivations_NNS ._.
c_LS -RRB-_-RRB- E-mails_NNS :_: Kolcz_NNP et_NNP al_NNP -LRB-_-LRB- 40_CD -RRB-_-RRB- identify_VBP near-duplicates_NNS for_IN spam_NN detection_NN ._.
d_LS -RRB-_-RRB- Domain-specific_JJ corpora_NN :_: Various_JJ groups_NNS have_VBP developed_VBN ne_NN
approach_NN is_VBZ to_TO use_VB Latent_JJ Semantic_JJ Indexing_NN -LRB-_-LRB- 26_CD -RRB-_-RRB- ._.
Another_DT approach_NN is_VBZ to_TO exploit_VB the_DT linkage_NN structure_NN of_IN the_DT web_NN -LRB-_-LRB- see_VB Dean_NNP and_CC Henzinger_NNP -LRB-_-LRB- 25_CD -RRB-_-RRB- who_WP build_VBP upon_IN Kleinberg_NNP 's_POS idea_NN of_IN hubs_NNS and_CC authorities_NNS =_JJ -_: =[_NN 39_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
Going_VBG further_RBR along_IN these_DT lines_NNS ,_, Kumar_NNP et_FW al_FW -LRB-_-LRB- 41_CD -RRB-_-RRB- have_VBP proposed_VBN discovering_VBG ``_`` online_JJ communities_NNS ''_'' by_IN identifying_VBG dense_JJ bipartite_JJ sub-graphs_NNS of_IN the_DT web-graph_NN ._.
c_LS -RRB-_-RRB- Data_NNP extraction_NN :_: Given_IN a_DT moderate-siz_NN
o_NN developed_VBD an_DT efficient_JJ algorithm_NN for_IN d_NN =_JJ 1_CD ._.
Their_PRP$ algorithm_NN was_VBD improved_VBN by_IN Brodal_NNP and_CC G_NNP ¸_FW asienec_FW -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC Brodal_NNP and_CC Venkatesh_NNP -LRB-_-LRB- 11_CD -RRB-_-RRB- ._.
For_IN large_JJ d_NN ,_, some_DT progress_NN is_VBZ reported_VBN by_IN Greene_NNP ,_, Parnas_NNP and_CC Yao_NNP =_SYM -_: =[_NN 31_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Dolev_NNP et_FW al_FW -LRB-_-LRB- 28_CD -RRB-_-RRB- and_CC Arslan_NN and_CC E˘gecio˘glu_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
Our_PRP$ problem_NN differs_VBZ from_IN the_DT one_CD addressed_VBN by_IN the_DT theory_NN community_NN in_IN two_CD aspects_NNS ._.
First_RB ,_, we_PRP assume_VBP that_IN the_DT input_NN consists_VBZ of_IN bit-strings_JJ chosen_JJ uni_NN
f_LS A_NN and_CC B_NN match_NN is_VBZ exactly_RB the_DT Jaccard_NNP measure_NN -LRB-_-LRB- 13_CD ,_, 14_CD -RRB-_-RRB- ._.
Several_JJ experimental_JJ studies_NNS have_VBP tested_VBN the_DT efficacy_NN of_IN min-hash_JJ in_IN various_JJ settings_NNS -LRB-_-LRB- Cohen_NNP et_FW al_FW -LRB-_-LRB- 21_CD -RRB-_-RRB- for_IN associationrule_JJ mining_NN ,_, Chen_NNP et_FW al_FW =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_SYM -_: for_IN selectivity_NN estimation_NN of_IN boolean_JJ queries_NNS ,_, Gionis_FW et_FW al_FW -LRB-_-LRB- 30_CD -RRB-_-RRB- for_IN indexing_VBG set-value_JJ predicates_NNS and_CC Haveliwala_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- for_IN web-clustering_NN -RRB-_-RRB- ._.
c_LS -RRB-_-RRB- Signatures\/fingerprints_NNS over_IN IR-based_JJ document_NN vectors_NNS :_:
-_: matches_NNS ._.
A_DT drawback_NN of_IN this_DT scheme_NN is_VBZ that_IN the_DT distance_NN between_IN successive_JJ shingles_NNS that_WDT are_VBP retained_VBN ,_, is_VBZ unbounded_JJ ._.
This_DT problem_NN has_VBZ been_VBN ameliorated_VBN by_IN the_DT ``_`` winnowing_NN ''_'' technique_NN by_IN Schliemer_NNP et_FW al_FW =_JJ -_: =[_NN 50_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Hoad_NNP and_CC Zobel_NNP -LRB-_-LRB- 36_CD -RRB-_-RRB- compare_VBP a_DT variety_NN of_IN other_JJ ideas_NNS for_IN pruning_NN the_DT set_NN of_IN shingle-based_JJ fingerprints_NNS ._.
b_LS -RRB-_-RRB- Min-hash_JJ for_IN Jaccard_NNP similarity_NN of_IN sets_NNS :_: For_IN two_CD sets_NNS A_NN and_CC B_NN ,_, let_VBD the_DT measure_NN of_IN similarit_NN
simhash_NN ,_, done_VBN by_IN Moses_NNP Charikar_NNP himself_PRP ._.
Concomitant_JJ with_IN the_DT development_NN of_IN our_PRP$ system_NN in_IN 2004_CD --_: 2005_CD ,_, Monika_NNP Henzinger_NNP conducted_VBD a_DT study_NN that_WDT compared_VBD simhash_JJ with_IN Broder_NNP 's_POS shingle-based_JJ fingerprints_NNS =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
An_DT excellent_JJ comparison_NN of_IN these_DT two_CD approaches_NNS appears_VBZ in_IN Henzinger_NNP -LRB-_-LRB- 35_CD -RRB-_-RRB- ._.
A_DT great_JJ advantage_NN of_IN using_VBG simhash_NN over_IN shingles_NNS is_VBZ that_IN it_PRP requires_VBZ relatively_RB small-sized_JJ fingerprints_NNS ._.
For_IN example_NN ,_, Brod_NNP
,_, 43_CD ,_, 46_CD -RRB-_-RRB- use_VBP some_DT specialized_JJ knowledge_NN to_TO limit_VB the_DT crawl_NN to_TO pages_NNS pertaining_VBG to_TO specific_JJ topics_NNS ._.
For_IN web_NN crawling_NN ,_, issues_NNS like_IN freshness_NN and_CC efficient_JJ resource_NN usage_NN have_VBP previously_RB been_VBN addressed_VBN =_JJ -_: =[_NN 15_CD ,_, 16_CD ,_, 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, the_DT problem_NN of_IN elimination_NN of_IN near-duplicate_JJ web_NN documents_NNS in_IN a_DT generic_JJ crawl_NN has_VBZ not_RB received_VBN attention_NN ._.
∗_NNP Anish_NNP worked_VBD on_IN this_DT problem_NN at_IN Google_NNP in_IN Dec_NNP 2005_CD ._.
Copyright_NN is_VBZ held_VBN by_IN the_DT Inte_NNP
nother_JJ approach_NN is_VBZ to_TO exploit_VB the_DT linkage_NN structure_NN of_IN the_DT web_NN -LRB-_-LRB- see_VB Dean_NNP and_CC Henzinger_NNP -LRB-_-LRB- 25_CD -RRB-_-RRB- who_WP build_VBP upon_IN Kleinberg_NNP 's_POS idea_NN of_IN hubs_NNS and_CC authorities_NNS -LRB-_-LRB- 39_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Going_VBG further_RBR along_IN these_DT lines_NNS ,_, Kumar_NNP et_FW al_FW =_JJ -_: =[_NN 41_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP proposed_VBN discovering_VBG ``_`` online_JJ communities_NNS ''_'' by_IN identifying_VBG dense_JJ bipartite_JJ sub-graphs_NNS of_IN the_DT web-graph_NN ._.
c_LS -RRB-_-RRB- Data_NNP extraction_NN :_: Given_IN a_DT moderate-sized_JJ collection_NN of_IN similar_JJ pages_NNS ,_, say_VBP reviews_NNS at_IN www_NN ._.
i_LS
ng_NN web_NN mirrors_VBZ -LRB-_-LRB- 6,7_CD -RRB-_-RRB- ._.
b_LS -RRB-_-RRB- Files_NNS in_IN a_DT file_NN system_NN :_: Manber_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- develops_VBZ algorithms_NNS for_IN near-duplicate_JJ detection_NN to_TO reduce_VB storage_NN for_IN files_NNS ._.
The_DT Venti_NNP file_NN system_NN -LRB-_-LRB- 48_CD -RRB-_-RRB- and_CC the_DT Low-bandwidth_JJ file_NN system_NN =_JJ -_: =[_NN 45_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP similar_JJ motivations_NNS ._.
c_LS -RRB-_-RRB- E-mails_NNS :_: Kolcz_NNP et_NNP al_NNP -LRB-_-LRB- 40_CD -RRB-_-RRB- identify_VBP near-duplicates_NNS for_IN spam_NN detection_NN ._.
d_LS -RRB-_-RRB- Domain-specific_JJ corpora_NN :_: Various_JJ groups_NNS have_VBP developed_VBN near-duplicate_JJ detection_NN systems_NNS for_IN lega_NN
s_NNS are_VBP broken_VBN into_IN 64MB_NN chunks_NNS ._.
Each_DT chunk_NN is_VBZ replicated_VBN at_IN three_CD -LRB-_-LRB- almost_RB -RRB-_-RRB- randomly_RB chosen_VBN machines_NNS in_IN a_DT cluster_NN ;_: each_DT chunk_NN is_VBZ stored_VBN as_IN a_DT file_NN in_IN the_DT local_JJ file_NN system_NN ._.
Using_VBG the_DT MapReduce_NNP framework_NN =_JJ -_: =[_NN 24_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT overall_JJ computation_NN can_MD be_VB split_VBN conveniently_RB into_IN two_CD phases_NNS ._.
In_IN the_DT first_JJ phase_NN ,_, there_EX are_VBP as_IN many_JJ computational_JJ tasks_NNS as_IN the_DT number_NN of_IN chunks_NNS of_IN F_NN -LRB-_-LRB- in_FW MapReduce_FW terminology_NN ,_, such_JJ tasks_NNS are_VBP ca_MD
experimental_JJ studies_NNS have_VBP tested_VBN the_DT efficacy_NN of_IN min-hash_JJ in_IN various_JJ settings_NNS -LRB-_-LRB- Cohen_NNP et_FW al_FW -LRB-_-LRB- 21_CD -RRB-_-RRB- for_IN associationrule_JJ mining_NN ,_, Chen_NNP et_FW al_FW -LRB-_-LRB- 18_CD -RRB-_-RRB- for_IN selectivity_NN estimation_NN of_IN boolean_JJ queries_NNS ,_, Gionis_FW et_FW al_FW =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_SYM -_: for_IN indexing_VBG set-value_JJ predicates_NNS and_CC Haveliwala_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- for_IN web-clustering_NN -RRB-_-RRB- ._.
c_LS -RRB-_-RRB- Signatures\/fingerprints_NNS over_IN IR-based_JJ document_NN vectors_NNS :_: Charikar_NNP 's_POS simhash_NN -LRB-_-LRB- 17_CD -RRB-_-RRB- is_VBZ a_DT fingerprinting_VBG technique_NN for_IN compres_NNS
ns_NNS -LRB-_-LRB- both_CC source-code_JJ and_CC textual_JJ reports_NNS -RRB-_-RRB- ,_, the_DT goal_NN is_VBZ to_TO identify_VB pairs_NNS of_IN documents_NNS that_WDT seem_VBP to_TO have_VB borrowed_VBN from_IN each_DT other_JJ significantly_RB ._.
For_IN some_DT early_JJ work_NN in_IN this_DT area_NN ,_, see_VB articles_NNS by_IN Baker_NNP =_SYM -_: =[_NN 4_CD ,_, 5_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT COPS_NN system_NN by_IN Brin_NNP et_FW al_FW -LRB-_-LRB- 8_CD -RRB-_-RRB- and_CC SCAM_NN by_IN Shivakumar_NNP and_CC Garcia-Molina_NNP -LRB-_-LRB- 51_CD -RRB-_-RRB- ._.
e_LS -RRB-_-RRB- Spam_NNP detection_NN :_: Given_IN a_DT large_JJ number_NN of_IN recentlyreceived_FW e-mails_FW ,_, the_DT goal_NN is_VBZ to_TO identify_VB SPAM_NNP before_IN depositing_VBG t_NN
B._NNP A_NNP batch_NN has_VBZ of_IN the_DT order_NN of_IN 1M_NN fingerprints_NNS ,_, so_RB let_VB us_PRP assume_VB that_DT file_NN Q_NNP occupies_VBZ 8MB_NN ._.
At_IN Google_NNP ,_, for_IN example_NN ,_, files_NNS F_NN and_CC Q_NNP would_MD be_VB stored_VBN in_IN a_DT shared-nothing_JJ distributed_VBN file_NN system_NN called_VBD GFS_NN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_SYM -_: ._.
GFS_NN files_NNS are_VBP broken_VBN into_IN 64MB_NN chunks_NNS ._.
Each_DT chunk_NN is_VBZ replicated_VBN at_IN three_CD -LRB-_-LRB- almost_RB -RRB-_-RRB- randomly_RB chosen_VBN machines_NNS in_IN a_DT cluster_NN ;_: each_DT chunk_NN is_VBZ stored_VBN as_IN a_DT file_NN in_IN the_DT local_JJ file_NN system_NN ._.
Using_VBG the_DT MapReduce_NN
nt_NN 1_CD ._.
INTRODUCTION_NN Web_NN crawling_VBG is_VBZ an_DT integral_JJ piece_NN of_IN infrastructure_NN for_IN search_NN engines_NNS ._.
Generic_JJ crawlers_NNS -LRB-_-LRB- 1_CD ,_, 9_CD -RRB-_-RRB- crawl_VBP documents_NNS and_CC links_NNS belonging_VBG to_TO a_DT variety_NN of_IN topics_NNS ,_, whereas_IN focused_JJ crawlers_NNS =_JJ -_: =[_NN 27_CD ,_, 43_CD ,_, 46_CD -RRB-_-RRB- -_: =_SYM -_: use_VB some_DT specialized_JJ knowledge_NN to_TO limit_VB the_DT crawl_NN to_TO pages_NNS pertaining_VBG to_TO specific_JJ topics_NNS ._.
For_IN web_NN crawling_NN ,_, issues_NNS like_IN freshness_NN and_CC efficient_JJ resource_NN usage_NN have_VBP previously_RB been_VBN addressed_VBN -LRB-_-LRB- 15_CD ,_, 16_CD ,_,
pients_NNS '_POS mailboxes_NNS ._.
The_DT premise_NN is_VBZ that_IN spammers_NNS send_VBP similar_JJ e-mails_NNS en_IN masse_NN ,_, with_IN small_JJ variation_NN in_IN the_DT body_NN of_IN these_DT e-mails_NNS ._.
See_NNP Kolcz_NNP et_FW al_FW -LRB-_-LRB- 40_CD -RRB-_-RRB- ,_, who_WP build_VBP upon_IN previous_JJ work_NN by_IN Chowdhury_NNP et_FW al_FW =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
f_LS -RRB-_-RRB- Duplicates_VBZ in_IN domain-specific_JJ corpora_NN :_: The_DT goal_NN is_VBZ to_TO identify_VB near-duplicates_NNS arising_VBG out_IN of_IN revisions_NNS ,_, modifications_NNS ,_, copying_NN or_CC merger_NN of_IN documents_NNS ,_, etc._FW ._.
See_NNP Conrad_NNP and_CC Schriber_NNP -LRB-_-LRB- 22_CD -RRB-_-RRB- for_IN a_DT cas_NN
t\/window_NN are_VBP folded_VBN into_IN the_DT document-vector_NN itself_PRP ._.
A_DT weighing_VBG function_NN that_WDT diminishes_VBZ the_DT weight_NN of_IN words_NNS that_WDT are_VBP farther_RBR away_RB from_IN the_DT anchor_NN text_NN is_VBZ shown_VBN to_TO work_VB well_RB ._.
e_LS -RRB-_-RRB- Phrases_NNS :_: Cooper_NNP et_FW al_FW =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_SYM -_: propose_VBP identification_NN of_IN phrases_NNS using_VBG a_DT phrase-detection_NN system_NN and_CC computing_VBG a_DT document-vector_NN that_WDT includes_VBZ phrases_NNS as_IN terms_NNS ._.
They_PRP have_VBP tested_VBN their_PRP$ ideas_NNS on_IN a_DT very_RB small_JJ collection_NN -LRB-_-LRB- tens_NNS of_IN thou_NN
removal_NN ,_, stemming_VBG ,_, computing_VBG term-frequencies_NNS and_CC finally_RB ,_, weighing_VBG each_DT term_NN by_IN its_PRP$ inverse_JJ document_NN frequency_NN -LRB-_-LRB- IDF_NN -RRB-_-RRB- ._.
Next_RB ,_, given_VBN two_CD documents_NNS ,_, a_DT ``_`` measure_NN ''_'' of_IN similarity_NN is_VBZ defined_VBN ._.
Hoad_NN and_CC Zobel_NN =_JJ -_: =[_NN 36_CD -RRB-_-RRB- -_: =_SYM -_: argue_VBP that_IN the_DT traditional_JJ cosine-similarity_NN measure_NN is_VBZ inadequate_JJ for_IN nearduplicate_JJ detection_NN ._.
They_PRP define_VBP and_CC evaluate_VBP a_DT variety_NN of_IN similarity_NN measures_NNS -LRB-_-LRB- but_CC they_PRP do_VBP not_RB develop_VB any_DT signature-scheme_NN
-_: significant_JJ 1-bit_NN in_IN the_DT XOR_NN of_IN two_CD successive_JJ fingerprints_NNS ._.
Thus_RB h_NN takes_VBZ values_NNS between_IN 0_CD and_CC f_FW −_FW 1_CD ._.
For_IN a_DT given_VBN table_NN ,_, we_PRP first_RB compute_VBP the_DT distribution_NN of_IN h_NN values_NNS and_CC then_RB compute_VB a_DT Huffman_NNP code_NN =_JJ -_: =[_NN 37_CD -RRB-_-RRB- -_: =_SYM -_: over_IN -LRB-_-LRB- 0_CD ,_, f_FW −_FW 1_LS -RRB-_-RRB- for_IN this_DT distribution_NN ._.
Next_RB ,_, we_PRP choose_VBP a_DT parameter_NN B_NN denoting_VBG the_DT block_NN size_NN ._.
A_DT typical_JJ value_NN for_IN B_NN would_MD be_VB 1024_CD bytes_NNS ._.
A_DT block_NN with_IN B_NN bytes_NNS has_VBZ 8B_NN bits_NNS ._.
We_PRP scan_VBP the_DT sorted_VBN sequence_NN o_NN
:_: Kolcz_NN et_FW al_FW -LRB-_-LRB- 40_CD -RRB-_-RRB- identify_VBP near-duplicates_NNS for_IN spam_NN detection_NN ._.
d_LS -RRB-_-RRB- Domain-specific_JJ corpora_NN :_: Various_JJ groups_NNS have_VBP developed_VBN near-duplicate_JJ detection_NN systems_NNS for_IN legal_JJ documents_NNS -LRB-_-LRB- see_VB Conrad_NNP and_CC Schriber_NNP =_SYM -_: =[_NN 22_CD -RRB-_-RRB- -_: =--RRB-_NN ,_, TREC_NN benchmarks_NNS ,_, Reuters_NNP news_NN articles_NNS ,_, and_CC Citeseer_NNP data_NNS ._.
Our_PRP$ work_NN falls_VBZ into_IN the_DT first_JJ category_NN -LRB-_-LRB- Web_NN Documents_NNS -RRB-_-RRB- ._.
We_PRP experimented_VBD with_IN 8B_NN pages_NNS --_: this_DT is_VBZ way_RB larger_JJR than_IN collection_NN sizes_NNS tackled_VBD b_NN
similar_JJ pages_NNS ,_, say_VBP reviews_NNS at_IN www.imdb.com_NNP ,_, the_DT goal_NN is_VBZ to_TO identify_VB the_DT schema\/DTD_NN underlying_VBG the_DT collection_NN so_IN that_IN we_PRP can_MD extract_VB and_CC categorize_VB useful_JJ information_NN from_IN these_DT pages_NNS ._.
See_NNP Joshi_NNP et_FW al_FW =_JJ -_: =[_NN 38_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- and_CC references_NNS therein_RB -RRB-_-RRB- for_IN a_DT technique_NN that_IN clusters_NNS web-pages_NNS on_IN the_DT basis_NN of_IN structural_JJ similarity_NN ._.
See_NNP Arasu_NNP and_CC GarciaMolina_NNP -LRB-_-LRB- 2_CD -RRB-_-RRB- for_IN another_DT technique_NN that_WDT identifies_VBZ templates_NNS underlying_VBG pages_NNS
h_NN that_IN the_DT probability_NN that_IN the_DT signatures_NNS of_IN A_NN and_CC B_NN match_NN is_VBZ exactly_RB the_DT Jaccard_NNP measure_NN -LRB-_-LRB- 13_CD ,_, 14_CD -RRB-_-RRB- ._.
Several_JJ experimental_JJ studies_NNS have_VBP tested_VBN the_DT efficacy_NN of_IN min-hash_JJ in_IN various_JJ settings_NNS -LRB-_-LRB- Cohen_NNP et_FW al_FW =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: for_IN associationrule_JJ mining_NN ,_, Chen_NNP et_FW al_FW -LRB-_-LRB- 18_CD -RRB-_-RRB- for_IN selectivity_NN estimation_NN of_IN boolean_JJ queries_NNS ,_, Gionis_FW et_FW al_FW -LRB-_-LRB- 30_CD -RRB-_-RRB- for_IN indexing_VBG set-value_JJ predicates_NNS and_CC Haveliwala_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- for_IN web-clustering_NN -RRB-_-RRB- ._.
c_LS -RRB-_-RRB- Signatures\/f_NN
f_LS our_PRP$ system_NN in_IN 2004_CD --_: 2005_CD ,_, Monika_NNP Henzinger_NNP conducted_VBD a_DT study_NN that_WDT compared_VBD simhash_JJ with_IN Broder_NNP 's_POS shingle-based_JJ fingerprints_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
An_DT excellent_JJ comparison_NN of_IN these_DT two_CD approaches_NNS appears_VBZ in_IN Henzinger_NN =_JJ -_: =[_NN 35_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT great_JJ advantage_NN of_IN using_VBG simhash_NN over_IN shingles_NNS is_VBZ that_IN it_PRP requires_VBZ relatively_RB small-sized_JJ fingerprints_NNS ._.
For_IN example_NN ,_, Broder_NNP 's_POS shingle-based_JJ fingerprints_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- require_VBP 24_CD bytes_NNS per_IN fingerprint_NN -LRB-_-LRB- it_PRP b_SYM
ns_NNS -LRB-_-LRB- both_CC source-code_JJ and_CC textual_JJ reports_NNS -RRB-_-RRB- ,_, the_DT goal_NN is_VBZ to_TO identify_VB pairs_NNS of_IN documents_NNS that_WDT seem_VBP to_TO have_VB borrowed_VBN from_IN each_DT other_JJ significantly_RB ._.
For_IN some_DT early_JJ work_NN in_IN this_DT area_NN ,_, see_VB articles_NNS by_IN Baker_NNP =_SYM -_: =[_NN 4_CD ,_, 5_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT COPS_NN system_NN by_IN Brin_NNP et_FW al_FW -LRB-_-LRB- 8_CD -RRB-_-RRB- and_CC SCAM_NN by_IN Shivakumar_NNP and_CC Garcia-Molina_NNP -LRB-_-LRB- 51_CD -RRB-_-RRB- ._.
e_LS -RRB-_-RRB- Spam_NNP detection_NN :_: Given_IN a_DT large_JJ number_NN of_IN recentlyreceived_FW e-mails_FW ,_, the_DT goal_NN is_VBZ to_TO identify_VB SPAM_NNP before_IN depositing_VBG t_NN
tch_NN algorithm_NN appears_VBZ in_IN -LRB-_-LRB- 40_CD -RRB-_-RRB- ._.
These_DT algorithms_NNS have_VBP been_VBN tested_VBN on_IN small_JJ document-collections_NNS -LRB-_-LRB- of_IN the_DT order_NN of_IN tens_NNS of_IN thousands_NNS -RRB-_-RRB- and_CC appear_VBP fairly_RB brittle_JJ ._.
d_LS -RRB-_-RRB- Checksums_NNPS :_: Pugh_NNP and_CC Henzinger_NNP 's_POS patent_NN =_JJ -_: =[_NN 47_CD -RRB-_-RRB- -_: =_SYM -_: contains_VBZ the_DT following_JJ idea_NN :_: we_PRP divide_VBP words_NNS in_IN a_DT document_NN into_IN k_NN buckets_NNS -LRB-_-LRB- by_IN hashing_VBG the_DT words_NNS ,_, for_IN example_NN -RRB-_-RRB- ,_, and_CC compute_VB a_DT checksum_NN of_IN each_DT bucket_NN ._.
The_DT set_NN of_IN checksums_NNS of_IN two_CD similar_JJ documents_NNS sho_VBP
or_CC four_CD types_NNS of_IN document_NN collections_NNS :_: a_LS -RRB-_-RRB- Web_NN Documents_NNS :_: Near-duplicate_JJ systems_NNS have_VBP been_VBN developed_VBN for_IN finding_VBG related-pages_NNS -LRB-_-LRB- 25_CD -RRB-_-RRB- ,_, for_IN extracting_VBG structured_JJ data_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, and_CC for_IN identifying_VBG web_NN mirrors_VBZ =_JJ -_: =[_NN 6,7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
b_LS -RRB-_-RRB- Files_NNS in_IN a_DT file_NN system_NN :_: Manber_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- develops_VBZ algorithms_NNS for_IN near-duplicate_JJ detection_NN to_TO reduce_VB storage_NN for_IN files_NNS ._.
The_DT Venti_NNP file_NN system_NN -LRB-_-LRB- 48_CD -RRB-_-RRB- and_CC the_DT Low-bandwidth_JJ file_NN system_NN -LRB-_-LRB- 45_CD -RRB-_-RRB- have_VBP similar_JJ mo_NN
a_DT newly-crawled_JJ page_NN as_IN a_DT near-duplicate_NN of_IN an_DT existing_VBG page_NN should_MD be_VB made_VBN quickly_RB ._.
Finally_RB ,_, the_DT system_NN should_MD use_VB as_IN few_JJ machines_NNS as_IN possible_JJ ._.
Our_PRP$ contributions_NNS :_: A._NN We_PRP show_VBP that_IN Charikar_NNP 's_POS simhash_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ practically_RB useful_JJ for_IN identifying_VBG near-duplicates_NNS in_IN web_NN documents_NNS belonging_VBG to_TO a_DT multi-billion_JJ page_NN repository_NN ._.
simhash_NN is_VBZ a_DT fingerprinting_VBG technique_NN that_WDT enjoys_VBZ the_DT property_NN that_IN fingerprints_NNS o_NN
,_, 43_CD ,_, 46_CD -RRB-_-RRB- use_VBP some_DT specialized_JJ knowledge_NN to_TO limit_VB the_DT crawl_NN to_TO pages_NNS pertaining_VBG to_TO specific_JJ topics_NNS ._.
For_IN web_NN crawling_NN ,_, issues_NNS like_IN freshness_NN and_CC efficient_JJ resource_NN usage_NN have_VBP previously_RB been_VBN addressed_VBN =_JJ -_: =[_NN 15_CD ,_, 16_CD ,_, 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
However_RB ,_, the_DT problem_NN of_IN elimination_NN of_IN near-duplicate_JJ web_NN documents_NNS in_IN a_DT generic_JJ crawl_NN has_VBZ not_RB received_VBN attention_NN ._.
∗_NNP Anish_NNP worked_VBD on_IN this_DT problem_NN at_IN Google_NNP in_IN Dec_NNP 2005_CD ._.
Copyright_NN is_VBZ held_VBN by_IN the_DT Inte_NNP
a_DT document-vector_NN that_WDT includes_VBZ phrases_NNS as_IN terms_NNS ._.
They_PRP have_VBP tested_VBN their_PRP$ ideas_NNS on_IN a_DT very_RB small_JJ collection_NN -LRB-_-LRB- tens_NNS of_IN thousands_NNS -RRB-_-RRB- ._.
The_DT idea_NN of_IN using_VBG phrases_NNS also_RB appears_VBZ in_IN the_DT work_NN of_IN Hammouda_NNP and_CC Kamel_NNP =_SYM -_: =[_NN 32_CD -RRB-_-RRB- -_: =_JJ -_: who_WP build_VBP sophisticated_JJ indexing_NN techniques_NNS for_IN web-clustering_NN ._.
We_PRP chose_VBD to_TO work_VB with_IN the_DT document_NN vector_NN model_NN ;_: simhash_NN converts_VBZ document_NN vectors_NNS into_IN fingerprints_NNS ._.
Augmenting_VBG the_DT document_NN vector_NN by_IN
F_NN ,_, the_DT goal_NN is_VBZ to_TO identify_VB strings_NNS in_IN the_DT set_NN which_WDT differ_VBP from_IN F_NN in_IN at_IN most_JJS d_NN bit-positions_NNS ._.
No_DT efficient_JJ solutions_NNS are_VBP known_VBN for_IN general_JJ n_NN ,_, f_FW and_CC d._NN A_NN theoretical_JJ study_NN was_VBD initiated_VBN by_IN Yao_NN and_CC Yao_NN =_JJ -_: =[_NN 53_CD -RRB-_-RRB- -_: =_JJ -_: ,_, who_WP developed_VBD an_DT efficient_JJ algorithm_NN for_IN d_NN =_JJ 1_CD ._.
Their_PRP$ algorithm_NN was_VBD improved_VBN by_IN Brodal_NNP and_CC G_NNP ¸_FW asienec_FW -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC Brodal_NNP and_CC Venkatesh_NNP -LRB-_-LRB- 11_CD -RRB-_-RRB- ._.
For_IN large_JJ d_NN ,_, some_DT progress_NN is_VBZ reported_VBN by_IN Greene_NNP ,_, Parnas_NNP and_CC
-LRB-_-LRB- 42_CD -RRB-_-RRB- develops_VBZ algorithms_NNS for_IN near-duplicate_JJ detection_NN to_TO reduce_VB storage_NN for_IN files_NNS ._.
The_DT Venti_NNP file_NN system_NN -LRB-_-LRB- 48_CD -RRB-_-RRB- and_CC the_DT Low-bandwidth_JJ file_NN system_NN -LRB-_-LRB- 45_CD -RRB-_-RRB- have_VBP similar_JJ motivations_NNS ._.
c_LS -RRB-_-RRB- E-mails_NNS :_: Kolcz_NNP et_NNP al_NNP =_JJ -_: =[_NN 40_CD -RRB-_-RRB- -_: =_SYM -_: identify_VB near-duplicates_NNS for_IN spam_NN detection_NN ._.
d_LS -RRB-_-RRB- Domain-specific_JJ corpora_NN :_: Various_JJ groups_NNS have_VBP developed_VBN near-duplicate_JJ detection_NN systems_NNS for_IN legal_JJ documents_NNS -LRB-_-LRB- see_VB Conrad_NNP and_CC Schriber_NNP -LRB-_-LRB- 22_CD -RRB-_-RRB- -RRB-_-RRB- ,_, TREC_NN benchm_NN
ing_NN distance_NN ,_, near-duplicate_NN ,_, similarity_NN ,_, search_NN ,_, sketch_NN ,_, fingerprint_NN ,_, web_NN crawl_NN ,_, web_NN document_NN 1_CD ._.
INTRODUCTION_NN Web_NN crawling_VBG is_VBZ an_DT integral_JJ piece_NN of_IN infrastructure_NN for_IN search_NN engines_NNS ._.
Generic_JJ crawlers_NNS =_JJ -_: =[_NN 1_CD ,_, 9_CD -RRB-_-RRB- -_: =_SYM -_: crawl_VB documents_NNS and_CC links_NNS belonging_VBG to_TO a_DT variety_NN of_IN topics_NNS ,_, whereas_IN focused_JJ crawlers_NNS -LRB-_-LRB- 27_CD ,_, 43_CD ,_, 46_CD -RRB-_-RRB- use_VBP some_DT specialized_JJ knowledge_NN to_TO limit_VB the_DT crawl_NN to_TO pages_NNS pertaining_VBG to_TO specific_JJ topics_NNS ._.
For_IN web_NN cra_NN
nt_NN 1_CD ._.
INTRODUCTION_NN Web_NN crawling_VBG is_VBZ an_DT integral_JJ piece_NN of_IN infrastructure_NN for_IN search_NN engines_NNS ._.
Generic_JJ crawlers_NNS -LRB-_-LRB- 1_CD ,_, 9_CD -RRB-_-RRB- crawl_VBP documents_NNS and_CC links_NNS belonging_VBG to_TO a_DT variety_NN of_IN topics_NNS ,_, whereas_IN focused_JJ crawlers_NNS =_JJ -_: =[_NN 27_CD ,_, 43_CD ,_, 46_CD -RRB-_-RRB- -_: =_SYM -_: use_VB some_DT specialized_JJ knowledge_NN to_TO limit_VB the_DT crawl_NN to_TO pages_NNS pertaining_VBG to_TO specific_JJ topics_NNS ._.
For_IN web_NN crawling_NN ,_, issues_NNS like_IN freshness_NN and_CC efficient_JJ resource_NN usage_NN have_VBP previously_RB been_VBN addressed_VBN -LRB-_-LRB- 15_CD ,_, 16_CD ,_,
corpus_NN Broadly_RB speaking_VBG ,_, duplicate-detection_JJ systems_NNS have_VBP been_VBN developed_VBN for_IN four_CD types_NNS of_IN document_NN collections_NNS :_: a_LS -RRB-_-RRB- Web_NN Documents_NNS :_: Near-duplicate_JJ systems_NNS have_VBP been_VBN developed_VBN for_IN finding_VBG related-pages_NNS =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_JJ -_: ,_, for_IN extracting_VBG structured_JJ data_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, and_CC for_IN identifying_VBG web_NN mirrors_VBZ -LRB-_-LRB- 6,7_CD -RRB-_-RRB- ._.
b_LS -RRB-_-RRB- Files_NNS in_IN a_DT file_NN system_NN :_: Manber_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- develops_VBZ algorithms_NNS for_IN near-duplicate_JJ detection_NN to_TO reduce_VB storage_NN for_IN files_NNS ._.
The_DT Ve_NN
of_IN πi_NN -LRB-_-LRB- F_NN -RRB-_-RRB- can_MD be_VB done_VBN in_IN O_NN -LRB-_-LRB- pi_NN -RRB-_-RRB- steps_NNS by_IN binary_JJ search_NN ._.
If_IN we_PRP assume_VBP that_IN each_DT fingerprint_NN were_VBD truly_RB a_DT random_JJ bit_NN sequence_NN ,_, interpolation_NN search_NN shrinks_VBZ the_DT run_NN time_NN to_TO O_NN -LRB-_-LRB- log_NN pi_NN -RRB-_-RRB- steps_NNS in_IN expectation_NN =_JJ -_: =[_NN 52_CD -RRB-_-RRB- -_: =_SYM -_: ._.
3.1.1_CD Exploration_NN of_IN Design_NN Parameters_NNS Let_VBP us_PRP see_VB how_WRB a_DT reasonable_JJ combination_NN of_IN t_NN and_CC pi_NN can_MD be_VB fixed_VBN ._.
We_PRP have_VBP two_CD design_NN goals_NNS :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- a_DT small_JJ set_NN of_IN permutations_NNS to_TO avoid_VB blowup_NN in_IN space_NN requiremen_NNS
nt_NN 1_CD ._.
INTRODUCTION_NN Web_NN crawling_VBG is_VBZ an_DT integral_JJ piece_NN of_IN infrastructure_NN for_IN search_NN engines_NNS ._.
Generic_JJ crawlers_NNS -LRB-_-LRB- 1_CD ,_, 9_CD -RRB-_-RRB- crawl_VBP documents_NNS and_CC links_NNS belonging_VBG to_TO a_DT variety_NN of_IN topics_NNS ,_, whereas_IN focused_JJ crawlers_NNS =_JJ -_: =[_NN 27_CD ,_, 43_CD ,_, 46_CD -RRB-_-RRB- -_: =_SYM -_: use_VB some_DT specialized_JJ knowledge_NN to_TO limit_VB the_DT crawl_NN to_TO pages_NNS pertaining_VBG to_TO specific_JJ topics_NNS ._.
For_IN web_NN crawling_NN ,_, issues_NNS like_IN freshness_NN and_CC efficient_JJ resource_NN usage_NN have_VBP previously_RB been_VBN addressed_VBN -LRB-_-LRB- 15_CD ,_, 16_CD ,_,
ts_NNS -RRB-_-RRB- ,_, the_DT goal_NN is_VBZ to_TO identify_VB pairs_NNS of_IN documents_NNS that_WDT seem_VBP to_TO have_VB borrowed_VBN from_IN each_DT other_JJ significantly_RB ._.
For_IN some_DT early_JJ work_NN in_IN this_DT area_NN ,_, see_VB articles_NNS by_IN Baker_NNP -LRB-_-LRB- 4_CD ,_, 5_CD -RRB-_-RRB- ,_, the_DT COPS_NN system_NN by_IN Brin_NNP et_FW al_FW =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: and_CC SCAM_NN by_IN Shivakumar_NNP and_CC Garcia-Molina_NNP -LRB-_-LRB- 51_CD -RRB-_-RRB- ._.
e_LS -RRB-_-RRB- Spam_NNP detection_NN :_: Given_IN a_DT large_JJ number_NN of_IN recentlyreceived_FW e-mails_FW ,_, the_DT goal_NN is_VBZ to_TO identify_VB SPAM_NNP before_IN depositing_VBG the_DT e-mail_JJ into_IN recipients_NNS '_POS mailboxe_NN
efficiently_RB computed_VBN by_IN using_VBG Rabin_NNP 's_POS fingerprinting_NN technique_NN -LRB-_-LRB- 49_CD -RRB-_-RRB- ._.
Manber_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- created_VBD shingles_NNS over_IN characters_NNS ._.
The_DT COPS_NN system_NN by_IN Brin_NNP et_FW al_FW -LRB-_-LRB- 8_CD -RRB-_-RRB- used_VBN sentences_NNS for_IN creating_VBG shingles_NNS ._.
Broder_NNP et_FW al_FW =_JJ -_: =[_NN 12_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: created_VBN shingles_NNS over_IN words_NNS ._.
The_DT total_JJ number_NN of_IN shingles_NNS per_IN document_NN is_VBZ clearly_RB large_JJ ._.
Therefore_RB ,_, a_DT 3_CD Small_JJ k_NN makes_VBZ dissimilar_JJ documents_NNS appear_VBP similar_JJ ._.
Large_JJ k_NN makes_VBZ similar_JJ documents_NNS appear_VBP dissi_NNS
ts_NNS that_WDT seem_VBP to_TO have_VB borrowed_VBN from_IN each_DT other_JJ significantly_RB ._.
For_IN some_DT early_JJ work_NN in_IN this_DT area_NN ,_, see_VB articles_NNS by_IN Baker_NNP -LRB-_-LRB- 4_CD ,_, 5_CD -RRB-_-RRB- ,_, the_DT COPS_NN system_NN by_IN Brin_NNP et_FW al_FW -LRB-_-LRB- 8_CD -RRB-_-RRB- and_CC SCAM_NN by_IN Shivakumar_NNP and_CC Garcia-Molina_NNP =_SYM -_: =[_NN 51_CD -RRB-_-RRB- -_: =_SYM -_: ._.
e_LS -RRB-_-RRB- Spam_NNP detection_NN :_: Given_IN a_DT large_JJ number_NN of_IN recentlyreceived_FW e-mails_FW ,_, the_DT goal_NN is_VBZ to_TO identify_VB SPAM_NNP before_IN depositing_VBG the_DT e-mail_JJ into_IN recipients_NNS '_POS mailboxes_NNS ._.
The_DT premise_NN is_VBZ that_IN spammers_NNS send_VBP similar_JJ e_SYM
B_NNP |_NNP ,_, also_RB known_VBN as_IN the_DT Jaccard_NNP measure_NN ._.
Interestingly_RB ,_, it_PRP is_VBZ possible_JJ to_TO devise_VB a_DT simple_JJ signature_NN scheme_NN such_JJ that_IN the_DT probability_NN that_IN the_DT signatures_NNS of_IN A_NN and_CC B_NN match_NN is_VBZ exactly_RB the_DT Jaccard_NNP measure_NN =_JJ -_: =[_NN 13_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Several_JJ experimental_JJ studies_NNS have_VBP tested_VBN the_DT efficacy_NN of_IN min-hash_JJ in_IN various_JJ settings_NNS -LRB-_-LRB- Cohen_NNP et_FW al_FW -LRB-_-LRB- 21_CD -RRB-_-RRB- for_IN associationrule_JJ mining_NN ,_, Chen_NNP et_FW al_FW -LRB-_-LRB- 18_CD -RRB-_-RRB- for_IN selectivity_NN estimation_NN of_IN boolean_JJ queries_NNS ,_, Gio_NN
collection_NN sizes_NNS tackled_VBN by_IN previous_JJ studies_NNS :_: web-clustering_JJ by_IN Broder_NNP et_FW al_FW -LRB-_-LRB- 14_CD -RRB-_-RRB- -LRB-_-LRB- 30M_CD URLs_NNS in_IN 1996_CD -RRB-_-RRB- ,_, ``_`` related_JJ pages_NNS ''_'' by_IN Dean_NNP and_CC Henzinger_NNP -LRB-_-LRB- 25_CD -RRB-_-RRB- -LRB-_-LRB- 180M_JJ URLs_NNS in_IN 1998_CD -RRB-_-RRB- ,_, webclustering_VBG by_IN Haveliwala_NNP et_NNP al_NNP =_JJ -_: =[_NN 33_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- 35M_CD URLs_NNS in_IN 2000_CD -RRB-_-RRB- ._.
5.2_CD The_DT end_NN goal_NN :_: why_WRB detect_VB duplicates_NNS ?_.
a_LS -RRB-_-RRB- Web_NN mirrors_VBZ :_: For_IN web_NN search_NN ,_, successful_JJ identification_NN of_IN web_NN mirrors_VBZ results_NNS in_IN smaller_JJR crawling\/storage\/indexing_NN costs_NNS in_IN the_DT absence_NN
icient_JJ algorithm_NN for_IN d_NN =_JJ 1_CD ._.
Their_PRP$ algorithm_NN was_VBD improved_VBN by_IN Brodal_NNP and_CC G_NNP ¸_FW asienec_FW -LRB-_-LRB- 10_CD -RRB-_-RRB- and_CC Brodal_NNP and_CC Venkatesh_NNP -LRB-_-LRB- 11_CD -RRB-_-RRB- ._.
For_IN large_JJ d_NN ,_, some_DT progress_NN is_VBZ reported_VBN by_IN Greene_NNP ,_, Parnas_NNP and_CC Yao_NNP -LRB-_-LRB- 31_CD -RRB-_-RRB- ,_, Dolev_NNP et_FW al_FW =_JJ -_: =[_NN 28_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Arslan_NN and_CC E˘gecio˘glu_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
Our_PRP$ problem_NN differs_VBZ from_IN the_DT one_CD addressed_VBN by_IN the_DT theory_NN community_NN in_IN two_CD aspects_NNS ._.
First_RB ,_, we_PRP assume_VBP that_IN the_DT input_NN consists_VBZ of_IN bit-strings_NNS chosen_VBN uniformly_RB at_IN random_JJ -LRB-_-LRB-
tection_NN systems_NNS have_VBP been_VBN developed_VBN for_IN four_CD types_NNS of_IN document_NN collections_NNS :_: a_LS -RRB-_-RRB- Web_NN Documents_NNS :_: Near-duplicate_JJ systems_NNS have_VBP been_VBN developed_VBN for_IN finding_VBG related-pages_NNS -LRB-_-LRB- 25_CD -RRB-_-RRB- ,_, for_IN extracting_VBG structured_JJ data_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC for_IN identifying_VBG web_NN mirrors_VBZ -LRB-_-LRB- 6,7_CD -RRB-_-RRB- ._.
b_LS -RRB-_-RRB- Files_NNS in_IN a_DT file_NN system_NN :_: Manber_NN -LRB-_-LRB- 42_CD -RRB-_-RRB- develops_VBZ algorithms_NNS for_IN near-duplicate_JJ detection_NN to_TO reduce_VB storage_NN for_IN files_NNS ._.
The_DT Venti_NNP file_NN system_NN -LRB-_-LRB- 48_CD -RRB-_-RRB- and_CC the_DT Low-ban_NN
ing_NN distance_NN ,_, near-duplicate_NN ,_, similarity_NN ,_, search_NN ,_, sketch_NN ,_, fingerprint_NN ,_, web_NN crawl_NN ,_, web_NN document_NN 1_CD ._.
INTRODUCTION_NN Web_NN crawling_VBG is_VBZ an_DT integral_JJ piece_NN of_IN infrastructure_NN for_IN search_NN engines_NNS ._.
Generic_JJ crawlers_NNS =_JJ -_: =[_NN 1_CD ,_, 9_CD -RRB-_-RRB- -_: =_SYM -_: crawl_VB documents_NNS and_CC links_NNS belonging_VBG to_TO a_DT variety_NN of_IN topics_NNS ,_, whereas_IN focused_JJ crawlers_NNS -LRB-_-LRB- 27_CD ,_, 43_CD ,_, 46_CD -RRB-_-RRB- use_VBP some_DT specialized_JJ knowledge_NN to_TO limit_VB the_DT crawl_NN to_TO pages_NNS pertaining_VBG to_TO specific_JJ topics_NNS ._.
For_IN web_NN cra_NN
purpose_NN of_IN finding_VBG ``_`` related_JJ pages_NNS ''_'' ,_, Dean_NNP and_CC Henzinger_NNP -LRB-_-LRB- 25_CD -RRB-_-RRB- exploited_VBD the_DT linkage_NN structure_NN of_IN the_DT web_NN ._.
The_DT premise_NN is_VBZ that_IN similar_JJ pages_NNS would_MD have_VB several_JJ incoming_JJ links_NNS in_IN common_NN ._.
Haveliwala_NNP et_NNP al_NNP =_JJ -_: =[_NN 34_CD -RRB-_-RRB- -_: =_JJ -_: point_NN out_RP that_IN the_DT quality_NN of_IN duplicate_VB detection_NN is_VBZ poor_JJ for_IN pages_NNS with_IN very_RB few_JJ incoming_JJ links_NNS ._.
This_DT can_MD be_VB ameliorated_VBN by_IN taking_VBG anchor_NN text_NN and_CC anchor_NN windows_NNS into_IN account_NN ._.
d_LS -RRB-_-RRB- Anchor_NNP text_NN ,_, anchor_NN
