Performance_NNP of_IN compressed_VBN inverted_JJ list_NN caching_NN in_IN search_NN engines_NNS
Due_JJ to_TO the_DT rapid_JJ growth_NN in_IN the_DT size_NN of_IN the_DT web_NN ,_, web_NN search_NN engines_NNS are_VBP facing_VBG enormous_JJ performance_NN challenges_NNS ._.
The_DT larger_JJR engines_NNS in_IN particular_JJ have_VBP to_TO be_VB able_JJ to_TO process_VB tens_NNS of_IN thousands_NNS of_IN queries_NNS per_IN second_NN on_IN tens_NNS of_IN billions_NNS of_IN documents_NNS ,_, making_VBG query_JJ throughput_NN a_DT critical_JJ issue_NN ._.
To_TO satisfy_VB this_DT heavy_JJ workload_NN ,_, search_NN engines_NNS use_VBP a_DT variety_NN of_IN performance_NN optimizations_NNS including_VBG index_NN compression_NN ,_, caching_NN ,_, and_CC early_JJ termination_NN ._.
We_PRP focus_VBP on_IN two_CD techniques_NNS ,_, inverted_JJ index_NN compression_NN and_CC index_NN caching_NN ,_, which_WDT play_VBP a_DT crucial_JJ rule_NN in_IN web_NN search_NN engines_NNS as_RB well_RB as_IN other_JJ high-performance_JJ information_NN retrieval_NN systems_NNS ._.
We_PRP perform_VBP a_DT comparison_NN and_CC evaluation_NN of_IN several_JJ inverted_JJ list_NN compression_NN algorithms_NNS ,_, including_VBG new_JJ variants_NNS of_IN existing_VBG algorithms_NNS that_WDT have_VBP not_RB been_VBN studied_VBN before_RB ._.
We_PRP then_RB evaluate_VBP different_JJ inverted_JJ list_NN caching_NN policies_NNS on_IN large_JJ query_NN traces_NNS ,_, and_CC finally_RB study_VB the_DT possible_JJ performance_NN benefits_NNS of_IN combining_VBG compression_NN and_CC caching_NN ._.
The_DT overall_JJ goal_NN of_IN this_DT paper_NN is_VBZ to_TO provide_VB an_DT updated_VBN discussion_NN and_CC evaluation_NN of_IN these_DT two_CD techniques_NNS ,_, and_CC to_TO show_VB how_WRB to_TO select_VB the_DT best_JJS set_NN of_IN approaches_NNS and_CC settings_NNS depending_VBG on_IN parameter_NN such_JJ as_IN disk_NN speed_NN and_CC main_JJ memory_NN cache_NN size_NN ._.
512_CD ,_, we_PRP can_MD store_VB them_PRP as_IN 3_CD 9-bit_JJ values_NNS -LRB-_-LRB- leaving_VBG one_CD data_NN bit_NN unused_JJ -RRB-_-RRB- ._.
Simple16_NN is_VBZ a_DT variation_NN of_IN Simple9_NN that_WDT uses_VBZ 16_CD instead_RB of_IN 9_CD cases_NNS and_CC thus_RB achieves_VBZ a_DT slightly_RB better_JJR use_NN of_IN each_DT 32-bit_JJ word_NN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_SYM -_: ._.
PForDelta_NN is_VBZ a_DT recent_JJ technique_NN proposed_VBN in_IN -LRB-_-LRB- 13_CD ,_, 31_CD -RRB-_-RRB- for_IN compression_NN in_IN database_NN and_CC IR_NN systems_NNS ._.
The_DT basic_JJ idea_NN is_VBZ to_TO split_VB a_DT list_NN into_IN chunks_NNS of_IN some_DT fixed_JJ size_NN ,_, and_CC then_RB select_VB a_DT value_NN b_NN such_JJ that_IN
IR_NNP was_VBD that_IN they_PRP easily_RB support_VBP integrating_VBG new_JJ fields_NNS required_VBN to_TO support_VB ranked_VBN queries_NNS ._.
The_DT switch_NN from_IN bitmap_NN indexes_NNS to_TO inverted_JJ indexes_NNS lead_VBP to_TO a_DT flood_NN of_IN research_NN on_IN efficient_JJ inverted_JJ indexes_NNS =_JJ -_: =[_NN 25_CD ,_, 30_CD ,_, 6_CD ,_, 13_CD ,_, 24_CD ,_, 3_CD ,_, 31_CD ,_, 29_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC inverted_JJ indexes_NNS are_VBP now_RB the_DT preferred_JJ indexing_NN method_NN in_IN search_NN engines_NNS -LRB-_-LRB- 30_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP are_VBP asking_VBG -LRB-_-LRB- and_CC answering_NN -RRB-_-RRB- the_DT question_NN :_: What_WP are_VBP the_DT trade-offs_NNS of_IN using_VBG inverted_JJ indexes_NNS in_IN DSS_NN
n_NN main_JJ memory_NN ._.
In_IN the_DT following_NN ,_, we_PRP review_VBP the_DT current_JJ methods_NNS that_IN ,_, from_IN our_PRP$ point_NN of_IN view_NN ,_, best_JJS address_NN these_DT objectives_NNS ,_, and_CC discuss_VBP their_PRP$ limitations_NNS ._.
In_IN particular_JJ ,_, we_PRP evaluate_VBP index_NN compression_NN =_JJ -_: =[_NN 15_CD ,_, 16_CD -RRB-_-RRB- -_: =_JJ -_: ,_, an_DT approach_NN that_WDT has_VBZ never_RB been_VBN considered_VBN in_IN large-scale_JJ image_NN search_NN ._.
3.1_CD ._.
Binary_JJ BOF_NN A_NN straightforward_JJ way_NN of_IN compacting_VBG a_DT BOF_NN vector_NN is_VBZ to_TO use_VB a_DT binary_JJ BOF_NN representation_NN ,_, i.e._FW ,_, to_TO discard_VB the_DT i_FW
uencies_NNS are_VBP often_RB stored_VBN separately_RB ,_, and_CC thus_RB we_PRP compress_VBP sequences_NNS of_IN d-gaps_NN and_CC frequencies_NNS ._.
A_DT large_JJ number_NN of_IN inverted_JJ index_NN compression_NN techniques_NNS have_VBP been_VBN proposed_VBN ;_: see_VB -LRB-_-LRB- 32_CD -RRB-_-RRB- for_IN an_DT overview_NN and_CC =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_SYM -_: for_IN a_DT recent_JJ experimental_JJ evaluation_NN of_IN state-of-the-art_JJ methods_NNS ._.
In_IN our_PRP$ work_NN here_RB ,_, we_PRP utilize_VBP two_CD techniques_NNS that_WDT have_VBP been_VBN previously_RB applied_VBN to_TO versioned_RB document_VB collections_NNS -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, Interpolative_JJ C_NN
effect_NN on_IN query_NN processing_NN throughput_NN ._.
In_IN addition_NN to_TO the_DT direct_JJ reduction_NN in_IN memory_NN and_CC disk_NN space_NN ,_, more_RBR compact_JJ indexes_NNS lead_VBP to_TO savings_NNS in_IN data_NN transfers_NNS and_CC increase_VB the_DT hit_NN rate_NN of_IN memory_NN caches_NNS =_JJ -_: =[_NN 22_CD ,_, 21_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Therefore_RB ,_, a_DT large_JJ body_NN of_IN work_NN has_VBZ focused_VBN on_IN index_NN compaction_NN and_CC compression_NN methods_NNS ._.
The_DT structure_NN described_VBN above_IN leaves_NNS two_CD main_JJ degrees_NNS of_IN freedom_NN for_IN compression_NN optimization_NN ._.
The_DT first_JJ is_VBZ t_NN
docIDs_NN and_CC frequencies_NNS but_CC do_VBP not_RB consider_VB other_JJ data_NNS such_JJ as_IN positions_NNS or_CC contexts_NNS ._.
Many_JJ techniques_NNS for_IN inverted_JJ index_NN compression_NN have_VBP been_VBN studied_VBN in_IN the_DT literature_NN ;_: see_VB -LRB-_-LRB- 26_CD ,_, 29_CD -RRB-_-RRB- for_IN a_DT survey_NN and_CC =_JJ -_: =[_NN 1_CD ,_, 2_CD ,_, 3_CD ,_, 30_CD ,_, 27_CD ,_, 14_CD -RRB-_-RRB- -_: =_SYM -_: for_IN very_RB recent_JJ work_NN ._.
Most_JJS techniques_NNS first_RB replace_VB each_DT docID_NN -LRB-_-LRB- except_IN the_DT first_JJ in_IN a_DT list_NN -RRB-_-RRB- by_IN the_DT difference_NN between_IN it_PRP and_CC the_DT preceding_VBG docID_NN ,_, called_VBN d-gap_NN ,_, and_CC then_RB encode_VBP the_DT d-gap_NN using_VBG some_DT in_IN
ance_NN ._.
2_CD ._.
BACKGROUND_NN AND_CC RELATED_NNS WORK_VBP For_IN a_DT basic_JJ overview_NN of_IN IR_FW query_FW processing_NN ,_, see_VB -LRB-_-LRB- 24_CD -RRB-_-RRB- ._.
For_IN recent_JJ work_NN on_IN performance_NN optimizations_NNS such_JJ as_IN index_NN compression_NN ,_, caching_NN ,_, and_CC early_JJ termination_NN ,_, see_VBP =_JJ -_: =[_NN 2_CD ,_, 23_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP assume_VBP that_IN we_PRP are_VBP given_VBN a_DT collection_NN of_IN N_NN documents_NNS -LRB-_-LRB- web_NN pages_NNS covered_VBN by_IN the_DT search_NN engine_NN -RRB-_-RRB- ,_, where_WRB each_DT document_NN is_VBZ uniquely_RB identified_VBN by_IN a_DT document_NN ID_NN -LRB-_-LRB- docID_NN -RRB-_-RRB- between_IN 0_CD and_CC N_NN −_NN 1_CD ._.
The_DT collect_VBP
counts_NNS of_IN how_WRB many_JJ times_NNS each_DT cache_NN item_NN was_VBD hit_VBN in_IN the_DT past_NN and_CC evicts_VBZ the_DT least_JJS frequently_RB used_VBN item_NN when_WRB needed_VBN ._.
Several_JJ variants_NNS of_IN lfu_NN have_VBP been_VBN proposed_VBN to_TO deal_VB with_IN its_PRP$ different_JJ shortcomings_NNS =_JJ -_: =[_NN 1_CD ,_, 21_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, it_PRP may_MD happen_VB in_IN lfu_NN that_IN certain_JJ items_NNS occur_VBP in_IN a_DT burst_NN to_TO accumulate_VB such_JJ high_JJ frequency_NN counts_VBZ that_IN they_PRP never_RB get_VBP evicted_VBN from_IN the_DT cache_NN ._.
Window-lfu_JJ deals_NNS with_IN this_DT by_IN counting_VBG the_DT
trieval_NN ._.
Query_NN processing_NN in_IN search_NN engines_NNS has_VBZ been_VBN extensively_RB studied_VBN ;_: for_IN a_DT basic_JJ overview_NN ,_, see_VB -LRB-_-LRB- 37_CD ,_, 6_CD -RRB-_-RRB- ._.
For_IN recent_JJ research_NN on_IN performance_NN optimization_NN such_JJ as_IN index_NN compression_NN and_CC pruning_NN ,_, see_VBP =_JJ -_: =[_NN 26_CD ,_, 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP assume_VBP we_PRP are_VBP given_VBN a_DT collection_NN of_IN N_NN documents_NNS ,_, where_WRB each_DT document_NN is_VBZ uniquely_RB identified_VBN by_IN a_DT document_NN ID_NN -LRB-_-LRB- docID_NN -RRB-_-RRB- between_IN 0_CD and_CC N_NN −_NN 1_CD ._.
The_DT collection_NN is_VBZ indexed_VBN by_IN an_DT inverted_JJ index_NN structure_NN ,_,
or_CC current_JJ search_NN systems_NNS ,_, which_WDT usually_RB cache_NN at_IN least_JJS some_DT of_IN the_DT inverted_JJ lists_NNS in_IN main_JJ memory_NN even_RB when_WRB the_DT complete_JJ index_NN does_VBZ not_RB fit_VB ._.
Caching_NN is_VBZ known_VBN to_TO provide_VB significant_JJ performance_NN boosts_VBZ =_JJ -_: =[_NN 24_CD -RRB-_-RRB- -_: =_SYM -_: ._.
To_TO determine_VB the_DT impact_NN of_IN caching_NN ,_, we_PRP implemented_VBD a_DT simple_JJ caching_NN scheme_NN that_WDT selects_VBZ a_DT static_JJ subset_NN of_IN lists_NNS to_TO be_VB kept_VBN in_IN memory_NN ._.
Lists_NNS are_VBP selected_VBN based_VBN on_IN their_PRP$ frequency_NN in_IN a_DT large_JJ query_NN tr_NN
and_CC text_NN information_NN retrieval_NN systems_NNS are_VBP based_VBN on_IN inverted_JJ indexes_NNS ,_, and_CC substantial_JJ efforts_NNS have_VBP been_VBN invested_VBN in_IN optimizing_VBG the_DT construction_NN ,_, size_NN ,_, and_CC access_NN speed_NN of_IN these_DT structures_NNS ;_: see_VB ,_, e.g._FW ,_, =_JJ -_: =[_NN 28_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
An_DT inverted_JJ index_NN contains_VBZ one_CD inverted_JJ list_NN for_IN each_DT distinct_JJ term_NN -LRB-_-LRB- word_NN -RRB-_-RRB- in_IN the_DT document_NN collection_NN ._.
Each_DT list_NN consists_VBZ of_IN postings_NNS describing_VBG occurrences_NNS of_IN the_DT term_NN in_IN the_DT collection_NN ._.
We_PRP assume_VBP
trieval_NN ._.
Query_NN processing_NN in_IN search_NN engines_NNS has_VBZ been_VBN extensively_RB studied_VBN ;_: for_IN a_DT basic_JJ overview_NN ,_, see_VB -LRB-_-LRB- 37_CD ,_, 6_CD -RRB-_-RRB- ._.
For_IN recent_JJ research_NN on_IN performance_NN optimization_NN such_JJ as_IN index_NN compression_NN and_CC pruning_NN ,_, see_VBP =_JJ -_: =[_NN 26_CD ,_, 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP assume_VBP we_PRP are_VBP given_VBN a_DT collection_NN of_IN N_NN documents_NNS ,_, where_WRB each_DT document_NN is_VBZ uniquely_RB identified_VBN by_IN a_DT document_NN ID_NN -LRB-_-LRB- docID_NN -RRB-_-RRB- between_IN 0_CD and_CC N_NN −_NN 1_CD ._.
The_DT collection_NN is_VBZ indexed_VBN by_IN an_DT inverted_JJ index_NN structure_NN ,_,
converted_VBN into_IN document_NN gaps_NNS ,_, or_CC differences_NNS between_IN consecutive_JJ document_NN ids_NNS ._.
These_DT gaps_NNS are_VBP then_RB compressed_VBN with_IN integer_NN coding_NN techniques_NNS such_JJ as_IN γ_NN or_CC Rice_NNP codes_NNS ,_, or_CC more_RBR recently_RB ,_, PForDelta_NN -LRB-_-LRB- 44_CD -RRB-_-RRB- ,_, =_JJ -_: =[_NN 45_CD -RRB-_-RRB- -_: =_SYM -_: ._.
It_PRP would_MD be_VB tricky_JJ for_IN gap-based_JJ compression_NN -LRB-_-LRB- also_RB commonly_RB known_VBN as_IN delta_NN compression_NN -RRB-_-RRB- to_TO support_VB backwards_RB traversal_JJ ._.
Prefix-free_JJ codes_NNS -LRB-_-LRB- γ_NN and_CC Rice_NNP codes_NNS -RRB-_-RRB- are_VBP meant_VBN to_TO be_VB decoded_VBN only_RB in_IN the_DT forwa_NN
h_NN of_IN documents_NNS at_IN a_DT time_NN in_IN a_DT structure_NN where_WRB the_DT lists_NNS are_VBP compressed_VBN using_VBG VByte_NN -LRB-_-LRB- 30_CD -RRB-_-RRB- ._.
The_DT batches_NNS are_VBP combined_VBN in_IN the_DT end_NN to_TO form_VB the_DT complete_JJ index_NN ,_, where_WRB the_DT lists_NNS are_VBP compressed_VBN using_VBG PForDelta_NN =_JJ -_: =[_NN 38_CD ,_, 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Next_RB ,_, we_PRP describe_VBP how_WRB queries_NNS are_VBP processed_VBN ._.
3_LS ._.
THE_DT HEAPUNION_JJ OPERATOR_NN In_IN this_DT section_NN ,_, we_PRP describe_VBP how_WRB our_PRP$ solution_NN supports_VBZ efficient_JJ query_NN processing_NN that_IN scales_NNS to_TO a_DT large_JJ number_NN of_IN author_NN lists_NNS
al._FW -LRB-_-LRB- 2_CD -RRB-_-RRB- investigate_VBP the_DT impact_NN of_IN results_NNS caching_VBG and_CC static_JJ caching_NN of_IN posting_VBG lists_NNS in_IN the_DT context_NN of_IN Web_NN search_NN engine_NN architecture_NN ._.
The_DT impact_NN of_IN compression_NN on_IN caching_NN efficiency_NN is_VBZ addressed_VBN in_IN =_JJ -_: =[_NN 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Finally_RB ,_, Long_NNP and_CC Suel_NNP -LRB-_-LRB- 17_CD -RRB-_-RRB- introduce_VB a_DT 3-level_JJ caching_NN architecture_NN that_WDT includes_VBZ on-disk_JJ caching_NN of_IN the_DT posting_VBG lists_NNS for_IN popular_JJ term_NN combinations_NNS ._.
Index_NN pruning_NN reduces_VBZ significantly_RB the_DT fractio_NN
ance_NN ._.
2_CD ._.
BACKGROUND_NN AND_CC RELATED_NNS WORK_VBP For_IN a_DT basic_JJ overview_NN of_IN IR_FW query_FW processing_NN ,_, see_VB -LRB-_-LRB- 24_CD -RRB-_-RRB- ._.
For_IN recent_JJ work_NN on_IN performance_NN optimizations_NNS such_JJ as_IN index_NN compression_NN ,_, caching_NN ,_, and_CC early_JJ termination_NN ,_, see_VBP =_JJ -_: =[_NN 2_CD ,_, 23_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
We_PRP assume_VBP that_IN we_PRP are_VBP given_VBN a_DT collection_NN of_IN N_NN documents_NNS -LRB-_-LRB- web_NN pages_NNS covered_VBN by_IN the_DT search_NN engine_NN -RRB-_-RRB- ,_, where_WRB each_DT document_NN is_VBZ uniquely_RB identified_VBN by_IN a_DT document_NN ID_NN -LRB-_-LRB- docID_NN -RRB-_-RRB- between_IN 0_CD and_CC N_NN −_NN 1_CD ._.
The_DT collect_VBP
y_NN be_VB handled_VBN by_IN result_NN caching_NN ._.
Note_VB that_IN keeping_VBG these_DT duplicate_VBP queries_NNS would_MD result_VB in_IN better_JJR but_CC unrealistic_JJ cache_NN hit_NN rates_NNS ._.
The_DT performance_NN benefits_NNS of_IN result_NN caching_NN were_VBD previously_RB studied_VBN in_IN =_JJ -_: =[_NN 14_CD ,_, 23_CD ,_, 12_CD ,_, 6_CD ,_, 9_CD ,_, 3_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT benefits_NNS can_MD vary_VB significantly_RB between_IN search_NN engines_NNS ,_, however_RB ,_, based_VBN on_IN whether_IN term_NN ordering_VBG in_IN queries_NNS is_VBZ considered_VBN or_CC stemming_VBG is_VBZ performed_VBN ._.
Early_JJ work_NN on_IN index_NN caching_NN in_IN IR_NNP systems_NNS appea_NN
block_NN is_VBZ inserted_VBN into_IN a_DT full_JJ cache_NN ,_, the_DT LRU_NNP block_NN in_IN the_DT lowest_JJS nonempty_JJ queue_NN is_VBZ evicted_VBN and_CC its_PRP$ frequency_NN information_NN is_VBZ put_VBN intoÉÓÙØ_NN ._.
Adaptive_JJ Replacement_NN Cache_NN -LRB-_-LRB- ARC_NN -RRB-_-RRB- :_: This_DT policy_NN was_VBD proposed_VBN in_IN =_JJ -_: =[_NN 15_CD ,_, 16_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC like_IN Landlord_NNP and_CC MQ_NNP also_RB tries_VBZ to_TO balance_VB recency_NN -LRB-_-LRB- LRU_NN -RRB-_-RRB- and_CC frequency_NN -LRB-_-LRB- LFU_NN -RRB-_-RRB- ._.
Conceptually_RB ,_, ARC_NN operates_VBZ on_IN two_CD levels_NNS :_: it_PRP maintains_VBZ -LRB-_-LRB- i_LS -RRB-_-RRB- two_CD listsÄandÄreferring_NN to_TO pages_NNS each_DT that_WDT were_VBD recently_RB
y_NN be_VB handled_VBN by_IN result_NN caching_NN ._.
Note_VB that_IN keeping_VBG these_DT duplicate_VBP queries_NNS would_MD result_VB in_IN better_JJR but_CC unrealistic_JJ cache_NN hit_NN rates_NNS ._.
The_DT performance_NN benefits_NNS of_IN result_NN caching_NN were_VBD previously_RB studied_VBN in_IN =_JJ -_: =[_NN 14_CD ,_, 23_CD ,_, 12_CD ,_, 6_CD ,_, 9_CD ,_, 3_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT benefits_NNS can_MD vary_VB significantly_RB between_IN search_NN engines_NNS ,_, however_RB ,_, based_VBN on_IN whether_IN term_NN ordering_VBG in_IN queries_NNS is_VBZ considered_VBN or_CC stemming_VBG is_VBZ performed_VBN ._.
Early_JJ work_NN on_IN index_NN caching_NN in_IN IR_NNP systems_NNS appea_NN
g_NN various_JJ weighting_NN schemes_NNS we_PRP did_VBD not_RB see_VB any_DT significant_JJ performance_NN over_IN basic_JJ LFU_NN ._.
Optimized_VBN Landlord_NN -LRB-_-LRB- LD_NN -RRB-_-RRB- :_: Landlord_NN is_VBZ a_DT class_NN of_IN algorithms_NNS for_IN weighted_JJ caching_NN that_WDT was_VBD proposed_VBN and_CC studied_VBN in_IN =_JJ -_: =[_NN 8_CD ,_, 24_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC recently_RB applied_VBN to_TO another_DT caching_NN problem_NN in_IN search_NN engines_NNS in_IN -LRB-_-LRB- 13_CD -RRB-_-RRB- ._.
When_WRB an_DT object_NN is_VBZ inserted_VBN into_IN the_DT cache_NN ,_, it_PRP is_VBZ assigned_VBN a_DT deadline_NN given_VBN by_IN the_DT ratio_NN between_IN its_PRP$ benefit_NN and_CC its_PRP$ size_NN ._.
W_NN
g_NN various_JJ weighting_NN schemes_NNS we_PRP did_VBD not_RB see_VB any_DT significant_JJ performance_NN over_IN basic_JJ LFU_NN ._.
Optimized_VBN Landlord_NN -LRB-_-LRB- LD_NN -RRB-_-RRB- :_: Landlord_NN is_VBZ a_DT class_NN of_IN algorithms_NNS for_IN weighted_JJ caching_NN that_WDT was_VBD proposed_VBN and_CC studied_VBN in_IN =_JJ -_: =[_NN 8_CD ,_, 24_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC recently_RB applied_VBN to_TO another_DT caching_NN problem_NN in_IN search_NN engines_NNS in_IN -LRB-_-LRB- 13_CD -RRB-_-RRB- ._.
When_WRB an_DT object_NN is_VBZ inserted_VBN into_IN the_DT cache_NN ,_, it_PRP is_VBZ assigned_VBN a_DT deadline_NN given_VBN by_IN the_DT ratio_NN between_IN its_PRP$ benefit_NN and_CC its_PRP$ size_NN ._.
W_NN
cores_NNS such_JJ as_IN Pagerank_NN -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP are_VBP not_RB concerned_VBN with_IN details_NNS of_IN the_DT particular_JJ ranking_NN function_NN that_WDT is_VBZ used_VBN ._.
Many_JJ classes_NNS of_IN functions_NNS have_VBP been_VBN studied_VBN in_IN the_DT IR_NNP literature_NN ;_: see_VB ,_, e.g._FW ,_, =_JJ -_: =[_NN 22_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: for_IN an_DT introduction_NN and_CC overview_NN ._.
2.2_CD Compressed_VBN Index_NNP Organization_NNP In_IN large_JJ search_NN engines_NNS ,_, each_DT machine_NN typically_RB indexes_NNS and_CC searches_VBZ a_DT subset_NN of_IN the_DT collection_NN ,_, consisting_VBG of_IN up_IN to_TO hundreds_NNS of_IN mi_FW
y_NN be_VB handled_VBN by_IN result_NN caching_NN ._.
Note_VB that_IN keeping_VBG these_DT duplicate_VBP queries_NNS would_MD result_VB in_IN better_JJR but_CC unrealistic_JJ cache_NN hit_NN rates_NNS ._.
The_DT performance_NN benefits_NNS of_IN result_NN caching_NN were_VBD previously_RB studied_VBN in_IN =_JJ -_: =[_NN 14_CD ,_, 23_CD ,_, 12_CD ,_, 6_CD ,_, 9_CD ,_, 3_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT benefits_NNS can_MD vary_VB significantly_RB between_IN search_NN engines_NNS ,_, however_RB ,_, based_VBN on_IN whether_IN term_NN ordering_VBG in_IN queries_NNS is_VBZ considered_VBN or_CC stemming_VBG is_VBZ performed_VBN ._.
Early_JJ work_NN on_IN index_NN caching_NN in_IN IR_NNP systems_NNS appea_NN
ble_NN to_TO seek_VB forward_RB in_IN an_DT inverted_JJ list_NN without_IN reading_VBG and_CC decoding_VBG all_DT postings_NNS ,_, and_CC inverted_JJ index_NN structures_NNS often_RB store_VBP extra_JJ pointers_NNS that_WDT allow_VBP us_PRP to_TO skip_VB over_IN many_JJ of_IN the_DT postings_NNS ;_: see_VB ,_, e.g._FW ,_, =_JJ -_: =[_NN 17_CD ,_, 18_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ easily_RB achieved_VBN as_IN follows_VBZ :_: For_IN each_DT chunk_NN ,_, we_PRP separately_RB store_VBP the_DT size_NN of_IN this_DT chunk_NN -LRB-_-LRB- in_IN bytes_NNS or_CC words_NNS -RRB-_-RRB- ,_, and_CC in_IN uncomto_JJ pressed_VBN form_NN the_DT largest_JJS -LRB-_-LRB- last_JJ -RRB-_-RRB- docID_NN in_IN the_DT chunk_NN ._.
This_DT data_NNS can_MD
y_NN be_VB handled_VBN by_IN result_NN caching_NN ._.
Note_VB that_IN keeping_VBG these_DT duplicate_VBP queries_NNS would_MD result_VB in_IN better_JJR but_CC unrealistic_JJ cache_NN hit_NN rates_NNS ._.
The_DT performance_NN benefits_NNS of_IN result_NN caching_NN were_VBD previously_RB studied_VBN in_IN =_JJ -_: =[_NN 14_CD ,_, 23_CD ,_, 12_CD ,_, 6_CD ,_, 9_CD ,_, 3_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT benefits_NNS can_MD vary_VB significantly_RB between_IN search_NN engines_NNS ,_, however_RB ,_, based_VBN on_IN whether_IN term_NN ordering_VBG in_IN queries_NNS is_VBZ considered_VBN or_CC stemming_VBG is_VBZ performed_VBN ._.
Early_JJ work_NN on_IN index_NN caching_NN in_IN IR_NNP systems_NNS appea_NN
gines_VBZ Caching_NNP is_VBZ a_DT standard_JJ technique_NN in_IN computer_NN systems_NNS ,_, and_CC search_NN engines_NNS use_VBP several_JJ levels_NNS of_IN caching_NN to_TO improve_VB query_NN throughput_NN ._.
The_DT most_RBS common_JJ mechanisms_NNS are_VBP result_NN caching_NN and_CC list_NN caching_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Result_NN caching_NN basically_RB means_VBZ that_IN if_IN a_DT query_NN is_VBZ identical_JJ to_TO another_DT query_NN -LRB-_-LRB- by_IN possibly_RB a_DT different_JJ user_NN -RRB-_-RRB- that_WDT was_VBD recently_RB processed_VBN ,_, then_RB we_PRP can_MD simply_RB return_VB the_DT previous_JJ result_NN -LRB-_-LRB- assuming_VBG no_DT ma_NN
pare_VB LRU_NNP with_IN several_JJ other_JJ caching_NN policies_NNS and_CC show_VBP that_IN there_EX are_VBP in_IN fact_NN much_RB better_JJR list_NN caching_NN policies_NNS than_IN LRU_NNP for_IN typical_JJ search_NN engine_NN query_NN traces_NNS under_IN our_PRP$ model_NN ._.
Finally_RB ,_, recent_JJ work_NN in_IN =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: proposes_VBZ a_DT three-level_JJ caching_NN scheme_NN that_IN inserts_NNS an_DT additional_JJ level_NN of_IN caching_NN between_IN result_NN caching_NN and_CC list_NN caching_NN ;_: we_PRP do_VBP not_RB consider_VB this_DT scheme_NN here_RB ._.
3_LS ._.
CONTRIBUTIONS_NNS OF_IN THIS_NNP PAPER_NNP We_PRP study_VBD
y_NN be_VB handled_VBN by_IN result_NN caching_NN ._.
Note_VB that_IN keeping_VBG these_DT duplicate_VBP queries_NNS would_MD result_VB in_IN better_JJR but_CC unrealistic_JJ cache_NN hit_NN rates_NNS ._.
The_DT performance_NN benefits_NNS of_IN result_NN caching_NN were_VBD previously_RB studied_VBN in_IN =_JJ -_: =[_NN 14_CD ,_, 23_CD ,_, 12_CD ,_, 6_CD ,_, 9_CD ,_, 3_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT benefits_NNS can_MD vary_VB significantly_RB between_IN search_NN engines_NNS ,_, however_RB ,_, based_VBN on_IN whether_IN term_NN ordering_VBG in_IN queries_NNS is_VBZ considered_VBN or_CC stemming_VBG is_VBZ performed_VBN ._.
Early_JJ work_NN on_IN index_NN caching_NN in_IN IR_NNP systems_NNS appea_NN
tings_NNS ._.
To_TO allow_VB faster_RBR fetching_VBG of_IN the_DT lists_NNS from_IN disk_NN ,_, search_NN engines_NNS use_VBP sophisticated_JJ compression_NN techniques_NNS that_WDT significantly_RB reduce_VB the_DT size_NN of_IN each_DT inverted_JJ list_NN ;_: see_VB -LRB-_-LRB- 22_CD -RRB-_-RRB- for_IN an_DT overview_NN ,_, and_CC =_JJ -_: =[_NN 1_CD ,_, 10_CD ,_, 26_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: for_IN some_DT recent_JJ methods_NNS that_IN we_PRP consider_VBP in_IN this_DT paper_NN ._.
We_PRP describe_VBP some_DT of_IN these_DT techniques_NNS in_IN more_JJR detail_NN later_RB ._.
However_RB ,_, the_DT main_JJ idea_NN is_VBZ that_IN we_PRP can_MD compress_VB docIDs_NN by_IN storing_VBG not_RB the_DT raw_JJ docID_NN b_NN
tings_NNS ._.
To_TO allow_VB faster_RBR fetching_VBG of_IN the_DT lists_NNS from_IN disk_NN ,_, search_NN engines_NNS use_VBP sophisticated_JJ compression_NN techniques_NNS that_WDT significantly_RB reduce_VB the_DT size_NN of_IN each_DT inverted_JJ list_NN ;_: see_VB -LRB-_-LRB- 22_CD -RRB-_-RRB- for_IN an_DT overview_NN ,_, and_CC =_JJ -_: =[_NN 1_CD ,_, 10_CD ,_, 26_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: for_IN some_DT recent_JJ methods_NNS that_IN we_PRP consider_VBP in_IN this_DT paper_NN ._.
We_PRP describe_VBP some_DT of_IN these_DT techniques_NNS in_IN more_JJR detail_NN later_RB ._.
However_RB ,_, the_DT main_JJ idea_NN is_VBZ that_IN we_PRP can_MD compress_VB docIDs_NN by_IN storing_VBG not_RB the_DT raw_JJ docID_NN b_NN
also_RB recently_RB studied_VBN in_IN -LRB-_-LRB- 4_CD -RRB-_-RRB- for_IN the_DT case_NN of_IN result_NN caching_NN ,_, where_WRB the_DT skew_VBP is_VBZ even_RB more_RBR extreme_JJ and_CC thus_RB use_NN of_IN a_DT cache_NN admission_NN policy_NN crucial_JJ for_IN performance_NN ._. -RRB-_-RRB-
Multi-Queue_NN -LRB-_-LRB- MQ_NN -RRB-_-RRB- :_: MQ_NN is_VBZ studied_VBN in_IN =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT idea_NN is_VBZ to_TO use_VB not_RB one_CD butÑ_NN -LRB-_-LRB- say_NN ,_, Ñ_NN -RRB-_-RRB- LRU_NN queuesÉ_NN É_NN ÉÑ_NN ,_, whereÉ_NN contains_VBZ pages_NNS that_WDT have_VBP been_VBN seen_VBN at_IN least_JJS times_NNS but_CC no_DT more_JJR than_IN times_NNS recently_RB or_CC that_WDT have_VBP been_VBN seen_VBN at_IN least_JJS times_NNS but_CC h_NN
p_NN ,_, which_WDT we_PRP will_MD also_RB use_VB in_IN later_JJ sections_NNS ._.
The_DT data_NNS set_VBD we_PRP used_VBD in_IN our_PRP$ experiments_NNS is_VBZ a_DT set_NN of_IN million_CD web_NN pages_NNS selected_VBN randomly_RB from_IN a_DT crawl_NN of_IN million_CD pages_NNS crawled_VBN by_IN the_DT PolyBot_NNP web_NN crawler_NN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: in_IN October_NNP of_IN 2002_CD ._.
To_TO evaluate_VB our_PRP$ inverted_JJ list_NN compression_NN algorithms_NNS and_CC caching_NN policies_NNS ,_, we_PRP generated_VBD several_JJ sets_NNS of_IN inverted_JJ index_NN structures_NNS using_VBG different_JJ compression_NN methods_NNS ._.
All_DT our_PRP$ expe_NN
y_NN be_VB handled_VBN by_IN result_NN caching_NN ._.
Note_VB that_IN keeping_VBG these_DT duplicate_VBP queries_NNS would_MD result_VB in_IN better_JJR but_CC unrealistic_JJ cache_NN hit_NN rates_NNS ._.
The_DT performance_NN benefits_NNS of_IN result_NN caching_NN were_VBD previously_RB studied_VBN in_IN =_JJ -_: =[_NN 14_CD ,_, 23_CD ,_, 12_CD ,_, 6_CD ,_, 9_CD ,_, 3_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT benefits_NNS can_MD vary_VB significantly_RB between_IN search_NN engines_NNS ,_, however_RB ,_, based_VBN on_IN whether_IN term_NN ordering_VBG in_IN queries_NNS is_VBZ considered_VBN or_CC stemming_VBG is_VBZ performed_VBN ._.
Early_JJ work_NN on_IN index_NN caching_NN in_IN IR_NNP systems_NNS appea_NN
block_NN is_VBZ inserted_VBN into_IN a_DT full_JJ cache_NN ,_, the_DT LRU_NNP block_NN in_IN the_DT lowest_JJS nonempty_JJ queue_NN is_VBZ evicted_VBN and_CC its_PRP$ frequency_NN information_NN is_VBZ put_VBN intoÉÓÙØ_NN ._.
Adaptive_JJ Replacement_NN Cache_NN -LRB-_-LRB- ARC_NN -RRB-_-RRB- :_: This_DT policy_NN was_VBD proposed_VBN in_IN =_JJ -_: =[_NN 15_CD ,_, 16_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC like_IN Landlord_NNP and_CC MQ_NNP also_RB tries_VBZ to_TO balance_VB recency_NN -LRB-_-LRB- LRU_NN -RRB-_-RRB- and_CC frequency_NN -LRB-_-LRB- LFU_NN -RRB-_-RRB- ._.
Conceptually_RB ,_, ARC_NN operates_VBZ on_IN two_CD levels_NNS :_: it_PRP maintains_VBZ -LRB-_-LRB- i_LS -RRB-_-RRB- two_CD listsÄandÄreferring_NN to_TO pages_NNS each_DT that_WDT were_VBD recently_RB
consist_VBP of_IN millions_NNS of_IN postings_NNS ._.
To_TO allow_VB faster_RBR fetching_VBG of_IN the_DT lists_NNS from_IN disk_NN ,_, search_NN engines_NNS use_VBP sophisticated_JJ compression_NN techniques_NNS that_WDT significantly_RB reduce_VB the_DT size_NN of_IN each_DT inverted_JJ list_NN ;_: see_VB =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_SYM -_: for_IN an_DT overview_NN ,_, and_CC -LRB-_-LRB- 1_CD ,_, 11_CD ,_, 27_CD ,_, 21_CD -RRB-_-RRB- for_IN recent_JJ methods_NNS that_IN we_PRP consider_VBP in_IN this_DT paper_NN ._.
We_PRP describe_VBP some_DT of_IN these_DT techniques_NNS in_IN more_JJR detail_NN later_RB ._.
However_RB ,_, the_DT main_JJ idea_NN is_VBZ that_IN we_PRP can_MD compress_VB docID_NN
tings_NNS ._.
To_TO allow_VB faster_RBR fetching_VBG of_IN the_DT lists_NNS from_IN disk_NN ,_, search_NN engines_NNS use_VBP sophisticated_JJ compression_NN techniques_NNS that_WDT significantly_RB reduce_VB the_DT size_NN of_IN each_DT inverted_JJ list_NN ;_: see_VB -LRB-_-LRB- 22_CD -RRB-_-RRB- for_IN an_DT overview_NN ,_, and_CC =_JJ -_: =[_NN 1_CD ,_, 10_CD ,_, 26_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: for_IN some_DT recent_JJ methods_NNS that_IN we_PRP consider_VBP in_IN this_DT paper_NN ._.
We_PRP describe_VBP some_DT of_IN these_DT techniques_NNS in_IN more_JJR detail_NN later_RB ._.
However_RB ,_, the_DT main_JJ idea_NN is_VBZ that_IN we_PRP can_MD compress_VB docIDs_NN by_IN storing_VBG not_RB the_DT raw_JJ docID_NN b_NN
tings_NNS ._.
To_TO allow_VB faster_RBR fetching_VBG of_IN the_DT lists_NNS from_IN disk_NN ,_, search_NN engines_NNS use_VBP sophisticated_JJ compression_NN techniques_NNS that_WDT significantly_RB reduce_VB the_DT size_NN of_IN each_DT inverted_JJ list_NN ;_: see_VB -LRB-_-LRB- 22_CD -RRB-_-RRB- for_IN an_DT overview_NN ,_, and_CC =_JJ -_: =[_NN 1_CD ,_, 10_CD ,_, 26_CD ,_, 20_CD -RRB-_-RRB- -_: =_SYM -_: for_IN some_DT recent_JJ methods_NNS that_IN we_PRP consider_VBP in_IN this_DT paper_NN ._.
We_PRP describe_VBP some_DT of_IN these_DT techniques_NNS in_IN more_JJR detail_NN later_RB ._.
However_RB ,_, the_DT main_JJ idea_NN is_VBZ that_IN we_PRP can_MD compress_VB docIDs_NN by_IN storing_VBG not_RB the_DT raw_JJ docID_NN b_NN
usually_RB be_VB handled_VBN by_IN result_NN caching_NN ._.
Note_VB that_IN keeping_VBG these_DT duplicate_VBP queries_NNS would_MD result_VB in_IN better_JJR but_CC unrealistic_JJ hit_NN rates_NNS ._.
The_DT performance_NN benefits_NNS of_IN result_NN caching_NN were_VBD previously_RB studied_VBN in_IN =_JJ -_: =[_NN 15_CD ,_, 23_CD ,_, 13_CD ,_, 6_CD ,_, 10_CD ,_, 3_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT benefits_NNS can_MD vary_VB significantly_RB between_IN search_NN engines_NNS ,_, however_RB ,_, based_VBN on_IN whether_IN term_NN ordering_VBG in_IN queries_NNS is_VBZ considered_VBN or_CC stemming_VBG is_VBZ performed_VBN ._.
Early_JJ work_NN on_IN index_NN caching_NN in_IN IR_NNP systems_NNS appea_NN
cores_NNS such_JJ as_IN Pagerank_NN -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP are_VBP not_RB concerned_VBN with_IN details_NNS of_IN the_DT particular_JJ ranking_NN function_NN that_WDT is_VBZ used_VBN ._.
Many_JJ classes_NNS of_IN functions_NNS have_VBP been_VBN studied_VBN in_IN the_DT IR_NNP literature_NN ;_: see_VB ,_, e.g._FW ,_, =_JJ -_: =[_NN 22_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: for_IN an_DT introduction_NN and_CC overview_NN ._.
2.2_CD Compressed_VBN Index_NNP Organization_NNP In_IN large_JJ search_NN engines_NNS ,_, each_DT machine_NN typically_RB indexes_NNS and_CC searches_VBZ a_DT subset_NN of_IN the_DT collection_NN ,_, consisting_VBG of_IN up_IN to_TO hundreds_NNS of_IN mi_FW
ble_NN to_TO seek_VB forward_RB in_IN an_DT inverted_JJ list_NN without_IN reading_VBG and_CC decoding_VBG all_DT postings_NNS ,_, and_CC inverted_JJ index_NN structures_NNS often_RB store_VBP extra_JJ pointers_NNS that_WDT allow_VBP us_PRP to_TO skip_VB over_IN many_JJ of_IN the_DT postings_NNS ;_: see_VB ,_, e.g._FW ,_, =_JJ -_: =[_NN 17_CD ,_, 18_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ easily_RB achieved_VBN as_IN follows_VBZ :_: For_IN each_DT chunk_NN ,_, we_PRP separately_RB store_VBP the_DT size_NN of_IN this_DT chunk_NN -LRB-_-LRB- in_IN bytes_NNS or_CC words_NNS -RRB-_-RRB- ,_, and_CC in_IN uncomto_JJ pressed_VBN form_NN the_DT largest_JJS -LRB-_-LRB- last_JJ -RRB-_-RRB- docID_NN in_IN the_DT chunk_NN ._.
This_DT data_NNS can_MD
ble_NN to_TO seek_VB forward_RB in_IN an_DT inverted_JJ list_NN without_IN reading_VBG and_CC decoding_VBG all_DT postings_NNS ,_, and_CC inverted_JJ index_NN structures_NNS often_RB store_VBP extra_JJ pointers_NNS that_WDT allow_VBP us_PRP to_TO skip_VB over_IN many_JJ of_IN the_DT postings_NNS ;_: see_VB ,_, e.g._FW ,_, =_JJ -_: =[_NN 17_CD ,_, 18_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ easily_RB achieved_VBN as_IN follows_VBZ :_: For_IN each_DT chunk_NN ,_, we_PRP separately_RB store_VBP the_DT size_NN of_IN this_DT chunk_NN -LRB-_-LRB- in_IN bytes_NNS or_CC words_NNS -RRB-_-RRB- ,_, and_CC in_IN uncomto_JJ pressed_VBN form_NN the_DT largest_JJS -LRB-_-LRB- last_JJ -RRB-_-RRB- docID_NN in_IN the_DT chunk_NN ._.
This_DT data_NNS can_MD
ble_NN to_TO seek_VB forward_RB in_IN an_DT inverted_JJ list_NN without_IN reading_VBG and_CC decoding_VBG all_DT postings_NNS ,_, and_CC inverted_JJ index_NN structures_NNS often_RB store_VBP extra_JJ pointers_NNS that_WDT allow_VBP us_PRP to_TO skip_VB over_IN many_JJ of_IN the_DT postings_NNS ;_: see_VB ,_, e.g._FW ,_, =_JJ -_: =[_NN 18_CD ,_, 19_CD ,_, 7_CD ,_, 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ easily_RB achieved_VBN as_IN follows_VBZ :_: For_IN each_DT chunk_NN ,_, we_PRP separately_RB store_VBP the_DT size_NN of_IN this_DT chunk_NN -LRB-_-LRB- in_IN bytes_NNS or_CC words_NNS -RRB-_-RRB- ,_, and_CC in_IN uncompressed_JJ form_NN the_DT largest_JJS -LRB-_-LRB- last_JJ -RRB-_-RRB- docID_NN in_IN the_DT chunk_NN ._.
This_DT data_NNS can_MD be_VB s_NN
ll_NN values_NNS -LRB-_-LRB- i._NN e_SYM ,_, frequency_NN values_NNS ,_, or_CC docIDs_NN in_IN very_RB long_JJ lists_NNS -RRB-_-RRB- ,_, overall_RB the_DT extra_JJ benefits_NNS were_VBD limited_VBN -LRB-_-LRB- up_RB to_TO additional_JJ size_NN reduction_NN if_IN we_PRP select_VBP the_DT best_JJS settings_NNS for_IN each_DT list_NN -RRB-_-RRB- ._.
Recent_JJ work_NN in_IN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: also_RB proposed_VBN another_DT variation_NN of_IN Carryover12_NN called_VBN Slide_NNP ._.
PForDelta_NNP Coding_NNP :_: Our_PRP$ next_JJ method_NN is_VBZ a_DT very_RB recent_JJ technique_NN proposed_VBN in_IN -LRB-_-LRB- 11_CD ,_, 27_CD -RRB-_-RRB- for_IN compression_NN in_IN database_NN and_CC IR_NN systems_NNS ._.
It_PRP is_VBZ part_NN o_NN
