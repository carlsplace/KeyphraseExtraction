Learning_NNP from_IN the_DT past_NN :_: answering_VBG new_JJ questions_NNS with_IN past_JJ answers_NNS
Community-based_JJ Question_NNP Answering_NNP sites_NNS ,_, such_JJ as_IN Yahoo_NNP !_.
Answers_NNS or_CC Baidu_NNP Zhidao_NNP ,_, allow_VBP users_NNS to_TO get_VB answers_NNS to_TO complex_JJ ,_, detailed_JJ and_CC personal_JJ questions_NNS from_IN other_JJ users_NNS ._.
However_RB ,_, since_IN answering_VBG a_DT question_NN depends_VBZ on_IN the_DT ability_NN and_CC willingness_NN of_IN users_NNS to_TO address_VB the_DT asker_NN 's_POS needs_NNS ,_, a_DT significant_JJ fraction_NN of_IN the_DT questions_NNS remain_VBP unanswered_JJ ._.
We_PRP measured_VBD that_IN in_IN Yahoo_NNP !_.
Answers_NNS ,_, this_DT fraction_NN represents_VBZ 15_CD %_NN of_IN all_DT incoming_JJ English_NNP questions_NNS ._.
At_IN the_DT same_JJ time_NN ,_, we_PRP discovered_VBD that_IN around_IN 25_CD %_NN of_IN questions_NNS in_IN certain_JJ categories_NNS are_VBP recurrent_JJ ,_, at_IN least_JJS at_IN the_DT question-title_JJ level_NN ,_, over_IN a_DT period_NN of_IN one_CD year_NN ._.
We_PRP attempt_VBP to_TO reduce_VB the_DT rate_NN of_IN unanswered_JJ questions_NNS in_IN Yahoo_NNP !_.
Answers_NNS by_IN reusing_VBG the_DT large_JJ repository_NN of_IN past_JJ resolved_VBN questions_NNS ,_, openly_RB available_JJ on_IN the_DT site_NN ._.
More_RBR specifically_RB ,_, we_PRP estimate_VBP the_DT probability_NN whether_IN certain_JJ new_JJ questions_NNS can_MD be_VB satisfactorily_RB answered_VBN by_IN a_DT best_JJS answer_NN from_IN the_DT past_NN ,_, using_VBG a_DT statistical_JJ model_NN specifically_RB trained_VBN for_IN this_DT task_NN ._.
We_PRP leverage_NN concepts_NNS and_CC methods_NNS from_IN query-performance_JJ prediction_NN and_CC natural_JJ language_NN processing_NN in_IN order_NN to_TO extract_VB a_DT wide_JJ range_NN of_IN features_NNS for_IN our_PRP$ model_NN ._.
The_DT key_JJ challenge_NN here_RB is_VBZ to_TO achieve_VB a_DT level_NN of_IN quality_NN similar_JJ to_TO the_DT one_NN provided_VBN by_IN the_DT best_JJS human_JJ answerers_NNS ._.
We_PRP evaluated_VBD our_PRP$ algorithm_NN on_IN offline_JJ data_NNS extracted_VBN from_IN Yahoo_NNP !_.
Answers_NNS ,_, but_CC more_RBR interestingly_RB ,_, also_RB on_IN online_JJ data_NNS by_IN using_VBG three_CD ``_`` live_VB ''_'' answering_VBG robots_NNS that_WDT automatically_RB provide_VBP past_JJ answers_NNS to_TO new_JJ questions_NNS when_WRB a_DT certain_JJ degree_NN of_IN confidence_NN is_VBZ reached_VBN ._.
We_PRP report_VBP the_DT success_NN rate_NN of_IN these_DT robots_NNS in_IN three_CD active_JJ Yahoo_NNP !_.
Answers_NNS categories_NNS in_IN terms_NNS of_IN both_DT accuracy_NN ,_, coverage_NN and_CC askers_NNS '_POS satisfaction_NN ._.
This_DT work_NN presents_VBZ a_DT first_JJ attempt_NN ,_, to_TO the_DT best_JJS of_IN our_PRP$ knowledge_NN ,_, of_IN automatic_JJ question_NN answering_VBG to_TO questions_NNS of_IN social_JJ nature_NN ,_, by_IN reusing_VBG past_JJ answers_NNS of_IN high_JJ quality_NN ._.
method_NN used_VBN in_IN this_DT approach_NN consists_VBZ of_IN first_RB retrieving_VBG text_NN passages_NNS that_WDT may_MD contain_VB the_DT answer_NN to_TO the_DT target_NN question_NN ,_, then_RB extracting_VBG candidate_NN answers_NNS from_IN the_DT retrieved_VBN passages_NNS and_CC rank_VB them_PRP =_JJ -_: =[_NN 22_CD ,_, 30_CD ,_, 8_CD ,_, 25_CD ,_, 24_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ the_DT preferred_JJ framework_NN for_IN factual_JJ unambiguous_JJ questions_NNS ,_, such_JJ as_IN ``_`` Why_WRB is_VBZ the_DT sun_NN bright_JJ ?_. ''_''
,_, or_CC ``_`` Where_WRB is_VBZ the_DT Taj_NNP Mahal_NNP ?_. ''_''
,_, for_IN which_WDT a_DT unique_JJ correct_JJ answer_NN is_VBZ expected_VBN ._.
Yet_CC it_PRP is_VBZ not_RB applic_JJ
ns_NNS do_VBP not_RB receive_VB any_DT answer_NN and_CC leave_VBP the_DT asker_NN unsatisfied_JJ ._.
One_CD approach_NN to_TO reduce_VB the_DT amount_NN of_IN unanswered_JJ questions_NNS is_VBZ to_TO pro-actively_RB push_VB open_JJ questions_NNS to_TO the_DT most_RBS relevant_JJ potential_JJ answerers_NNS =_JJ -_: =[_NN 21_CD ,_, 17_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Another_DT approach_NN is_VBZ to_TO attempt_VB to_TO automatically_RB generate_VB answers_NNS from_IN external_JJ knowledge_NN resources_NNS such_JJ as_IN Wikipedia_NNP or_CC the_DT Web_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP investigate_VBP a_DT third_JJ approach_NN ,_, which_WDT is_VBZ to_TO answ_VB
stion_NN in_IN the_DT ``_`` mood_NN ''_'' to_TO answer_VB a_DT recommended_JJ question_NN ._.
A_DT complementary_JJ approach_NN is_VBZ to_TO automatically_RB generate_VB answers_NNS ._.
Automatic_NNP question_NN answering_NN has_VBZ been_VBN an_DT active_JJ research_NN field_NN for_IN several_JJ decades_NNS =_JJ -_: =[_NN 32_CD ,_, 33_CD ,_, 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD common_JJ method_NN used_VBN in_IN this_DT approach_NN consists_VBZ of_IN first_RB retrieving_VBG text_NN passages_NNS that_WDT may_MD contain_VB the_DT answer_NN to_TO the_DT target_NN question_NN ,_, then_RB extracting_VBG candidate_NN answers_NNS from_IN the_DT retrieved_VBN passages_NNS a_DT
for_IN answer_NN similarity_NN as_IN part_NN of_IN the_DT retrieval_NN model_NN for_IN similar_JJ questions_NNS ._.
Duan_NNP et_FW al._FW -LRB-_-LRB- 12_CD -RRB-_-RRB- retrieve_VBP questions_NNS with_IN similar_JJ topic_NN and_CC focus_VB on_IN those_DT that_WDT pertain_VBP to_TO the_DT target_NN question_NN ._.
Wang_NNP et_FW al._FW =_SYM -_: =[_NN 34_CD -RRB-_-RRB- -_: =_SYM -_: identify_VB similar_JJ questions_NNS by_IN assessing_VBG the_DT similarity_NN between_IN their_PRP$ syntactic_JJ parse_NN trees_NNS ._.
Our_PRP$ work_NN belongs_VBZ to_TO the_DT above_JJ school_NN that_WDT seems_VBZ the_DT most_RBS promising_JJ given_VBN the_DT huge_JJ repository_NN of_IN more_JJR than_IN a_DT
ith_NN humans_NNS is_VBZ clearly_RB important_JJ in_IN CQA_NNP ,_, as_IN demonstrated_VBN by_IN the_DT recent_JJ success_NN of_IN Quora_NNP ,_, a_DT significant_JJ portion_NN of_IN questions_NNS is_VBZ driven_VBN by_IN a_DT real_JJ need_NN for_IN which_WDT the_DT user_NN expects_VBZ a_DT single_JJ relevant_JJ answer_NN =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Yet_RB in_IN spite_NN of_IN active_JJ participation_NN in_IN CQA_NNP sites_NNS ,_, a_DT significant_JJ portion_NN of_IN questions_NNS remain_VBP unanswered_JJ ,_, a_DT phenomenon_NN we_PRP refer_VBP to_TO as_IN question_NN starvation_NN -RRB-_-RRB- -LRB-_-LRB- 21_CD -RRB-_-RRB- ._.
In_IN an_DT analysis_NN we_PRP conducted_VBD on_IN Yahoo_NNP !_.
ork_NN ._.
3.1_CD Stage_NNP One_CD :_: Top_NNP Candidate_NNP Selection_NN Since_IN our_PRP$ purpose_NN is_VBZ to_TO eventually_RB serve_VB a_DT single_JJ answer_NN that_WDT will_MD satisfy_VB the_DT needs_NNS of_IN the_DT asker_NN ,_, we_PRP follow_VBP the_DT definition_NN of_IN a_DT satisfying_JJ answer_NN given_VBN in_IN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC limit_VB our_PRP$ search_NN space_NN to_TO past_JJ questions_NNS with_IN answers_NNS that_WDT were_VBD marked_VBN as_IN best_JJS answer_NN by_IN the_DT askers_NNS ,_, and_CC were_VBD rated_VBN with_IN at_IN least_JJS three_CD stars_NNS ._.
Several_JJ works_NNS present_VBP effective_JJ similar_JJ question_NN re_NN
ns_NNS do_VBP not_RB receive_VB any_DT answer_NN and_CC leave_VBP the_DT asker_NN unsatisfied_JJ ._.
One_CD approach_NN to_TO reduce_VB the_DT amount_NN of_IN unanswered_JJ questions_NNS is_VBZ to_TO pro-actively_RB push_VB open_JJ questions_NNS to_TO the_DT most_RBS relevant_JJ potential_JJ answerers_NNS =_JJ -_: =[_NN 21_CD ,_, 17_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Another_DT approach_NN is_VBZ to_TO attempt_VB to_TO automatically_RB generate_VB answers_NNS from_IN external_JJ knowledge_NN resources_NNS such_JJ as_IN Wikipedia_NNP or_CC the_DT Web_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP investigate_VBP a_DT third_JJ approach_NN ,_, which_WDT is_VBZ to_TO answ_VB
e_LS user_NN expects_VBZ a_DT single_JJ relevant_JJ answer_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- ._.
Yet_RB in_IN spite_NN of_IN active_JJ participation_NN in_IN CQA_NNP sites_NNS ,_, a_DT significant_JJ portion_NN of_IN questions_NNS remain_VBP unanswered_JJ ,_, a_DT phenomenon_NN we_PRP refer_VBP to_TO as_IN question_NN starvation_NN -RRB-_-RRB- =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN an_DT analysis_NN we_PRP conducted_VBD on_IN Yahoo_NNP !_.
Answers_NNS ,_, one_CD of_IN the_DT first_JJ CQA_NN sites_NNS on_IN the_DT Web_NN ,_, we_PRP discovered_VBD that_IN about_IN 15_CD %_NN of_IN the_DT questions_NNS do_VBP not_RB receive_VB any_DT answer_NN and_CC leave_VBP the_DT asker_NN unsatisfied_JJ ._.
One_CD app_NN
s_NN ,_, users_NNS assume_VBP that_IN no_DT single_JJ Web_NN page_NN will_MD directly_RB answer_VB their_PRP$ possibly_RB complex_JJ and_CC heterogeneous_JJ needs_NNS ,_, or_CC maybe_RB they_PRP perceive_VBP that_IN real_JJ humans_NNS should_MD understand_VB and_CC answer_VB better_JJR than_IN a_DT machine_NN =_JJ -_: =[_NN 31_CD -RRB-_-RRB- -_: =_SYM -_: ._.
While_IN the_DT social_JJ angle_NN of_IN interacting_VBG with_IN humans_NNS is_VBZ clearly_RB important_JJ in_IN CQA_NNP ,_, as_IN demonstrated_VBN by_IN the_DT recent_JJ success_NN of_IN Quora_NNP ,_, a_DT significant_JJ portion_NN of_IN questions_NNS is_VBZ driven_VBN by_IN a_DT real_JJ need_NN for_IN which_WDT t_NN
andom_NN Forest_NN ,_, Logistic_JJ regression_NN ,_, SVM_NN and_CC Naive_JJ Bayes_NNS ,_, as_IN implemented_VBN by_IN the_DT Weka_NNP machine_NN learning_NN workbench_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
Using_VBG F1_NN and_CC Area_NN under_IN ROC_NN curve_NN as_IN quality_NN measures_NNS ,_, the_DT Random_NNP Forest_NNP classifier_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: showed_VBD consistently_RB superior_JJ results_NNS and_CC was_VBD thus_RB selected_VBN as_IN our_PRP$ classification_NN model_NN for_IN stage_NN two_CD of_IN the_DT algorithm_NN ._.
There_EX are_VBP two_CD parameters_NNS controlling_VBG Random_NNP Forest_NNP :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- 763WWW_NN 2012_CD --_: Session_NN :_:
stion_NN in_IN the_DT ``_`` mood_NN ''_'' to_TO answer_VB a_DT recommended_JJ question_NN ._.
A_DT complementary_JJ approach_NN is_VBZ to_TO automatically_RB generate_VB answers_NNS ._.
Automatic_NNP question_NN answering_NN has_VBZ been_VBN an_DT active_JJ research_NN field_NN for_IN several_JJ decades_NNS =_JJ -_: =[_NN 32_CD ,_, 33_CD ,_, 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD common_JJ method_NN used_VBN in_IN this_DT approach_NN consists_VBZ of_IN first_RB retrieving_VBG text_NN passages_NNS that_WDT may_MD contain_VB the_DT answer_NN to_TO the_DT target_NN question_NN ,_, then_RB extracting_VBG candidate_NN answers_NNS from_IN the_DT retrieved_VBN passages_NNS a_DT
two_CD of_IN these_DT measures_NNS that_WDT can_MD be_VB effectively_RB applied_VBN for_IN the_DT task_NN question_NN difficulty_NN estimation_NN in_IN CQA_NNP ._.
Query_NNP Clarity_NNP is_VBZ an_DT effective_JJ measure_NN for_IN query_NN ambiguity_NN proposed_VBN by_IN Cronen-Townsend_NNP et_FW al._FW =_SYM -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
It_PRP measures_VBZ the_DT coherence_NN of_IN the_DT result_NN list_NN with_IN respect_NN to_TO the_DT corpus_NN via_IN the_DT KL-divergence_NN between_IN the_DT language_NN model_NN of_IN the_DT result-list_NN and_CC that_DT of_IN the_DT corpus_NN ._.
It_PRP relies_VBZ on_IN the_DT premise_NN that_IN ambi_NNS
method_NN used_VBN in_IN this_DT approach_NN consists_VBZ of_IN first_RB retrieving_VBG text_NN passages_NNS that_WDT may_MD contain_VB the_DT answer_NN to_TO the_DT target_NN question_NN ,_, then_RB extracting_VBG candidate_NN answers_NNS from_IN the_DT retrieved_VBN passages_NNS and_CC rank_VB them_PRP =_JJ -_: =[_NN 22_CD ,_, 30_CD ,_, 8_CD ,_, 25_CD ,_, 24_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ the_DT preferred_JJ framework_NN for_IN factual_JJ unambiguous_JJ questions_NNS ,_, such_JJ as_IN ``_`` Why_WRB is_VBZ the_DT sun_NN bright_JJ ?_. ''_''
,_, or_CC ``_`` Where_WRB is_VBZ the_DT Taj_NNP Mahal_NNP ?_. ''_''
,_, for_IN which_WDT a_DT unique_JJ correct_JJ answer_NN is_VBZ expected_VBN ._.
Yet_CC it_PRP is_VBZ not_RB applic_JJ
e_LS worker_NN ._.
This_DT procedure_NN proved_VBD itself_PRP very_RB significant_JJ in_IN terms_NNS of_IN data_NNS quality_NN ._.
To_TO assess_VB the_DT quality_NN of_IN the_DT workers_NNS ,_, we_PRP calculated_VBD the_DT inter-worker_JJ agreement_NN in_IN each_DT category_NN using_VBG Fleiss_NNP '_POS kappa_NN 9_CD =_JJ -_: =[_NN 13_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Table_NNP 1_CD summarizes_VBZ the_DT calculated_JJ kappa_NN values_NNS and_CC their_PRP$ standard_JJ errors_NNS ._.
The_DT agreement_NN is_VBZ fair_JJ for_IN all_DT three_CD categories_NNS ,_, with_IN somewhat_RB lower_JJR agreement_NN for_IN Health_NNP ._.
Indeed_RB ,_, Health_NNP examples_NNS were_VBD more_JJR
answering_VBG algorithm_NN for_IN CQA_NNP ._.
past_JJ questions_NNS that_WDT are_VBP similar_JJ to_TO the_DT target_NN question_NN ,_, based_VBN on_IN the_DT hypothesis_NN that_IN answers_NNS to_TO similar_JJ questions_NNS should_MD be_VB relevant_JJ to_TO the_DT target_NN question_NN ._.
Carmel_NNP et_FW al._FW =_SYM -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: rank_JJ past_JJ questions_NNS using_VBG both_CC inter-question_NN and_CC question-answer_NN similarity_NN ,_, with_IN response_NN to_TO a_DT newly_RB posed_VBN question_NN ._.
Jeon_NNP et_FW al._FW -LRB-_-LRB- 18_CD ,_, 19_CD -RRB-_-RRB- demonstrate_VBP that_IN similar_JJ answers_NNS are_VBP a_DT good_JJ indicator_NN of_IN si_FW
sonal_JJ ,_, narrow_JJ ,_, ambiguous_JJ ,_, openended_JJ or_CC advice-seeking_JJ questions_NNS ,_, such_JJ as_IN ``_`` Should_MD I_PRP get_VB lovebirds_NNS or_CC cockateils_NNS ?_. ''_''
,_, that_WDT often_RB appear_VBP on_IN CQA_NN sites_NNS ._.
Fewer_JJR efforts_NNS focus_VB on_IN the_DT latter_JJ types_NNS of_IN questions_NNS ,_, =_JJ -_: =[_NN 1_CD ,_, 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN such_JJ questions_NNS several_JJ answers_NNS may_MD be_VB valid_JJ and_CC the_DT answers_NNS may_MD be_VB quite_RB complex_JJ ._.
Figure_NN 2_CD depicts_VBZ such_PDT a_DT detailed_JJ answer_NN to_TO the_DT previous_JJ question_NN ._.
A_DT different_JJ type_NN of_IN effort_NN proposes_VBZ to_TO identif_VB
stion_NN in_IN the_DT ``_`` mood_NN ''_'' to_TO answer_VB a_DT recommended_JJ question_NN ._.
A_DT complementary_JJ approach_NN is_VBZ to_TO automatically_RB generate_VB answers_NNS ._.
Automatic_NNP question_NN answering_NN has_VBZ been_VBN an_DT active_JJ research_NN field_NN for_IN several_JJ decades_NNS =_JJ -_: =[_NN 32_CD ,_, 33_CD ,_, 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD common_JJ method_NN used_VBN in_IN this_DT approach_NN consists_VBZ of_IN first_RB retrieving_VBG text_NN passages_NNS that_WDT may_MD contain_VB the_DT answer_NN to_TO the_DT target_NN question_NN ,_, then_RB extracting_VBG candidate_NN answers_NNS from_IN the_DT retrieved_VBN passages_NNS a_DT
These_DT features_NNS try_VBP to_TO identify_VB the_DT focus_NN ,_, complexity_NN and_CC informativeness_NN of_IN the_DT text_NN ._.
Various_JJ IDF_NN statistics_NNS over_IN query_NN terms_NNS have_VBP been_VBN found_VBN to_TO be_VB correlated_VBN to_TO query_VB difficulty_NN in_IN ad-hoc_JJ retrieval_NN =_JJ -_: =[_NN 16_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, low_JJ maximal_JJ IDF_NN indicates_VBZ a_DT general_JJ ,_, non_JJ informative_JJ question_NN and_CC thus_RB we_PRP expect_VBP it_PRP would_MD be_VB harder_JJR to_TO find_VB a_DT question_NN with_IN the_DT same_JJ intent_NN and_CC provide_VB a_DT correct_JJ answer_NN ._.
Other_JJ features_NNS ,_,
d_NN the_DT language_NN model_NN of_IN the_DT whole_JJ repository_NN is_VBZ calculated_VBN and_CC serves_VBZ as_IN the_DT Clarity_NN score_NN ._.
Query_NNP Feedback_NNP is_VBZ a_DT state-of-the-art_JJ performance_NN predictor_NN for_IN ad-hoc_JJ retrieval_NN ,_, proposed_VBN by_IN Zhou_NNP and_CC Croft_NNP =_SYM -_: =[_NN 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Query_NNP Feedback_NNP treats_VBZ the_DT retrieval_NN process_NN as_IN a_DT transmission_NN of_IN the_DT query_FW q_FW over_IN a_DT noisy_JJ channel_NN and_CC the_DT retrieved_VBN result-list_NN L_NN as_IN the_DT corrupted_VBN version_NN of_IN q._NN The_DT quality_NN of_IN L_NN is_VBZ associated_VBN with_IN t_NN
estions_NNS should_MD be_VB relevant_JJ to_TO the_DT target_NN question_NN ._.
Carmel_NNP et_FW al._FW -LRB-_-LRB- 7_CD -RRB-_-RRB- rank_VBP past_JJ questions_NNS using_VBG both_CC inter-question_NN and_CC question-answer_NN similarity_NN ,_, with_IN response_NN to_TO a_DT newly_RB posed_VBN question_NN ._.
Jeon_NNP et_FW al._FW =_SYM -_: =[_NN 18_CD ,_, 19_CD -RRB-_-RRB- -_: =_SYM -_: demonstrate_VBP that_IN similar_JJ answers_NNS are_VBP a_DT good_JJ indicator_NN of_IN similar_JJ questions_NNS ._.
Once_IN pairs_NNS of_IN similar_JJ questions_NNS are_VBP collected_VBN based_VBN on_IN their_PRP$ similar_JJ answers_NNS ,_, they_PRP are_VBP used_VBN to_TO learn_VB a_DT translation_NN model_NN be_VB
estions_NNS should_MD be_VB relevant_JJ to_TO the_DT target_NN question_NN ._.
Carmel_NNP et_FW al._FW -LRB-_-LRB- 7_CD -RRB-_-RRB- rank_VBP past_JJ questions_NNS using_VBG both_CC inter-question_NN and_CC question-answer_NN similarity_NN ,_, with_IN response_NN to_TO a_DT newly_RB posed_VBN question_NN ._.
Jeon_NNP et_FW al._FW =_SYM -_: =[_NN 18_CD ,_, 19_CD -RRB-_-RRB- -_: =_SYM -_: demonstrate_VBP that_IN similar_JJ answers_NNS are_VBP a_DT good_JJ indicator_NN of_IN similar_JJ questions_NNS ._.
Once_IN pairs_NNS of_IN similar_JJ questions_NNS are_VBP collected_VBN based_VBN on_IN their_PRP$ similar_JJ answers_NNS ,_, they_PRP are_VBP used_VBN to_TO learn_VB a_DT translation_NN model_NN be_VB
method_NN used_VBN in_IN this_DT approach_NN consists_VBZ of_IN first_RB retrieving_VBG text_NN passages_NNS that_WDT may_MD contain_VB the_DT answer_NN to_TO the_DT target_NN question_NN ,_, then_RB extracting_VBG candidate_NN answers_NNS from_IN the_DT retrieved_VBN passages_NNS and_CC rank_VB them_PRP =_JJ -_: =[_NN 22_CD ,_, 30_CD ,_, 8_CD ,_, 25_CD ,_, 24_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ the_DT preferred_JJ framework_NN for_IN factual_JJ unambiguous_JJ questions_NNS ,_, such_JJ as_IN ``_`` Why_WRB is_VBZ the_DT sun_NN bright_JJ ?_. ''_''
,_, or_CC ``_`` Where_WRB is_VBZ the_DT Taj_NNP Mahal_NNP ?_. ''_''
,_, for_IN which_WDT a_DT unique_JJ correct_JJ answer_NN is_VBZ expected_VBN ._.
Yet_CC it_PRP is_VBZ not_RB applic_JJ
ase_NN ._.
Indeed_RB our_PRP$ collection_NN is_VBZ too_RB large_JJ and_CC the_DT questions_NNS too_RB numerous_JJ and_CC too_RB various_JJ to_TO know_VB whether_IN a_DT valid_JJ answer_NN even_RB exists_VBZ within_IN the_DT collection_NN of_IN past_JJ answers_NNS ._.
In_IN a_DT similar_JJ vein_NN ,_, Bian_NNP et_FW al._FW =_SYM -_: =[_NN 4_CD -RRB-_-RRB- -_: =_JJ -_: attempt_NN to_TO rank_VB past_JJ CQA_NN question-answer_NN pairs_NNS in_IN response_NN to_TO factual_JJ questions_NNS ._.
They_PRP utilize_VBP a_DT supervised_JJ learning-to-rank_JJ algorithm_NN to_TO promote_VB relevant_JJ past_JJ answers_NNS to_TO the_DT input_NN question_NN based_VBN on_IN t_NN
t_NN April_NNP 16_CD --_: 20_CD ,_, 2012_CD ,_, Lyon_NNP ,_, France_NNP binary_JJ match\/mismatch_NN of_IN the_DT most_RBS probable_JJ topic_NN in_IN each_DT distribution_NN ._.
Lexico-syntactic_JJ Analysis_NNP :_: We_PRP parse_VBP each_DT question_NN title_NN using_VBG the_DT Stanford_NNP dependency_NN parser_NN 6_CD =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
From_IN the_DT parse_NN tree_NN we_PRP extract_VBP the_DT WH_NN question_NN type_NN ,_, if_IN it_PRP exists_VBZ ,_, and_CC the_DT number_NN of_IN nouns_NNS ,_, verbs_NNS and_CC adjectives_NNS as_IN question_NN quality_NN features_NNS ._.
We_PRP also_RB check_VBP for_IN a_DT match_NN between_IN the_DT WH_NN question_NN type_NN
alculated_VBN ._.
Finally_RB ,_, we_PRP also_RB measure_VBP the_DT difference_NN between_IN the_DT similarity_NN score_NN of_IN -LRB-_-LRB- Qnew_NNP ,_, A_NNP -RRB-_-RRB- andof_NN -LRB-_-LRB- Qpast_NN ,_, A_NN -RRB-_-RRB- ._.
Linguistic_NNP Analysis_NNP ._.
Latent_JJ Topics_NNS :_: For_IN each_DT category_NN in_IN Yahoo_NNP !_.
Answers_NNS we_PRP learn_VBP LDA_NN topics_NNS =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: from_IN the_DT corpus_NN of_IN past_JJ resolved_VBN questions_NNS in_IN that_DT category_NN ._.
Then_RB ,_, for_IN each_DT input_NN triplet_NN we_PRP infer_VBP the_DT distribution_NN over_IN topics_NNS for_IN Qnew_NNP ,_, Qpast_NNP and_CC A_NNP separately_RB ._.
From_IN these_DT distributions_NNS ,_, we_PRP generate_VBP
e_LS worker_NN ._.
This_DT procedure_NN proved_VBD itself_PRP very_RB significant_JJ in_IN terms_NNS of_IN data_NNS quality_NN ._.
To_TO assess_VB the_DT quality_NN of_IN the_DT workers_NNS ,_, we_PRP calculated_VBD the_DT inter-worker_JJ agreement_NN in_IN each_DT category_NN using_VBG Fleiss_NNP '_POS kappa_NN 9_CD =_JJ -_: =[_NN 13_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Table_NNP 1_CD summarizes_VBZ the_DT calculated_JJ kappa_NN values_NNS and_CC their_PRP$ standard_JJ errors_NNS ._.
The_DT agreement_NN is_VBZ fair_JJ for_IN all_DT three_CD categories_NNS ,_, with_IN somewhat_RB lower_JJR agreement_NN for_IN Health_NNP ._.
Indeed_RB ,_, Health_NNP examples_NNS were_VBD more_JJR
method_NN used_VBN in_IN this_DT approach_NN consists_VBZ of_IN first_RB retrieving_VBG text_NN passages_NNS that_WDT may_MD contain_VB the_DT answer_NN to_TO the_DT target_NN question_NN ,_, then_RB extracting_VBG candidate_NN answers_NNS from_IN the_DT retrieved_VBN passages_NNS and_CC rank_VB them_PRP =_JJ -_: =[_NN 22_CD ,_, 30_CD ,_, 8_CD ,_, 25_CD ,_, 24_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ the_DT preferred_JJ framework_NN for_IN factual_JJ unambiguous_JJ questions_NNS ,_, such_JJ as_IN ``_`` Why_WRB is_VBZ the_DT sun_NN bright_JJ ?_. ''_''
,_, or_CC ``_`` Where_WRB is_VBZ the_DT Taj_NNP Mahal_NNP ?_. ''_''
,_, for_IN which_WDT a_DT unique_JJ correct_JJ answer_NN is_VBZ expected_VBN ._.
Yet_CC it_PRP is_VBZ not_RB applic_JJ
ere_NN obtained_VBD using_VBG cross-validation_NN ,_, whereas_IN the_DT former_JJ by_IN using_VBG a_DT model_NN trained_VBN on_IN the_DT whole_JJ training_NN set_NN ._.
It_PRP is_VBZ a_DT well_RB known_VBN fact_NN that_IN the_DT cross_JJ validation_NN performance_NN assessment_NN is_VBZ slightly_RB biased_VBN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Second_RB ,_, the_DT two_CD datasets_NNS were_VBD labeled_VBN by_IN different_JJ annotators_NNS ,_, with_IN different_JJ qualifications_NNS and_CC motivation_NN ._.
Finally_RB ,_, the_DT different_JJ time-frames_NNS from_IN which_WDT the_DT examples_NNS for_IN the_DT two_CD datasets_NNS were_VBD take_VB
cation_NN Model_NNP We_PRP performed_VBD preliminary_JJ experimentation_NN with_IN four_CD families_NNS of_IN classifiers_NNS :_: Random_NNP Forest_NNP ,_, Logistic_JJ regression_NN ,_, SVM_NN and_CC Naive_JJ Bayes_NNS ,_, as_IN implemented_VBN by_IN the_DT Weka_NNP machine_NN learning_NN workbench_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Using_VBG F1_NN and_CC Area_NN under_IN ROC_NN curve_NN as_IN quality_NN measures_NNS ,_, the_DT Random_NNP Forest_NNP classifier_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- showed_VBD consistently_RB superior_JJ results_NNS and_CC was_VBD thus_RB selected_VBN as_IN our_PRP$ classification_NN model_NN for_IN stage_NN two_CD of_IN the_DT al_FW
picts_NNS such_PDT a_DT detailed_JJ answer_NN to_TO the_DT previous_JJ question_NN ._.
A_DT different_JJ type_NN of_IN effort_NN proposes_VBZ to_TO identify_VB within_IN a_DT collection_NN of_IN answers_NNS the_DT most_RBS relevant_JJ ones_NNS to_TO a_DT given_VBN question_NN ._.
Bernhard_NN and_CC Gurevych_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: use_NN translation_NN models_NNS to_TO this_DT effect_NN ,_, and_CC evaluate_VB their_PRP$ approach_NN on_IN a_DT small_JJ set_NN of_IN factual_JJ questions_NNS ,_, for_IN which_WDT answers_NNS are_VBP known_VBN ahead_RB of_IN time_NN ._.
Surdeanu_FW et_FW al._FW -LRB-_-LRB- 29_CD -RRB-_-RRB- ,_, combine_VBP translation_NN and_CC simila_NN
questions_NNS are_VBP collected_VBN based_VBN on_IN their_PRP$ similar_JJ answers_NNS ,_, they_PRP are_VBP used_VBN to_TO learn_VB a_DT translation_NN model_NN between_IN question_NN titles_NNS to_TO overcome_VB the_DT lexical_JJ chasm_NN when_WRB retrieving_VBG similar_JJ questions_NNS ._.
Xue_NNP et_FW al._FW =_SYM -_: =[_NN 35_CD -RRB-_-RRB- -_: =_SYM -_: combine_VB a_DT translation_NN model_NN for_IN question_NN similarity_NN and_CC a_DT language_NN model_NN for_IN answer_NN similarity_NN as_IN part_NN of_IN the_DT retrieval_NN model_NN for_IN similar_JJ questions_NNS ._.
Duan_NNP et_FW al._FW -LRB-_-LRB- 12_CD -RRB-_-RRB- retrieve_VBP questions_NNS with_IN similar_JJ t_NN
ing_JJ similar_JJ questions_NNS ._.
Xue_NNP et_FW al._FW -LRB-_-LRB- 35_CD -RRB-_-RRB- combine_VBP a_DT translation_NN model_NN for_IN question_NN similarity_NN and_CC a_DT language_NN model_NN for_IN answer_NN similarity_NN as_IN part_NN of_IN the_DT retrieval_NN model_NN for_IN similar_JJ questions_NNS ._.
Duan_NNP et_FW al._FW =_SYM -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: retrieve_VB questions_NNS with_IN similar_JJ topic_NN and_CC focus_VB on_IN those_DT that_WDT pertain_VBP to_TO the_DT target_NN question_NN ._.
Wang_NNP et_FW al._FW -LRB-_-LRB- 34_CD -RRB-_-RRB- identify_VBP similar_JJ questions_NNS by_IN assessing_VBG the_DT similarity_NN between_IN their_PRP$ syntactic_JJ parse_NN tre_NN
These_DT features_NNS try_VBP to_TO identify_VB the_DT focus_NN ,_, complexity_NN and_CC informativeness_NN of_IN the_DT text_NN ._.
Various_JJ IDF_NN statistics_NNS over_IN query_NN terms_NNS have_VBP been_VBN found_VBN to_TO be_VB correlated_VBN to_TO query_VB difficulty_NN in_IN ad-hoc_JJ retrieval_NN =_JJ -_: =[_NN 16_CD ,_, 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, low_JJ maximal_JJ IDF_NN indicates_VBZ a_DT general_JJ ,_, non_JJ informative_JJ question_NN and_CC thus_RB we_PRP expect_VBP it_PRP would_MD be_VB harder_JJR to_TO find_VB a_DT question_NN with_IN the_DT same_JJ intent_NN and_CC provide_VB a_DT correct_JJ answer_NN ._.
Other_JJ features_NNS ,_,
question_NN ._.
Bernhard_NNP and_CC Gurevych_NNP -LRB-_-LRB- 3_LS -RRB-_-RRB- use_NN translation_NN models_NNS to_TO this_DT effect_NN ,_, and_CC evaluate_VB their_PRP$ approach_NN on_IN a_DT small_JJ set_NN of_IN factual_JJ questions_NNS ,_, for_IN which_WDT answers_NNS are_VBP known_VBN ahead_RB of_IN time_NN ._.
Surdeanu_FW et_FW al._FW =_SYM -_: =[_NN 29_CD -RRB-_-RRB- -_: =_JJ -_: ,_, combine_VB translation_NN and_CC similarity_NN features_NNS in_IN order_NN to_TO rank_VB answers_NNS by_IN relevance_NN to_TO a_DT given_VBN question_NN ,_, but_CC focus_VBP only_RB on_IN how_WRB to_TO questions_NNS ._.
Both_DT efforts_NNS share_VBP the_DT same_JJ goal_NN of_IN identifying_VBG the_DT existin_NN
method_NN used_VBN in_IN this_DT approach_NN consists_VBZ of_IN first_RB retrieving_VBG text_NN passages_NNS that_WDT may_MD contain_VB the_DT answer_NN to_TO the_DT target_NN question_NN ,_, then_RB extracting_VBG candidate_NN answers_NNS from_IN the_DT retrieved_VBN passages_NNS and_CC rank_VB them_PRP =_JJ -_: =[_NN 22_CD ,_, 30_CD ,_, 8_CD ,_, 25_CD ,_, 24_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ the_DT preferred_JJ framework_NN for_IN factual_JJ unambiguous_JJ questions_NNS ,_, such_JJ as_IN ``_`` Why_WRB is_VBZ the_DT sun_NN bright_JJ ?_. ''_''
,_, or_CC ``_`` Where_WRB is_VBZ the_DT Taj_NNP Mahal_NNP ?_. ''_''
,_, for_IN which_WDT a_DT unique_JJ correct_JJ answer_NN is_VBZ expected_VBN ._.
Yet_CC it_PRP is_VBZ not_RB applic_JJ
