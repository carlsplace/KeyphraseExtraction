A_DT unified_JJ approach_NN to_TO learning_VBG task-specific_JJ bit_NN vector_NN representations_NNS for_IN fast_RB nearest_JJS neighbor_NN search_NN
Fast_JJ nearest_JJS neighbor_NN search_NN is_VBZ necessary_JJ for_IN a_DT variety_NN of_IN large_JJ scale_NN web_NN applications_NNS such_JJ as_IN information_NN retrieval_NN ,_, nearest_IN neighbor_NN classification_NN and_CC nearest_JJS neighbor_NN regression_NN ._.
Recently_RB a_DT number_NN of_IN machine_NN learning_NN algorithms_NNS have_VBP been_VBN proposed_VBN for_IN representing_VBG the_DT data_NNS to_TO be_VB searched_VBN as_IN -LRB-_-LRB- short_JJ -RRB-_-RRB- bit_NN vectors_NNS and_CC then_RB using_VBG hashing_VBG to_TO do_VB rapid_JJ search_NN ._.
These_DT algorithms_NNS have_VBP been_VBN limited_VBN in_IN their_PRP$ applicability_NN in_IN that_IN they_PRP are_VBP suited_VBN for_IN only_RB one_CD type_NN of_IN task_NN --_: e.g._NNP Spectral_NNP Hashing_NNP learns_VBZ bit_NN vector_NN representations_NNS for_IN retrieval_NN ,_, but_CC not_RB say_VB ,_, classification_NN ._.
In_IN this_DT paper_NN we_PRP present_VBP a_DT unified_JJ approach_NN to_TO learning_VBG bit_NN vector_NN representations_NNS for_IN many_JJ applications_NNS that_WDT use_VBP nearest_JJS neighbor_NN search_NN ._.
The_DT main_JJ contribution_NN is_VBZ a_DT single_JJ learning_NN algorithm_NN that_WDT can_MD be_VB customized_VBN to_TO learn_VB a_DT bit_NN vector_NN representation_NN suited_VBN for_IN the_DT task_NN at_IN hand_NN ._.
This_DT broadens_VBZ the_DT usefulness_NN of_IN bit_NN vector_NN representations_NNS to_TO tasks_NNS beyond_IN just_RB conventional_JJ retrieval_NN ._.
We_PRP propose_VBP a_DT learning-to-rank_JJ formulation_NN to_TO learn_VB the_DT bit_NN vector_NN representation_NN of_IN the_DT data_NNS ._.
LambdaRank_NN algorithm_NN is_VBZ used_VBN for_IN learning_VBG a_DT function_NN that_WDT computes_VBZ a_DT task-specific_JJ bit_NN vector_NN from_IN an_DT input_NN data_NN vector_NN ._.
Our_PRP$ approach_NN outperforms_VBZ state-of-the-art_JJ nearest_JJS neighbor_NN methods_NNS on_IN a_DT number_NN of_IN real_JJ world_NN text_NN and_CC image_NN classification_NN and_CC retrieval_NN datasets_NNS ._.
It_PRP is_VBZ scalable_JJ and_CC learns_VBZ a_DT 32-bit_JJ representation_NN on_IN 1.46_CD million_CD training_NN cases_NNS in_IN two_CD days_NNS ._.
a_DT structural_JJ SVM_NN learning_NN framework_NN -LRB-_-LRB- figure_NN 1_CD -LRB-_-LRB- b_NN -RRB-_-RRB- -RRB-_-RRB- for_IN learning_VBG the_DT metric_NN where_WRB various_JJ ranking_JJ measures_NNS such_JJ as_IN precision@k,_NNP NDCG_NNP ,_, etc._NN ,_, can_MD be_VB optimized_VBN -LRB-_-LRB- referred_VBN as_IN MLR_NN in_IN Table_NNP 1_CD -RRB-_-RRB- ._.
Chechik_NNP et_FW al._FW =_SYM -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: propose_VBP an_DT online_JJ algorithm_NN where_WRB each_DT bin_NN contains_VBZ the_DT data_NN points_NNS that_WDT were_VBD mapped_VBN to_TO the_DT corresponding_JJ bit_NN vector_NN ._.
for_IN scalable_JJ image_NN similarity_NN -LRB-_-LRB- OASIS_NN -RRB-_-RRB- that_WDT learns_VBZ a_DT similarity_NN measure_NN -LRB-_-LRB- figure_NN 1_CD -LRB-_-LRB-
iscussed_VBN several_JJ popular_JJ methods_NNS closely_RB related_JJ to_TO our_PRP$ work_NN in_IN the_DT introduction_NN ,_, and_CC empirically_RB compared_VBN with_IN representative_JJ methods_NNS ._.
Here_RB ,_, we_PRP present_VBP other_JJ related_JJ work_NN ._.
Hashing_VBG Methods_NNS Kernel_NNP LSH_NN =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ a_DT recent_JJ scheme_NN that_WDT generalizes_VBZ LSH_NN ,_, and_CC is_VBZ useful_JJ when_WRB similarity_NN measure_NN is_VBZ given_VBN directly_RB via_IN a_DT kernel_NN function_NN -LRB-_-LRB- without_IN explicit_JJ knowledge_NN of_IN the_DT underlying_JJ transformation_NN -RRB-_-RRB- ,_, or_CC the_DT underlying_VBG
use_NN here_RB contains_VBZ only_RB the_DT top-ranked_JJ images_NNS for_IN the_DT query_NN terms_NNS ,_, so_IN it_PRP is_VBZ likely_JJ to_TO be_VB less_RBR noisy_JJ than_IN the_DT full_JJ 80_CD million_CD set_NN ._.
The_DT images_NNS are_VBP represented_VBN using_VBG 512_CD dimensional_JJ GIST_NN feature_NN vectors_NNS =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT retrieval_NN task_NN is_VBZ defined_VBN in_IN the_DT same_JJ way_NN as_IN in_IN INRIA_NNP SIFT1M_NNP :_: the_DT goal_NN is_VBZ to_TO retrieve_VB the_DT 50_CD nearest_JJS neighbors_NNS ,_, according_VBG to_TO Euclidean_JJ distance_NN ,_, of_IN a_DT query_JJ image_NN 's_POS GIST_NN feature_NN vector_NN ._.
5.3_CD Basel_NNP
al._FW ._.
Metric_NNP learning_NN has_VBZ also_RB been_VBN seen_VBN as_IN a_DT special_JJ case_NN of_IN ranking_NN problem_NN ,_, from_IN the_DT view_NN point_NN that_IN good_JJ neighbors_NNS appear_VBP at_IN the_DT top_NN of_IN the_DT list_NN and_CC bad_JJ neighbors_NNS appear_VBP at_IN the_DT bottom_NN ._.
McFee_FW et_FW al._FW =_SYM -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: propose_VBP a_DT structural_JJ SVM_NN learning_NN framework_NN -LRB-_-LRB- figure_NN 1_CD -LRB-_-LRB- b_NN -RRB-_-RRB- -RRB-_-RRB- for_IN learning_VBG the_DT metric_NN where_WRB various_JJ ranking_JJ measures_NNS such_JJ as_IN precision@k,_NNP NDCG_NNP ,_, etc._NN ,_, can_MD be_VB optimized_VBN -LRB-_-LRB- referred_VBN as_IN MLR_NN in_IN Table_NNP 1_CD -RRB-_-RRB- ._.
Chechi_NNP
is_VBZ a_DT set_NN of_IN handwritten_JJ images_NNS of_IN the_DT digits_NNS 0_CD to_TO 9_CD ._.
The_DT images_NNS are_VBP grayscale_NN and_CC of_IN size_NN 28_CD ×_NN 28_CD ._.
MCAT_NN contains_VBZ text_NN documents_NNS that_WDT belong_VBP to_TO a_DT subtree_NN of_IN the_DT Reuters_NNP Corpus_NNP Volume_NNP 1_CD -LRB-_-LRB- RCV1_NN -RRB-_-RRB- dataset_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT document_NN is_VBZ represented_VBN as_IN a_DT bag-of-words_NNS with_IN a_DT vocabulary_NN size_NN of_IN 11429_CD ._.
Only_RB about_RB 0.58_CD %_NN of_IN the_DT word_NN counts_NNS are_VBP nonzero_JJ ,_, so_IN the_DT representation_NN is_VBZ sparse_JJ ._.
Covertype_NN 9_CD -LRB-_-LRB- 3_CD -RRB-_-RRB- is_VBZ a_DT dataset_NN of_IN geospat_NN
hout_JJ explicit_JJ knowledge_NN of_IN the_DT underlying_JJ transformation_NN -RRB-_-RRB- ,_, or_CC the_DT underlying_JJ transformation_NN is_VBZ infinitely_RB i_LS =_JJ 1_CD 14_CD http:\/\/www.gaussianprocess.org\/gpml\/data\/dimensional_NN -LRB-_-LRB- hence_RB ,_, incomputable_JJ -RRB-_-RRB- ._.
He_PRP et_FW al._FW =_SYM -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: propose_VBP a_DT joint_JJ optimization_NN method_NN to_TO optimize_VB the_DT codes_NNS for_IN both_DT preserving_VBG similarity_NN as_RB well_RB as_IN minimizing_VBG search_NN time_NN ._.
The_DT main_JJ drawback_NN of_IN these_DT hashing_VBG approaches_NNS is_VBZ that_IN they_PRP can_MD not_RB be_VB direct_JJ
olume_NN 1_CD -LRB-_-LRB- RCV1_NN -RRB-_-RRB- dataset_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ._.
A_DT document_NN is_VBZ represented_VBN as_IN a_DT bag-of-words_NNS with_IN a_DT vocabulary_NN size_NN of_IN 11429_CD ._.
Only_RB about_RB 0.58_CD %_NN of_IN the_DT word_NN counts_NNS are_VBP nonzero_JJ ,_, so_IN the_DT representation_NN is_VBZ sparse_JJ ._.
Covertype_NN 9_CD =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ a_DT dataset_NN of_IN geospatial_JJ measurements_NNS that_WDT are_VBP used_VBN to_TO predict_VB the_DT forest_NN covertype_NN at_IN various_JJ locations_NNS in_IN the_DT US_NNP ._.
RCV1_NN Subset_NN 10_CD contains_VBZ only_RB those_DT documents_NNS in_IN the_DT RCV1_NN dataset_NN that_WDT do_VBP not_RB have_VB
nobis_NN distance_NN -RRB-_-RRB- ._.
These_DT methods_NNS make_VBP use_NN of_IN additional_JJ information_NN and_CC learn_VB the_DT distance_NN metric_NN by_IN a_DT optimizing_VBG task-specific_JJ objective_NN function_NN ._.
Methods_NNS such_JJ as_IN Neighborhood_NN component_NN analysis_NN -LRB-_-LRB- NCA_NN -RRB-_-RRB- =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_JJ -_: and_CC large_JJ margin_NN nearest_IN neighbor_NN -LRB-_-LRB- LMNN_NN -RRB-_-RRB- -LRB-_-LRB- 22_CD -RRB-_-RRB- -LRB-_-LRB- figure_NN 1_CD -LRB-_-LRB- b_NN -RRB-_-RRB- -RRB-_-RRB- classification_NN learn_VBP the_DT metric_NN using_VBG class_NN label_NN information_NN ,_, keeping_VBG nearest_IN neighbor_NN classification_NN as_IN the_DT goal_NN ._.
Metric_NNP learning_NN has_VBZ als_NNS
rove_NN convergence_NN speed_NN ._.
Such_JJ methods_NNS may_MD help_VB in_IN RankNet_NNP training_NN ,_, but_CC are_VBP unlikely_JJ to_TO be_VB usefulfor_JJ LambdaRank_NN since_IN the_DT actual_JJ objective_NN function_NN is_VBZ implicit_JJ and_CC can_MD not_RB be_VB directly_RB evaluated_VBN ._.
As_IN in_IN =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_JJ -_: ,_, we_PRP maintain_VBP an_DT exponentially_RB decaying_JJ sum_NN of_IN the_DT previous_JJ gradients_NNS which_WDT is_VBZ added_VBN to_TO the_DT current_JJ gradient_NN to_TO compute_VB the_DT weight_NN update_VB ._.
The_DT decay_NN factor_NN is_VBZ set_VBN to_TO 0.8_CD ,_, so_IN the_DT effect_NN of_IN the_DT gradient_NN
ry_NN size_NN of_IN 47236_CD and_CC 101_CD classes_NNS ._.
The_DT representation_NN is_VBZ 0.14_CD %_NN sparse_NN ._.
INRIA_FW SIFT1M_FW 11_CD is_VBZ a_DT web_NN image_NN dataset_NN designed_VBN for_IN evaluating_VBG retrieval_NN algorithms_NNS ._.
It_PRP consists_VBZ of_IN 128-dimensional_JJ SIFT_NN features_VBZ =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_SYM -_: computed_VBN for_IN images_NNS collected_VBN from_IN the_DT web_NN ._.
Given_VBN a_DT query_JJ image_NN 's_POS SIFT_NN feature_NN vector_NN ,_, the_DT relevant_JJ images_NNS to_TO retrieve_VB are_VBP defined_VBN to_TO be_VB its_PRP$ 50_CD nearest_JJS neighbors_NNS ,_, according_VBG to_TO Euclidean_JJ distance_NN ,_, in_IN
vector_NN learning_NN and_CC explicit_JJ optimization_NN of_IN task-specific_JJ performance_NN measure_NN ._.
•_VB It_PRP is_VBZ easy_JJ to_TO adapt_VB the_DT method_NN for_IN different_JJ applications_NNS via_IN choices_NNS of_IN performance_NN measure_NN and_CC ranking_NN ._.
LambdaRank_NN =_SYM -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: can_MD be_VB used_VBN to_TO optimize_VB various_JJ non-smooth_JJ task-specific_JJ performance_NN measures_NNS -LRB-_-LRB- e.g._FW ,_, precision@k_NN and_CC nearest_JJS neighbor_NN classification_NN accuracy_NN -RRB-_-RRB- -LRB-_-LRB- Section_NN 3_CD -RRB-_-RRB- ._.
3_CD In_IN LMNN_NN and_CC MLR_NN ,_, computationally_RB complex_JJ
ison_NN of_IN various_JJ approaches_NNS with_IN respect_NN to_TO our_PRP$ algorithm_NN ._.
neighbors_NNS are_VBP identified_VBN as_IN the_DT points_NNS that_WDT are_VBP within_IN a_DT user_NN specified_VBN Hamming_VBG distance_NN from_IN a_DT given_VBN query_NN ._.
Locality_NN Sensitive_JJ Hashing_NN -LRB-_-LRB- LSH_NN -RRB-_-RRB- =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ a_DT simple_JJ method_NN -LRB-_-LRB- figure_NN 1_CD -LRB-_-LRB- a_DT -RRB-_-RRB- -RRB-_-RRB- in_IN which_WDT bit_NN vector_NN representation_NN for_IN a_DT data_NN point_NN -LRB-_-LRB- object_NN -RRB-_-RRB- is_VBZ obtained_VBN from_IN projecting_VBG the_DT data_NNS vector_NN on_IN several_JJ random_JJ directions_NNS ,_, and_CC converting_VBG the_DT projected_JJ va_NN
ditional_JJ information_NN and_CC learn_VB the_DT distance_NN metric_NN by_IN a_DT optimizing_VBG task-specific_JJ objective_NN function_NN ._.
Methods_NNS such_JJ as_IN Neighborhood_NN component_NN analysis_NN -LRB-_-LRB- NCA_NN -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- and_CC large_JJ margin_NN nearest_IN neighbor_NN -LRB-_-LRB- LMNN_NN -RRB-_-RRB- =_JJ -_: =[_NN 22_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- figure_NN 1_CD -LRB-_-LRB- b_NN -RRB-_-RRB- -RRB-_-RRB- classification_NN learn_VBP the_DT metric_NN using_VBG class_NN label_NN information_NN ,_, keeping_VBG nearest_IN neighbor_NN classification_NN as_IN the_DT goal_NN ._.
Metric_NNP learning_NN has_VBZ also_RB been_VBN seen_VBN as_IN a_DT special_JJ case_NN of_IN ranking_JJ probl_NN
._.
One_CD potential_JJ application_NN of_IN nearest_JJS neighbor_NN regression_NN is_VBZ in_IN Collaborative_NNP Filtering_NNP ._.
Neighborhood_NN based_JJ models_NNS have_VBP been_VBN shown_VBN to_TO be_VB useful_JJ for_IN predicting_VBG the_DT rating_NN a_DT user_NN would_MD give_VB to_TO an_DT item_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, in_IN a_DT user-based_JJ neighborhood_NN model_NN ,_, given_VBN a_DT user-item_JJ pair_NN for_IN which_WDT to_TO predict_VB a_DT rating_NN ,_, a_DT bit_NN vectorbased_JJ representation_NN can_MD be_VB used_VBN to_TO retrieve_VB similar_JJ users_NNS who_WP have_VBP rated_VBN the_DT same_JJ
d_NN before_IN fall_NN under_IN this_DT category_NN ._.
Other_JJ approaches_NNS include_VBP Fisher_NNP 's_POS linear_JJ discriminant_JJ analysis_NN -LRB-_-LRB- FLDA_NN -RRB-_-RRB- ,_, maximally_RB collapsing_VBG metric_JJ learning_NN algorithm_NN -LRB-_-LRB- MCML_NN -RRB-_-RRB- -LRB-_-LRB- 8_CD -RRB-_-RRB- ,_, relevance_NN component_NN analysis_NN -LRB-_-LRB- RCA_NN -RRB-_-RRB- =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: ,_, etc._NN ._.
While_IN FLDA_NN and_CC MCML_NN use_VBP class_NN label_NN information_NN ,_, RCA_NN assumes_VBZ that_IN a_DT set_NN of_IN chunklets_NNS is_VBZ available_JJ ,_, where_WRB each_DT chunklet_NN is_VBZ a_DT set_NN of_IN examples_NNS which_WDT belong_VBP to_TO the_DT same_JJ class_NN -LRB-_-LRB- but_CC ,_, the_DT class_NN inform_VB
resented_VBN as_IN a_DT matrix_NN of_IN size_NN -LRB-_-LRB- number_NN of_IN inputs_NNS -RRB-_-RRB- ×_NN -LRB-_-LRB- number_NN of_IN bits_NNS -RRB-_-RRB- ._.
See_VB section_NN 3_CD for_IN more_JJR details_NNS ._.
Learning_NNP :_: LambdaRank_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- is_VBZ the_DT algorithm_NN we_PRP use_VBP for_IN learning_NN ._.
It_PRP is_VBZ based_VBN on_IN the_DT RankNet_NNP algorithm_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT learns_VBZ a_DT pairwise_JJ ranking_NN function_NN ._.
Given_VBN a_DT triplet_NN -LRB-_-LRB- query_NN ,_, document1_NN ,_, document2_NN -RRB-_-RRB- ,_, the_DT ranking_JJ function_NN computes_VBZ the_DT probability_NN that_IN document_NN 1_CD should_MD be_VB ranked_VBN higher_JJR than_IN document_NN 2_CD for_IN tha_NN
ed_VBN methods_NNS such_JJ as_IN NCA_NN and_CC LMNN_NN discussed_VBN before_IN fall_NN under_IN this_DT category_NN ._.
Other_JJ approaches_NNS include_VBP Fisher_NNP 's_POS linear_JJ discriminant_JJ analysis_NN -LRB-_-LRB- FLDA_NN -RRB-_-RRB- ,_, maximally_RB collapsing_VBG metric_JJ learning_NN algorithm_NN -LRB-_-LRB- MCML_NN -RRB-_-RRB- =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: ,_, relevance_NN component_NN analysis_NN -LRB-_-LRB- RCA_NN -RRB-_-RRB- -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, etc._NN ._.
While_IN FLDA_NN and_CC MCML_NN use_VBP class_NN label_NN information_NN ,_, RCA_NN assumes_VBZ that_IN a_DT set_NN of_IN chunklets_NNS is_VBZ available_JJ ,_, where_WRB each_DT chunklet_NN is_VBZ a_DT set_NN of_IN examples_NNS which_WDT belong_VBP
ch_NN is_VBZ not_RB the_DT case_NN in_IN many_JJ applications_NNS -RRB-_-RRB- ._.
Also_RB ,_, learning_NN is_VBZ computationally_RB expensive_JJ with_IN NCA_NN ,_, LMNN_NN and_CC MLR_NN approaches_NNS 3_CD ._.
Therefore_RB ,_, they_PRP are_VBP not_RB suitable_JJ for_IN very_RB large-scale_JJ problems_NNS ._.
Jain_NNP et_FW al._FW =_SYM -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: propose_VBP a_DT method_NN -LRB-_-LRB- figure_NN 1_CD -LRB-_-LRB- c_NN -RRB-_-RRB- -RRB-_-RRB- that_WDT applies_VBZ LSH_NN on_IN a_DT learned_VBN metric_NN -LRB-_-LRB- referred_VBN as_IN M+LSH_NN in_IN Table_NNP 1_CD -RRB-_-RRB- ._.
However_RB ,_, this_DT method_NN does_VBZ not_RB use_VB task-specific_JJ objective_JJ function_NN for_IN learning_VBG the_DT metric_NN ;_: more_JJR im_NN
tations_NNS ,_, which_WDT in_IN turn_NN results_VBZ in_IN improved_JJ speed_NN and_CC taskspecific_JJ performance_NN ._.
Hence_RB ,_, attempts_NNS have_VBP been_VBN made_VBN to_TO develop_VB better_RBR hashing_VBG methods_NNS ._.
Sophisticated_JJ hashing_VBG methods_NNS such_JJ as_IN Semantic_JJ Hashing_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: and_CC Spectral_JJ Hashing_NN -LRB-_-LRB- 23_CD -RRB-_-RRB- -LRB-_-LRB- figure_NN 1_CD -LRB-_-LRB- d_NN -RRB-_-RRB- -RRB-_-RRB- learn_VBP compact_JJ bit_NN vector_NN representations_NNS -LRB-_-LRB- codes_NNS -RRB-_-RRB- with_IN the_DT desirable_JJ property_NN that_IN similar_JJ objects_NNS have_VBP similar_JJ codes_NNS ._.
In_IN Semantic_NNP Hashing_NNP ,_, each_DT object_NN in_IN the_DT t_NN
tor_NN ,_, the_DT relevant_JJ images_NNS to_TO retrieve_VB are_VBP defined_VBN to_TO be_VB its_PRP$ 50_CD nearest_JJS neighbors_NNS ,_, according_VBG to_TO Euclidean_JJ distance_NN ,_, in_IN the_DT SIFT_NNP feature_NN space_NN ._.
Tiny_NNP Images_NNP Subset_NNP is_VBZ derived_VBN from_IN the_DT Tiny_NNP Images_NNPS dataset_NN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT contains_VBZ 80_CD million_CD images_NNS collected_VBN from_IN the_DT web_NN ._.
Various_JJ text_NN queries_NNS were_VBD given_VBN to_TO popular_JJ image_NN search_NN engines_NNS and_CC the_DT results_NNS were_VBD downloaded_VBN ._.
The_DT subset_NN we_PRP use_VBP here_RB contains_VBZ only_RB the_DT top_NN
ults_NNS in_IN improved_JJ speed_NN and_CC taskspecific_JJ performance_NN ._.
Hence_RB ,_, attempts_NNS have_VBP been_VBN made_VBN to_TO develop_VB better_RBR hashing_VBG methods_NNS ._.
Sophisticated_JJ hashing_VBG methods_NNS such_JJ as_IN Semantic_JJ Hashing_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- and_CC Spectral_JJ Hashing_NN =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_JJ -_: -LRB-_-LRB- figure_NN 1_CD -LRB-_-LRB- d_NN -RRB-_-RRB- -RRB-_-RRB- learn_VBP compact_JJ bit_NN vector_NN representations_NNS -LRB-_-LRB- codes_NNS -RRB-_-RRB- with_IN the_DT desirable_JJ property_NN that_IN similar_JJ objects_NNS have_VBP similar_JJ codes_NNS ._.
In_IN Semantic_NNP Hashing_NNP ,_, each_DT object_NN in_IN the_DT training_NN database_NN is_VBZ repres_NNS
istwise_RB ordering_VBG computed_VBN by_IN the_DT current_JJ ranking_NN function_NN ._.
Optimizing_VBG with_IN the_DT LambdaRank_NN gradient_NN has_VBZ been_VBN shown_VBN empirically_RB to_TO converge_VB to_TO a_DT local_JJ optimum_NN of_IN various_JJ non-smooth_JJ IR_NN evaluation_NN scores_NNS =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Adapting_VBG LambdaRank_NN to_TO learn_VB a_DT bit_NN vector_NN representation_NN requires_VBZ several_JJ modifications_NNS ._.
These_DT are_VBP 1_LS -RRB-_-RRB- the_DT parameterization_NN of_IN the_DT ranking_JJ function_NN ,_, 2_LS -RRB-_-RRB- the_DT procedure_NN for_IN finding_VBG pairwise_JJ swaps_NNS that_IN g_NN
