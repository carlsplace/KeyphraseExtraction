A_DT multi-threaded_JJ PIPELINED_JJ Web_NN server_NN architecture_NN for_IN SMP\/SoC_NN machines_NNS
Design_NN of_IN high_JJ performance_NN Web_NN servers_NNS has_VBZ become_VBN a_DT recent_JJ research_NN thrust_NN to_TO meet_VB the_DT increasing_VBG demand_NN of_IN network-based_JJ services_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP propose_VBP a_DT new_JJ Web_NN server_NN architecture_NN ,_, called_VBN multi-threaded_JJ PIPELINED_JJ Web_NN server_NN ,_, suitable_JJ for_IN Symmetric_JJ Multi-Processor_NN -LRB-_-LRB- SMP_NN -RRB-_-RRB- or_CC System-on-Chip_NN -LRB-_-LRB- SoC_NN -RRB-_-RRB- architectures_NNS ._.
The_DT proposed_VBN PIPELINED_NN model_NN consists_VBZ of_IN multiple_JJ thread_NN pools_NNS ,_, where_WRB each_DT thread_NN pool_NN consists_VBZ of_IN five_CD basic_JJ threads_NNS and_CC two_CD helper_NN threads_NNS ._.
The_DT main_JJ advantages_NNS of_IN the_DT proposed_VBN model_NN are_VBP global_JJ information_NN sharing_NN by_IN the_DT threads_NNS ,_, minimal_JJ synchronization_NN overhead_NN due_JJ to_TO less_JJR number_NN of_IN threads_NNS ,_, and_CC non-blocking_JJ I\/O_NN operations_NNS ,_, possible_JJ with_IN the_DT helper_NN threads_NNS ._.
We_PRP have_VBP conducted_VBN an_DT in-depth_JJ performance_NN analysis_NN of_IN the_DT proposed_VBN server_NN model_NN along_IN with_IN four_CD prior_JJ Web_NN server_NN models_NNS -LRB-_-LRB- Multi-Process_NN -LRB-_-LRB- MP_NN -RRB-_-RRB- ,_, Multi-Thread_NN -LRB-_-LRB- MT_NN -RRB-_-RRB- ,_, Single-Process_NNP Event-Driven_NNP -LRB-_-LRB- SPED_NNP -RRB-_-RRB- and_CC Asynchronous_NNP Multi-Process_NNP Event-Driven_NNP -LRB-_-LRB- AMPED_NNP -RRB-_-RRB- -RRB-_-RRB- via_IN simulation_NN using_VBG six_CD Web_NN server_NN workloads_NNS ._.
The_DT experiments_NNS are_VBP conducted_VBN to_TO investigate_VB the_DT impact_NN of_IN various_JJ factors_NNS such_JJ as_IN the_DT memory_NN size_NN ,_, disk_NN speed_NN and_CC numbers_NNS of_IN clients_NNS ._.
The_DT simulation_NN results_NNS indicate_VBP that_IN the_DT proposed_JJ PIPELINED_JJ Web_NN server_NN architecture_NN shows_VBZ the_DT best_JJS performance_NN across_IN all_DT system_NN and_CC workload_NN parameters_NNS compared_VBN to_TO the_DT MP_NNP ,_, MT_NNP ,_, SPED_NNP and_CC AMPED_NNP models_NNS ._.
Although_IN the_DT MT_NNP and_CC AMPED_NNP models_NNS show_VBP competitive_JJ performance_NN with_IN less_JJR number_NN of_IN processors_NNS ,_, the_DT advantage_NN of_IN the_DT PIPELINED_JJ model_NN becomes_VBZ obvious_JJ as_IN the_DT number_NN of_IN processors_NNS or_CC clients_NNS in_IN an_DT SMP\/SoC_NN machine_NN increases_NNS ._.
The_DT MP_NN model_NN shows_VBZ the_DT worst_JJS performance_NN in_IN most_JJS of_IN the_DT cases_NNS ._.
The_DT results_NNS indicate_VBP that_IN the_DT proposed_VBN server_NN architecture_NN can_MD be_VB used_VBN in_IN future_JJ large-scale_JJ SMP\/SoC_NN machines_NNS to_TO boost_VB system_NN performance_NN ._.
e_LS based_VBN approach_NN attempts_NNS to_TO improve_VB a_DT Web_NN server_NN 's_POS cache_NN hit_NN ratio_NN ,_, and_CC thus_RB ,_, minimize_VBP the_DT disk_NN access_NN latency_NN in_IN satisfying_JJ user_NN requests_NNS ._.
It_PRP has_VBZ been_VBN observed_VBN that_IN by_IN employing_VBG a_DT larger_JJR data_NN cache_NN =_JJ -_: =[_NN 12_CD ,_, 6_CD ,_, 8_CD -RRB-_-RRB- -_: =_JJ -_: and_CC suitable_JJ cache_NN replacement_NN techniques_NNS -LRB-_-LRB- 7_CD -RRB-_-RRB- ,_, server_NN throughput_NN can_MD be_VB significantly_RB improved_VBN ._.
On_IN the_DT other_JJ hand_NN ,_, a_DT hardware_NN scale-up_NN provides_VBZ additional_JJ computing_NN facility_NN by_IN adding_VBG more_JJR processor_NN
e_LS based_VBN approach_NN attempts_NNS to_TO improve_VB a_DT Web_NN server_NN 's_POS cache_NN hit_NN ratio_NN ,_, and_CC thus_RB ,_, minimize_VBP the_DT disk_NN access_NN latency_NN in_IN satisfying_JJ user_NN requests_NNS ._.
It_PRP has_VBZ been_VBN observed_VBN that_IN by_IN employing_VBG a_DT larger_JJR data_NN cache_NN =_JJ -_: =[_NN 12_CD ,_, 6_CD ,_, 8_CD -RRB-_-RRB- -_: =_JJ -_: and_CC suitable_JJ cache_NN replacement_NN techniques_NNS -LRB-_-LRB- 7_CD -RRB-_-RRB- ,_, server_NN throughput_NN can_MD be_VB significantly_RB improved_VBN ._.
On_IN the_DT other_JJ hand_NN ,_, a_DT hardware_NN scale-up_NN provides_VBZ additional_JJ computing_NN facility_NN by_IN adding_VBG more_JJR processor_NN
in_IN deep_JJ sub-micron_JJ technology_NN ,_, SoC_NN architectures_NNS have_VBP become_VBN a_DT reality_NN ,_, and_CC by_IN the_DT end_NN of_IN the_DT decade_NN ,_, SoCs_NNS with_IN billions_NNS of_IN transistors_NNS are_VBP likely_JJ to_TO dominate_VB the_DT high_JJ performance_NN computing_NN landscape_NN =_JJ -_: =[_NN 5_CD ,_, 10_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
With_IN technology_NN scaling_VBG down_RB to_TO 35nm_CD ,_, it_PRP would_MD be_VB possible_JJ to_TO fabricate_VB SoCs_NNS with_IN up_IN to_TO 32\/64_CD processors_NNS ._.
Hence_RB ,_, we_PRP expect_VBP that_IN many_JJ Web_NN servers_NNS will_MD be_VB employed_VBN on_IN a_DT SoC_NN system_NN to_TO provide_VB high-perf_NN
ache_NN hit_VBD ratio_NN ,_, and_CC thus_RB ,_, minimize_VBP the_DT disk_NN access_NN latency_NN in_IN satisfying_JJ user_NN requests_NNS ._.
It_PRP has_VBZ been_VBN observed_VBN that_IN by_IN employing_VBG a_DT larger_JJR data_NN cache_NN -LRB-_-LRB- 12_CD ,_, 6_CD ,_, 8_CD -RRB-_-RRB- and_CC suitable_JJ cache_NN replacement_NN techniques_NNS =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: ,_, server_NN throughput_NN can_MD be_VB significantly_RB improved_VBN ._.
On_IN the_DT other_JJ hand_NN ,_, a_DT hardware_NN scale-up_NN provides_VBZ additional_JJ computing_NN facility_NN by_IN adding_VBG more_JJR processor_NN and_CC memory_NN to_TO a_DT single_JJ system_NN ._.
Finally_RB ,_, the_DT cl_NN
in_IN deep_JJ sub-micron_JJ technology_NN ,_, SoC_NN architectures_NNS have_VBP become_VBN a_DT reality_NN ,_, and_CC by_IN the_DT end_NN of_IN the_DT decade_NN ,_, SoCs_NNS with_IN billions_NNS of_IN transistors_NNS are_VBP likely_JJ to_TO dominate_VB the_DT high_JJ performance_NN computing_NN landscape_NN =_JJ -_: =[_NN 5_CD ,_, 10_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
With_IN technology_NN scaling_VBG down_RB to_TO 35nm_CD ,_, it_PRP would_MD be_VB possible_JJ to_TO fabricate_VB SoCs_NNS with_IN up_IN to_TO 32\/64_CD processors_NNS ._.
Hence_RB ,_, we_PRP expect_VBP that_IN many_JJ Web_NN servers_NNS will_MD be_VB employed_VBN on_IN a_DT SoC_NN system_NN to_TO provide_VB high-perf_NN
e_LS transactions_NNS and_CC distributed_VBN service_NN ,_, provided_VBN through_IN SOAP_NN ,_, mandates_VBZ design_NN of_IN high_JJ performance_NN Web_NN servers_NNS since_IN such_JJ servers_NNS are_VBP anticipated_VBN to_TO be_VB the_DT bottleneck_NN in_IN hosting_VBG networkbased_JJ services_NNS =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Three_CD techniques_NNS have_VBP been_VBN proposed_VBN and_CC adopted_VBN to_TO improve_VB the_DT performance_NN of_IN a_DT Web_NN server_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- ;_: -LRB-_-LRB- i_LS -RRB-_-RRB- software_NN scale-up_NN ,_, -LRB-_-LRB- ii_LS -RRB-_-RRB- hardware_NN scale-up_NN and_CC -LRB-_-LRB- iii_LS -RRB-_-RRB- clusterbased_JJ scale-up_NN ._.
Several_JJ software_NN and_CC har_NN
a_DT cost-effective_JJ solution_NN by_IN utilizing_VBG a_DT cluster_NN of_IN homogeneous_JJ or_CC heterogeneous_JJ nodes_NNS under_IN a_DT single_JJ domain_NN name_NN ._.
Commercial_JJ servers_NNS like_IN Google_NNP and_CC e-Bay_NN have_VBP used_VBN this_DT technique_NN quite_RB effectively_RB =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Although_IN cluster-based_JJ Web_NN servers_NNS seem_VBP a_DT viable_JJ solution_NN from_IN performance_NN ,_, scalability_NN and_CC economic_JJ standpoints_NNS ,_, this_DT is_VBZ certainly_RB not_RB the_DT only_JJ choice_NN ,_, and_CC any_DT application_NN specific_JJ design_NN should_MD ex_FW
irst_RB analyze_VB the_DT memory_NN usage_NN of_IN four_CD server_NN architectures_NNS ;_: Multi-Process_NN -LRB-_-LRB- MP_NN -RRB-_-RRB- -LRB-_-LRB- 18_CD -RRB-_-RRB- ,_, MultiThread_NN -LRB-_-LRB- MT_NN -RRB-_-RRB- -LRB-_-LRB- 18_CD -RRB-_-RRB- ,_, Single-Process_NNP Event-Driven_NNP -LRB-_-LRB- SPED_NNP -RRB-_-RRB- -LRB-_-LRB- 21_CD -RRB-_-RRB- and_CC Asynchronous_NNP Multi-Process_NNP Event-Driven_NNP -LRB-_-LRB- AMPED_NNP -RRB-_-RRB- =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT is_VBZ done_VBN through_IN measuring_VBG the_DT memory_NN requirements_NNS of_IN Flash_NNP -LRB-_-LRB- AMPED_NNP model_NN -RRB-_-RRB- -LRB-_-LRB- 13_CD -RRB-_-RRB- and_CC Apache_NNP -LRB-_-LRB- 18_CD -RRB-_-RRB- Web_NN servers_NNS on_IN a_DT Sun_NNP solaris_NN machine_NN ._.
This_DT analysis_NN is_VBZ then_RB extended_VBN to_TO three_CD other_JJ architectures_NNS -LRB-_-LRB-
we_PRP focus_VBP on_IN two_CD types_NNS of_IN high_JJ performance_NN architectures_NNS that_WDT can_MD be_VB used_VBN in_IN designing_VBG Web_NN servers_NNS ;_: Symmetric_JJ Multi-Processors_NNS -LRB-_-LRB- SMPs_NNS -RRB-_-RRB- and_CC System-on-Chip_NN -LRB-_-LRB- SoC_NN -RRB-_-RRB- architectures_NNS ._.
Recently_RB ,_, a_DT Dual-Core_NNP CPU_NNP =_SYM -_: =[_NN 15_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ released_VBN by_IN Intel_NNP andsAMD_NNP to_TO target_VB the_DT high-performance_JJ server_NN market_NN ._.
Four_CD and_CC Eight_CD core_NN SMPs_NNS are_VBP expected_VBN to_TO be_VB released_VBN soon_RB ._.
In_IN addition_NN ,_, with_IN the_DT advent_NN in_IN deep_JJ sub-micron_JJ technology_NN ,_, SoC_NN a_DT
in_IN deep_JJ sub-micron_JJ technology_NN ,_, SoC_NN architectures_NNS have_VBP become_VBN a_DT reality_NN ,_, and_CC by_IN the_DT end_NN of_IN the_DT decade_NN ,_, SoCs_NNS with_IN billions_NNS of_IN transistors_NNS are_VBP likely_JJ to_TO dominate_VB the_DT high_JJ performance_NN computing_NN landscape_NN =_JJ -_: =[_NN 5_CD ,_, 10_CD ,_, 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
With_IN technology_NN scaling_VBG down_RB to_TO 35nm_CD ,_, it_PRP would_MD be_VB possible_JJ to_TO fabricate_VB SoCs_NNS with_IN up_IN to_TO 32\/64_CD processors_NNS ._.
Hence_RB ,_, we_PRP expect_VBP that_IN many_JJ Web_NN servers_NNS will_MD be_VB employed_VBN on_IN a_DT SoC_NN system_NN to_TO provide_VB high-perf_NN
compute_VB the_DT cache_NN overhead_NN to_TO maintain_VB the_DT cache_NN information_NN in_IN each_DT server_NN architecture_NN in_IN Table_NNP 1_CD ,_, when_WRB system_NN memory_NN size_NN is_VBZ known_VBN ._.
Since_IN we_PRP assume_VBP that_IN the_DT size_NN of_IN an_DT average_JJ Web_NN file_NN is_VBZ 15KBytes_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT number_NN of_IN files_NNS that_WDT can_MD be_VB cached_VBN is_VBZ file_NN entries_NNS =_JJ data_NNS cache_NN size\/15KBytes_NNS ._.
The_DT memory_NN requirement_NN for_IN keeping_VBG the_DT information_NN of_IN these_DT entries_NNS is_VBZ file_NN entries_NNS Ã—_FW 850Bytes_FW ,_, since_IN the_DT average_JJ s_NN
ce_IN Web_NN servers_NNS since_IN such_JJ servers_NNS are_VBP anticipated_VBN to_TO be_VB the_DT bottleneck_NN in_IN hosting_VBG networkbased_JJ services_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Three_CD techniques_NNS have_VBP been_VBN proposed_VBN and_CC adopted_VBN to_TO improve_VB the_DT performance_NN of_IN a_DT Web_NN server_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: ;_: -LRB-_-LRB- i_LS -RRB-_-RRB- software_NN scale-up_NN ,_, -LRB-_-LRB- ii_LS -RRB-_-RRB- hardware_NN scale-up_NN and_CC -LRB-_-LRB- iii_LS -RRB-_-RRB- clusterbased_JJ scale-up_NN ._.
Several_JJ software_NN and_CC hardware_NN scale-up_NN techniques_NNS have_VBP been_VBN proposed_VBN to_TO enhance_VB the_DT performance_NN of_IN single_JJ node_NN servers_NNS ._.
eral_JJ parameters_NNS such_JJ as_IN the_DT number_NN of_IN processors_NNS in_IN the_DT SMP\/SoC_NN system_NN ,_, memory_NN size_NN ,_, and_CC number_NN of_IN clients_NNS with_IN six_CD Web_NN server_NN traces_NNS ;_: Penn_NNP State_NNP CSE_NNP -LRB-_-LRB- 17_CD -RRB-_-RRB- ,_, UC_NN Berkeley_NNP -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, Penn_NNP State_NNP -LRB-_-LRB- 16_CD -RRB-_-RRB- ,_, Clarknet_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: ,_, WorldCup98_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- and_CC NASA_NNP -LRB-_-LRB- 2_CD -RRB-_-RRB- workloads_NNS ._.
The_DT main_JJ conclusions_NNS of_IN this_DT paper_NN are_VBP the_DT following_NN :_: First_JJ ,_, 731_CD our_PRP$ proposed_VBN PIPELINED_JJ Web_NN server_NN architecture_NN shows_VBZ the_DT best_JJS performance_NN across_IN various_JJ envir_NN
