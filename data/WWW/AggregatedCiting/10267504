Learning_NNP consensus_NN opinion_NN :_: mining_NN data_NNS from_IN a_DT labeling_NN game_NN
We_PRP consider_VBP the_DT problem_NN of_IN identifying_VBG the_DT consensus_NN ranking_NN for_IN the_DT results_NNS of_IN a_DT query_NN ,_, given_VBN preferences_NNS among_IN those_DT results_NNS from_IN a_DT set_NN of_IN individual_JJ users_NNS ._.
Once_IN consensus_NN rankings_NNS are_VBP identified_VBN for_IN a_DT set_NN of_IN queries_NNS ,_, these_DT rankings_NNS can_MD serve_VB for_IN both_CC evaluation_NN and_CC training_NN of_IN retrieval_NN and_CC learning_NN systems_NNS ._.
We_PRP present_VBP a_DT novel_JJ approach_NN to_TO collecting_VBG the_DT individual_JJ user_NN preferences_NNS over_IN image-search_JJ results_NNS :_: we_PRP use_VBP a_DT collaborative_JJ game_NN in_IN which_WDT players_NNS are_VBP rewarded_VBN for_IN agreeing_VBG on_IN which_WDT image_NN result_NN is_VBZ best_JJS for_IN a_DT query_NN ._.
Our_PRP$ approach_NN is_VBZ distinct_JJ from_IN other_JJ labeling_NN games_NNS because_IN we_PRP are_VBP able_JJ to_TO elicit_VB directly_RB the_DT preferences_NNS of_IN interest_NN with_IN respect_NN to_TO image_NN queries_NNS extracted_VBN from_IN query_JJ logs_NNS ._.
As_IN a_DT source_NN of_IN relevance_NN judgments_NNS ,_, this_DT data_NN provides_VBZ a_DT useful_JJ complement_NN to_TO click_VB data_NNS ._.
Furthermore_RB ,_, the_DT data_NN is_VBZ free_JJ of_IN positional_JJ biases_NNS and_CC is_VBZ collected_VBN by_IN the_DT game_NN without_IN the_DT risk_NN of_IN frustrating_VBG users_NNS with_IN non-relevant_JJ results_NNS ;_: this_DT risk_NN is_VBZ prevalent_JJ in_IN standard_JJ mechanisms_NNS for_IN debiasing_VBG clicks_NNS ._.
We_PRP describe_VBP data_NNS collected_VBN over_IN 34_CD days_NNS from_IN a_DT deployed_VBN version_NN of_IN this_DT game_NN that_WDT amounts_VBZ to_TO about_IN 18_CD million_CD expressed_VBN preferences_NNS between_IN pairs_NNS ._.
Finally_RB ,_, we_PRP present_VBP several_JJ approaches_NNS to_TO modeling_NN this_DT data_NN in_IN order_NN to_TO extract_VB the_DT consensus_NN rankings_NNS from_IN the_DT preferences_NNS and_CC better_JJR sort_NN the_DT search_NN results_VBZ for_IN targeted_VBN queries_NNS ._.
complicated_JJ models_NNS are_VBP justified_JJ ._.
4.2.2_CD A_NNP Pairwise_NNP Probability_NNP Model_NNP Because_IN we_PRP are_VBP measuring_VBG responses_NNS by_IN humans_NNS ,_, it_PRP is_VBZ natural_JJ to_TO look_VB to_TO psychometric_JJ theory_NN for_IN insights_NNS into_IN this_DT area_NN ._.
Thurstone_NN =_JJ -_: =[_NN 16_CD ,_, 17_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: formulated_VBD a_DT general_JJ law_NN of_IN comparative_JJ judgment_NN that_WDT hypothesizes_VBZ a_DT relationship_NN of_IN the_DT human_JJ ability_NN -LRB-_-LRB- which_WDT has_VBZ been_VBN repeatedly_RB born_VBN out_RP in_IN empirical_JJ observations_NNS -RRB-_-RRB- to_TO make_VB pairwise_JJ comparisons_NNS betw_VBP
complicated_JJ models_NNS are_VBP justified_JJ ._.
4.2.2_CD A_NNP Pairwise_NNP Probability_NNP Model_NNP Because_IN we_PRP are_VBP measuring_VBG responses_NNS by_IN humans_NNS ,_, it_PRP is_VBZ natural_JJ to_TO look_VB to_TO psychometric_JJ theory_NN for_IN insights_NNS into_IN this_DT area_NN ._.
Thurstone_NN =_JJ -_: =[_NN 16_CD ,_, 17_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: formulated_VBD a_DT general_JJ law_NN of_IN comparative_JJ judgment_NN that_WDT hypothesizes_VBZ a_DT relationship_NN of_IN the_DT human_JJ ability_NN -LRB-_-LRB- which_WDT has_VBZ been_VBN repeatedly_RB born_VBN out_RP in_IN empirical_JJ observations_NNS -RRB-_-RRB- to_TO make_VB pairwise_JJ comparisons_NNS betw_VBP
complicated_JJ models_NNS are_VBP justified_JJ ._.
4.2.2_CD A_NNP Pairwise_NNP Probability_NNP Model_NNP Because_IN we_PRP are_VBP measuring_VBG responses_NNS by_IN humans_NNS ,_, it_PRP is_VBZ natural_JJ to_TO look_VB to_TO psychometric_JJ theory_NN for_IN insights_NNS into_IN this_DT area_NN ._.
Thurstone_NN =_JJ -_: =[_NN 16_CD ,_, 17_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: formulated_VBD a_DT general_JJ law_NN of_IN comparative_JJ judgment_NN that_WDT hypothesizes_VBZ a_DT relationship_NN of_IN the_DT human_JJ ability_NN -LRB-_-LRB- which_WDT has_VBZ been_VBN repeatedly_RB born_VBN out_RP in_IN empirical_JJ observations_NNS -RRB-_-RRB- to_TO make_VB pairwise_JJ comparisons_NNS betw_VBP
s_NN in_IN a_DT multiclass_JJ classification_NN problem_NN -RRB-_-RRB- into_IN a_DT series_NN of_IN binary_JJ classification_NN tasks_NNS -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
The_DT primary_JJ issue_NN that_WDT concerns_VBZ us_PRP here_RB ,_, however_RB ,_, is_VBZ one_CD of_IN instance-preference_NN ranking_NN ._.
Chu_NN and_CC Ghahramani_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: propose_VBP a_DT Gaussian-process_JJ model_NN applicable_JJ to_TO both_CC instance_NN and_CC label_NN preference_NN learning_NN ._.
The_DT model_NN is_VBZ most_RBS similar_JJ to_TO the_DT Go_NNP model_NN we_PRP present_VBP but_CC does_VBZ not_RB have_VB some_DT of_IN the_DT flexibility_NN to_TO model_NN pla_NN
for_IN the_DT purpose_NN of_IN collecting_VBG data_NNS ._.
Arguably_RB the_DT most_RBS successful_JJ such_JJ game_NN is_VBZ the_DT ESP_NNP Game_NNP -LRB-_-LRB- 19_CD -RRB-_-RRB- ,_, where_WRB as_IN a_DT result_NN of_IN game_NN play_NN ,_, participants_NNS produce_VBP descriptions_NNS of_IN images_NNS ._.
Others_NNS include_VBP Peekaboom_NN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: ,_, where_WRB the_DT players_NNS produce_VBP data_NNS about_IN where_WRB objects_NNS are_VBP located_JJ in_IN an_DT image_NN ,_, and_CC TagATune_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- where_WRB players_NNS produce_VBP descriptions_NNS of_IN sounds_NNS and_CC music_NN ._.
The_DT image-description_JJ data_NNS produced_VBN by_IN the_DT ESP_NNP g_NN
s_NN ,_, what_WDT ranking_NN of_IN the_DT retrieved_VBN set_NN would_MD best_RB satisfy_VB all_DT users_NNS ?_.
While_IN the_DT standard_JJ approach_NN to_TO ranking_NN has_VBZ been_VBN to_TO rank_VB items_NNS according_VBG to_TO their_PRP$ relevance_NN -LRB-_-LRB- 14_CD -RRB-_-RRB- ,_, and_CC in_IN particular_JJ topical_JJ relevance_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_JJ -_: ,_, an_DT item_NN may_MD be_VB preferred_VBN by_IN a_DT user_NN based_VBN on_IN a_DT variety_NN of_IN other_JJ characteristics_NNS including_VBG quality_NN ,_, authoritativeness_NN ,_, and_CC readability_NN ;_: these_DT characteristics_NNS may_MD be_VB seen_VBN as_IN defining_VBG a_DT broader_JJR notion_NN o_NN
potentially_RB scaled_VBN down_RP -RRB-_-RRB- ._.
Furthermore_RB ,_, if_IN the_DT designers_NNS of_IN a_DT ranking_JJ system_NN experiment_NN with_IN the_DT live_JJ system_NN by_IN -LRB-_-LRB- e.g._FW -RRB-_-RRB- swapping_VBG items_NNS or_CC placing_VBG potentially_RB non-relevant_JJ results_NNS in_IN the_DT top_NN of_IN the_DT list_NN =_JJ -_: =[_NN 12_CD ,_, 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, there_EX is_VBZ a_DT risk_NN of_IN frustrating_VBG the_DT user_NN and_CC prompting_VBG him_PRP to_TO switch_VB search_NN engines_NNS ._.
In_IN this_DT work_NN ,_, we_PRP attempt_VBP to_TO solve_VB the_DT data-acquisition_NN problem_NN in_IN the_DT domain_NN of_IN image_NN search_NN with_IN a_DT social_JJ labelin_NN
._.
-LRB-_-LRB- 2_LS -RRB-_-RRB- address_NN how_WRB to_TO infer_VB a_DT ranking_NN given_VBN only_RB a_DT linear_JJ number_NN of_IN preferences_NNS from_IN a_DT single_JJ assessor_NN but_CC do_VBP not_RB address_VB how_WRB to_TO use_VB preferences_NNS across_IN a_DT population_NN of_IN users_NNS ._.
Fürnkranz_NN and_CC Hüllermeier_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_SYM -_: present_VB a_DT study_NN on_IN breaking_JJ label_NN preference_NN ranking_NN -LRB-_-LRB- e.g._FW ,_, predicting_VBG order_NN of_IN preferred_JJ classes_NNS in_IN a_DT multiclass_JJ classification_NN problem_NN -RRB-_-RRB- into_IN a_DT series_NN of_IN binary_JJ classification_NN tasks_NNS -LRB-_-LRB- 7_CD -RRB-_-RRB- ._.
The_DT primary_NN
derstanding_VBG of_IN whether_IN the_DT conditional_JJ model_NN is_VBZ needed_VBN to_TO gain_VB the_DT majority_NN of_IN the_DT predictive_JJ power_NN ._.
4.2.3_CD Go_NNP Model_NNP The_DT final_JJ model_NN was_VBD first_RB applied_VBN to_TO learning_VBG to_TO predict_VB moves_NNS in_IN the_DT board_NN game_NN Go_VBP =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_JJ -_: and_CC is_VBZ related_VBN in_IN some_DT aspects_NNS to_TO the_DT TrueSkill_NNP TM_NNP model_NN used_VBN to_TO rank_VB and_CC match_VB players_NNS in_IN online_NN gaming_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
The_DT Go_NNP model_NN is_VBZ a_DT Bayesian_JJ system_NN with_IN conditional_JJ online_NN updates_NNS that_WDT can_MD be_VB understood_VBN
evant_JJ items_NNS out_IN of_IN a_DT large_JJ number_NN of_IN matching_JJ items_NNS -RRB-_-RRB- ._.
While_IN obtaining_VBG absolute_JJ relevance_NN judgments_NNS over_IN a_DT particular_JJ image\/query_NN pair_NN may_MD seem_VB like_IN a_DT better_JJR way_NN to_TO obtain_VB judgments_NNS ,_, Carterette_NNP et_FW al._FW =_SYM -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: demonstrate_VBP that_IN absolute_JJ judgments_NNS are_VBP less_RBR reliable_JJ in_IN terms_NNS of_IN agreement_NN with_IN other_JJ assessors_NNS than_IN pairwise_JJ preferences_NNS ,_, i.e._FW ,_, relative_JJ comparisons_NNS between_IN two_CD items_NNS ._.
In_IN Section_NNP 4.2_CD ,_, we_PRP discuss_VBP se_FW
is_VBZ a_DT risk_NN of_IN frustrating_VBG the_DT user_NN and_CC prompting_VBG him_PRP to_TO switch_VB search_NN engines_NNS ._.
In_IN this_DT work_NN ,_, we_PRP attempt_VBP to_TO solve_VB the_DT data-acquisition_NN problem_NN in_IN the_DT domain_NN of_IN image_NN search_NN with_IN a_DT social_JJ labeling_NN game_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT game_NN ,_, which_WDT we_PRP describe_VBP in_IN detail_NN in_IN Section_NN 3.1_CD ,_, pairs_NNS two_CD participants_NNS on_IN the_DT internet_NN who_WP are_VBP shown_VBN asequence_NN of_IN queries_NNS and_CC corresponding_JJ sets_NNS of_IN image_NN results_NNS ;_: they_PRP are_VBP both_DT asked_VBD to_TO choos_NNS
r_NN training_NN and_CC evaluation_NN purposes_NNS ._.
That_DT is_VBZ ,_, what_WDT ranking_NN of_IN the_DT retrieved_VBN set_NN would_MD best_RB satisfy_VB all_DT users_NNS ?_.
While_IN the_DT standard_JJ approach_NN to_TO ranking_NN has_VBZ been_VBN to_TO rank_VB items_NNS according_VBG to_TO their_PRP$ relevance_NN =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC in_IN particular_JJ topical_JJ relevance_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ,_, an_DT item_NN may_MD be_VB preferred_VBN by_IN a_DT user_NN based_VBN on_IN a_DT variety_NN of_IN other_JJ characteristics_NNS including_VBG quality_NN ,_, authoritativeness_NN ,_, and_CC readability_NN ;_: these_DT characteristics_NNS m_NN
to_TO consider_VB averaging_VBG the_DT preferences_NNS of_IN the_DT users_NNS in_IN the_DT training_NN set_NN and_CC then_RB extracting_VBG the_DT optimal_JJ ranking_NN for_IN the_DT averaged_VBN preferences_NNS to_TO predict_VB on_IN the_DT testing_NN set_NN ._.
Cohen_NNP ,_, Schapire_NNP ,_, and_CC Singer_NNP =_SYM -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: demonstrated_VBD that_IN the_DT problem_NN of_IN extracting_VBG the_DT optimal_JJ ranking_NN is_VBZ NP-complete_JJ ,_, and_CC whereas_IN they_PRP provide_VBP useful_JJ approximation_NN algorithms_NNS for_IN this_DT ,_, we_PRP are_VBP more_RBR focused_JJ on_IN the_DT second_JJ question_NN of_IN how_WRB we_PRP
setting_VBG ,_, we_PRP do_VBP not_RB ask_VB directly_RB for_IN rankings_NNS because_IN the_DT increased_VBN complexity_NN in_IN the_DT task_NN both_DT increases_NNS noise_NN in_IN response_NN and_CC interferes_VBZ with_IN the_DT fast-paced_JJ excitement_NN of_IN the_DT game_NN ._.
Finally_RB ,_, Joachims_NN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: proposes_VBZ ranking_JJ SVMs_NNS for_IN preference_NN learning_NN and_CC applies_VBZ them_PRP to_TO preference_NN learning_NN using_VBG click_VB data_NNS ._.
Our_PRP$ work_NN is_VBZ most_RBS similar_JJ in_IN flavor_NN to_TO this_DT ,_, but_CC we_PRP deviate_VBP in_IN both_CC the_DT source_NN of_IN our_PRP$ data_NNS and_CC t_NN
of_IN each_DT quantity_NN involved_VBN ._.
Under_IN certain_JJ assumptions_NNS ,_, and_CC using_VBG the_DT logistic_JJ function_NN as_IN the_DT underlying_JJ distribution_NN ,_, this_DT can_MD be_VB used_VBN to_TO derive_VB the_DT Bradley-TerryLuce_NNP -LRB-_-LRB- BTL_NNP -RRB-_-RRB- pairwise_JJ comparison_NN model_NN =_JJ -_: =[_NN 1_CD ,_, 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN the_DT BTL_NN model_NN ,_, assuming_VBG a_DT set_NN of_IN location_NN parameters_NNS si_NN -LRB-_-LRB- in_IN our_PRP$ case_NN ,_, ``_`` relevance_NN score_NN ''_'' parameters_NNS -RRB-_-RRB- ,_, the_DT probability_NN of_IN selecting_VBG one_CD item_NN as_IN being_VBG greater_JJR -LRB-_-LRB- ``_`` more_RBR relevant_JJ ''_'' -RRB-_-RRB- than_IN another_DT is_VBZ modele_NN
Model_NNP The_DT final_JJ model_NN was_VBD first_RB applied_VBN to_TO learning_VBG to_TO predict_VB moves_NNS in_IN the_DT board_NN game_NN Go_NNP -LRB-_-LRB- 15_CD -RRB-_-RRB- and_CC is_VBZ related_VBN in_IN some_DT aspects_NNS to_TO the_DT TrueSkill_NNP TM_NNP model_NN used_VBN to_TO rank_VB and_CC match_VB players_NNS in_IN online_NN gaming_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT Go_NNP model_NN is_VBZ a_DT Bayesian_JJ system_NN with_IN conditional_JJ online_NN updates_NNS that_WDT can_MD be_VB understood_VBN as_IN a_DT general_JJ preference_NN learning_NN algorithm_NN which_WDT learns_VBZ to_TO predict_VB when_WRB the_DT winning_JJ item_NN -LRB-_-LRB- originally_RB which_WDT Go_VBP
potentially_RB scaled_VBN down_RP -RRB-_-RRB- ._.
Furthermore_RB ,_, if_IN the_DT designers_NNS of_IN a_DT ranking_JJ system_NN experiment_NN with_IN the_DT live_JJ system_NN by_IN -LRB-_-LRB- e.g._FW -RRB-_-RRB- swapping_VBG items_NNS or_CC placing_VBG potentially_RB non-relevant_JJ results_NNS in_IN the_DT top_NN of_IN the_DT list_NN =_JJ -_: =[_NN 12_CD ,_, 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, there_EX is_VBZ a_DT risk_NN of_IN frustrating_VBG the_DT user_NN and_CC prompting_VBG him_PRP to_TO switch_VB search_NN engines_NNS ._.
In_IN this_DT work_NN ,_, we_PRP attempt_VBP to_TO solve_VB the_DT data-acquisition_NN problem_NN in_IN the_DT domain_NN of_IN image_NN search_NN with_IN a_DT social_JJ labelin_NN
are_VBP more_RBR focused_JJ on_IN the_DT second_JJ question_NN of_IN how_WRB well_RB this_DT generalizes_VBZ to_TO the_DT full_JJ population_NN ._.
Similarly_RB ,_, as_IN alternate_JJ models_NNS to_TO those_DT presented_VBN here_RB ,_, we_PRP could_MD consider_VB this_DT a_DT task_NN of_IN rank_NN aggregation_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_JJ -_: and_CC apply_VB rank_JJ aggregation_NN methods_NNS to_TO extract_VB the_DT consensus_NN ranking_NN ._.
Whereas_IN a_DT number_NN of_IN these_DT approaches_NNS would_MD require_VB rankings_NNS from_IN users_NNS instead_RB of_IN preferences_NNS ,_, these_DT rankings_NNS could_MD easily_RB be_VB extr_VBN
-RRB-_-RRB- ,_, where_WRB as_IN a_DT result_NN of_IN game_NN play_NN ,_, participants_NNS produce_VBP descriptions_NNS of_IN images_NNS ._.
Others_NNS include_VBP Peekaboom_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, where_WRB the_DT players_NNS produce_VBP data_NNS about_IN where_WRB objects_NNS are_VBP located_JJ in_IN an_DT image_NN ,_, and_CC TagATune_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: where_WRB players_NNS produce_VBP descriptions_NNS of_IN sounds_NNS and_CC music_NN ._.
The_DT image-description_JJ data_NNS produced_VBN by_IN the_DT ESP_NNP game_NN could_MD in_IN principle_NN be_VB used_VBN to_TO help_VB infer_VB ranking_JJ quality_NN ;_: for_IN example_NN ,_, if_IN players_NNS annotate_VBP
