Enhancing_NN diversity_NN ,_, coverage_NN and_CC balance_NN for_IN summarization_NN through_IN structure_NN learning_VBG
Document_NNP summarization_NN plays_VBZ an_DT increasingly_RB important_JJ role_NN with_IN the_DT exponential_JJ growth_NN of_IN documents_NNS on_IN the_DT Web_NN ._.
Many_JJ supervised_JJ and_CC unsupervised_JJ approaches_NNS have_VBP been_VBN proposed_VBN to_TO generate_VB summaries_NNS from_IN documents_NNS ._.
However_RB ,_, these_DT approaches_NNS seldom_RB simultaneously_RB consider_VB summary_NN diversity_NN ,_, coverage_NN ,_, and_CC balance_NN issues_NNS which_WDT to_TO a_DT large_JJ extent_NN determine_VBD the_DT quality_NN of_IN summaries_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP consider_VBP extract-based_JJ summarization_NN emphasizing_VBG the_DT following_JJ three_CD requirements_NNS :_: 1_LS -RRB-_-RRB- diversity_NN in_IN summarization_NN ,_, which_WDT seeks_VBZ to_TO reduce_VB redundancy_NN among_IN sentences_NNS in_IN the_DT summary_NN ;_: 2_LS -RRB-_-RRB- sufficient_JJ coverage_NN ,_, which_WDT focuses_VBZ on_IN avoiding_VBG the_DT loss_NN of_IN the_DT document_NN 's_POS main_JJ information_NN when_WRB generating_VBG the_DT summary_NN ;_: and_CC 3_LS -RRB-_-RRB- balance_NN ,_, which_WDT demands_VBZ that_IN different_JJ aspects_NNS of_IN the_DT document_NN need_VBP to_TO have_VB about_IN the_DT same_JJ relative_JJ importance_NN in_IN the_DT summary_NN ._.
We_PRP formulate_VBP the_DT extract-based_JJ summarization_NN problem_NN as_IN learning_VBG a_DT mapping_NN from_IN a_DT set_NN of_IN sentences_NNS of_IN a_DT given_VBN document_NN to_TO a_DT subset_NN of_IN the_DT sentences_NNS that_WDT satisfies_VBZ the_DT above_JJ three_CD requirements_NNS ._.
The_DT mapping_NN is_VBZ learned_VBN by_IN incorporating_VBG several_JJ constraints_NNS in_IN a_DT structure_NN learning_NN framework_NN ,_, and_CC we_PRP explore_VBP the_DT graph_NN structure_NN of_IN the_DT output_NN variables_NNS and_CC employ_VB structural_JJ SVM_NN for_IN solving_VBG the_DT resulted_VBN optimization_NN problem_NN ._.
Experiments_NNS on_IN the_DT DUC2001_NN data_NN sets_NNS demonstrate_VBP significant_JJ performance_NN improvements_NNS in_IN terms_NNS of_IN F1_NN and_CC ROUGE_NN metrics_NNS ._.
iversity_NN ,_, coverage_NN and_CC balance_NN in_IN terms_NNS of_IN subtopics_NNS ._.
4.1_CD Constraints_NNS Based_VBN on_IN Subtopic_NNP Set_NNP Documents_NNS tend_VBP to_TO contain_VB several_JJ subtopics_NNS ,_, and_CC each_DT subtopic_NN can_MD be_VB represented_VBN by_IN a_DT cluster_NN of_IN sentences_NNS =_JJ -_: =[_NN 11_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Our_PRP$ constraints_NNS are_VBP based_VBN on_IN this_DT notion_NN of_IN subtopics_NNS ._.
One_CD important_JJ thing_NN to_TO notice_NN is_VBZ that_IN the_DT structure_NN of_IN subtopics_NNS of_IN documents_NNS are_VBP only_RB used_VBN in_IN the_DT training_NN process_NN through_IN additional_JJ constrai_NNS
ith_JJ other_JJ approaches_NNS ._.
Many_JJ unsupervised_JJ methods_NNS also_RB contribute_VBP greatly_RB to_TO document_VB summarization_NN ._.
Zha_NN in_IN -LRB-_-LRB- 32_CD -RRB-_-RRB- proposed_VBD a_DT mutual_JJ reinforcement_NN principle_NN for_IN sentence_NN extraction_NN using_VBG the_DT idea_NN of_IN HITS_NN =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Several_JJ related_JJ methods_NNS such_JJ as_IN TextRank_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ,_, LexPageRank_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- and_CC CollabSum_NN -LRB-_-LRB- 30_CD -RRB-_-RRB- gain_NN remarkable_JJ performance_NN also_RB by_IN exploring_VBG methodologies_NNS used_VBN in_IN PageRank_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- and_CC HITS_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
These_DT methods_NNS mostly_RB
iversity_NN ,_, coverage_NN and_CC balance_NN in_IN terms_NNS of_IN subtopics_NNS ._.
4.1_CD Constraints_NNS Based_VBN on_IN Subtopic_NNP Set_NNP Documents_NNS tend_VBP to_TO contain_VB several_JJ subtopics_NNS ,_, and_CC each_DT subtopic_NN can_MD be_VB represented_VBN by_IN a_DT cluster_NN of_IN sentences_NNS =_JJ -_: =[_NN 11_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Our_PRP$ constraints_NNS are_VBP based_VBN on_IN this_DT notion_NN of_IN subtopics_NNS ._.
One_CD important_JJ thing_NN to_TO notice_NN is_VBZ that_IN the_DT structure_NN of_IN subtopics_NNS of_IN documents_NNS are_VBP only_RB used_VBN in_IN the_DT training_NN process_NN through_IN additional_JJ constrai_NNS
forms_VBZ a_DT path_NN in_IN the_DT independence_NN graph_NN ._.
The_DT algorithm_NN ends_VBZ with_IN an_DT extracted_VBN sentence_NN set_NN of_IN size_NN k._NNP This_NNP algorithm_NN has_VBZ the_DT same_JJ approximation_NN bound_VBD as_IN the_DT greedy_JJ algorithm_NN proposed_VBN by_IN Khuller_NNP et_FW al._FW =_SYM -_: =[_NN 14_CD -RRB-_-RRB- -_: =_SYM -_: to_TO solve_VB the_DT budgeted_VBN maximum_NN coverage_NN problem_NN ,_, that_WDT is_VBZ to_TO say_VB ,_, a_DT -LRB-_-LRB- 1_CD −_NN 1_CD -RRB-_-RRB- -_: approximation_NN bound_VBD ._.
So_RB e_LS Algorithm_NN 1_CD has_VBZ a_DT polynomial_JJ time_NN complexity_NN overall_NN ._.
or_CC 5.3_CD Making_VBG Prediction_NN According_VBG to_TO -LRB-_-LRB- 1_LS -RRB-_-RRB- an_DT
ed_VBN -LRB-_-LRB- 26_CD -RRB-_-RRB- ._.
Abstract-based_JJ summarization_NN can_MD be_VB seen_VBN as_IN a_DT reproduction_NN of_IN the_DT original_JJ document_NN in_IN a_DT new_JJ way_NN ,_, while_IN extract-based_JJ summarization_NN focuses_VBZ on_IN extracting_VBG sentences_NNS from_IN the_DT original_JJ document_NN =_JJ -_: =[_NN 13_CD ,_, 16_CD ,_, 17_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, we_PRP consider_VBP generic_JJ extractbased_JJ summarization_NN of_IN a_DT single_JJ document_NN ._.
Several_JJ learning-based_JJ methods_NNS have_VBP been_VBN proposed_VBN for_IN extract-based_JJ summarization_NN ._.
They_PRP usually_RB utilize_VBP a_DT set_NN of_IN f_SYM
ntences_NNS with_IN already_RB extracted_VBN highly_RB ranked_VBN sentences_NNS ._.
Goldstein_NNP et_FW al._FW consider_VB this_DT redundancy_NN issue_NN by_IN employing_VBG a_DT metric_NN for_IN reducing_VBG redundancy_NN and_CC maximizing_VBG diversity_NN in_IN the_DT selected_VBN passages_NNS =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
An_DT earlier_JJR work_NN by_IN Carbonell_NNP and_CC Goldstein_NNP -LRB-_-LRB- 3_LS -RRB-_-RRB- uses_VBZ the_DT idea_NN of_IN maximum_NN marginal_JJ relevance_NN for_IN document_NN reordering_NN ._.
In_IN fact_NN ,_, most_RBS supervised_JJ methods_NNS which_WDT claim_VBP to_TO deal_VB with_IN the_DT diversity_NN issue_NN foll_NN
tences_NNS ._.
Goldstein_NNP et_FW al._FW consider_VB this_DT redundancy_NN issue_NN by_IN employing_VBG a_DT metric_NN for_IN reducing_VBG redundancy_NN and_CC maximizing_VBG diversity_NN in_IN the_DT selected_VBN passages_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
An_DT earlier_JJR work_NN by_IN Carbonell_NNP and_CC Goldstein_NNP =_SYM -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: uses_VBZ the_DT idea_NN of_IN maximum_NN marginal_JJ relevance_NN for_IN document_NN reordering_NN ._.
In_IN fact_NN ,_, most_RBS supervised_JJ methods_NNS which_WDT claim_VBP to_TO deal_VB with_IN the_DT diversity_NN issue_NN follows_VBZ similar_JJ approaches_NNS by_IN using_VBG a_DT pre-defined_JJ fi_NN
ed_VBN -LRB-_-LRB- 26_CD -RRB-_-RRB- ._.
Abstract-based_JJ summarization_NN can_MD be_VB seen_VBN as_IN a_DT reproduction_NN of_IN the_DT original_JJ document_NN in_IN a_DT new_JJ way_NN ,_, while_IN extract-based_JJ summarization_NN focuses_VBZ on_IN extracting_VBG sentences_NNS from_IN the_DT original_JJ document_NN =_JJ -_: =[_NN 13_CD ,_, 16_CD ,_, 17_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, we_PRP consider_VBP generic_JJ extractbased_JJ summarization_NN of_IN a_DT single_JJ document_NN ._.
Several_JJ learning-based_JJ methods_NNS have_VBP been_VBN proposed_VBN for_IN extract-based_JJ summarization_NN ._.
They_PRP usually_RB utilize_VBP a_DT set_NN of_IN f_SYM
es_NNS as_IN the_DT summary_NN ._.
LSA_NN :_: We_PRP identify_VBP semantically_RB important_JJ sentences_NNS using_VBG the_DT Latent_JJ Semantic_JJ Analysis_NN technique_NN and_CC select_VB the_DT k_NN most_RBS important_JJ sentences_NNS as_IN the_DT summary_NN ._.
HITS_NNS :_: One_CD of_IN the_DT Mihalcea_NNP 's_POS =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: algorithms_NNS based_VBN on_IN the_DT authority_NN score_NN of_IN HITS_NN on_IN the_DT directed_JJ backward_RB graph_NN ._.
The_DT sentences_NNS with_IN the_DT highest_JJS authority_NN score_NN are_VBP selected_VBN in_IN the_DT summary_NN generation_NN ._.
The_DT results_NNS of_IN the_DT baselines_NNS '_POS pe_NN
eneric_JJ text_NN summarization_NN ,_, web_NN document_NN summarization_NN usually_RB explore_VBP more_JJR data_NNS sources_NNS ,_, such_JJ as_IN clickthrough_JJ data_NNS ,_, metadata_NN ,_, or_CC hyperlinks_NNS ._.
Summarization_NN is_VBZ also_RB used_VBN for_IN web_NN document_NN classification_NN =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC particular_JJ for_IN providing_VBG the_DT snippets_NNS for_IN search_NN results_NNS ._.
The_DT Diversity_NNP issue_NN has_VBZ be_VB researched_VBN in_IN many_JJ areas_NNS other_JJ than_IN summarization_NN ._.
From_IN the_DT point_NN of_IN view_NN of_IN searching_VBG for_IN diversified_JJ result_NN
use_NN of_IN the_DT information_NN contained_VBN in_IN training_NN data_NNS to_TO enforce_VB the_DT coverage_NN ratio_NN of_IN the_DT summarization_NN ._.
We_PRP also_RB mention_VBP that_IN summarization_NN has_VBZ always_RB had_VBD a_DT wide_JJ range_NN of_IN applications_NNS for_IN web_NN documents_NNS =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Compared_VBN with_IN generic_JJ text_NN summarization_NN ,_, web_NN document_NN summarization_NN usually_RB explore_VBP more_JJR data_NNS sources_NNS ,_, such_JJ as_IN clickthrough_JJ data_NNS ,_, metadata_NN ,_, or_CC hyperlinks_NNS ._.
Summarization_NN is_VBZ also_RB used_VBN for_IN web_NN documen_NN
given_VBN training_NN set_NN -LCB-_-LRB- -LRB-_-LRB- x_NN -LRB-_-LRB- i_LS -RRB-_-RRB- ,_, y_NN -LRB-_-LRB- i_LS -RRB-_-RRB- -RRB-_-RRB- |_FW i_FW =_JJ 1_CD ,_, ·_FW ·_FW ·_NN ,_, n_NN -RCB-_-RRB- ,_, structural_JJ SVM_NN is_VBZ employed_VBN to_TO learn_VB a_DT weight_NN vector_NN w_NN for_IN the_DT discriminant_JJ function_NN F_NN -LRB-_-LRB- x_NN ,_, y_NN -RRB-_-RRB- through_IN the_DT following_JJ quadratic_JJ programing_NN problem_NN =_JJ -_: =[_NN 8_CD ,_, 28_CD ,_, 31_CD -RRB-_-RRB- -_: =_JJ -_: :_: Optimization_NNP Problem_NNP 1_CD ._.
-LRB-_-LRB- Structural_JJ SVM_NN -RRB-_-RRB- subjected_VBN to_TO :_: Track_NNP :_: Data_NNP Mining_NNP \/_: Session_NN :_: Text_NNP Mining_NNP 1_CD min_NN w_NN ,_, ξ_FW ≥_FW 0_CD 2_CD ‖_CD w_NN ‖_NN 2_CD +_CC c_NN n_NN ∀_FW i_FW ,_, ∀_FW y_FW ∈_FW Y_NN \_FW y_FW -LRB-_-LRB- i_LS -RRB-_-RRB- ,_, ξi_FW ≥_FW 0_CD ,_, n_NN ∑_FW ξi_FW ,_, -LRB-_-LRB- 4_CD -RRB-_-RRB- i_LS =_JJ 1_CD w_NN T_NN Ψ_NN -LRB-_-LRB- x_NN -LRB-_-LRB- i_LS -RRB-_-RRB- ,_, y_NN -LRB-_-LRB- i_LS -RRB-_-RRB- -RRB-_-RRB- ≥_FW w_FW T_NN Ψ_NN -LRB-_-LRB- x_NN -LRB-_-LRB-
also_RB contribute_VBP greatly_RB to_TO document_VB summarization_NN ._.
Zha_NN in_IN -LRB-_-LRB- 32_CD -RRB-_-RRB- proposed_VBD a_DT mutual_JJ reinforcement_NN principle_NN for_IN sentence_NN extraction_NN using_VBG the_DT idea_NN of_IN HITS_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
Several_JJ related_JJ methods_NNS such_JJ as_IN TextRank_NN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_JJ -_: ,_, LexPageRank_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- and_CC CollabSum_NN -LRB-_-LRB- 30_CD -RRB-_-RRB- gain_NN remarkable_JJ performance_NN also_RB by_IN exploring_VBG methodologies_NNS used_VBN in_IN PageRank_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- and_CC HITS_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
These_DT methods_NNS mostly_RB focus_VB on_IN the_DT dependence_NN ,_, for_IN instance_NN ,_, similar_JJ
ed_VBN -LRB-_-LRB- 26_CD -RRB-_-RRB- ._.
Abstract-based_JJ summarization_NN can_MD be_VB seen_VBN as_IN a_DT reproduction_NN of_IN the_DT original_JJ document_NN in_IN a_DT new_JJ way_NN ,_, while_IN extract-based_JJ summarization_NN focuses_VBZ on_IN extracting_VBG sentences_NNS from_IN the_DT original_JJ document_NN =_JJ -_: =[_NN 13_CD ,_, 16_CD ,_, 17_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN ,_, we_PRP consider_VBP generic_JJ extractbased_JJ summarization_NN of_IN a_DT single_JJ document_NN ._.
Several_JJ learning-based_JJ methods_NNS have_VBP been_VBN proposed_VBN for_IN extract-based_JJ summarization_NN ._.
They_PRP usually_RB utilize_VBP a_DT set_NN of_IN f_SYM
ces_NNS and_CC non-summary_JJ sentences_NNS -LRB-_-LRB- 24_CD -RRB-_-RRB- ._.
However_RB ,_, it_PRP relies_VBZ on_IN the_DT assumption_NN that_IN sentences_NNS are_VBP independent_JJ from_IN each_DT other_JJ and_CC ignores_VBZ the_DT correlation_NN between_IN sentences_NNS ._.
The_DT HMM-based_JJ method_NN proposed_VBN in_IN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: relaxes_VBZ this_DT assumption_NN by_IN modeling_NN the_DT relations_NNS between_IN different_JJ sentences_NNS through_IN hidden_JJ Markov_NNP models_NNS ._.
Unfortunately_RB ,_, the_DT training_NN process_NN of_IN the_DT HMM-based_JJ method_NN becomes_VBZ intractable_JJ when_WRB the_DT fe_NN
ased_VBN summarization_NN as_IN a_DT sentence_NN ranking_NN problem_NN ,_, those_DT include_VBP ranking_NN through_IN standard_JJ IR_NN methods_NNS or_CC identifying_VBG semantically_RB important_JJ sentences_NNS by_IN employing_VBG the_DT latent_JJ semantic_JJ analysis_NN technique_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Several_JJ learning_NN to_TO rank_VB methods_NNS such_JJ as_IN ranking_JJ SVM_NN ,_, support_NN vector_NN regression_NN and_CC gradient_NN boosted_VBD decision_NN trees_NNS are_VBP also_RB applied_VBN to_TO the_DT summarization_NN task_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- ._.
Nomoto_NNP and_CC Matsumoto_NNP take_VB the_DT div_NN
summarization_NN task_NN -LRB-_-LRB- 19_CD -RRB-_-RRB- ._.
Nomoto_NNP and_CC Matsumoto_NNP take_VB the_DT diversity_NN issue_NN into_IN consideration_NN with_IN a_DT preprocessing_VBG step_NN in_IN which_WDT the_DT sentences_NNS of_IN a_DT given_VBN document_NN are_VBP first_RB clustered_VBN into_IN several_JJ groups_NNS =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
CollabSum_NN -LRB-_-LRB- 30_CD -RRB-_-RRB- reduces_VBZ sentence_NN redundancy_NN by_IN discarding_VBG the_DT highly_RB overlapping_VBG sentences_NNS with_IN already_RB extracted_VBN highly_RB ranked_VBN sentences_NNS ._.
Goldstein_NNP et_FW al._FW consider_VB this_DT redundancy_NN issue_NN by_IN employing_VBG
reatly_RB to_TO document_NN summarization_NN ._.
Zha_NN in_IN -LRB-_-LRB- 32_CD -RRB-_-RRB- proposed_VBD a_DT mutual_JJ reinforcement_NN principle_NN for_IN sentence_NN extraction_NN using_VBG the_DT idea_NN of_IN HITS_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
Several_JJ related_JJ methods_NNS such_JJ as_IN TextRank_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ,_, LexPageRank_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: and_CC CollabSum_NNP -LRB-_-LRB- 30_CD -RRB-_-RRB- gain_NN remarkable_JJ performance_NN also_RB by_IN exploring_VBG methodologies_NNS used_VBN in_IN PageRank_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- and_CC HITS_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
These_DT methods_NNS mostly_RB focus_VB on_IN the_DT dependence_NN ,_, for_IN instance_NN ,_, similarity_NN ,_, between_IN sent_VBN
to_TO predict_VB diverse_JJ subsets_NNS using_VBG loss_NN functions_NNS to_TO penalize_VB low_JJ diversity_NN ._.
The_DT approach_NN taken_VBN by_IN the_DT DD-PREF_NN modeling_NN language_NN tackles_VBZ the_DT diversity_NN problem_NN by_IN measuring_VBG diversity_NN on_IN a_DT feature_NN basis_NN =_JJ -_: =[_NN 6_CD ,_, 29_CD -RRB-_-RRB- -_: =_SYM -_: ._.
As_IN another_DT example_NN ,_, a_DT framework_NN presented_VBN by_IN Clarke_NNP et_FW al._FW rewards_VBZ diversity_NN in_IN retrieval_NN evaluation_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
Besides_IN ,_, Kennedy_NNP and_CC Naaman_NNP also_RB propose_VBP a_DT tool_NN to_TO generate_VB diverse_JJ image_NN search_NN results_NNS -LRB-_-LRB- 22_CD
way_RB ,_, users_NNS can_MD save_VB time_NN by_IN browsing_VBG the_DT summaries_NNS before_IN deciding_VBG whether_IN or_CC not_RB to_TO read_VB the_DT whole_JJ documents_NNS ._.
Document_NNP summarization_NN can_MD generally_RB be_VB categorized_VBN as_IN abstract-based_JJ and_CC extract-based_JJ =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Abstract-based_JJ summarization_NN can_MD be_VB seen_VBN as_IN a_DT reproduction_NN of_IN the_DT original_JJ document_NN in_IN a_DT new_JJ way_NN ,_, while_IN extract-based_JJ summarization_NN focuses_VBZ on_IN extracting_VBG sentences_NNS from_IN the_DT original_JJ document_NN -LRB-_-LRB- 13_CD ,_, 16_CD
to_TO predict_VB diverse_JJ subsets_NNS using_VBG loss_NN functions_NNS to_TO penalize_VB low_JJ diversity_NN ._.
The_DT approach_NN taken_VBN by_IN the_DT DD-PREF_NN modeling_NN language_NN tackles_VBZ the_DT diversity_NN problem_NN by_IN measuring_VBG diversity_NN on_IN a_DT feature_NN basis_NN =_JJ -_: =[_NN 6_CD ,_, 29_CD -RRB-_-RRB- -_: =_SYM -_: ._.
As_IN another_DT example_NN ,_, a_DT framework_NN presented_VBN by_IN Clarke_NNP et_FW al._FW rewards_VBZ diversity_NN in_IN retrieval_NN evaluation_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
Besides_IN ,_, Kennedy_NNP and_CC Naaman_NNP also_RB propose_VBP a_DT tool_NN to_TO generate_VB diverse_JJ image_NN search_NN results_NNS -LRB-_-LRB- 22_CD
29_CD -RRB-_-RRB- ._.
As_IN another_DT example_NN ,_, a_DT framework_NN presented_VBN by_IN Clarke_NNP et_FW al._FW rewards_VBZ diversity_NN in_IN retrieval_NN evaluation_NN -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
Besides_IN ,_, Kennedy_NNP and_CC Naaman_NNP also_RB propose_VBP a_DT tool_NN to_TO generate_VB diverse_JJ image_NN search_NN results_VBZ =_JJ -_: =[_NN 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Our_PRP$ method_NN differs_VBZ from_IN above_JJ methods_NNS by_IN incorporating_VBG diversity_NN as_IN a_DT constraint_NN for_IN the_DT training_NN process_NN ,_, which_WDT proves_VBZ to_TO be_VB a_DT novel_JJ solution_NN for_IN the_DT summarization_NN task_NN ._.
3_LS ._.
PROBLEM_NN FORMULATION_NNS Give_VBP
extraction_NN using_VBG the_DT idea_NN of_IN HITS_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
Several_JJ related_JJ methods_NNS such_JJ as_IN TextRank_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ,_, LexPageRank_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- and_CC CollabSum_NN -LRB-_-LRB- 30_CD -RRB-_-RRB- gain_NN remarkable_JJ performance_NN also_RB by_IN exploring_VBG methodologies_NNS used_VBN in_IN PageRank_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: and_CC HITS_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
These_DT methods_NNS mostly_RB focus_VB on_IN the_DT dependence_NN ,_, for_IN instance_NN ,_, similarity_NN ,_, between_IN sentences_NNS of_IN the_DT same_JJ document_NN or_CC within_IN multiple_JJ documents_NNS ._.
Several_JJ clustering_NN methods_NNS have_VBP also_RB been_VBN e_SYM
re_IN compared_VBN directly_RB and_CC the_DT precision_NN ,_, recall_NN ,_, F1_NN scores_NNS are_VBP calculated_VBN as_IN follows_VBZ :_: ∆_NN -LRB-_-LRB- y_NN ,_, ¯_FW y_FW -RRB-_-RRB- =_JJ 2pr_NN -LRB-_-LRB- y_NN ,_, ¯_FW y_FW -RRB-_-RRB- -LRB-_-LRB- y_NN ,_, ¯_FW y_FW -RRB-_-RRB- ,_, p_NN =_JJ ,_, r_NN =_JJ p_NN +_CC r_NN -LRB-_-LRB- ¯_FW y_FW ,_, ¯_FW y_FW -RRB-_-RRB- -LRB-_-LRB- y_NN ,_, y_NN -RRB-_-RRB- ._.
6.2.2_FW ROUGE_FW Evaluation_NN The_DT ROUGE_NN measure_NN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ widely_RB used_VBN for_IN evaluation_NN ._.
In_IN fact_NN ,_, the_DT DUC_NNP contests_NNS usually_RB employ_VBP ROUGE_NN measures_NNS for_IN automatic_JJ summarization_NN evaluation_NN ._.
In_IN ROUGE_NN evaluation_NN ,_, the_DT summarization_NN quality_NN is_VBZ measured_VBN by_IN counting_VBG t_NN
providing_VBG the_DT snippets_NNS for_IN search_NN results_NNS ._.
The_DT Diversity_NNP issue_NN has_VBZ be_VB researched_VBN in_IN many_JJ areas_NNS other_JJ than_IN summarization_NN ._.
From_IN the_DT point_NN of_IN view_NN of_IN searching_VBG for_IN diversified_JJ results_NNS ,_, Yue_NN and_CC Joachims_NN =_JJ -_: =[_NN 31_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP employed_VBN structural_JJ SVM_NN to_TO predict_VB diverse_JJ subsets_NNS using_VBG loss_NN functions_NNS to_TO penalize_VB low_JJ diversity_NN ._.
The_DT approach_NN taken_VBN by_IN the_DT DD-PREF_NN modeling_NN language_NN tackles_VBZ the_DT diversity_NN problem_NN by_IN measuring_VBG
given_VBN training_NN set_NN -LCB-_-LRB- -LRB-_-LRB- x_NN -LRB-_-LRB- i_LS -RRB-_-RRB- ,_, y_NN -LRB-_-LRB- i_LS -RRB-_-RRB- -RRB-_-RRB- |_FW i_FW =_JJ 1_CD ,_, ·_FW ·_FW ·_NN ,_, n_NN -RCB-_-RRB- ,_, structural_JJ SVM_NN is_VBZ employed_VBN to_TO learn_VB a_DT weight_NN vector_NN w_NN for_IN the_DT discriminant_JJ function_NN F_NN -LRB-_-LRB- x_NN ,_, y_NN -RRB-_-RRB- through_IN the_DT following_JJ quadratic_JJ programing_NN problem_NN =_JJ -_: =[_NN 8_CD ,_, 28_CD ,_, 31_CD -RRB-_-RRB- -_: =_JJ -_: :_: Optimization_NNP Problem_NNP 1_CD ._.
-LRB-_-LRB- Structural_JJ SVM_NN -RRB-_-RRB- subjected_VBN to_TO :_: Track_NNP :_: Data_NNP Mining_NNP \/_: Session_NN :_: Text_NNP Mining_NNP 1_CD min_NN w_NN ,_, ξ_FW ≥_FW 0_CD 2_CD ‖_CD w_NN ‖_NN 2_CD +_CC c_NN n_NN ∀_FW i_FW ,_, ∀_FW y_FW ∈_FW Y_NN \_FW y_FW -LRB-_-LRB- i_LS -RRB-_-RRB- ,_, ξi_FW ≥_FW 0_CD ,_, n_NN ∑_FW ξi_FW ,_, -LRB-_-LRB- 4_CD -RRB-_-RRB- i_LS =_JJ 1_CD w_NN T_NN Ψ_NN -LRB-_-LRB- x_NN -LRB-_-LRB- i_LS -RRB-_-RRB- ,_, y_NN -LRB-_-LRB- i_LS -RRB-_-RRB- -RRB-_-RRB- ≥_FW w_FW T_NN Ψ_NN -LRB-_-LRB- x_NN -LRB-_-LRB-
modeling_NN language_NN tackles_VBZ the_DT diversity_NN problem_NN by_IN measuring_VBG diversity_NN on_IN a_DT feature_NN basis_NN -LRB-_-LRB- 6_CD ,_, 29_CD -RRB-_-RRB- ._.
As_IN another_DT example_NN ,_, a_DT framework_NN presented_VBN by_IN Clarke_NNP et_FW al._FW rewards_VBZ diversity_NN in_IN retrieval_NN evaluation_NN =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Besides_IN ,_, Kennedy_NNP and_CC Naaman_NNP also_RB propose_VBP a_DT tool_NN to_TO generate_VB diverse_JJ image_NN search_NN results_NNS -LRB-_-LRB- 22_CD -RRB-_-RRB- ._.
Our_PRP$ method_NN differs_VBZ from_IN above_JJ methods_NNS by_IN incorporating_VBG diversity_NN as_IN a_DT constraint_NN for_IN the_DT training_NN proce_NN
latent_JJ semantic_JJ analysis_NN technique_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- ._.
Several_JJ learning_NN to_TO rank_VB methods_NNS such_JJ as_IN ranking_JJ SVM_NN ,_, support_NN vector_NN regression_NN and_CC gradient_NN boosted_VBD decision_NN trees_NNS are_VBP also_RB applied_VBN to_TO the_DT summarization_NN task_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Nomoto_NNP and_CC Matsumoto_NNP take_VB the_DT diversity_NN issue_NN into_IN consideration_NN with_IN a_DT preprocessing_VBG step_NN in_IN which_WDT the_DT sentences_NNS of_IN a_DT given_VBN document_NN are_VBP first_RB clustered_VBN into_IN several_JJ groups_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ._.
CollabSum_NN -LRB-_-LRB- 30_CD -RRB-_-RRB- red_JJ
summarization_NN ._.
Zha_NN in_IN -LRB-_-LRB- 32_CD -RRB-_-RRB- proposed_VBD a_DT mutual_JJ reinforcement_NN principle_NN for_IN sentence_NN extraction_NN using_VBG the_DT idea_NN of_IN HITS_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
Several_JJ related_JJ methods_NNS such_JJ as_IN TextRank_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ,_, LexPageRank_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- and_CC CollabSum_NN =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_SYM -_: gain_VB remarkable_JJ performance_NN also_RB by_IN exploring_VBG methodologies_NNS used_VBN in_IN PageRank_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- and_CC HITS_NN -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
These_DT methods_NNS mostly_RB focus_VB on_IN the_DT dependence_NN ,_, for_IN instance_NN ,_, similarity_NN ,_, between_IN sentences_NNS of_IN the_DT same_JJ d_NN
