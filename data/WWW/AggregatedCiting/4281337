Large-scale_JJ text_NN categorization_NN by_IN batch_NN mode_NN active_JJ learning_NN
Large-scale_JJ text_NN categorization_NN is_VBZ an_DT important_JJ research_NN topic_NN for_IN Web_NN data_NNS mining_NN ._.
One_CD of_IN the_DT challenges_NNS in_IN large-scale_JJ text_NN categorization_NN is_VBZ how_WRB to_TO reduce_VB the_DT human_JJ efforts_NNS in_IN labeling_NN text_NN documents_NNS for_IN building_VBG reliable_JJ classification_NN models_NNS ._.
In_IN the_DT past_NN ,_, there_EX have_VBP been_VBN many_JJ studies_NNS on_IN applying_VBG active_JJ learning_VBG methods_NNS to_TO automatic_JJ text_NN categorization_NN ,_, which_WDT try_VBP to_TO select_VB the_DT most_RBS informative_JJ documents_NNS for_IN labeling_NN manually_RB ._.
Most_JJS of_IN these_DT studies_NNS focused_VBD on_IN selecting_VBG a_DT single_JJ unlabeled_JJ document_NN in_IN each_DT iteration_NN ._.
As_IN a_DT result_NN ,_, the_DT text_NN categorization_NN model_NN has_VBZ to_TO be_VB retrained_VBN after_IN each_DT labeled_VBN document_NN is_VBZ solicited_VBN ._.
In_IN this_DT paper_NN ,_, we_PRP present_VBP a_DT novel_JJ active_JJ learning_NN algorithm_NN that_WDT selects_VBZ a_DT batch_NN of_IN text_NN documents_NNS for_IN labeling_NN manually_RB in_IN each_DT iteration_NN ._.
The_DT key_NN of_IN the_DT batch_NN mode_NN active_JJ learning_NN is_VBZ how_WRB to_TO reduce_VB the_DT redundancy_NN among_IN the_DT selected_VBN examples_NNS such_JJ that_IN each_DT example_NN provides_VBZ unique_JJ information_NN for_IN model_NN updating_VBG ._.
To_TO this_DT end_NN ,_, we_PRP use_VBP the_DT Fisher_NNP information_NN matrix_NN as_IN the_DT measurement_NN of_IN model_NN uncertainty_NN and_CC choose_VB the_DT set_NN of_IN documents_NNS to_TO effectively_RB maximize_VB the_DT Fisher_NNP information_NN of_IN a_DT classification_NN model_NN ._.
Extensive_JJ experiments_NNS with_IN three_CD different_JJ datasets_NNS have_VBP shown_VBN that_IN our_PRP$ algorithm_NN is_VBZ more_RBR effective_JJ than_IN the_DT state-of-the-art_JJ active_JJ learning_NN techniques_NNS for_IN text_NN categorization_NN and_CC can_MD be_VB a_DT promising_JJ tool_NN toward_IN large-scale_JJ text_NN categorization_NN for_IN World_NN Wide_NN Web_NN documents_NNS ._.
ively_RB until_IN most_JJS of_IN the_DT examples_NNS can_MD be_VB classified_VBN with_IN reasonably_RB high_JJ confidence_NN ._.
One_CD of_IN the_DT key_JJ issues_NNS in_IN active_JJ learning_NN is_VBZ how_WRB to_TO measure_VB the_DT classification_NN uncertainty_NN of_IN unlabeled_JJ examples_NNS ._.
In_IN =_JJ -_: =[_NN 6_CD ,_, 7_CD ,_, 8_CD ,_, 14_CD ,_, 21_CD ,_, 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT number_NN of_IN distinct_JJ classification_NN models_NNS are_VBP first_RB generated_VBN ._.
Then_RB ,_, the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN is_VBZ measured_VBN by_IN the_DT amount_NN of_IN disagreement_NN among_IN the_DT ensemble_NN of_IN classification_NN
ines_NNS in_IN finding_VBG relevant_JJ documents_NNS and_CC to_TO facilitate_VB users_NNS in_IN browsing_VBG Web_NN pages_NNS or_CC Web_NN sites_NNS ._.
In_IN the_DT past_JJ decade_NN ,_, a_DT number_NN of_IN statistical_JJ learning_NN techniques_NNS have_VBP been_VBN applied_VBN to_TO text_NN categorization_NN =_JJ -_: =[_NN 34_CD -RRB-_-RRB- -_: =_JJ -_: ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, decision_NN trees_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, Bayesian_JJ classifiers_NNS -LRB-_-LRB- 32_CD -RRB-_-RRB- ,_, inductive_JJ rule_NN learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, neural_JJ networks_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Empirical_JJ s_NN
introduce_VB the_DT theoretical_JJ foundation_NN of_IN our_PRP$ active_JJ learning_NN algorithm_NN ._.
Based_VBN on_IN the_DT theoretical_JJ framework_NN ,_, we_PRP then_RB formulate_VBP the_DT active_JJ learning_NN problem_NN into_IN a_DT semi-definite_JJ programming_NN -LRB-_-LRB- SDP_NN -RRB-_-RRB- problem_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Finally_RB ,_, we_PRP present_VBP an_DT efficient_JJ learning_NN algorithm_NN for_IN the_DT related_JJ optimization_NN problem_NN based_VBN on_IN the_DT eigen_NN space_NN simplification_NN and_CC a_DT bound_VBN optimization_NN strategy_NN ._.
4.1_CD Theoretical_NNP Foundation_NNP Our_NNP act_NN
nique_VB among_IN all_PDT the_DT methods_NNS mentioned_VBN above_IN ._.
Recently_RB ,_, logistic_JJ regression_NN ,_, a_DT traditional_JJ statistical_JJ tool_NN ,_, has_VBZ attracted_VBN considerable_JJ attention_NN for_IN text_NN categorization_NN and_CC high-dimension_JJ data_NNS mining_NN =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Several_JJ recent_JJ studies_NNS have_VBP shown_VBN that_IN the_DT logistic_JJ regression_NN model_NN can_MD achieve_VB comparable_JJ classification_NN accuracy_NN as_IN SVMs_NNS in_IN text_NN categorization_NN ._.
Compared_VBN to_TO SVMs_NNS ,_, the_DT logistic_JJ regression_NN model_NN ha_NN
ively_RB until_IN most_JJS of_IN the_DT examples_NNS can_MD be_VB classified_VBN with_IN reasonably_RB high_JJ confidence_NN ._.
One_CD of_IN the_DT key_JJ issues_NNS in_IN active_JJ learning_NN is_VBZ how_WRB to_TO measure_VB the_DT classification_NN uncertainty_NN of_IN unlabeled_JJ examples_NNS ._.
In_IN =_JJ -_: =[_NN 6_CD ,_, 7_CD ,_, 8_CD ,_, 14_CD ,_, 21_CD ,_, 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT number_NN of_IN distinct_JJ classification_NN models_NNS are_VBP first_RB generated_VBN ._.
Then_RB ,_, the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN is_VBZ measured_VBN by_IN the_DT amount_NN of_IN disagreement_NN among_IN the_DT ensemble_NN of_IN classification_NN
that_WDT tries_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ examples_NNS for_IN labeling_NN manually_RB ._.
Although_IN previous_JJ studies_NNS have_VBP shown_VBN the_DT promising_JJ performance_NN of_IN semi-supervised_JJ learning_NN for_IN text_NN categorization_NN =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT high_JJ computation_NN cost_NN has_VBZ limited_VBN its_PRP$ application_NN -LRB-_-LRB- 38_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP focus_VBP our_PRP$ discussion_NN on_IN active_JJ learning_NN ._.
Active_JJ learning_NN ,_, or_CC called_VBN pool-based_JJ active_JJ learning_NN ,_, has_VBZ been_VBN extensively_RB stu_VBP
stic_JJ regression_NN tool_NN developed_VBN by_IN Komarek_NNP and_CC Moore_NNP recently_RB -LRB-_-LRB- 13_CD -RRB-_-RRB- ._.
To_TO implement_VB our_PRP$ active_JJ learning_NN algorithm_NN based_VBN on_IN the_DT bound_VBN optimization_NN approach_NN ,_, we_PRP employ_VBP a_DT standard_JJ math_NN package_NN ,_, i.e._FW ,_, LAPACK_NN =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_JJ -_: ,_, to_TO solve_VB the_DT eigen_NN decomposition_NN in_IN our_PRP$ algorithm_NN efficiently_RB ._.
The_DT SVM_NNP light_NN package_NN -LRB-_-LRB- 10_CD -RRB-_-RRB- is_VBZ used_VBN in_IN our_PRP$ experiments_NNS for_IN the_DT implementation_NN of_IN SVM_NNP ,_, which_WDT has_VBZ been_VBN considered_VBN as_IN the_DT state-of-the-art_JJ
tive_JJ learning_NN ._.
Active_JJ learning_NN ,_, or_CC called_VBN pool-based_JJ active_JJ learning_NN ,_, has_VBZ been_VBN extensively_RB studied_VBN in_IN machine_NN learning_NN for_IN many_JJ years_NNS and_CC has_VBZ already_RB been_VBN employed_VBN for_IN text_NN categorization_NN in_IN the_DT past_NN =_JJ -_: =[_NN 16_CD ,_, 17_CD ,_, 21_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_RBS active_JJ learning_NN algorithms_NNS are_VBP conducted_VBN in_IN the_DT iterative_JJ fashion_NN ._.
In_IN each_DT iteration_NN ,_, the_DT example_NN with_IN the_DT highest_JJS classification_NN uncertainty_NN is_VBZ chosen_VBN for_IN labeling_NN manually_RB ._.
Then_RB ,_, the_DT classifi_NNS
I_PRP 1\/2_CD p_NN qi_NN =_JJ 1_CD ,_, qi_FW ≥_FW 0_CD ,_, i_FW =_JJ 1_CD ,_, ..._: ,_, n_NN I_CD 1\/2_CD p_NN M_NN 0_CD -LRB-_-LRB- 10_CD -RRB-_-RRB- The_DT above_JJ problem_NN belongs_VBZ to_TO the_DT family_NN of_IN Semi-definite_JJ programming_NN and_CC can_MD be_VB solved_VBN by_IN the_DT standard_JJ convex_NN optimization_NN packages_NNS such_JJ as_IN SeDuMi_NN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_SYM -_: ._.
4.4_CD Eigen_NNP Space_NNP Simplification_NNP Although_IN the_DT formulation_NN in_IN -LRB-_-LRB- 10_CD -RRB-_-RRB- is_VBZ mathematically_RB sound_JJ ,_, directly_RB solving_VBG the_DT optimization_NN problem_NN could_MD be_VB computationally_RB expensive_RB due_JJ to_TO the_DT large_JJ size_NN of_IN matrix_NN
odel_NN suitable_JJ for_IN probabilistic_JJ binary_JJ classification_NN ._.
Recently_RB ,_, logistic_JJ regression_NN has_VBZ been_VBN actively_RB studied_VBN in_IN statistical_JJ machine_NN learning_NN community_NN due_JJ to_TO its_PRP$ close_JJ relation_NN to_TO SVMs_NNS and_CC Adaboost_NN =_JJ -_: =[_NN 33_CD ,_, 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Compared_VBN with_IN many_JJ other_JJ statistical_JJ learning_NN models_NNS ,_, such_JJ as_IN SVMs_NNS ,_, the_DT logistic_JJ regression_NN model_NN has_VBZ the_DT following_JJ advantages_NNS :_: •_CD It_PRP is_VBZ a_DT high_JJ performance_NN classifier_NN that_WDT can_MD be_VB efficiently_RB trained_VBN w_NN
tive_JJ learning_NN ._.
Active_JJ learning_NN ,_, or_CC called_VBN pool-based_JJ active_JJ learning_NN ,_, has_VBZ been_VBN extensively_RB studied_VBN in_IN machine_NN learning_NN for_IN many_JJ years_NNS and_CC has_VBZ already_RB been_VBN employed_VBN for_IN text_NN categorization_NN in_IN the_DT past_NN =_JJ -_: =[_NN 16_CD ,_, 17_CD ,_, 21_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_RBS active_JJ learning_NN algorithms_NNS are_VBP conducted_VBN in_IN the_DT iterative_JJ fashion_NN ._.
In_IN each_DT iteration_NN ,_, the_DT example_NN with_IN the_DT highest_JJS classification_NN uncertainty_NN is_VBZ chosen_VBN for_IN labeling_NN manually_RB ._.
Then_RB ,_, the_DT classifi_NNS
lassification_NN model_NN from_IN the_DT mixture_NN of_IN labeled_JJ and_CC unlabeled_JJ examples_NNS -LRB-_-LRB- 30_CD -RRB-_-RRB- ._.
A_DT comprehensive_JJ study_NN of_IN semi-supervised_JJ learning_NN techniques_NNS can_MD be_VB found_VBN in_IN -LRB-_-LRB- 25_CD ,_, 38_CD -RRB-_-RRB- ._.
Another_DT solution_NN is_VBZ active_JJ learning_NN =_JJ -_: =[_NN 19_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: that_WDT tries_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ examples_NNS for_IN labeling_NN manually_RB ._.
Although_IN previous_JJ studies_NNS have_VBP shown_VBN the_DT promising_JJ performance_NN of_IN semi-supervised_JJ learning_NN for_IN text_NN categorization_NN
or_CC the_DT test_NN example_NN ._.
Another_DT group_NN of_IN approaches_NNS measure_VBP the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN by_IN how_WRB far_RB the_DT example_NN is_VBZ away_RB from_IN the_DT classification_NN boundary_NN -LRB-_-LRB- i.e._FW ,_, classification_NN margin_NN -RRB-_-RRB- =_JJ -_: =[_NN 4_CD ,_, 24_CD ,_, 31_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT most_RBS well-known_JJ approaches_NNS within_IN this_DT group_NN is_VBZ support_NN vector_NN machine_NN active_JJ learning_NN developed_VBN by_IN Tong_NNP and_CC Koller_NNP -LRB-_-LRB- 31_CD -RRB-_-RRB- ._.
Due_JJ to_TO its_PRP$ popularity_NN and_CC success_NN in_IN the_DT previous_JJ studies_NNS ,_, it_PRP is_VBZ
egorization_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, decision_NN trees_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, Bayesian_JJ classifiers_NNS -LRB-_-LRB- 32_CD -RRB-_-RRB- ,_, inductive_JJ rule_NN learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, neural_JJ networks_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Empirical_JJ studies_NNS in_IN recent_JJ years_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- have_VBP shown_VBN that_IN SVM_NN is_VBZ the_DT state-of-the-art_JJ technique_NN among_IN all_PDT the_DT methods_NNS mentioned_VBN above_IN ._.
Recently_RB ,_, logistic_JJ regression_NN ,_, a_DT traditional_JJ statistical_JJ tool_NN ,_, has_VBZ
-_: supervised_JJ learning_NN ,_, which_WDT tries_VBZ to_TO learn_VB a_DT classification_NN model_NN from_IN the_DT mixture_NN of_IN labeled_JJ and_CC unlabeled_JJ examples_NNS -LRB-_-LRB- 30_CD -RRB-_-RRB- ._.
A_DT comprehensive_JJ study_NN of_IN semi-supervised_JJ learning_NN techniques_NNS can_MD be_VB found_VBN in_IN =_JJ -_: =[_NN 25_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Another_DT solution_NN is_VBZ active_JJ learning_NN -LRB-_-LRB- 19_CD ,_, 26_CD -RRB-_-RRB- that_WDT tries_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ examples_NNS for_IN labeling_NN manually_RB ._.
Although_IN previous_JJ studies_NNS have_VBP shown_VBN the_DT promising_JJ performance_NN of_IN sem_NN
rization_NN ._.
Compared_VBN to_TO SVMs_NNS ,_, the_DT logistic_JJ regression_NN model_NN has_VBZ the_DT advantage_NN in_IN that_IN it_PRP is_VBZ usually_RB more_RBR efficient_JJ than_IN SVMs_NNS in_IN model_NN training_NN ,_, especially_RB when_WRB the_DT number_NN of_IN training_NN documents_NNS is_VBZ large_JJ =_JJ -_: =[_NN 13_CD ,_, 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT motivates_VBZ us_PRP to_TO choose_VB logistic_JJ regression_NN as_IN the_DT basis_NN classifier_NN for_IN large-scale_JJ text_NN categorization_NN ._.
The_DT other_JJ critical_JJ issue_NN for_IN large-scale_JJ text_NN document_NN categorization_NN is_VBZ how_WRB to_TO reduce_VB th_DT
rization_NN ._.
Compared_VBN to_TO SVMs_NNS ,_, the_DT logistic_JJ regression_NN model_NN has_VBZ the_DT advantage_NN in_IN that_IN it_PRP is_VBZ usually_RB more_RBR efficient_JJ than_IN SVMs_NNS in_IN model_NN training_NN ,_, especially_RB when_WRB the_DT number_NN of_IN training_NN documents_NNS is_VBZ large_JJ =_JJ -_: =[_NN 13_CD ,_, 36_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT motivates_VBZ us_PRP to_TO choose_VB logistic_JJ regression_NN as_IN the_DT basis_NN classifier_NN for_IN large-scale_JJ text_NN categorization_NN ._.
The_DT other_JJ critical_JJ issue_NN for_IN large-scale_JJ text_NN document_NN categorization_NN is_VBZ how_WRB to_TO reduce_VB th_DT
te_NN users_NNS in_IN browsing_VBG Web_NN pages_NNS or_CC Web_NN sites_NNS ._.
In_IN the_DT past_JJ decade_NN ,_, a_DT number_NN of_IN statistical_JJ learning_NN techniques_NNS have_VBP been_VBN applied_VBN to_TO text_NN categorization_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_VBZ =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_JJ -_: ,_, decision_NN trees_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, Bayesian_JJ classifiers_NNS -LRB-_-LRB- 32_CD -RRB-_-RRB- ,_, inductive_JJ rule_NN learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, neural_JJ networks_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Empirical_JJ studies_NNS in_IN recent_JJ years_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- have_VBP shown_VBN that_IN SVM_NN is_VBZ
ining_NN ,_, information_NN retrieval_NN and_CC statistical_JJ learning_NN -LRB-_-LRB- 15_CD ,_, 35_CD -RRB-_-RRB- ._.
Essentially_RB the_DT text_NN categorization_NN techniques_NNS have_VBP been_VBN the_DT key_NN toward_IN automated_JJ categorization_NN of_IN large-scale_JJ Web_NN pages_NNS and_CC Web_NN sites_NNS =_JJ -_: =[_NN 18_CD ,_, 27_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT is_VBZ further_RB applied_VBN to_TO improve_VB Web_NN searching_VBG engines_NNS in_IN finding_VBG relevant_JJ documents_NNS and_CC to_TO facilitate_VB users_NNS in_IN browsing_VBG Web_NN pages_NNS or_CC Web_NN sites_NNS ._.
In_IN the_DT past_JJ decade_NN ,_, a_DT number_NN of_IN statistical_JJ learni_NNS
ur_NN conclusions_NNS ._.
2_CD ._.
RELATED_NNS WORK_VBP Text_NN categorization_NN is_VBZ a_DT long-term_JJ research_NN topic_NN which_WDT has_VBZ been_VBN actively_RB studied_VBN in_IN the_DT communities_NNS of_IN Web_NN data_NNS mining_NN ,_, information_NN retrieval_NN and_CC statistical_JJ learning_NN =_JJ -_: =[_NN 15_CD ,_, 35_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Essentially_RB the_DT text_NN categorization_NN techniques_NNS have_VBP been_VBN the_DT key_NN toward_IN automated_JJ categorization_NN of_IN large-scale_JJ Web_NN pages_NNS and_CC Web_NN sites_NNS -LRB-_-LRB- 18_CD ,_, 27_CD -RRB-_-RRB- ,_, which_WDT is_VBZ further_RB applied_VBN to_TO improve_VB Web_NN searching_VBG en_IN
d_NN choose_VB the_DT set_NN of_IN examples_NNS that_WDT efficiently_RB maximize_VBP the_DT Fisher_NNP information_NN of_IN the_DT classification_NN model_NN ._.
Fisher_NNP information_NN matrix_NN has_VBZ been_VBN used_VBN widely_RB in_IN statistics_NNS for_IN measuring_VBG model_NN uncertainty_NN =_JJ -_: =[_NN 28_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, in_IN the_DT Cramer-Rao_NNP bound_VBD ,_, Fisher_NNP information_NN matrix_NN provides_VBZ the_DT low_NN bound_VBN for_IN the_DT variance_NN of_IN a_DT statistical_JJ model_NN ._.
In_IN this_DT study_NN ,_, we_PRP choose_VBP the_DT set_NN of_IN examples_NNS that_WDT can_MD well_RB represent_VB t_NN
Web_NN pages_NNS or_CC Web_NN sites_NNS ._.
In_IN the_DT past_JJ decade_NN ,_, a_DT number_NN of_IN statistical_JJ learning_NN techniques_NNS have_VBP been_VBN applied_VBN to_TO text_NN categorization_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, decision_NN trees_NNS =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Bayesian_JJ classifiers_NNS -LRB-_-LRB- 32_CD -RRB-_-RRB- ,_, inductive_JJ rule_NN learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, neural_JJ networks_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Empirical_JJ studies_NNS in_IN recent_JJ years_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- have_VBP shown_VBN that_IN SVM_NN is_VBZ the_DT state-of-the-art_JJ
learning_VBG algorithm_NN based_VBN on_IN the_DT bound_VBN optimization_NN approach_NN ,_, we_PRP employ_VBP a_DT standard_JJ math_NN package_NN ,_, i.e._FW ,_, LAPACK_NN -LRB-_-LRB- 1_CD -RRB-_-RRB- ,_, to_TO solve_VB the_DT eigen_NN decomposition_NN in_IN our_PRP$ algorithm_NN efficiently_RB ._.
The_DT SVM_NNP light_JJ package_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ used_VBN in_IN our_PRP$ experiments_NNS for_IN the_DT implementation_NN of_IN SVM_NNP ,_, which_WDT has_VBZ been_VBN considered_VBN as_IN the_DT state-of-the-art_JJ tool_NN for_IN text_NN categorization_NN ._.
Since_IN SVM_NN is_VBZ not_RB parameter-free_JJ and_CC can_MD be_VB very_RB sensitive_JJ to_TO
statistical_JJ learning_NN techniques_NNS have_VBP been_VBN applied_VBN to_TO text_NN categorization_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, decision_NN trees_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, Bayesian_JJ classifiers_NNS -LRB-_-LRB- 32_CD -RRB-_-RRB- ,_, inductive_JJ rule_NN learning_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: ,_, neural_JJ networks_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Empirical_JJ studies_NNS in_IN recent_JJ years_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- have_VBP shown_VBN that_IN SVM_NN is_VBZ the_DT state-of-the-art_JJ technique_NN among_IN all_PDT the_DT methods_NNS mentioned_VBN above_IN ._.
Recent_JJ
for_IN the_DT related_JJ optimization_NN problem_NN based_VBN on_IN the_DT eigen_NN space_NN simplification_NN and_CC a_DT bound_VBN optimization_NN strategy_NN ._.
4.1_CD Theoretical_NNP Foundation_NNP Our_NNP active_JJ learning_NN methodology_NN is_VBZ motivated_VBN by_IN the_DT work_NN in_IN =_JJ -_: =[_NN 37_CD -RRB-_-RRB- -_: =_JJ -_: ,_, in_IN which_WDT the_DT author_NN presented_VBD a_DT theoretical_JJ framework_NN of_IN active_JJ learning_NN based_VBN on_IN the_DT Fisher_NNP information_NN matrix_NN ._.
Given_VBN the_DT Fisher_NNP information_NN matrix_NN represents_VBZ the_DT overall_JJ uncertainty_NN of_IN a_DT classific_JJ
ining_NN ,_, information_NN retrieval_NN and_CC statistical_JJ learning_NN -LRB-_-LRB- 15_CD ,_, 35_CD -RRB-_-RRB- ._.
Essentially_RB the_DT text_NN categorization_NN techniques_NNS have_VBP been_VBN the_DT key_NN toward_IN automated_JJ categorization_NN of_IN large-scale_JJ Web_NN pages_NNS and_CC Web_NN sites_NNS =_JJ -_: =[_NN 18_CD ,_, 27_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT is_VBZ further_RB applied_VBN to_TO improve_VB Web_NN searching_VBG engines_NNS in_IN finding_VBG relevant_JJ documents_NNS and_CC to_TO facilitate_VB users_NNS in_IN browsing_VBG Web_NN pages_NNS or_CC Web_NN sites_NNS ._.
In_IN the_DT past_JJ decade_NN ,_, a_DT number_NN of_IN statistical_JJ learni_NNS
or_CC the_DT test_NN example_NN ._.
Another_DT group_NN of_IN approaches_NNS measure_VBP the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN by_IN how_WRB far_RB the_DT example_NN is_VBZ away_RB from_IN the_DT classification_NN boundary_NN -LRB-_-LRB- i.e._FW ,_, classification_NN margin_NN -RRB-_-RRB- =_JJ -_: =[_NN 4_CD ,_, 24_CD ,_, 31_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT most_RBS well-known_JJ approaches_NNS within_IN this_DT group_NN is_VBZ support_NN vector_NN machine_NN active_JJ learning_NN developed_VBN by_IN Tong_NNP and_CC Koller_NNP -LRB-_-LRB- 31_CD -RRB-_-RRB- ._.
Due_JJ to_TO its_PRP$ popularity_NN and_CC success_NN in_IN the_DT previous_JJ studies_NNS ,_, it_PRP is_VBZ
or_CC the_DT test_NN example_NN ._.
Another_DT group_NN of_IN approaches_NNS measure_VBP the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN by_IN how_WRB far_RB the_DT example_NN is_VBZ away_RB from_IN the_DT classification_NN boundary_NN -LRB-_-LRB- i.e._FW ,_, classification_NN margin_NN -RRB-_-RRB- =_JJ -_: =[_NN 4_CD ,_, 24_CD ,_, 31_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT most_RBS well-known_JJ approaches_NNS within_IN this_DT group_NN is_VBZ support_NN vector_NN machine_NN active_JJ learning_NN developed_VBN by_IN Tong_NNP and_CC Koller_NNP -LRB-_-LRB- 31_CD -RRB-_-RRB- ._.
Due_JJ to_TO its_PRP$ popularity_NN and_CC success_NN in_IN the_DT previous_JJ studies_NNS ,_, it_PRP is_VBZ
the_DT past_JJ decade_NN ,_, a_DT number_NN of_IN statistical_JJ learning_NN techniques_NNS have_VBP been_VBN applied_VBN to_TO text_NN categorization_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, decision_NN trees_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, Bayesian_JJ classifiers_NNS =_JJ -_: =[_NN 32_CD -RRB-_-RRB- -_: =_JJ -_: ,_, inductive_JJ rule_NN learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, neural_JJ networks_NNS -LRB-_-LRB- 23_CD -RRB-_-RRB- ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Empirical_JJ studies_NNS in_IN recent_JJ years_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- have_VBP shown_VBN that_IN SVM_NN is_VBZ the_DT state-of-the-art_JJ technique_NN among_IN all_PDT the_DT me_PRP
ively_RB until_IN most_JJS of_IN the_DT examples_NNS can_MD be_VB classified_VBN with_IN reasonably_RB high_JJ confidence_NN ._.
One_CD of_IN the_DT key_JJ issues_NNS in_IN active_JJ learning_NN is_VBZ how_WRB to_TO measure_VB the_DT classification_NN uncertainty_NN of_IN unlabeled_JJ examples_NNS ._.
In_IN =_JJ -_: =[_NN 6_CD ,_, 7_CD ,_, 8_CD ,_, 14_CD ,_, 21_CD ,_, 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT number_NN of_IN distinct_JJ classification_NN models_NNS are_VBP first_RB generated_VBN ._.
Then_RB ,_, the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN is_VBZ measured_VBN by_IN the_DT amount_NN of_IN disagreement_NN among_IN the_DT ensemble_NN of_IN classification_NN
documents_NNS ,_, the_DT key_NN is_VBZ to_TO exploit_VB the_DT unlabeled_JJ documents_NNS ._.
One_CD solution_NN is_VBZ the_DT semi-supervised_JJ learning_NN ,_, which_WDT tries_VBZ to_TO learn_VB a_DT classification_NN model_NN from_IN the_DT mixture_NN of_IN labeled_JJ and_CC unlabeled_JJ examples_NNS =_JJ -_: =[_NN 30_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT comprehensive_JJ study_NN of_IN semi-supervised_JJ learning_NN techniques_NNS can_MD be_VB found_VBN in_IN -LRB-_-LRB- 25_CD ,_, 38_CD -RRB-_-RRB- ._.
Another_DT solution_NN is_VBZ active_JJ learning_NN -LRB-_-LRB- 19_CD ,_, 26_CD -RRB-_-RRB- that_WDT tries_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ examples_NNS for_IN l_NN
tive_JJ learning_NN ._.
Active_JJ learning_NN ,_, or_CC called_VBN pool-based_JJ active_JJ learning_NN ,_, has_VBZ been_VBN extensively_RB studied_VBN in_IN machine_NN learning_NN for_IN many_JJ years_NNS and_CC has_VBZ already_RB been_VBN employed_VBN for_IN text_NN categorization_NN in_IN the_DT past_NN =_JJ -_: =[_NN 16_CD ,_, 17_CD ,_, 21_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_RBS active_JJ learning_NN algorithms_NNS are_VBP conducted_VBN in_IN the_DT iterative_JJ fashion_NN ._.
In_IN each_DT iteration_NN ,_, the_DT example_NN with_IN the_DT highest_JJS classification_NN uncertainty_NN is_VBZ chosen_VBN for_IN labeling_NN manually_RB ._.
Then_RB ,_, the_DT classifi_NNS
tive_JJ learning_NN ._.
Active_JJ learning_NN ,_, or_CC called_VBN pool-based_JJ active_JJ learning_NN ,_, has_VBZ been_VBN extensively_RB studied_VBN in_IN machine_NN learning_NN for_IN many_JJ years_NNS and_CC has_VBZ already_RB been_VBN employed_VBN for_IN text_NN categorization_NN in_IN the_DT past_NN =_JJ -_: =[_NN 16_CD ,_, 17_CD ,_, 21_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Most_RBS active_JJ learning_NN algorithms_NNS are_VBP conducted_VBN in_IN the_DT iterative_JJ fashion_NN ._.
In_IN each_DT iteration_NN ,_, the_DT example_NN with_IN the_DT highest_JJS classification_NN uncertainty_NN is_VBZ chosen_VBN for_IN labeling_NN manually_RB ._.
Then_RB ,_, the_DT classifi_NNS
techniques_NNS have_VBP been_VBN applied_VBN to_TO text_NN categorization_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- ,_, including_VBG the_DT K_NNP Nearest_NNP Neighbor_NNP approaches_NNS -LRB-_-LRB- 20_CD -RRB-_-RRB- ,_, decision_NN trees_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, Bayesian_JJ classifiers_NNS -LRB-_-LRB- 32_CD -RRB-_-RRB- ,_, inductive_JJ rule_NN learning_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, neural_JJ networks_NNS =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- SVM_NN -RRB-_-RRB- -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Empirical_JJ studies_NNS in_IN recent_JJ years_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- have_VBP shown_VBN that_IN SVM_NN is_VBZ the_DT state-of-the-art_JJ technique_NN among_IN all_PDT the_DT methods_NNS mentioned_VBN above_IN ._.
Recently_RB ,_, logistic_JJ regressio_NN
-_: supervised_JJ learning_NN ,_, which_WDT tries_VBZ to_TO learn_VB a_DT classification_NN model_NN from_IN the_DT mixture_NN of_IN labeled_JJ and_CC unlabeled_JJ examples_NNS -LRB-_-LRB- 30_CD -RRB-_-RRB- ._.
A_DT comprehensive_JJ study_NN of_IN semi-supervised_JJ learning_NN techniques_NNS can_MD be_VB found_VBN in_IN =_JJ -_: =[_NN 25_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Another_DT solution_NN is_VBZ active_JJ learning_NN -LRB-_-LRB- 19_CD ,_, 26_CD -RRB-_-RRB- that_WDT tries_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ examples_NNS for_IN labeling_NN manually_RB ._.
Although_IN previous_JJ studies_NNS have_VBP shown_VBN the_DT promising_JJ performance_NN of_IN sem_NN
ively_RB until_IN most_JJS of_IN the_DT examples_NNS can_MD be_VB classified_VBN with_IN reasonably_RB high_JJ confidence_NN ._.
One_CD of_IN the_DT key_JJ issues_NNS in_IN active_JJ learning_NN is_VBZ how_WRB to_TO measure_VB the_DT classification_NN uncertainty_NN of_IN unlabeled_JJ examples_NNS ._.
In_IN =_JJ -_: =[_NN 6_CD ,_, 7_CD ,_, 8_CD ,_, 14_CD ,_, 21_CD ,_, 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT number_NN of_IN distinct_JJ classification_NN models_NNS are_VBP first_RB generated_VBN ._.
Then_RB ,_, the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN is_VBZ measured_VBN by_IN the_DT amount_NN of_IN disagreement_NN among_IN the_DT ensemble_NN of_IN classification_NN
lassification_NN model_NN from_IN the_DT mixture_NN of_IN labeled_JJ and_CC unlabeled_JJ examples_NNS -LRB-_-LRB- 30_CD -RRB-_-RRB- ._.
A_DT comprehensive_JJ study_NN of_IN semi-supervised_JJ learning_NN techniques_NNS can_MD be_VB found_VBN in_IN -LRB-_-LRB- 25_CD ,_, 38_CD -RRB-_-RRB- ._.
Another_DT solution_NN is_VBZ active_JJ learning_NN =_JJ -_: =[_NN 19_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: that_WDT tries_VBZ to_TO choose_VB the_DT most_RBS informative_JJ unlabeled_JJ examples_NNS for_IN labeling_NN manually_RB ._.
Although_IN previous_JJ studies_NNS have_VBP shown_VBN the_DT promising_JJ performance_NN of_IN semi-supervised_JJ learning_NN for_IN text_NN categorization_NN
ur_NN conclusions_NNS ._.
2_CD ._.
RELATED_NNS WORK_VBP Text_NN categorization_NN is_VBZ a_DT long-term_JJ research_NN topic_NN which_WDT has_VBZ been_VBN actively_RB studied_VBN in_IN the_DT communities_NNS of_IN Web_NN data_NNS mining_NN ,_, information_NN retrieval_NN and_CC statistical_JJ learning_NN =_JJ -_: =[_NN 15_CD ,_, 35_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Essentially_RB the_DT text_NN categorization_NN techniques_NNS have_VBP been_VBN the_DT key_NN toward_IN automated_JJ categorization_NN of_IN large-scale_JJ Web_NN pages_NNS and_CC Web_NN sites_NNS -LRB-_-LRB- 18_CD ,_, 27_CD -RRB-_-RRB- ,_, which_WDT is_VBZ further_RB applied_VBN to_TO improve_VB Web_NN searching_VBG en_IN
ively_RB until_IN most_JJS of_IN the_DT examples_NNS can_MD be_VB classified_VBN with_IN reasonably_RB high_JJ confidence_NN ._.
One_CD of_IN the_DT key_JJ issues_NNS in_IN active_JJ learning_NN is_VBZ how_WRB to_TO measure_VB the_DT classification_NN uncertainty_NN of_IN unlabeled_JJ examples_NNS ._.
In_IN =_JJ -_: =[_NN 6_CD ,_, 7_CD ,_, 8_CD ,_, 14_CD ,_, 21_CD ,_, 26_CD -RRB-_-RRB- -_: =_JJ -_: ,_, a_DT number_NN of_IN distinct_JJ classification_NN models_NNS are_VBP first_RB generated_VBN ._.
Then_RB ,_, the_DT classification_NN uncertainty_NN of_IN a_DT test_NN example_NN is_VBZ measured_VBN by_IN the_DT amount_NN of_IN disagreement_NN among_IN the_DT ensemble_NN of_IN classification_NN
