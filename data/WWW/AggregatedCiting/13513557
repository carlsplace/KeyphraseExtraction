Measuring_VBG the_DT similarity_NN between_IN implicit_JJ semantic_JJ relations_NNS from_IN the_DT web_NN
Measuring_VBG the_DT similarity_NN between_IN semantic_JJ relations_NNS that_WDT hold_VBP among_IN entities_NNS is_VBZ an_DT important_JJ and_CC necessary_JJ step_NN in_IN various_JJ Web_NN related_JJ tasks_NNS such_JJ as_IN relation_NN extraction_NN ,_, information_NN retrieval_NN and_CC analogy_NN detection_NN ._.
For_IN example_NN ,_, consider_VB the_DT case_NN in_IN which_WDT a_DT person_NN knows_VBZ a_DT pair_NN of_IN entities_NNS -LRB-_-LRB- e.g._FW Google_NNP ,_, YouTube_NNP -RRB-_-RRB- ,_, between_IN which_WDT a_DT particular_JJ relation_NN holds_VBZ -LRB-_-LRB- e.g._FW acquisition_NN -RRB-_-RRB- ._.
The_DT person_NN is_VBZ interested_JJ in_IN retrieving_VBG other_JJ such_JJ pairs_NNS with_IN similar_JJ relations_NNS -LRB-_-LRB- e.g._FW Microsoft_NNP ,_, Powerset_NNP -RRB-_-RRB- ._.
Existing_VBG keyword-based_JJ search_NN engines_NNS can_MD not_RB be_VB applied_VBN directly_RB in_IN this_DT case_NN because_IN ,_, in_IN keyword-based_JJ search_NN ,_, the_DT goal_NN is_VBZ to_TO retrieve_VB documents_NNS that_WDT are_VBP relevant_JJ to_TO the_DT words_NNS used_VBN in_IN a_DT query_NN --_: not_RB necessarily_RB to_TO the_DT relations_NNS implied_VBN by_IN a_DT pair_NN of_IN words_NNS ._.
We_PRP propose_VBP a_DT relational_JJ similarity_NN measure_NN ,_, using_VBG a_DT Web_NN search_NN engine_NN ,_, to_TO compute_VB the_DT similarity_NN between_IN semantic_JJ relations_NNS implied_VBN by_IN two_CD pairs_NNS of_IN words_NNS ._.
Our_PRP$ method_NN has_VBZ three_CD components_NNS :_: representing_VBG the_DT various_JJ semantic_JJ relations_NNS that_WDT exist_VBP between_IN a_DT pair_NN of_IN words_NNS using_VBG automatically_RB extracted_VBN lexical_JJ patterns_NNS ,_, clustering_VBG the_DT extracted_VBN lexical_JJ patterns_NNS to_TO identify_VB the_DT different_JJ patterns_NNS that_WDT express_VBP a_DT particular_JJ semantic_JJ relation_NN ,_, and_CC measuring_VBG the_DT similarity_NN between_IN semantic_JJ relations_NNS using_VBG a_DT metric_JJ learning_NN approach_NN ._.
We_PRP evaluate_VBP the_DT proposed_VBN method_NN in_IN two_CD tasks_NNS :_: classifying_VBG semantic_JJ relations_NNS between_IN named_VBN entities_NNS ,_, and_CC solving_VBG word-analogy_JJ questions_NNS ._.
The_DT proposed_VBN method_NN outperforms_VBZ all_DT baselines_NNS in_IN a_DT relation_NN classification_NN task_NN with_IN a_DT statistically_RB significant_JJ average_JJ precision_NN score_NN of_IN 0.74_CD ._.
Moreover_RB ,_, it_PRP reduces_VBZ the_DT time_NN taken_VBN by_IN Latent_JJ Relational_NNP Analysis_NNP to_TO process_VB 374_CD word-analogy_JJ questions_NNS from_IN 9_CD days_NNS to_TO less_JJR than_IN 6_CD hours_NNS ,_, with_IN an_DT SAT_NNP score_NN of_IN 51_CD %_NN ._.
te_IN instance_NN pairs_NNS with_IN high_JJ relational_JJ similarity_NN with_IN the_DT seed_NN pairs_NNS can_MD then_RB be_VB selected_VBN as_IN the_DT correct_JJ instances_NNS of_IN a_DT relation_NN ._.
Relational_JJ similarity_NN measures_NNS have_VBP been_VBN used_VBN to_TO find_VB word_NN analogies_NNS =_JJ -_: =[_NN 10_CD ,_, 24_CD ,_, 31_CD ,_, 33_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Word_NN analogy_NN questions_NNS have_VBP been_VBN used_VBN from_IN the_DT Scholastic_NNP Aptitude_NNP Test_NNP -LRB-_-LRB- SAT_NNP ;_: Educational_NNP Testing_NNP Service_NNP -RRB-_-RRB- to_TO benchmark_JJ relational_JJ similarity_NN measures_NNS ._.
An_DT SAT_NNP word_NN analogy_NN question_NN consists_VBZ of_IN a_DT ste_NN
terns_NNS Lexical_JJ syntactic_JJ patterns_NNS have_VBP been_VBN used_VBN in_IN various_JJ natural_JJ language_NN processing_NN tasks_NNS such_JJ as_IN extracting_VBG hypernyms_NNS -LRB-_-LRB- 17_CD ,_, 30_CD -RRB-_-RRB- ,_, or_CC meronyms_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, question_NN answering_NN -LRB-_-LRB- 28_CD -RRB-_-RRB- ,_, and_CC paraphrase_NN extraction_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Following_VBG these_DT previous_JJ works_NNS ,_, we_PRP present_VBP a_DT shallow_JJ lexical_JJ pattern_NN extraction_NN algorithm_NN to_TO represent_VB the_DT semantic_JJ relations_NNS between_IN two_CD words_NNS ._.
The_DT proposed_VBN method_NN requires_VBZ no_DT languagedependent_JJ pre_JJ
we_PRP compute_VBP the_DT relational_JJ similarity_NN between_IN two_CD word_NN pairs_NNS ._.
We_PRP can_MD expect_VB a_DT high_JJ relational_JJ similarity_NN if_IN there_EX are_VBP many_JJ related_JJ patterns_NNS between_IN two_CD word_NN pairs_NNS ._.
We_PRP use_VBP the_DT distributional_JJ hypothesis_NN =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: to_TO find_VB semantically_RB related_JJ lexical_JJ patterns_NNS ._.
The_DT distributional_JJ hypothesis_NN states_NNS that_IN words_NNS that_WDT occur_VBP in_IN the_DT same_JJ context_NN have_VBP similar_JJ meanings_NNS ._.
The_DT distributional_JJ hypothesis_NN has_VBZ been_VBN used_VBN in_IN var_NN
-LRB-_-LRB- 33_CD -RRB-_-RRB- 27.3_CD %_NN Bicici_NNP &_CC Yuret_NNP -LRB-_-LRB- 4_CD -RRB-_-RRB- 44.0_CD %_NN Leacock_NNP &_CC Chodrow_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 31.3_CD %_NN VSM_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- 47.1_CD %_NN Hirst_NNP &_CC St.-Onge_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 32.1_CD %_NN PROPOSED_VBD 51.1_CD %_NN Resnik_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- 33.2_CD %_NN Pertinence_NN -LRB-_-LRB- 32_CD -RRB-_-RRB- 53.5_CD %_NN PMI-IR_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- 35.0_CD %_NN LRA_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- 56.1_CD %_NN SVM_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: 40.1_CD %_NN Human_NNP 57.0_CD %_NN The_DT four_CD methods_NNS described_VBN above_RB presented_VBN for_IN comparison_NN in_IN Table_NNP 3_CD ._.
For_IN each_DT relation_NN type_NN ,_, Table_NNP 3_CD shows_VBZ the_DT average_JJ precision_NN scores_NNS computed_VBN using_VBG Formula_NN 8_CD ._.
Moreover_RB ,_, the_DT over_IN
scipy.org_FW 658WWW_FW 2009_CD MADRID_NNP !_.
Track_NNP :_: Semantic\/Data_NN Web_NN \/_: Session_NN :_: Mining_NNP for_IN Semantics_NNP Table_NNP 4_CD :_: Performance_NNP on_IN the_DT SAT_NNP dataset_NN ._.
Algorithm_NN score_NN Algorithm_NN score_NN Random_NNP guessing_VBG 20.0_CD %_NN LSA+P_NN redictation_NN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: 42.0_CD %_NN Jiang_NNP &_CC Conrath_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 27.3_CD %_NN Veale_NNP -LRB-_-LRB- WordNet_NNP -RRB-_-RRB- -LRB-_-LRB- 38_CD -RRB-_-RRB- 43.0_CD %_NN Lin_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 27.3_CD %_NN Bicici_NNP &_CC Yuret_NNP -LRB-_-LRB- 4_CD -RRB-_-RRB- 44.0_CD %_NN Leacock_NNP &_CC Chodrow_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 31.3_CD %_NN VSM_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- 47.1_CD %_NN Hirst_NNP &_CC St.-Onge_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 32.1_CD %_NN PROPOSED_VBD 51.1_CD %_NN Resnik_NN -LRB-_-LRB- 33_CD -RRB-_-RRB-
bout_NN relations_NNS ,_, rather_RB than_IN simple_JJ features_NNS ._.
Although_IN this_DT approach_NN works_VBZ best_JJS when_WRB the_DT base_NN and_CC the_DT target_NN are_VBP rich_JJ in_IN higher-order_JJ causal_JJ structures_NNS ,_, it_PRP can_MD fail_VB when_WRB structures_NNS are_VBP missing_JJ or_CC flat_JJ =_JJ -_: =[_NN 39_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Turney_NNP et_FW al._FW -LRB-_-LRB- 35_CD -RRB-_-RRB- combined_VBN 13_CD independent_JJ modules_NNS by_IN considering_VBG the_DT weighted_JJ sum_NN of_IN the_DT outputs_NNS of_IN each_DT module_NN to_TO solve_VB SAT_NNP analogy_NN questions_NNS ._.
The_DT best_JJS performing_VBG individual_JJ module_NN was_VBD based_VBN on_IN th_DT
ves_VBZ an_DT SAT_NNP score_NN of_IN 51.1_CD and_CC reduces_VBZ the_DT time_NN taken_VBN to_TO answer_VB 374_CD questions_NNS by_IN LRA_NNP from_IN 9_CD days_NNS to_TO less_JJR than_IN 6_CD hours_NNS ._.
1_CD http:\/\/wordnet.princeton.edu\/_NN 2_CD ._.
RELATED_NNS WORK_VBP The_DT Structure_NN Mapping_NN Theory_NNP -LRB-_-LRB- SMT_NNP -RRB-_-RRB- =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_JJ -_: is_VBZ based_VBN on_IN the_DT premise_NN that_IN an_DT analogy_NN is_VBZ a_DT mapping_NN of_IN knowledge_NN from_IN one_CD domain_NN -LRB-_-LRB- base_NN -RRB-_-RRB- into_IN another_DT -LRB-_-LRB- target_NN -RRB-_-RRB- ,_, which_WDT conveys_VBZ that_IN a_DT system_NN of_IN relations_NNS known_VBN to_TO hold_VB in_IN the_DT base_NN also_RB holds_VBZ in_IN the_DT ta_NN
een_NN implicitly_RB stated_VBD semantic_JJ relations_NNS in_IN two_CD word_NN pairs_NNS ._.
Formally_RB ,_, given_VBN two_CD word_NN pairs_NNS ,_, -LRB-_-LRB- a_DT ,_, b_NN -RRB-_-RRB- and_CC -LRB-_-LRB- c_NN ,_, d_NN -RRB-_-RRB- ,_, we_PRP design_VBP a_DT function_NN ,_, relsim_NN -LRB-_-LRB- -LRB-_-LRB- a_DT ,_, b_NN -RRB-_-RRB- ,_, -LRB-_-LRB- c_NN ,_, d_NN -RRB-_-RRB- -RRB-_-RRB- ,_, that_WDT returns_VBZ a_DT similarity_NN score_NN in_IN the_DT range_NN =_JJ -_: =[_NN 0_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT proposed_VBN relational_JJ similarity_NN measure_NN first_RB extracts_VBZ implicitly_RB stated_VBN relations_NNS that_WDT exist_VBP between_IN the_DT two_CD words_NNS in_IN each_DT word_NN pair_NN ._.
The_DT measure_NN then_RB compares_VBZ the_DT extracted_VBN relations_NNS between_IN wo_MD
er_JJR than_IN simple_JJ features_NNS ._.
Although_IN this_DT approach_NN works_VBZ best_JJS when_WRB the_DT base_NN and_CC the_DT target_NN are_VBP rich_JJ in_IN higher-order_JJ causal_JJ structures_NNS ,_, it_PRP can_MD fail_VB when_WRB structures_NNS are_VBP missing_JJ or_CC flat_JJ -LRB-_-LRB- 39_CD -RRB-_-RRB- ._.
Turney_NNP et_FW al._FW =_SYM -_: =[_NN 35_CD -RRB-_-RRB- -_: =_SYM -_: combined_VBN 13_CD independent_JJ modules_NNS by_IN considering_VBG the_DT weighted_JJ sum_NN of_IN the_DT outputs_NNS of_IN each_DT module_NN to_TO solve_VB SAT_NNP analogy_NN questions_NNS ._.
The_DT best_JJS performing_VBG individual_JJ module_NN was_VBD based_VBN on_IN the_DT Vector_NNP Space_NNP Model_NNP
hat_NN words_NNS that_WDT occur_VBP in_IN the_DT same_JJ context_NN have_VBP similar_JJ meanings_NNS ._.
The_DT distributional_JJ hypothesis_NN has_VBZ been_VBN used_VBN in_IN various_JJ related_JJ tasks_NNS ,_, such_JJ as_IN identifying_VBG related_JJ words_NNS -LRB-_-LRB- 18_CD -RRB-_-RRB- ,_, discovering_VBG inference_NN rules_NNS =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC extracting_VBG paraphrases_NNS -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
If_IN two_CD lexical_JJ patterns_NNS are_VBP similarly_RB distributed_VBN over_IN a_DT set_NN of_IN word_NN pairs_NNS -LRB-_-LRB- i.e._FW occurs_VBZ with_IN the_DT same_JJ set_NN of_IN word_NN pairs_NNS -RRB-_-RRB- ,_, then_RB from_IN the_DT distributional_JJ hypothesis_NN it_PRP fo_FW
both_DT words_NNS are_VBP named_VBN entities_NNS -LRB-_-LRB- e.g._FW ,_, company_NN names_NNS ,_, personal_JJ names_NNS ,_, locations_NNS ,_, etc._NN -RRB-_-RRB- is_VBZ even_RB more_RBR difficult_JJ because_IN such_JJ words_NNS are_VBP not_RB well_RB covered_VBN by_IN manually_RB created_VBN dictionaries_NNS such_JJ as_IN WordNet_NNP 1_CD =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
As_IN described_VBN herein_RB ,_, we_PRP propose_VBP a_DT relational_JJ similarity_NN measure_NN that_WDT uses_VBZ a_DT Web_NN search_NN engine_NN to_TO measure_VB the_DT similarity_NN between_IN implicitly_RB stated_VBN semantic_JJ relations_NNS in_IN two_CD word_NN pairs_NNS ._.
Formally_RB ,_, give_VB
egate_JJ search_NN results_NNS to_TO circumvent_VB this_DT limitation_NN ._.
3.3_CD Extracting_VBG Lexical_JJ Patterns_NN Lexical_JJ syntactic_JJ patterns_NNS have_VBP been_VBN used_VBN in_IN various_JJ natural_JJ language_NN processing_NN tasks_NNS such_JJ as_IN extracting_VBG hypernyms_NN =_JJ -_: =[_NN 17_CD ,_, 30_CD -RRB-_-RRB- -_: =_JJ -_: ,_, or_CC meronyms_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, question_NN answering_NN -LRB-_-LRB- 28_CD -RRB-_-RRB- ,_, and_CC paraphrase_NN extraction_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
Following_VBG these_DT previous_JJ works_NNS ,_, we_PRP present_VBP a_DT shallow_JJ lexical_JJ pattern_NN extraction_NN algorithm_NN to_TO represent_VB the_DT semantic_JJ relations_NNS
e_LS ,_, given_VBN the_DT relation_NN ,_, ACQUIRER-ACQUIREE_NN ,_, a_DT relation_NN extraction_NN system_NN must_MD extract_VB the_DT instance_NN -LRB-_-LRB- Google_NNP ,_, YouTube_NNP -RRB-_-RRB- from_IN the_DT sentence_NN Google_NNP completed_VBD the_DT acquisition_NN of_IN YouTube_NNP ._.
Bootstrapping_VBG methods_NNS =_JJ -_: =[_NN 25_CD ,_, 6_CD ,_, 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT require_VBP a_DT few_JJ seeds_NNS -LRB-_-LRB- ca._FW 10_CD pairs_NNS of_IN instances_NNS per_IN relation_NN -RRB-_-RRB- have_VBP extracted_VBN numerous_JJ candidate_NN instance_NN pairs_NNS from_IN a_DT text_NN corpus_NN ._.
Given_VBN a_DT set_NN of_IN candidate_NN instance_NN pairs_NNS ,_, a_DT relational_JJ similari_NN
as_IN personal_JJ names_NNS ,_, organizations_NNS and_CC locations_NNS ,_, which_WDT becomes_VBZ problematic_JJ when_WRB using_VBG this_DT method_NN to_TO measure_VB relational_JJ similarity_NN between_IN named_VBN entities_NNS ._.
Using_VBG a_DT relational_JJ similarity_NN measure_NN ,_, Turney_NN =_JJ -_: =[_NN 32_CD -RRB-_-RRB- -_: =_SYM -_: proposed_VBD an_DT unsupervised_JJ learning_NN algorithm_NN to_TO extract_NN patterns_NNS that_WDT express_VBP implicit_JJ semantic_JJ relations_NNS from_IN a_DT corpus_NN ._.
His_PRP$ method_NN produces_VBZ a_DT ranked_VBN set_NN of_IN lexical_JJ patterns_NNS that_WDT unambiguously_RB describ_VBP
e_LS ,_, given_VBN the_DT relation_NN ,_, ACQUIRER-ACQUIREE_NN ,_, a_DT relation_NN extraction_NN system_NN must_MD extract_VB the_DT instance_NN -LRB-_-LRB- Google_NNP ,_, YouTube_NNP -RRB-_-RRB- from_IN the_DT sentence_NN Google_NNP completed_VBD the_DT acquisition_NN of_IN YouTube_NNP ._.
Bootstrapping_VBG methods_NNS =_JJ -_: =[_NN 25_CD ,_, 6_CD ,_, 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT require_VBP a_DT few_JJ seeds_NNS -LRB-_-LRB- ca._FW 10_CD pairs_NNS of_IN instances_NNS per_IN relation_NN -RRB-_-RRB- have_VBP extracted_VBN numerous_JJ candidate_NN instance_NN pairs_NNS from_IN a_DT text_NN corpus_NN ._.
Given_VBN a_DT set_NN of_IN candidate_NN instance_NN pairs_NNS ,_, a_DT relational_JJ similari_NN
istributional_JJ hypothesis_NN states_NNS that_IN words_NNS that_WDT occur_VBP in_IN the_DT same_JJ context_NN have_VBP similar_JJ meanings_NNS ._.
The_DT distributional_JJ hypothesis_NN has_VBZ been_VBN used_VBN in_IN various_JJ related_JJ tasks_NNS ,_, such_JJ as_IN identifying_VBG related_JJ words_NNS =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_JJ -_: ,_, discovering_VBG inference_NN rules_NNS -LRB-_-LRB- 19_CD -RRB-_-RRB- ,_, and_CC extracting_VBG paraphrases_NNS -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
If_IN two_CD lexical_JJ patterns_NNS are_VBP similarly_RB distributed_VBN over_IN a_DT set_NN of_IN word_NN pairs_NNS -LRB-_-LRB- i.e._FW occurs_VBZ with_IN the_DT same_JJ set_NN of_IN word_NN pairs_NNS -RRB-_-RRB- ,_, then_RB from_IN th_DT
te_IN instance_NN pairs_NNS with_IN high_JJ relational_JJ similarity_NN with_IN the_DT seed_NN pairs_NNS can_MD then_RB be_VB selected_VBN as_IN the_DT correct_JJ instances_NNS of_IN a_DT relation_NN ._.
Relational_JJ similarity_NN measures_NNS have_VBP been_VBN used_VBN to_TO find_VB word_NN analogies_NNS =_JJ -_: =[_NN 10_CD ,_, 24_CD ,_, 31_CD ,_, 33_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Word_NN analogy_NN questions_NNS have_VBP been_VBN used_VBN from_IN the_DT Scholastic_NNP Aptitude_NNP Test_NNP -LRB-_-LRB- SAT_NNP ;_: Educational_NNP Testing_NNP Service_NNP -RRB-_-RRB- to_TO benchmark_JJ relational_JJ similarity_NN measures_NNS ._.
An_DT SAT_NNP word_NN analogy_NN question_NN consists_VBZ of_IN a_DT ste_NN
se_FW objects_NNS ._.
Measuring_VBG the_DT similarity_NN between_IN semantic_JJ relations_NNS is_VBZ an_DT important_JJ intermediate_JJ step_NN in_IN various_JJ tasks_NNS in_IN information_NN retrieval_NN and_CC natural_JJ language_NN processing_NN such_JJ as_IN relation_NN extraction_NN =_JJ -_: =[_NN 7_CD ,_, 8_CD ,_, 40_CD -RRB-_-RRB- -_: =_JJ -_: ,_, in_IN which_WDT the_DT goal_NN is_VBZ to_TO retrieve_VB instances_NNS of_IN a_DT given_VBN relation_NN ._.
For_IN example_NN ,_, given_VBN the_DT relation_NN ,_, ACQUIRER-ACQUIREE_NN ,_, a_DT relation_NN extraction_NN system_NN must_MD extract_VB the_DT instance_NN -LRB-_-LRB- Google_NNP ,_, YouTube_NNP -RRB-_-RRB- from_IN the_DT
measure_NN relational_JJ similarity_NN is_VBZ two-fold_JJ ._.
First_JJ ,_, Mahalanobis_JJ distance_NN can_MD be_VB learned_VBN from_IN a_DT few_JJ data_NNS points_NNS ,_, and_CC efficient_JJ algorithms_NNS that_WDT can_MD scale_VB well_RB to_TO high-dimensional_JJ feature_NN spaces_NNS are_VBP known_VBN =_JJ -_: =[_NN 13_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Second_RB ,_, unlike_IN Euclidean_JJ distance_NN ,_, Mahalanobis_NNP distance_NN does_VBZ not_RB assume_VB that_IN features_NNS are_VBP independent_JJ ._.
This_DT is_VBZ particularly_RB important_JJ for_IN relational_JJ similarity_NN measures_NNS because_IN semantic_JJ relations_NNS ar_IN
he_PRP KL_VBD divergence_NN between_IN two_CD multivariate_JJ Gaussians_NNS can_MD be_VB expressed_VBN as_IN the_DT convex_NN combination_NN of_IN a_DT Mahalanobis_NNP distance_NN between_IN mean_NN vectors_NNS and_CC the_DT LogDet_NNP divergence_NN between_IN the_DT covariance_NN matrices_NNS =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Therefore_RB ,_, assuming_VBG that_IN the_DT means_NNS of_IN the_DT Gaussians_NNPS are_VBP equal_JJ ,_, we_PRP have_VBP KL_NN -LRB-_-LRB- p_NN -LRB-_-LRB- x_NN ;_: I_PRP -RRB-_-RRB- ‖_CD p_NN -LRB-_-LRB- x_NN ;_: A_NN -RRB-_-RRB- -RRB-_-RRB- =_JJ 1_CD 2_CD Dld_NN -LRB-_-LRB- A_NN ,_, I_NN -RRB-_-RRB- ._.
-LRB-_-LRB- 4_LS -RRB-_-RRB- Here_RB ,_, Dld_NN -LRB-_-LRB- A_NN ,_, B_NN -RRB-_-RRB- is_VBZ the_DT LogDet_NNP divergence_NN of_IN n_NN ×_CD n_NN positive-definite_JJ matrices_NNS A_NNP ,_, B._NNP It_PRP
the_DT choice_NN word_NN pair_NN with_IN the_DT highest_JJS relational_JJ similarity_NN as_IN the_DT answer_NN ._.
An_DT interesting_JJ application_NN of_IN relational_JJ similarity_NN in_IN information_NN retrieval_NN is_VBZ to_TO search_VB using_VBG implicitly_RB stated_VBN analogies_NNS =_JJ -_: =[_NN 21_CD ,_, 37_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, the_DT query_NN ``_`` Muslim_JJ Church_NN ''_'' is_VBZ expected_VBN to_TO return_VB ``_`` mosque_NN ''_'' ,_, and_CC the_DT query_NN ``_`` Hindu_NNP bible_NN ''_'' is_VBZ expected_VBN to_TO return_VB ``_`` the_DT Vedas_NNPS ''_'' ._.
These_DT queries_NNS can_MD be_VB formalized_VBN as_IN word_NN pairs_NNS :_: -LRB-_-LRB- Christian_NNP ,_, 651W_NNP
se_FW objects_NNS ._.
Measuring_VBG the_DT similarity_NN between_IN semantic_JJ relations_NNS is_VBZ an_DT important_JJ intermediate_JJ step_NN in_IN various_JJ tasks_NNS in_IN information_NN retrieval_NN and_CC natural_JJ language_NN processing_NN such_JJ as_IN relation_NN extraction_NN =_JJ -_: =[_NN 7_CD ,_, 8_CD ,_, 40_CD -RRB-_-RRB- -_: =_JJ -_: ,_, in_IN which_WDT the_DT goal_NN is_VBZ to_TO retrieve_VB instances_NNS of_IN a_DT given_VBN relation_NN ._.
For_IN example_NN ,_, given_VBN the_DT relation_NN ,_, ACQUIRER-ACQUIREE_NN ,_, a_DT relation_NN extraction_NN system_NN must_MD extract_VB the_DT instance_NN -LRB-_-LRB- Google_NNP ,_, YouTube_NNP -RRB-_-RRB- from_IN the_DT
that_WDT appears_VBZ between_IN the_DT queried_VBN words_NNS -RRB-_-RRB- ._.
Moreover_RB ,_, the_DT consideration_NN of_IN gaps_NNS enables_VBZ us_PRP to_TO capture_VB relations_NNS between_IN distant_JJ words_NNS in_IN a_DT snippet_NN ._.
We_PRP use_VBP a_DT modified_VBN version_NN of_IN the_DT prefixspan_JJ algorithm_NN =_JJ -_: =[_NN 26_CD -RRB-_-RRB- -_: =_SYM -_: to_TO generate_VB subsequences_NNS ._.
The_DT conditions_NNS in_IN Step_NN 2_CD are_VBP used_VBN to_TO prune_VB the_DT search_NN space_NN ,_, thereby_RB reducing_VBG the_DT number_NN of_IN generated_VBN subsequences_NNS in_IN prefixspan_NN ._.
For_IN example_NN ,_, some_DT patterns_NNS extracted_VBD form_NN t_NN
ble_NN to_TO use_VB Formula_NN 1_CD directly_RB to_TO compare_VB word_NN pairs_NNS ._.
However_RB ,_, if_IN one_CD wants_VBZ to_TO convert_VB distance_NN values_NNS ranging_VBG in_IN -LRB-_-LRB- 0_CD ,_, +_CC ∞_NN -RRB-_-RRB- to_TO similarity_NN scores_NNS ranging_VBG in_IN -LRB-_-LRB- 0_CD ,_, 1_CD -RRB-_-RRB- ,_, it_PRP can_MD be_VB done_VBN using_VBG sigmoid_JJ functions_NNS =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Algorithm_NN 2_CD Information-theoretic_JJ metric_JJ learning_NN ._.
Input_NN :_: X_NN ,_, -LRB-_-LRB- d_FW ×_FW n_NN matrix_NN -RRB-_-RRB- ;_: S_NN ,_, set_VBN of_IN similar_JJ pairs_NNS ;_: D_NN ,_, set_VBN of_IN dissimilar_JJ pairs_NNS ;_: u_NN ,_, l_NN :_: distance_NN thresholds_NNS ;_: I_NN ,_, identity_NN matrix_NN ;_: γ_NN ,_, slack_NN parameter_NN ;_: c_NN
ign_RB higher_JJR similarity_NN scores_NNS to_TO word_NN pairs_NNS with_IN similar_JJ implicit_JJ relations_NNS ._.
However_RB ,_, the_DT classification_NN accuracy_NN does_VBZ not_RB evaluate_VB the_DT relative_JJ rankings_NNS of_IN similarity_NN scores_NNS ._.
We_PRP use_VBP average_JJ precision_NN =_JJ -_: =[_NN 29_CD -RRB-_-RRB- -_: =_SYM -_: to_TO evaluate_VB the_DT top_JJ k_NN most_RBS similar_JJ entity_NN pairs_NNS to_TO a_DT given_VBN entity_NN pair_NN ._.
Average_JJ precision_NN integrates_VBZ the_DT precision_NN at_IN different_JJ ranks_NNS ._.
It_PRP is_VBZ frequently_RB used_VBN as_IN an_DT evaluation_NN measure_NN in_IN retrieval_NN task_NN
egate_JJ search_NN results_NNS to_TO circumvent_VB this_DT limitation_NN ._.
3.3_CD Extracting_VBG Lexical_JJ Patterns_NN Lexical_JJ syntactic_JJ patterns_NNS have_VBP been_VBN used_VBN in_IN various_JJ natural_JJ language_NN processing_NN tasks_NNS such_JJ as_IN extracting_VBG hypernyms_NN =_JJ -_: =[_NN 17_CD ,_, 30_CD -RRB-_-RRB- -_: =_JJ -_: ,_, or_CC meronyms_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, question_NN answering_NN -LRB-_-LRB- 28_CD -RRB-_-RRB- ,_, and_CC paraphrase_NN extraction_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
Following_VBG these_DT previous_JJ works_NNS ,_, we_PRP present_VBP a_DT shallow_JJ lexical_JJ pattern_NN extraction_NN algorithm_NN to_TO represent_VB the_DT semantic_JJ relations_NNS
:_: Performance_NNP on_IN the_DT SAT_NNP dataset_NN ._.
Algorithm_NN score_NN Algorithm_NN score_NN Random_NNP guessing_VBG 20.0_CD %_NN LSA+P_NN redictation_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- 42.0_CD %_NN Jiang_NNP &_CC Conrath_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 27.3_CD %_NN Veale_NNP -LRB-_-LRB- WordNet_NNP -RRB-_-RRB- -LRB-_-LRB- 38_CD -RRB-_-RRB- 43.0_CD %_NN Lin_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 27.3_CD %_NN Bicici_NNP &_CC Yuret_NNP =_SYM -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: 44.0_CD %_NN Leacock_NNP &_CC Chodrow_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 31.3_CD %_NN VSM_NN -LRB-_-LRB- 34_CD -RRB-_-RRB- 47.1_CD %_NN Hirst_NNP &_CC St.-Onge_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 32.1_CD %_NN PROPOSED_VBD 51.1_CD %_NN Resnik_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- 33.2_CD %_NN Pertinence_NN -LRB-_-LRB- 32_CD -RRB-_-RRB- 53.5_CD %_NN PMI-IR_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- 35.0_CD %_NN LRA_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- 56.1_CD %_NN SVM_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- 40.1_CD %_NN Human_NNP 57.0_CD %_NN The_DT fou_NN
ers_NNPS contains_VBZ the_DT most_RBS common_JJ relations_NNS in_IN the_DT dataset_NN ._.
3.5_CD Measuring_VBG Relational_JJ Similarity_NN Evidence_NN from_IN psychological_JJ experiments_NNS suggest_VBP that_IN similarity_NN can_MD be_VB context-dependent_JJ and_CC even_RB asymmetric_JJ =_JJ -_: =[_NN 36_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Human_JJ subjects_NNS have_VBP reportedly_RB assigned_VBN different_JJ similarity_NN ratings_NNS to_TO word_NN pairs_NNS when_WRB the_DT two_CD words_NNS were_VBD presented_VBN in_IN reverse_JJ order_NN ._.
However_RB ,_, experimental_JJ results_NNS investigating_VBG the_DT effects_NNS of_IN asym_NN
o_NN circumvent_VB this_DT limitation_NN ._.
3.3_CD Extracting_VBG Lexical_JJ Patterns_NN Lexical_JJ syntactic_JJ patterns_NNS have_VBP been_VBN used_VBN in_IN various_JJ natural_JJ language_NN processing_NN tasks_NNS such_JJ as_IN extracting_VBG hypernyms_NNS -LRB-_-LRB- 17_CD ,_, 30_CD -RRB-_-RRB- ,_, or_CC meronyms_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_JJ -_: ,_, question_NN answering_NN -LRB-_-LRB- 28_CD -RRB-_-RRB- ,_, and_CC paraphrase_NN extraction_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
Following_VBG these_DT previous_JJ works_NNS ,_, we_PRP present_VBP a_DT shallow_JJ lexical_JJ pattern_NN extraction_NN algorithm_NN to_TO represent_VB the_DT semantic_JJ relations_NNS between_IN two_CD word_NN
ers_NNPS contains_VBZ the_DT most_RBS common_JJ relations_NNS in_IN the_DT dataset_NN ._.
3.5_CD Measuring_VBG Relational_JJ Similarity_NN Evidence_NN from_IN psychological_JJ experiments_NNS suggest_VBP that_IN similarity_NN can_MD be_VB context-dependent_JJ and_CC even_RB asymmetric_JJ =_JJ -_: =[_NN 36_CD ,_, 22_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Human_JJ subjects_NNS have_VBP reportedly_RB assigned_VBN different_JJ similarity_NN ratings_NNS to_TO word_NN pairs_NNS when_WRB the_DT two_CD words_NNS were_VBD presented_VBN in_IN reverse_JJ order_NN ._.
However_RB ,_, experimental_JJ results_NNS investigating_VBG the_DT effects_NNS of_IN asym_NN
score_NN Algorithm_NN score_NN Random_NNP guessing_VBG 20.0_CD %_NN LSA+P_NN redictation_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- 42.0_CD %_NN Jiang_NNP &_CC Conrath_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 27.3_CD %_NN Veale_NNP -LRB-_-LRB- WordNet_NNP -RRB-_-RRB- -LRB-_-LRB- 38_CD -RRB-_-RRB- 43.0_CD %_NN Lin_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 27.3_CD %_NN Bicici_NNP &_CC Yuret_NNP -LRB-_-LRB- 4_CD -RRB-_-RRB- 44.0_CD %_NN Leacock_NNP &_CC Chodrow_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 31.3_CD %_NN VSM_NN =_JJ -_: =[_NN 34_CD -RRB-_-RRB- -_: =_SYM -_: 47.1_CD %_NN Hirst_NNP &_CC St.-Onge_NNP -LRB-_-LRB- 33_CD -RRB-_-RRB- 32.1_CD %_NN PROPOSED_VBD 51.1_CD %_NN Resnik_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- 33.2_CD %_NN Pertinence_NN -LRB-_-LRB- 32_CD -RRB-_-RRB- 53.5_CD %_NN PMI-IR_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- 35.0_CD %_NN LRA_NN -LRB-_-LRB- 33_CD -RRB-_-RRB- 56.1_CD %_NN SVM_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- 40.1_CD %_NN Human_NNP 57.0_CD %_NN The_DT four_CD methods_NNS described_VBN above_RB presented_VBN for_IN comp_NN
the_DT choice_NN word_NN pair_NN with_IN the_DT highest_JJS relational_JJ similarity_NN as_IN the_DT answer_NN ._.
An_DT interesting_JJ application_NN of_IN relational_JJ similarity_NN in_IN information_NN retrieval_NN is_VBZ to_TO search_VB using_VBG implicitly_RB stated_VBN analogies_NNS =_JJ -_: =[_NN 21_CD ,_, 37_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN example_NN ,_, the_DT query_NN ``_`` Muslim_JJ Church_NN ''_'' is_VBZ expected_VBN to_TO return_VB ``_`` mosque_NN ''_'' ,_, and_CC the_DT query_NN ``_`` Hindu_NNP bible_NN ''_'' is_VBZ expected_VBN to_TO return_VB ``_`` the_DT Vedas_NNPS ''_'' ._.
These_DT queries_NNS can_MD be_VB formalized_VBN as_IN word_NN pairs_NNS :_: -LRB-_-LRB- Christian_NNP ,_, 651W_NNP
se_FW objects_NNS ._.
Measuring_VBG the_DT similarity_NN between_IN semantic_JJ relations_NNS is_VBZ an_DT important_JJ intermediate_JJ step_NN in_IN various_JJ tasks_NNS in_IN information_NN retrieval_NN and_CC natural_JJ language_NN processing_NN such_JJ as_IN relation_NN extraction_NN =_JJ -_: =[_NN 7_CD ,_, 8_CD ,_, 40_CD -RRB-_-RRB- -_: =_JJ -_: ,_, in_IN which_WDT the_DT goal_NN is_VBZ to_TO retrieve_VB instances_NNS of_IN a_DT given_VBN relation_NN ._.
For_IN example_NN ,_, given_VBN the_DT relation_NN ,_, ACQUIRER-ACQUIREE_NN ,_, a_DT relation_NN extraction_NN system_NN must_MD extract_VB the_DT instance_NN -LRB-_-LRB- Google_NNP ,_, YouTube_NNP -RRB-_-RRB- from_IN the_DT
tion_NN ._.
3.3_CD Extracting_VBG Lexical_JJ Patterns_NN Lexical_JJ syntactic_JJ patterns_NNS have_VBP been_VBN used_VBN in_IN various_JJ natural_JJ language_NN processing_NN tasks_NNS such_JJ as_IN extracting_VBG hypernyms_NNS -LRB-_-LRB- 17_CD ,_, 30_CD -RRB-_-RRB- ,_, or_CC meronyms_NNS -LRB-_-LRB- 2_CD -RRB-_-RRB- ,_, question_NN answering_NN =_JJ -_: =[_NN 28_CD -RRB-_-RRB- -_: =_JJ -_: ,_, and_CC paraphrase_NN extraction_NN -LRB-_-LRB- 3_CD -RRB-_-RRB- ._.
Following_VBG these_DT previous_JJ works_NNS ,_, we_PRP present_VBP a_DT shallow_JJ lexical_JJ pattern_NN extraction_NN algorithm_NN to_TO represent_VB the_DT semantic_JJ relations_NNS between_IN two_CD words_NNS ._.
The_DT proposed_VBN method_NN re_NN
e_LS ,_, given_VBN the_DT relation_NN ,_, ACQUIRER-ACQUIREE_NN ,_, a_DT relation_NN extraction_NN system_NN must_MD extract_VB the_DT instance_NN -LRB-_-LRB- Google_NNP ,_, YouTube_NNP -RRB-_-RRB- from_IN the_DT sentence_NN Google_NNP completed_VBD the_DT acquisition_NN of_IN YouTube_NNP ._.
Bootstrapping_VBG methods_NNS =_JJ -_: =[_NN 25_CD ,_, 6_CD ,_, 14_CD -RRB-_-RRB- -_: =_JJ -_: ,_, which_WDT require_VBP a_DT few_JJ seeds_NNS -LRB-_-LRB- ca._FW 10_CD pairs_NNS of_IN instances_NNS per_IN relation_NN -RRB-_-RRB- have_VBP extracted_VBN numerous_JJ candidate_NN instance_NN pairs_NNS from_IN a_DT text_NN corpus_NN ._.
Given_VBN a_DT set_NN of_IN candidate_NN instance_NN pairs_NNS ,_, a_DT relational_JJ similari_NN
te_IN instance_NN pairs_NNS with_IN high_JJ relational_JJ similarity_NN with_IN the_DT seed_NN pairs_NNS can_MD then_RB be_VB selected_VBN as_IN the_DT correct_JJ instances_NNS of_IN a_DT relation_NN ._.
Relational_JJ similarity_NN measures_NNS have_VBP been_VBN used_VBN to_TO find_VB word_NN analogies_NNS =_JJ -_: =[_NN 10_CD ,_, 24_CD ,_, 31_CD ,_, 33_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Word_NN analogy_NN questions_NNS have_VBP been_VBN used_VBN from_IN the_DT Scholastic_NNP Aptitude_NNP Test_NNP -LRB-_-LRB- SAT_NNP ;_: Educational_NNP Testing_NNP Service_NNP -RRB-_-RRB- to_TO benchmark_JJ relational_JJ similarity_NN measures_NNS ._.
An_DT SAT_NNP word_NN analogy_NN question_NN consists_VBZ of_IN a_DT ste_NN
measure_NN relational_JJ similarity_NN is_VBZ two-fold_JJ ._.
First_JJ ,_, Mahalanobis_JJ distance_NN can_MD be_VB learned_VBN from_IN a_DT few_JJ data_NNS points_NNS ,_, and_CC efficient_JJ algorithms_NNS that_WDT can_MD scale_VB well_RB to_TO high-dimensional_JJ feature_NN spaces_NNS are_VBP known_VBN =_JJ -_: =[_NN 13_CD ,_, 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Second_RB ,_, unlike_IN Euclidean_JJ distance_NN ,_, Mahalanobis_NNP distance_NN does_VBZ not_RB assume_VB that_IN features_NNS are_VBP independent_JJ ._.
This_DT is_VBZ particularly_RB important_JJ for_IN relational_JJ similarity_NN measures_NNS because_IN semantic_JJ relations_NNS ar_IN
te_IN instance_NN pairs_NNS with_IN high_JJ relational_JJ similarity_NN with_IN the_DT seed_NN pairs_NNS can_MD then_RB be_VB selected_VBN as_IN the_DT correct_JJ instances_NNS of_IN a_DT relation_NN ._.
Relational_JJ similarity_NN measures_NNS have_VBP been_VBN used_VBN to_TO find_VB word_NN analogies_NNS =_JJ -_: =[_NN 10_CD ,_, 24_CD ,_, 31_CD ,_, 33_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Word_NN analogy_NN questions_NNS have_VBP been_VBN used_VBN from_IN the_DT Scholastic_NNP Aptitude_NNP Test_NNP -LRB-_-LRB- SAT_NNP ;_: Educational_NNP Testing_NNP Service_NNP -RRB-_-RRB- to_TO benchmark_JJ relational_JJ similarity_NN measures_NNS ._.
An_DT SAT_NNP word_NN analogy_NN question_NN consists_VBZ of_IN a_DT ste_NN
te_IN instance_NN pairs_NNS with_IN high_JJ relational_JJ similarity_NN with_IN the_DT seed_NN pairs_NNS can_MD then_RB be_VB selected_VBN as_IN the_DT correct_JJ instances_NNS of_IN a_DT relation_NN ._.
Relational_JJ similarity_NN measures_NNS have_VBP been_VBN used_VBN to_TO find_VB word_NN analogies_NNS =_JJ -_: =[_NN 10_CD ,_, 24_CD ,_, 31_CD ,_, 33_CD ,_, 38_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Word_NN analogy_NN questions_NNS have_VBP been_VBN used_VBN from_IN the_DT Scholastic_NNP Aptitude_NNP Test_NNP -LRB-_-LRB- SAT_NNP ;_: Educational_NNP Testing_NNP Service_NNP -RRB-_-RRB- to_TO benchmark_JJ relational_JJ similarity_NN measures_NNS ._.
An_DT SAT_NNP word_NN analogy_NN question_NN consists_VBZ of_IN a_DT ste_NN
measures_NNS have_VBP been_VBN applied_VBN in_IN natural_JJ language_NN processing_NN tasks_NNS such_JJ as_IN generating_VBG word_NN analogies_NNS -LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, and_CC classifying_VBG noun-modifier_JJ compounds_NNS based_VBN on_IN the_DT relation_NN between_IN the_DT head_NN and_CC the_DT modifier_NN =_JJ -_: =[_NN 33_CD ,_, 24_CD ,_, 9_CD ,_, 24_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Davidov_NNP and_CC Rappoport_NNP -LRB-_-LRB- 10_CD -RRB-_-RRB- proposed_VBD an_DT unsupervised_JJ algorithm_NN to_TO discover_VB general_JJ semantic_JJ relations_NNS that_WDT pertain_VBP between_IN lexical_JJ items_NNS ._.
They_PRP represent_VBP a_DT semantic_JJ relation_NN with_IN a_DT cluster_NN of_IN patterns_NNS
