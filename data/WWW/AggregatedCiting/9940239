A_DT contextual-bandit_JJ approach_NN to_TO personalized_JJ news_NN article_NN recommendation_NN
Personalized_VBN web_NN services_NNS strive_VBP to_TO adapt_VB their_PRP$ services_NNS -LRB-_-LRB- advertisements_NNS ,_, news_NN articles_NNS ,_, etc._NN -RRB-_-RRB- to_TO individual_JJ users_NNS by_IN making_VBG use_NN of_IN both_CC content_NN and_CC user_NN information_NN ._.
Despite_IN a_DT few_JJ recent_JJ advances_NNS ,_, this_DT problem_NN remains_VBZ challenging_JJ for_IN at_IN least_JJS two_CD reasons_NNS ._.
First_RB ,_, web_NN service_NN is_VBZ featured_VBN with_IN dynamically_RB changing_VBG pools_NNS of_IN content_NN ,_, rendering_VBG traditional_JJ collaborative_JJ filtering_VBG methods_NNS inapplicable_JJ ._.
Second_RB ,_, the_DT scale_NN of_IN most_JJS web_NN services_NNS of_IN practical_JJ interest_NN calls_VBZ for_IN solutions_NNS that_WDT are_VBP both_DT fast_JJ in_IN learning_NN and_CC computation_NN ._.
In_IN this_DT work_NN ,_, we_PRP model_VBP personalized_JJ recommendation_NN of_IN news_NN articles_NNS as_IN a_DT contextual_JJ bandit_NN problem_NN ,_, a_DT principled_JJ approach_NN in_IN which_WDT a_DT learning_NN algorithm_NN sequentially_RB selects_VBZ articles_NNS to_TO serve_VB users_NNS based_VBN on_IN contextual_JJ information_NN about_IN the_DT users_NNS and_CC articles_NNS ,_, while_IN simultaneously_RB adapting_VBG its_PRP$ article-selection_JJ strategy_NN based_VBN on_IN user-click_JJ feedback_NN to_TO maximize_VB total_JJ user_NN clicks_NNS ._.
The_DT contributions_NNS of_IN this_DT work_NN are_VBP three-fold_JJ ._.
First_RB ,_, we_PRP propose_VBP a_DT new_JJ ,_, general_JJ contextual_JJ bandit_NN algorithm_NN that_WDT is_VBZ computationally_RB efficient_JJ and_CC well_RB motivated_VBN from_IN learning_VBG theory_NN ._.
Second_RB ,_, we_PRP argue_VBP that_IN any_DT bandit_NN algorithm_NN can_MD be_VB reliably_RB evaluated_VBN offline_NN using_VBG previously_RB recorded_VBN random_JJ traffic_NN ._.
Finally_RB ,_, using_VBG this_DT offline_JJ evaluation_NN method_NN ,_, we_PRP successfully_RB applied_VBD our_PRP$ new_JJ algorithm_NN to_TO a_DT Yahoo_NNP !_.
Front_NN Page_NNP Today_NNP Module_NNP dataset_NN containing_VBG over_IN 33_CD million_CD events_NNS ._.
Results_NNS showed_VBD a_DT 12.5_CD %_NN click_VBP lift_NN compared_VBN to_TO a_DT standard_JJ context-free_JJ bandit_NN algorithm_NN ,_, and_CC the_DT advantage_NN becomes_VBZ even_RB greater_JJR when_WRB data_NNS gets_VBZ more_RBR scarce_JJ ._.
tic_JJ ._.
Contentbased_JJ filtering_VBG helps_VBZ to_TO identify_VB new_JJ items_NNS which_WDT well_RB match_VBP anexisting_VBG user_NN 's_POS consumption_NN profile_NN ,_, but_CC the_DT recommended_VBN items_NNS are_VBP always_RB similar_JJ to_TO the_DT items_NNS previously_RB taken_VBN by_IN the_DT user_NN =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Hybrid_NN approaches_NNS -LRB-_-LRB- 11_CD -RRB-_-RRB- have_VBP been_VBN developed_VBN by_IN combining_VBG two_CD or_CC more_JJR recommendation_NN techniques_NNS ;_: for_IN example_NN ,_, the_DT inability_NN of_IN collaborative_JJ filtering_VBG to_TO recommend_VB new_JJ items_NNS is_VBZ commonly_RB alleviated_VBN by_IN
ee_NN of_IN Õ_NN -LRB-_-LRB- T_NN 2\/3_CD -RRB-_-RRB- ._.
Algorithms_NNS with_IN stronger_JJR regret_NN guarantees_NNS may_MD be_VB designed_VBN under_IN various_JJ modeling_NN assumptions_NNS about_IN the_DT bandit_NN ._.
Assuming_VBG the_DT expected_VBN payoff_NN of_IN an_DT arm_NN is_VBZ linear_JJ in_IN its_PRP$ features_NNS ,_, Auer_NN =_JJ -_: =[_NN 6_CD -RRB-_-RRB- -_: =_SYM -_: describes_VBZ the_DT LinRel_NNP algorithm_NN that_WDT is_VBZ essentially_RB a_DT UCB-type_JJ approach_NN and_CC shows_VBZ that_IN one_CD of_IN its_PRP$ variants_NNS has_VBZ a_DT regret_NN of_IN Õ_NN -LRB-_-LRB- √_CD T_NN -RRB-_-RRB- ,_, a_DT significant_JJ improvement_NN over_IN earlier_JJR algorithms_NNS -LRB-_-LRB- 1_LS -RRB-_-RRB- ._.
Finally_RB ,_, we_PRP not_RB
ret_NN ,_, RA_NN -LRB-_-LRB- T_NN -RRB-_-RRB- \/_: T_NN ,_, converges_VBZ to_TO 0_CD with_IN probability_NN 1_CD ._.
In_IN contrast_NN to_TO the_DT unguided_JJ exploration_NN strategy_NN adopted_VBN by_IN ǫgreedy_NN ,_, another_DT class_NN of_IN algorithms_NNS generally_RB known_VBN as_IN upper_JJ confidence_NN bound_VBD algorithms_NNS =_JJ -_: =[_NN 4_CD ,_, 7_CD ,_, 17_CD -RRB-_-RRB- -_: =_SYM -_: use_VB a_DT smarter_RBR way_NN to_TO balance_VB exploration_NN and_CC exploitation_NN ._.
Specifically_RB ,_, in_IN trial_NN t_NN ,_, these_DT algorithms_NNS estimate_VBP both_CC the_DT mean_JJ payoff_NN ˆµt_NN ,_, a_DT of_IN each_DT arm_NN a_DT as_RB well_RB as_IN a_DT corresponding_JJ confidence_NN interval_NN
ent-based_JJ filtering_VBG and_CC hybrid_NN approaches_NNS ,_, can_MD provide_VB meaningful_JJ recommendations_NNS at_IN an_DT individual_JJ level_NN by_IN leveraging_VBG users_NNS '_POS interests_NNS as_IN demonstrated_VBN by_IN their_PRP$ past_JJ activity_NN ._.
Collaborative_JJ filtering_VBG =_JJ -_: =[_NN 25_CD -RRB-_-RRB- -_: =_JJ -_: ,_, by_IN recognizing_VBG similarities_NNS across_IN users_NNS based_VBN on_IN their_PRP$ consumption_NN history_NN ,_, provides_VBZ a_DT good_JJ recommendation_NN solution_NN to_TO the_DT scenarios_NNS where_WRB overlap_VBP in_IN historical_JJ consumption_NN across_IN users_NNS is_VBZ relative_JJ
er_IN a_DT purely_RB exploring_VBG nor_CC a_DT purely_RB exploiting_VBG algorithm_NN works_VBZ best_JJS in_IN general_JJ ,_, and_CC a_DT good_JJ tradeoff_NN is_VBZ needed_VBN ._.
The_DT context-free_JJ K-armed_JJ bandit_NN problem_NN has_VBZ been_VBN studied_VBN by_IN statisticians_NNS for_IN a_DT long_JJ time_NN =_JJ -_: =[_NN 9_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT simplest_JJS and_CC most_JJS straightforward_JJ algorithms_NNS is_VBZ ǫ-greedy_NN ._.
In_IN each_DT trial_NN t_NN ,_, this_DT algorithm_NN first_RB estimates_VBZ the_DT average_JJ payoff_NN ˆµt_NN ,_, a_DT of_IN each_DT arm_NN a._NN Then_RB ,_, with_IN probability_NN 1_CD −_FW ǫ_FW ,_, it_PRP chooses_VBZ
model_NN ,_, the_DT predictive_JJ variance_NN of_IN the_DT expected_VBN payoff_NN x_NN ⊤_CD t_NN ,_, aθ_FW ∗_FW a_DT is_VBZ evaluated_VBN as_IN x_NN ⊤_CD t_NN ,_, aA_NN −_NN 1_CD a_DT xt_NN ,_, a_DT ,_, and_CC then_RB q_CD x_CC ⊤_CD t_NN ,_, aA_NN −_NN 1_CD a_DT xt_NN ,_, a_DT becomes_VBZ the_DT standard_JJ deviation_NN ._.
Furthermore_RB ,_, in_IN information_NN theory_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT differential_JJ entropy_NN of_IN p_NN -LRB-_-LRB- θa_NN -RRB-_-RRB- is_VBZ defined_VBN as_IN −_NN 1_CD 2_CD ln_NN -LRB-_-LRB- -LRB-_-LRB- 2π_NN -RRB-_-RRB- d_FW detAa_FW -RRB-_-RRB- ._.
The_DT entropy_NN of_IN p_NN -LRB-_-LRB- θa_NN -RRB-_-RRB- when_WRB updated_VBN by_IN the_DT inclusion_NN of_IN the_DT new_JJ point_NN xt_NN ,_, a_DT then_RB becomes_VBZ −_CD 1_CD 2_CD ln_NN -LRB-_-LRB- -LRB-_-LRB- 2π_NN -RRB-_-RRB- d_NN det_NN -LRB-_-LRB- Aa_NN +_CC xt_NN ,_, ax_NN ⊤_CD t_NN ,_, a_DT -RRB-_-RRB- -RRB-_-RRB- ._.
T_NN
clear_JJ how_WRB to_TO evaluate_VB π_NN based_VBN only_RB on_IN such_JJ logged_VBN data_NNS ._.
This_DT evaluation_NN problem_NN may_MD be_VB viewed_VBN as_IN a_DT special_JJ case_NN of_IN the_DT so-called_JJ ``_`` off-policy_NN evaluation_NN problem_NN ''_'' in_IN reinforcement_NN learning_NN -LRB-_-LRB- see_VB ,_, c.f._FW ,_, =_JJ -_: =[_NN 23_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
One_CD solution_NN is_VBZ to_TO build_VB a_DT simulator_NN to_TO model_VB the_DT bandit_NN process_NN from_IN the_DT logged_VBN data_NNS ,_, and_CC then_RB evaluate_VB π_NN with_IN the_DT simulator_NN ._.
However_RB ,_, the_DT modeling_NN step_NN will_MD introduce_VB bias_NN in_IN the_DT simulator_NN and_CC so_RB
s_NN features_NNS ,_, Auer_NN -LRB-_-LRB- 6_CD -RRB-_-RRB- describes_VBZ the_DT LinRel_NNP algorithm_NN that_WDT is_VBZ essentially_RB a_DT UCB-type_JJ approach_NN and_CC shows_VBZ that_IN one_CD of_IN its_PRP$ variants_NNS has_VBZ a_DT regret_NN of_IN Õ_NN -LRB-_-LRB- √_CD T_NN -RRB-_-RRB- ,_, a_DT significant_JJ improvement_NN over_IN earlier_JJR algorithms_NNS =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Finally_RB ,_, we_PRP note_VBP that_IN there_EX exist_VBP another_DT class_NN of_IN bandit_NN algorithms_NNS based_VBN on_IN Bayes_NNP rule_NN ,_, such_JJ as_IN Gittins_NNP index_NN methods_NNS -LRB-_-LRB- 15_CD -RRB-_-RRB- ._.
With_IN appropriately_RB defined_VBN prior_JJ distributions_NNS ,_, Bayesian_JJ approaches_NNS may_MD
ing_NN traffic_NN ._.
This_DT strategy_NN ,_, with_IN random_JJ exploration_NN on_IN an_DT ǫ_NN fraction_NN of_IN the_DT traffic_NN and_CC greedy_JJ exploitation_NN on_IN the_DT rest_NN ,_, is_VBZ known_VBN as_IN ǫ-greedy_NN ._.
Advanced_NNP exploration_NN approaches_NNS such_JJ as_IN EXP3_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- or_CC UCB1_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: could_MD be_VB applied_VBN as_RB well_RB ._.
Intuitively_RB ,_, we_PRP need_VBP to_TO distribute_VB more_JJR traffic_NN to_TO new_JJ content_NN to_TO learn_VB its_PRP$ value_NN more_RBR quickly_RB ,_, and_CC fewer_JJR users_NNS to_TO track_VB temporal_JJ changes_NNS of_IN existing_VBG content_NN ._.
Recently_RB ,_, pers_NNS
ing_NN helps_VBZ to_TO identify_VB new_JJ items_NNS which_WDT well_RB match_VBP anexisting_VBG user_NN 's_POS consumption_NN profile_NN ,_, but_CC the_DT recommended_VBN items_NNS are_VBP always_RB similar_JJ to_TO the_DT items_NNS previously_RB taken_VBN by_IN the_DT user_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
Hybrid_NN approaches_VBZ =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP been_VBN developed_VBN by_IN combining_VBG two_CD or_CC more_JJR recommendation_NN techniques_NNS ;_: for_IN example_NN ,_, the_DT inability_NN of_IN collaborative_JJ filtering_VBG to_TO recommend_VB new_JJ items_NNS is_VBZ commonly_RB alleviated_VBN by_IN combining_VBG it_PRP with_IN conten_NN
arity_NN changing_VBG over_IN time_NN as_RB well_RB ._.
Furthermore_RB ,_, a_DT significant_JJ number_NN of_IN visitors_NNS are_VBP likely_JJ to_TO be_VB entirely_RB new_JJ with_IN no_DT historical_JJ consumption_NN record_NN whatsoever_RB ;_: this_DT is_VBZ known_VBN as_IN a_DT cold-start_JJ situation_NN =_JJ -_: =[_NN 21_CD -RRB-_-RRB- -_: =_SYM -_: ._.
These_DT issues_NNS make_VBP traditional_JJ recommender-system_JJ approaches_NNS difficult_JJ to_TO apply_VB ,_, as_IN shown_VBN by_IN prior_JJ empirical_JJ studies_NNS -LRB-_-LRB- 12_CD -RRB-_-RRB- ._.
It_PRP thus_RB becomes_VBZ indispensable_JJ to_TO learn_VB the_DT goodness_NN of_IN match_NN between_IN user_NN in_IN
A._NN ACM_NNP 978-1-60558-799-8_CD \/_: 10\/04_CD ._.
service_NN vendors_NNS acquire_VBP and_CC maintain_VBP a_DT large_JJ amount_NN of_IN content_NN in_IN their_PRP$ repository_NN ,_, for_IN instance_NN ,_, for_IN filtering_VBG news_NN articles_NNS -LRB-_-LRB- 14_CD -RRB-_-RRB- or_CC for_IN the_DT display_NN of_IN advertisements_NNS =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Moreover_RB ,_, the_DT content_NN of_IN such_PDT a_DT web-service_JJ repository_NN changes_NNS dynamically_RB ,_, undergoing_VBG frequent_JJ insertions_NNS and_CC deletions_NNS ._.
In_IN such_PDT a_DT setting_NN ,_, it_PRP is_VBZ crucial_JJ to_TO quickly_RB identify_VB interesting_JJ content_NN for_IN
s_NN has_VBZ a_DT regret_NN of_IN Õ_NN -LRB-_-LRB- √_CD T_NN -RRB-_-RRB- ,_, a_DT significant_JJ improvement_NN over_IN earlier_JJR algorithms_NNS -LRB-_-LRB- 1_LS -RRB-_-RRB- ._.
Finally_RB ,_, we_PRP note_VBP that_IN there_EX exist_VBP another_DT class_NN of_IN bandit_NN algorithms_NNS based_VBN on_IN Bayes_NNP rule_NN ,_, such_JJ as_IN Gittins_NNP index_NN methods_NNS =_JJ -_: =[_NN 15_CD -RRB-_-RRB- -_: =_SYM -_: ._.
With_IN appropriately_RB defined_VBN prior_JJ distributions_NNS ,_, Bayesian_JJ approaches_NNS may_MD have_VB good_JJ performance_NN ._.
These_DT methods_NNS require_VBP extensive_JJ offline_JJ engineering_NN to_TO obtain_VB good_JJ prior_JJ models_NNS ,_, and_CC are_VBP often_RB computat_JJ
n_NN the_DT remaining_VBG traffic_NN ._.
This_DT strategy_NN ,_, with_IN random_JJ exploration_NN on_IN an_DT ǫ_NN fraction_NN of_IN the_DT traffic_NN and_CC greedy_JJ exploitation_NN on_IN the_DT rest_NN ,_, is_VBZ known_VBN as_IN ǫ-greedy_NN ._.
Advanced_NNP exploration_NN approaches_NNS such_JJ as_IN EXP3_NN =_JJ -_: =[_NN 8_CD -RRB-_-RRB- -_: =_JJ -_: or_CC UCB1_NN -LRB-_-LRB- 7_CD -RRB-_-RRB- could_MD be_VB applied_VBN as_RB well_RB ._.
Intuitively_RB ,_, we_PRP need_VBP to_TO distribute_VB more_JJR traffic_NN to_TO new_JJ content_NN to_TO learn_VB its_PRP$ value_NN more_RBR quickly_RB ,_, and_CC fewer_JJR users_NNS to_TO track_VB temporal_JJ changes_NNS of_IN existing_VBG content_NN ._.
Re_NNP
ret_NN ,_, RA_NN -LRB-_-LRB- T_NN -RRB-_-RRB- \/_: T_NN ,_, converges_VBZ to_TO 0_CD with_IN probability_NN 1_CD ._.
In_IN contrast_NN to_TO the_DT unguided_JJ exploration_NN strategy_NN adopted_VBN by_IN ǫgreedy_NN ,_, another_DT class_NN of_IN algorithms_NNS generally_RB known_VBN as_IN upper_JJ confidence_NN bound_VBD algorithms_NNS =_JJ -_: =[_NN 4_CD ,_, 7_CD ,_, 17_CD -RRB-_-RRB- -_: =_SYM -_: use_VB a_DT smarter_RBR way_NN to_TO balance_VB exploration_NN and_CC exploitation_NN ._.
Specifically_RB ,_, in_IN trial_NN t_NN ,_, these_DT algorithms_NNS estimate_VBP both_CC the_DT mean_JJ payoff_NN ˆµt_NN ,_, a_DT of_IN each_DT arm_NN a_DT as_RB well_RB as_IN a_DT corresponding_JJ confidence_NN interval_NN
er_IN a_DT purely_RB exploring_VBG nor_CC a_DT purely_RB exploiting_VBG algorithm_NN works_VBZ best_JJS in_IN general_JJ ,_, and_CC a_DT good_JJ tradeoff_NN is_VBZ needed_VBN ._.
The_DT context-free_JJ K-armed_JJ bandit_NN problem_NN has_VBZ been_VBN studied_VBN by_IN statisticians_NNS for_IN a_DT long_JJ time_NN =_JJ -_: =[_NN 9_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT simplest_JJS and_CC most_JJS straightforward_JJ algorithms_NNS is_VBZ ǫ-greedy_NN ._.
In_IN each_DT trial_NN t_NN ,_, this_DT algorithm_NN first_RB estimates_VBZ the_DT average_JJ payoff_NN ˆµt_NN ,_, a_DT of_IN each_DT arm_NN a._NN Then_RB ,_, with_IN probability_NN 1_CD −_FW ǫ_FW ,_, it_PRP chooses_VBZ
s_NN of_IN existing_VBG content_NN ._.
Recently_RB ,_, personalized_JJ recommendation_NN has_VBZ become_VBN a_DT desirable_JJ feature_NN for_IN websites_NNS to_TO improve_VB user_NN satisfaction_NN by_IN tailoring_VBG content_NN presentation_NN to_TO suit_VB individual_JJ users_NNS '_POS needs_NNS =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Personalization_NN involves_VBZ a_DT process_NN of_IN gathering_VBG and_CC storing_VBG user_NN attributes_NNS ,_, managing_VBG content_NN assets_NNS ,_, and_CC ,_, based_VBN on_IN an_DT analysis_NN of_IN current_JJ and_CC past_JJ users_NNS '_POS behavior_NN ,_, delivering_VBG the_DT individually_RB best_JJS
l_NN 26_CD --_: 30_CD ,_, 2010_CD ,_, Raleigh_NNP ,_, North_NNP Carolina_NNP ,_, USA_NNP ._.
ACM_NN 978-1-60558-799-8_CD \/_: 10\/04_CD ._.
service_NN vendors_NNS acquire_VBP and_CC maintain_VBP a_DT large_JJ amount_NN of_IN content_NN in_IN their_PRP$ repository_NN ,_, for_IN instance_NN ,_, for_IN filtering_VBG news_NN articles_NNS =_JJ -_: =[_NN 14_CD -RRB-_-RRB- -_: =_JJ -_: or_CC for_IN the_DT display_NN of_IN advertisements_NNS -LRB-_-LRB- 5_CD -RRB-_-RRB- ._.
Moreover_RB ,_, the_DT content_NN of_IN such_PDT a_DT web-service_JJ repository_NN changes_NNS dynamically_RB ,_, undergoing_VBG frequent_JJ insertions_NNS and_CC deletions_NNS ._.
In_IN such_PDT a_DT setting_NN ,_, it_PRP is_VBZ crucial_JJ to_TO
er_IN a_DT purely_RB exploring_VBG nor_CC a_DT purely_RB exploiting_VBG algorithm_NN works_VBZ best_JJS in_IN general_JJ ,_, and_CC a_DT good_JJ tradeoff_NN is_VBZ needed_VBN ._.
The_DT context-free_JJ K-armed_JJ bandit_NN problem_NN has_VBZ been_VBN studied_VBN by_IN statisticians_NNS for_IN a_DT long_JJ time_NN =_JJ -_: =[_NN 9_CD ,_, 24_CD ,_, 26_CD -RRB-_-RRB- -_: =_SYM -_: ._.
One_CD of_IN the_DT simplest_JJS and_CC most_JJS straightforward_JJ algorithms_NNS is_VBZ ǫ-greedy_NN ._.
In_IN each_DT trial_NN t_NN ,_, this_DT algorithm_NN first_RB estimates_VBZ the_DT average_JJ payoff_NN ˆµt_NN ,_, a_DT of_IN each_DT arm_NN a._NN Then_RB ,_, with_IN probability_NN 1_CD −_FW ǫ_FW ,_, it_PRP chooses_VBZ
2.1_CD A_DT Multi-armed_JJ Bandit_NN Formulation_NNP The_DT problem_NN of_IN personalized_JJ news_NN article_NN recommendation_NN can_MD be_VB naturally_RB modeled_VBN as_IN a_DT multi-armed_JJ bandit_NN problem_NN with_IN context_NN information_NN ._.
Following_VBG previous_JJ work_NN =_JJ -_: =[_NN 18_CD -RRB-_-RRB- -_: =_JJ -_: ,_, we_PRP call_VBP it_PRP a_DT contextual_JJ bandit_NN ._.
1_CD Formally_RB ,_, a_DT contextual-bandit_JJ algorithm_NN A_NN proceeds_VBZ in_IN discrete_JJ trials_NNS t_NN =_JJ 1_CD ,_, 2,3_CD ,_, ..._: In_IN trial_NN t_NN :_: 1_CD ._.
The_DT algorithm_NN observes_VBZ the_DT current_JJ user_NN ut_NN and_CC a_DT set_NN At_IN of_IN ar_NN
pool_NN is_VBZ large_JJ ._.
In_IN the_DT future_NN ,_, we_PRP plan_VBP to_TO investigate_VB bandit_NN approaches_NNS to_TO other_JJ similar_JJ web-based_JJ serviced_VBN such_JJ as_IN online_NN advertising_NN ,_, and_CC compare_VB our_PRP$ algorithms_NNS to_TO related_JJ methods_NNS such_JJ as_IN Banditron_NN =_JJ -_: =[_NN 16_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT second_JJ direction_NN is_VBZ to_TO extend_VB the_DT bandit_NN formulation_NN and_CC algorithms_NNS in_IN which_WDT an_DT ``_`` arm_NN ''_'' may_MD refer_VB to_TO a_DT complex_JJ object_NN rather_RB than_IN an_DT item_NN -LRB-_-LRB- like_IN an_DT article_NN -RRB-_-RRB- ._.
An_DT example_NN is_VBZ ranking_JJ ,_, where_WRB an_DT arm_NN corre_NN
lely_RB on_IN content_NN information_NN ._.
In_IN practice_NN ,_, we_PRP usually_RB explore_VBP the_DT unknown_NN by_IN collecting_VBG consumers_NNS '_POS feedback_NN in_IN real_JJ time_NN to_TO evaluate_VB the_DT popularity_NN of_IN new_JJ content_NN while_IN monitoring_VBG changes_NNS in_IN its_PRP$ value_NN =_JJ -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
For_IN instance_NN ,_, a_DT small_JJ amount_NN of_IN traffic_NN can_MD be_VB designated_VBN for_IN such_JJ exploration_NN ._.
Based_VBN on_IN the_DT users_NNS '_POS response_NN -LRB-_-LRB- such_JJ as_IN clicks_NNS -RRB-_-RRB- to_TO randomly_RB selected_VBN content_NN on_IN this_DT small_JJ slice_NN of_IN traffic_NN ,_, the_DT most_JJS po_NN
imate_NN of_IN the_DT coefficients_NNS :_: ˆθa_NN =_JJ -LRB-_-LRB- D_NN ⊤_CD a_DT Da_NN +_CC Id_NN -RRB-_-RRB- −_NN 1_CD D_NN ⊤_NN a_DT ca_MD ,_, -LRB-_-LRB- 3_CD -RRB-_-RRB- where_WRB Id_NN is_VBZ the_DT d_FW ×_FW d_FW identity_NN matrix_NN ._.
When_WRB components_NNS in_IN ca_MD are_VB independent_JJ conditioned_VBN on_IN corresponding_JJ rows_NNS in_IN Da_NN ,_, it_PRP can_MD be_VB shown_VBN =_JJ -_: =[_NN 27_CD -RRB-_-RRB- -_: =_SYM -_: that_IN ,_, with_IN probability_NN at_IN least_JJS 1_CD −_FW δ_FW ,_, ˛_FW ˛x_FW ⊤_FW t_NN ,_, a_DT ˆ_FW q_FW θa_FW −_FW E_NN -LRB-_-LRB- rt_NN ,_, a_DT |_FW xt_FW ,_, a_DT -RRB-_-RRB- ˛_FW ≤_FW α_FW x_NN ⊤_CD t_NN ,_, a_DT -LRB-_-LRB- D_NNP ⊤_NNP a_DT Da_NN +_CC Id_NN -RRB-_-RRB- −_FW 1xt_FW ,_, a_DT -LRB-_-LRB- 4_CD -RRB-_-RRB- for_IN any_DT δ_NN -RRB-_-RRB- 0_CD and_CC xt_NN ,_, a_DT ∈_NN R_NN d_NN ,_, where_WRB α_NN =_JJ 1_CD +_CC p_NN ln_NN -LRB-_-LRB- 2_CD \/_: δ_NN -RRB-_-RRB- \/_: 2_CD is_VBZ a_DT constant_NN ._.
In_IN other_JJ words_NNS ,_, t_NN
es_NNS may_MD have_VB good_JJ performance_NN ._.
These_DT methods_NNS require_VBP extensive_JJ offline_JJ engineering_NN to_TO obtain_VB good_JJ prior_JJ models_NNS ,_, and_CC are_VBP often_RB computationally_RB prohibitive_JJ without_IN coupling_NN with_IN approximation_NN techniques_NNS =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: ._.
3_LS ._.
ALGORITHM_NN Given_IN asymptotic_JJ optimality_NN and_CC the_DT strong_JJ regret_NN bound_VBD of_IN UCB_NNP methods_NNS for_IN context-free_JJ bandit_NN algorithms_NNS ,_, it_PRP is_VBZ tempting_JJ to_TO devise_VB similar_JJ algorithms_NNS for_IN contextual_JJ bandit_NN problems_NNS ._.
Gi_NN
orical_JJ consumption_NN record_NN whatsoever_RB ;_: this_DT is_VBZ known_VBN as_IN a_DT cold-start_JJ situation_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ._.
These_DT issues_NNS make_VBP traditional_JJ recommender-system_JJ approaches_NNS difficult_JJ to_TO apply_VB ,_, as_IN shown_VBN by_IN prior_JJ empirical_JJ studies_NNS =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: ._.
It_PRP thus_RB becomes_VBZ indispensable_JJ to_TO learn_VB the_DT goodness_NN of_IN match_NN between_IN user_NN interests_NNS and_CC content_NN when_WRB one_CD or_CC both_DT of_IN them_PRP are_VBP new_JJ ._.
However_RB ,_, acquiring_VBG such_JJ information_NN can_MD be_VB expensive_JJ and_CC may_MD reduce_VB
nd_NN capture_NN nonlinearity_NN in_IN these_DT raw_JJ features_NNS ,_, we_PRP carried_VBD out_RP conjoint_NN analysis_NN based_VBN on_IN random_JJ exploration_NN data_NNS collected_VBN in_IN September_NNP 2008_CD ._.
Following_VBG a_DT previous_JJ approach_NN to_TO dimensionality_NN reduction_NN =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: ,_, we_PRP projected_VBD user_NN features_NNS onto_IN article_NN categories_NNS and_CC then_RB clustered_VBD users_NNS with_IN similar_JJ preferences_NNS into_IN groups_NNS ._.
More_RBR specifically_RB :_: •_VB We_PRP first_RB used_VBD logistic_JJ regression_NN -LRB-_-LRB- LR_NN -RRB-_-RRB- to_TO fit_VB a_DT bilinear_JJ model_NN
t_NN ,_, at_IN 14_CD :_: end_NN for_IN Finally_RB ,_, we_PRP note_VBP that_IN ,_, under_IN the_DT assumption_NN that_IN input_NN features_NNS xt_VBP ,_, a_DT were_VBD drawn_VBN i.i.d._RB from_IN a_DT normal_JJ distribution_NN -LRB-_-LRB- in_IN addition_NN to_TO the_DT modeling_NN assumption_NN in_IN Eq_NN ._.
-LRB-_-LRB- 2_LS -RRB-_-RRB- -RRB-_-RRB- ,_, Pavlidis_FW et_FW al._FW =_SYM -_: =[_NN 22_CD -RRB-_-RRB- -_: =_SYM -_: came_VBD up_RP with_IN a_DT similar_JJ algorithm_NN that_WDT uses_VBZ a_DT least-squares_JJ solution_NN ˜_FW θa_FW instead_RB of_IN our_PRP$ ridge-regression_NN solution_NN -LRB-_-LRB- ˆ_FW θa_FW in_IN Eq_NN ._.
-LRB-_-LRB- 3_LS -RRB-_-RRB- -RRB-_-RRB- to_TO compute_VB the_DT UCB_NNP ._.
However_RB ,_, our_PRP$ approach_NN -LRB-_-LRB- and_CC theoretical_JJ analysi_NNS
