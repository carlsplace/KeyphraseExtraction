Recognizing_VBG and_CC Interpreting_VBG Gestures_NNS on_IN a_DT Mobile_NNP Robot_NNP Gesture_NNP recognition_NN is_VBZ an_DT important_JJ skill_NN for_IN robots_NNS that_WDT work_VBP closely_RB with_IN humans_NNS ._.
Gestures_NNS help_VBP to_TO clarify_VB spoken_VBN commands_NNS and_CC are_VBP a_DT compact_JJ means_NN of_IN relaying_VBG geometric_JJ information_NN ._.
We_PRP have_VBP developed_VBN a_DT real-time_JJ ,_, three-dimensional_JJ gesture_NN recognition_NN system_NN that_WDT resides_VBZ on-board_JJ a_DT mobile_JJ robot_NN ._.
Using_VBG a_DT coarse_JJ three-dimensional_JJ model_NN of_IN a_DT human_JJ to_TO guide_VB stereo_JJ measurements_NNS of_IN body_NN parts_NNS ,_, the_DT system_NN is_VBZ capable_JJ of_IN recognizing_VBG six_CD distinct_JJ gestures_NNS made_VBN by_IN an_DT unadorned_JJ human_NN in_IN an_DT unaltered_JJ environment_NN ._.
An_DT active_JJ vision_NN approach_NN focuses_VBZ the_DT vision_NN system_NN 's_POS attention_NN on_IN small_JJ ,_, moving_VBG areas_NNS of_IN space_NN to_TO allow_VB for_IN frame_NN rate_NN processing_NN even_RB when_WRB the_DT person_NN and\/or_CC the_DT robot_NN are_VBP moving_VBG ._.
This_DT paper_NN describes_VBZ the_DT gesture_NN recognition_NN system_NN ,_, including_VBG the_DT coarse_JJ model_NN and_CC the_DT active_JJ vision_NN approach_NN ._.
This_DT paper_NN also_RB describes_VBZ how_WRB the_DT gesture_NN recognition_NN system_NN is_VBZ integrated_VBN with_IN an_DT intelligent_JJ control_NN architecture_NN to_TO allow_VB for_IN complex_JJ gesture_NN interpretation_NN and_CC complex_JJ robot_NN action_NN ._.
Results_NNS from_IN e._NNP ._. ._.
