Learning_NNP Planning_NNP Operators_NNP in_IN Real-World_NNP ,_, Partially_RB Observable_JJ Environments_NNS We_PRP are_VBP interested_JJ in_IN the_DT development_NN of_IN activities_NNS in_IN situated_VBN ,_, embodied_VBN agents_NNS such_JJ as_IN mobile_JJ robots_NNS ._.
Central_JJ to_TO our_PRP$ theory_NN of_IN development_NN is_VBZ means-ends_JJ analysis_NN planning_NN ,_, and_CC as_IN such_JJ ,_, we_PRP must_MD rely_VB on_IN operator_NN models_NNS that_WDT can_MD express_VB the_DT eects_NNS of_IN a_DT robot_NN 's_POS action_NN in_IN a_DT dynamic_JJ ,_, partially-observable_JJ environment_NN ._.
This_DT paper_NN presents_VBZ a_DT two-step_JJ process_NN which_WDT employs_VBZ clustering_NN and_CC decision_NN tree_NN induction_NN to_TO perform_VB unsupervised_JJ learning_NN of_IN operator_NN models_NNS from_IN simple_JJ interactions_NNS between_IN an_DT agent_NN and_CC its_PRP$ environment_NN ._.
We_PRP report_VBP our_PRP$ ndings_NNS with_IN an_DT implementation_NN of_IN this_DT system_NN on_IN a_DT Pioneer-1_NN mobile_JJ robot_NN ._.
