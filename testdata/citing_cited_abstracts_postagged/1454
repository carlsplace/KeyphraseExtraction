Planning_NNP and_CC acting_VBG in_IN partially_RB observable_JJ stochastic_JJ domains_NNS In_IN this_DT paper_NN ,_, we_PRP bring_VBP techniques_NNS from_IN operations_NNS research_NN to_TO bear_VB on_IN the_DT problem_NN of_IN choosing_VBG optimal_JJ actions_NNS in_IN partially_RB observable_JJ stochastic_JJ domains_NNS ._.
We_PRP begin_VBP by_IN introducing_VBG the_DT theory_NN of_IN Markov_NNP decision_NN processes_NNS -LRB-_-LRB- mdps_NNS -RRB-_-RRB- and_CC partially_RB observable_JJ mdps_NNS -LRB-_-LRB- pomdps_NNS -RRB-_-RRB- ._.
We_PRP then_RB outline_VBP a_DT novel_JJ algorithm_NN for_IN solving_VBG pomdps_NNS offline_VB and_CC show_VB how_WRB ,_, in_IN some_DT cases_NNS ,_, a_DT finite-memory_JJ controller_NN can_MD be_VB extracted_VBN from_IN the_DT solution_NN to_TO a_DT pomdp_NN ._.
We_PRP conclude_VBP with_IN a_DT discussion_NN of_IN how_WRB our_PRP$ approach_NN relates_VBZ to_TO previous_JJ work_NN ,_, the_DT complexity_NN of_IN finding_VBG exact_JJ solutions_NNS to_TO pomdps_NNS ,_, and_CC of_IN some_DT possibilities_NNS for_IN finding_VBG approximate_JJ solutions_NNS ._.
