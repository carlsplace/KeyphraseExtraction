Information_NNP Geometry_NNP of_IN the_DT EM_NNP and_CC em_NNP Algorithms_NNP for_IN Neural_NNP Networks_NNP In_IN order_NN to_TO realize_VB an_DT input-output_JJ relation_NN given_VBN by_IN noise-contaminated_JJ examples_NNS ,_, it_PRP is_VBZ effective_JJ to_TO use_VB a_DT stochastic_JJ model_NN of_IN neural_JJ networks_NNS ._.
A_DT model_NN network_NN includes_VBZ hidden_JJ units_NNS whose_WP$ activation_NN values_NNS are_VBP not_RB specified_VBN nor_CC observed_VBN ._.
It_PRP is_VBZ useful_JJ to_TO estimate_VB the_DT hidden_JJ variables_NNS from_IN the_DT observed_VBN or_CC specified_VBN input-output_JJ data_NNS based_VBN on_IN the_DT stochastic_JJ model_NN ._.
Two_CD algorithms_NNS ,_, the_DT EM_NN -_: and_CC em-algorithms_NNS ,_, have_VBP so_RB far_RB been_VBN proposed_VBN for_IN this_DT purpose_NN ._.
The_DT EM-algorithm_NN is_VBZ an_DT iterative_JJ statistical_JJ technique_NN of_IN using_VBG the_DT conditional_JJ expectation_NN ,_, and_CC the_DT em-algorithm_NN is_VBZ a_DT geometrical_JJ one_CD given_VBN by_IN information_NN geometry_NN ._.
The_DT em-algorithm_NN minimizes_VBZ iteratively_RB the_DT Kullback-Leibler_NNP divergence_NN in_IN the_DT manifold_NN of_IN neural_JJ networks_NNS ._.
These_DT two_CD algorithms_NNS are_VBP equivalent_JJ in_IN most_JJS cases_NNS ._.
The_DT present_JJ paper_NN gives_VBZ a_DT unified_JJ information_NN geometrical_JJ framework_NN for_IN studying_VBG stochastic_JJ models_NNS of_IN neural_JJ networks_NNS ,_, by_IN forcussing_VBG on_IN the_DT EM_NN and_CC em_NN algorithms_NNS ,_, and_CC proves_VBZ a_DT condition_NN which_WDT guarantees_VBZ their_PRP$ equ_NN ..._:
