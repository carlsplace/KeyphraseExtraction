Reinforcement_NN learning_NN :_: a_DT survey_NN This_DT paper_NN surveys_VBZ the_DT field_NN of_IN reinforcement_NN learning_VBG from_IN a_DT computer-science_JJ perspective_NN ._.
It_PRP is_VBZ written_VBN to_TO be_VB accessible_JJ to_TO researchers_NNS familiar_JJ with_IN machine_NN learning_NN ._.
Both_CC the_DT historical_JJ basis_NN of_IN the_DT field_NN and_CC a_DT broad_JJ selection_NN of_IN current_JJ work_NN are_VBP summarized_VBN ._.
Reinforcement_NN learning_NN is_VBZ the_DT problem_NN faced_VBN by_IN an_DT agent_NN that_WDT learns_VBZ behavior_NN through_IN trial-and-error_JJ interactions_NNS with_IN a_DT dynamic_JJ environment_NN ._.
The_DT work_NN described_VBN here_RB has_VBZ a_DT resemblance_NN to_TO work_VB in_IN psychology_NN ,_, but_CC differs_VBZ considerably_RB in_IN the_DT details_NNS and_CC in_IN the_DT use_NN of_IN the_DT word_NN ``_`` reinforcement_NN ._. ''_''
The_DT paper_NN discusses_VBZ central_JJ issues_NNS of_IN reinforcement_NN learning_NN ,_, including_VBG trading_NN off_IN exploration_NN and_CC exploitation_NN ,_, establishing_VBG the_DT foundations_NNS of_IN the_DT field_NN via_IN Markov_NNP decision_NN theory_NN ,_, learning_VBG from_IN delayed_VBN reinforcement_NN ,_, constructing_VBG empirical_JJ models_NNS to_TO accelerate_VB learning_NN ,_, making_VBG use_NN of_IN generalization_NN and_CC hierarchy_NN ,_, and_CC coping_VBG with_IN hidden_JJ state_NN ._.
It_PRP concludes_VBZ with_IN a_DT survey_NN of_IN some_DT implemented_VBN systems_NNS and_CC an_DT assessment_NN of_IN the_DT practical_JJ utility_NN of_IN current_JJ methods_NNS for_IN reinforcement_NN learning_NN ._.
