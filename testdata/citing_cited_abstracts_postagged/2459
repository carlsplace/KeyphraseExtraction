On_IN the_DT Optimality_NN of_IN the_DT Simple_JJ Bayesian_NNP Classifier_NNP under_IN Zero-One_NNP Loss_NN The_DT simple_JJ Bayesian_JJ classifier_NN is_VBZ known_VBN to_TO be_VB optimal_JJ when_WRB attributes_NNS are_VBP independent_JJ given_VBN the_DT class_NN ,_, but_CC the_DT question_NN of_IN whether_IN other_JJ sufficient_JJ conditions_NNS for_IN its_PRP$ optimality_NN exist_VBP has_VBZ so_RB far_RB not_RB been_VBN explored_VBN ._.
Empirical_JJ results_NNS showing_VBG that_IN it_PRP performs_VBZ surprisingly_RB well_RB in_IN many_JJ domains_NNS containing_VBG clear_JJ attribute_NN dependences_NNS suggest_VBP that_IN the_DT answer_NN to_TO this_DT question_NN may_MD be_VB positive_JJ ._.
This_DT article_NN shows_VBZ that_IN ,_, although_IN the_DT Bayesian_JJ classifier_NN 's_POS probability_NN estimates_NNS are_VBP only_RB optimal_JJ under_IN quadratic_JJ loss_NN if_IN the_DT independence_NN assumption_NN holds_VBZ ,_, the_DT classifier_NN itself_PRP can_MD be_VB optimal_JJ under_IN zero-one_JJ loss_NN -LRB-_-LRB- misclassification_NN rate_NN -RRB-_-RRB- even_RB when_WRB this_DT assumption_NN is_VBZ violated_VBN by_IN a_DT wide_JJ margin_NN ._.
The_DT region_NN of_IN quadratic-loss_JJ optimality_NN of_IN the_DT Bayesian_JJ classifier_NN is_VBZ in_IN fact_NN a_DT second-order_JJ infinitesimal_JJ fraction_NN of_IN the_DT region_NN of_IN zero-one_JJ optimality_NN ._.
This_DT implies_VBZ that_IN the_DT Bayesian_JJ classifier_NN has_VBZ a_DT much_RB greater_JJR range_NN of_IN applicability_NN than_IN previously_RB thought_VBN ._.
For_IN example_NN ,_, in_IN this_DT article_NN it_PRP is_VBZ shown_VBN to_TO be_VB opti_NNS ..._:
