Integrating Natural Language and Gesture in a Robotics Domain Human-computer interfaces facilitate communication, assist in the exchange of information, process commands and controls, among many additional interactions. For our work in the robotics domain, we have concentrated on integrating spoken natural language and natural gesture for command and control of a semiautonomous mobile robot. We have assumed that both spoken natural language and natural gesture are more user-friendly means of interacting with a mobile robot, and from the human standpoint, such interactions are easier, given that the human is not required to learn additional interactions, but can rely on "natural" ways of communication. So-called "synthetic" methods, such as data gloves, require additional learning; however, this is not the case with natural language and natural gesture. We, therefore, rely on what is natural to both spoken language when it is used in conjunction with natural gestures for giving commands. Furthermore, we have been integrating these interactions wit...
