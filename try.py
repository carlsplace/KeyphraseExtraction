# -*- coding: utf-8 -*-
import re
import numpy as np
import itertools
from nltk.stem import SnowballStemmer
import nltk

def normalized_token(token):
    """
    Use stemmer to normalize the token.
    建图时调用该函数，而不是在file_text改变词形的存储
    """
    stemmer = SnowballStemmer("english") 
    return stemmer.stem(token.lower())

pi = [-0.012235799744845122, -0.004245795180621603, 0.007372788621222069, -0.0009504796766208166, -0.005521525996204158, -0.010217620075429023, -0.010679940208527411, -0.005937409876446051, -0.00021783922125878844, -0.001797234919907821, 0.14987478370778992, 0.0024231089928797443, 0.04073384526523308, -0.005937248405155814, -0.005922818107950073, -0.007223230664025547, -0.009713093900457501, -0.0009038416419072496, -0.006385742970002272, 0.007982505551069405, -0.0027558400188683707, -0.006356477862850248, 0.008815749805116027, 0.03200223876282581, 0.0009661907927502049, 0.026273238140023324, 0.5556911836098077, 0.019764067972469296, -0.006127017726074037, -0.006390086865997919, -0.003957644207977386, 0.01504903122552319, -0.00187267970168219, -0.00550759343135329, 0.05066267482501555, -0.00914037968287834, -0.004986359243522422, -0.0062533283914012645, -0.005393500681527986, -0.008515204871401113, -0.011840940180900528, 0.03147949141656355, -0.005609807213737546, 0.0033696676374696034, -0.002355392379870448, -0.004819366110725174, -0.005903002209112692, 0.02986514229168213, -0.011028612524226452, -0.005042537699897745, 0.13313626089359756, 0.010548115577013835, -0.007578905540603058, 0.0007525612657348471, 0.02746607810318204, 0.01836409412373126, 0.0004162161456192242, -0.004705583709722142, 0.033634447282013466, 0.003202170630104859, -0.0001287255527316702, -0.007225875274946, -0.003884765931937908, -0.005559733014512354, -0.004288366348052079, -0.0066247729544346426, 0.03189646728186661]

node_list = ['analysi', 'irregular', 'slice', 'problem', 'parafac2', 'approach', 'result', 'clir', 'other', 'translat', 'three-way', 'similar', 'altern', 'separ', 'perform', 'matrix', 'valu', 'whole', 'sens', 'lsa', 'task', 'particular', 'space', 'parallel', 'multi-way', 'topic', 'goal', 'differ', 'novel', 'drawback', 'standard', 'general', 'corpus', 'singular', 'languag', 'queri', 'document', 'multilingu', 'decomposit', 'right', 'promis', 'cluster', 'retriev', 'constraint', 'practic', 'singl', 'purpos', 'array', 'relat', 'language-independ', 'inform', 'conjunct', 'semant', 'cross-languag', 'concept', 'parafac', 'same', 'term-by-docu', 'svd', 'success', 'latent', 'applic', 'vector', 'sever', 'variant', 'such', 'present']

def get_keywords(pi, node_list):
    pi_sort = sorted(pi, reverse=True)
    # print(pi)
    # print(pi_sort)
    # pi_sort = pi_sort[:len(pi_sort)//10]
    keywords = []
    for score in pi_sort:
        keywords.append(node_list[pi.index(score)])
    return keywords

keywords = get_keywords(pi, node_list)
# print(keywords)
gold = """information retrieval
latent semantic analysis
multilingual
parafac2
performance evaluation"""
gold = gold.split()
for g in gold:
    print(normalized_token(g))

print("""[('languag', 0.05566911200589633), ('document', 0.04373143021176666), ('parafac2', 0.04098921504392934), ('approach', 0.03821449146156701), ('lsa', 0.03631932502527303), ('constraint', 0.03185756496108311), ('multilingu', 0.026293300374074936), ('problem', 0.025323775569859586), ('svd', 0.025027842322863363), ('concept', 0.024108343151269137), ('parallel', 0.022726506804021544), ('sens', 0.022420364197694272), ('same', 0.020892709692094735), ('translat', 0.020672339201149505), ('matrix', 0.0201831480761956), ('purpos', 0.0198368003243204), ('topic', 0.018472769263686593), ('altern', 0.018299713785077013), ('cluster', 0.01752838368412969), ('result', 0.016845352232874502), ('whole', 0.016603723525200544), ('corpus', 0.016293287965267623), ('perform', 0.015726866442723326), ('standard', 0.015507802644573113), ('term-by-docu', 0.014773974514445041), ('cross-languag', 0.014159664723646291), ('vector', 0.013636447567445295), ('singular', 0.013558673930894856), ('slice', 0.012938373567789832), ('similar', 0.012769680108229903), ('applic', 0.012524221785530587), ('promis', 0.01243404744284933), ('variant', 0.012239317147842006), ('goal', 0.012151545771825898), ('parafac', 0.011524461490895132), ('clir', 0.01104610351685354), ('practic', 0.010627150638837124), ('singl', 0.010070875738788765), ('retriev', 0.010053945815296587), ('semant', 0.009914028430496167), ('present', 0.00979337138582579), ('drawback', 0.009641627981916007), ('separ', 0.009209915235259547), ('multi-way', 0.009071528417255184), ('array', 0.008943619835864974), ('sever', 0.008770990644311149), ('other', 0.008758153171327051), ('decomposit', 0.00836843378293064), ('task', 0.008155722021188838), ('space', 0.007958381732793927), ('irregular', 0.007856061293378767), ('inform', 0.007853644930793486), ('novel', 0.007552930110118261), ('three-way', 0.006926050955633192), ('relat', 0.006912090911407791), ('valu', 0.006898035603678243), ('conjunct', 0.006886553297805282), ('particular', 0.00676579486601135), ('general', 0.0065346033947043716), ('success', 0.006221620978213083), ('analysi', 0.006073249422705105), ('right', 0.0056594637311160705), ('such', 0.005608099960664227), ('differ', 0.005287513199477048), ('language-independ', 0.005188094795935576), ('queri', 0.005144814149818561), ('latent', 0.003992954031609227)]
""")